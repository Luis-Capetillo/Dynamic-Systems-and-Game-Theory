NE T W O R K S

This page intentionally left blank

Networks
An Introduction

M. E. J. Newman
University of Michigan
and
Santa Fe Institute

1

3

Great Clarendon Street, Oxford OX2 6DP
Oxford University Press is a department of the University of Oxford.
It furthers the University’s objective of excellence in research, scholarship,
and education by publishing worldwide in
Oxford New York
Auckland Cape Town Dar es Salaam Hong Kong Karachi
Kuala Lumpur Madrid Melbourne Mexico City Nairobi
New Delhi Shanghai Taipei Toronto
With ofﬁces in
Argentina Austria Brazil Chile Czech Republic France Greece
Guatemala Hungary Italy Japan Poland Portugal Singapore
South Korea Switzerland Thailand Turkey Ukraine Vietnam
Oxford is a registered trade mark of Oxford University Press
in the UK and in certain other countries
Published in the United States
by Oxford University Press Inc., New York
© M. E. J. Newman 2010
The moral rights of the author have been asserted
Database right Oxford University Press (maker)
First printed 2010
All rights reserved. No part of this publication may be reproduced,
stored in a retrieval system, or transmitted, in any form or by any means,
without the prior permission in writing of Oxford University Press,
or as expressly permitted by law, or under terms agreed with the appropriate
reprographics rights organization. Enquiries concerning reproduction
outside the scope of the above should be sent to the Rights Department,
Oxford University Press, at the address above
You must not circulate this book in any other binding or cover
and you must impose the same condition on any acquirer
British Library Cataloguing in Publication Data
Data available
Library of Congress Cataloging in Publication Data
Data available
Typeset by SPI Publisher Services, Pondicherry, India
Printed in Great Britain
on acid-free paper by
CPI Antony Rowe, Chippenham, Wiltshire
ISBN 978–0–19–920665–0 (Hbk.)
1 3 5 7 9 10 8 6 4 2

C ONTENTS
Preface

x

1 Introduction

1

I

15

The empirical study of networks

2 Technological networks
2.1
The Internet . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2
The telephone network . . . . . . . . . . . . . . . . . . . . . . .
2.3
Power grids . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4
Transportation networks . . . . . . . . . . . . . . . . . . . . . .
2.5
Delivery and distribution networks . . . . . . . . . . . . . . . .

17
18
28
31
32
33

3 Social networks
3.1
The empirical study of social networks . . . . . . . . . . . . . .
3.2
Interviews and questionnaires . . . . . . . . . . . . . . . . . . .
3.3
Direct observation . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4
Data from archival or third-party records . . . . . . . . . . . .
3.5
Afﬁliation networks . . . . . . . . . . . . . . . . . . . . . . . . .
3.6
The small-world experiment . . . . . . . . . . . . . . . . . . . .
3.7
Snowball sampling, contact tracing, and random walks . . . .

36
36
39
46
47
53
54
58

4 Networks of information
4.1
The World Wide Web . . . . . . . . . . . . . . . . . . . . . . . .
4.2
Citation networks . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3
Other information networks . . . . . . . . . . . . . . . . . . . .

63
63
67
72

5 Biological networks
5.1
Biochemical networks . . . . . . . . . . . . . . . . . . . . . . .
5.2
Neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3
Ecological networks . . . . . . . . . . . . . . . . . . . . . . . . .

78
78
94
99

v

C ONTENTS

vi

II Fundamentals of network theory

107

6

Mathematics of networks
6.1
Networks and their representation . . . . . . . . . . . . . . . .
6.2
The adjacency matrix . . . . . . . . . . . . . . . . . . . . . . . .
6.3
Weighted networks . . . . . . . . . . . . . . . . . . . . . . . . .
6.4
Directed networks . . . . . . . . . . . . . . . . . . . . . . . . . .
6.5
Hypergraphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.6
Bipartite networks . . . . . . . . . . . . . . . . . . . . . . . . . .
6.7
Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.8
Planar networks . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.9
Degree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.10 Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.11 Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.12 Independent paths, connectivity, and cut sets . . . . . . . . . .
6.13 The graph Laplacian . . . . . . . . . . . . . . . . . . . . . . . .
6.14 Random walks . . . . . . . . . . . . . . . . . . . . . . . . . . . .

109
109
110
112
114
122
123
127
129
133
136
142
145
152
157

7

Measures and metrics
7.1
Degree centrality . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2
Eigenvector centrality . . . . . . . . . . . . . . . . . . . . . . . .
7.3
Katz centrality . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.4
PageRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.5
Hubs and authorities . . . . . . . . . . . . . . . . . . . . . . . .
7.6
Closeness centrality . . . . . . . . . . . . . . . . . . . . . . . . .
7.7
Betweenness centrality . . . . . . . . . . . . . . . . . . . . . . .
7.8
Groups of vertices . . . . . . . . . . . . . . . . . . . . . . . . . .
7.9
Transitivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.10 Reciprocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.11 Signed edges and structural balance . . . . . . . . . . . . . . .
7.12 Similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.13 Homophily and assortative mixing . . . . . . . . . . . . . . . .

168
168
169
172
175
178
181
185
193
198
204
206
211
220

8

The large-scale structure of networks
8.1
Components . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.2
Shortest paths and the small-world effect . . . . . . . . . . . .
8.3
Degree distributions . . . . . . . . . . . . . . . . . . . . . . . .
8.4
Power laws and scale-free networks . . . . . . . . . . . . . . .
8.5
Distributions of other centrality measures . . . . . . . . . . . .
8.6
Clustering coefﬁcients . . . . . . . . . . . . . . . . . . . . . . .

235
235
241
243
247
261
262

C ONTENTS

8.7

Assortative mixing . . . . . . . . . . . . . . . . . . . . . . . . . 266

III Computer algorithms

273

9 Basic concepts of algorithms
9.1
Running time and computational complexity . . . . . . . . . .
9.2
Storing network data . . . . . . . . . . . . . . . . . . . . . . . .
9.3
The adjacency matrix . . . . . . . . . . . . . . . . . . . . . . . .
9.4
The adjacency list . . . . . . . . . . . . . . . . . . . . . . . . . .
9.5
Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9.6
Other network representations . . . . . . . . . . . . . . . . . .
9.7
Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

275
278
282
283
286
290
298
301

10 Fundamental network algorithms
10.1 Algorithms for degrees and degree distributions . . . . . . . .
10.2 Clustering coefﬁcients . . . . . . . . . . . . . . . . . . . . . . .
10.3 Shortest paths and breadth-ﬁrst search . . . . . . . . . . . . . .
10.4 Shortest paths in networks with varying edge lengths . . . . .
10.5 Maximum ﬂows and minimum cuts . . . . . . . . . . . . . . .

308
308
310
315
329
333

11 Matrix algorithms and graph partitioning
11.1 Leading eigenvectors and eigenvector centrality . . . . . . . .
11.2 Dividing networks into clusters . . . . . . . . . . . . . . . . . .
11.3 Graph partitioning . . . . . . . . . . . . . . . . . . . . . . . . .
11.4 The Kernighan–Lin algorithm . . . . . . . . . . . . . . . . . . .
11.5 Spectral partitioning . . . . . . . . . . . . . . . . . . . . . . . .
11.6 Community detection . . . . . . . . . . . . . . . . . . . . . . . .
11.7 Simple modularity maximization . . . . . . . . . . . . . . . . .
11.8 Spectral modularity maximization . . . . . . . . . . . . . . . .
11.9 Division into more than two groups . . . . . . . . . . . . . . .
11.10 Other modularity maximization methods . . . . . . . . . . . .
11.11 Other algorithms for community detection . . . . . . . . . . .

345
345
354
358
360
364
371
373
375
378
380
382

IV Network models

395

12 Random graphs
12.1 Random graphs . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.2 Mean number of edges and mean degree . . . . . . . . . . . .
12.3 Degree distribution . . . . . . . . . . . . . . . . . . . . . . . . .

397
398
400
401

vii

C ONTENTS

12.4
12.5
12.6
12.7
12.8

Clustering coefﬁcient . . . . . . . . . . . . . . . . . . . . . . . .
Giant component . . . . . . . . . . . . . . . . . . . . . . . . . .
Small components . . . . . . . . . . . . . . . . . . . . . . . . . .
Path lengths . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Problems with the random graph . . . . . . . . . . . . . . . . .

402
403
408
419
423

13 Random graphs with general degree distributions
13.1 Generating functions . . . . . . . . . . . . . . . . . . . . . . . .
13.2 The conﬁguration model . . . . . . . . . . . . . . . . . . . . . .
13.3 Excess degree distribution . . . . . . . . . . . . . . . . . . . . .
13.4 Clustering coefﬁcient . . . . . . . . . . . . . . . . . . . . . . . .
13.5 Generating functions for degree distributions . . . . . . . . . .
13.6 Number of second neighbors of a vertex . . . . . . . . . . . . .
13.7 Generating functions for the small components . . . . . . . . .
13.8 Giant component . . . . . . . . . . . . . . . . . . . . . . . . . .
13.9 Size distribution for small components . . . . . . . . . . . . . .
13.10 Power-law degree distributions . . . . . . . . . . . . . . . . . .
13.11 Directed random graphs . . . . . . . . . . . . . . . . . . . . . .

428
429
434
445
449
450
451
456
460
465
470
473

14 Models of network formation
14.1 Preferential attachment . . . . . . . . . . . . . . . . . . . . . . .
14.2 The model of Barabási and Albert . . . . . . . . . . . . . . . . .
14.3 Further properties of preferential attachment models . . . . .
14.4 Extensions of preferential attachment models . . . . . . . . . .
14.5 Vertex copying models . . . . . . . . . . . . . . . . . . . . . . .
14.6 Network optimization models . . . . . . . . . . . . . . . . . . .

486
487
500
503
514
534
541

15 Other network models
552
15.1 The small-world model . . . . . . . . . . . . . . . . . . . . . . . 552
15.2 Exponential random graphs . . . . . . . . . . . . . . . . . . . . 565

viii

V Processes on networks

589

16 Percolation and network resilience
16.1 Percolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.2 Uniform random removal of vertices . . . . . . . . . . . . . . .
16.3 Non-uniform removal of vertices . . . . . . . . . . . . . . . . .
16.4 Percolation in real-world networks . . . . . . . . . . . . . . . .
16.5 Computer algorithms for percolation . . . . . . . . . . . . . . .

591
592
594
609
615
616

C ONTENTS

17 Epidemics on networks
17.1 Models of the spread of disease . . . . . . . . . . . . . . . . . .
17.2 The SI model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17.3 The SIR model . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17.4 The SIS model . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17.5 The SIRS model . . . . . . . . . . . . . . . . . . . . . . . . . . .
17.6 Epidemic models on networks . . . . . . . . . . . . . . . . . . .
17.7 Late-time properties of epidemics on networks . . . . . . . . .
17.8 Late-time properties of the SIR model . . . . . . . . . . . . . .
17.9 Time-dependent properties of epidemics on networks . . . . .
17.10 Time-dependent properties of the SI model . . . . . . . . . . .
17.11 Time-dependent properties of the SIR model . . . . . . . . . .
17.12 Time-dependent properties of the SIS model . . . . . . . . . .

627
627
628
631
636
637
639
640
642
648
648
661
669

18 Dynamical systems on networks
18.1 Dynamical systems . . . . . . . . . . . . . . . . . . . . . . . . .
18.2 Dynamics on networks . . . . . . . . . . . . . . . . . . . . . . .
18.3 Dynamics with more than one variable per vertex . . . . . . .
18.4 Synchronization . . . . . . . . . . . . . . . . . . . . . . . . . . .

676
677
686
695
701

19 Network search
19.1 Web search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19.2 Searching distributed databases . . . . . . . . . . . . . . . . . .
19.3 Message passing . . . . . . . . . . . . . . . . . . . . . . . . . . .

705
705
709
713

References

727

Index

740

ix

P REFACE
The scientiﬁc study of networks, such as computer networks, biological networks, and social networks, is an interdisciplinary ﬁeld that combines ideas
from mathematics, physics, biology, computer science, the social sciences, and
many other areas. The ﬁeld has beneﬁted enormously from the wide range
of viewpoints brought to it by practitioners from so many different disciplines,
but it has also suffered because human knowledge about networks is dispersed
across the scientiﬁc community and researchers in one area often do not have
ready access to discoveries made in another. The goal of this book is to bring
our knowledge of networks together and present it in consistent language and
notation, so that it becomes a coherent whole whose elements complement one
another and in combination teach us more than any single element can alone.
The book is divided into ﬁve parts. Following a short introductory chapter, Part I describes the basic types of networks studied by present-day science
and the empirical techniques used to determine their structure. Part II introduces the fundamental mathematical tools used in the study of networks as
well as measures and statistics for quantifying network structure. Part III describes computer algorithms for the efﬁcient analysis of network data, while
Part IV describes mathematical models of network structure that can help us
predict the behavior of networked systems and understand their formation
and growth. Finally, Part V describes theories of processes taking place on networks, such as epidemics on social networks or search processes on computer
networks.
The technical level of the presentation varies among the parts, Part I requiring virtually no mathematical knowledge for its comprehension, while Parts II
and III require a grasp of linear algebra and calculus at the undergraduate
level. Parts IV and V are mathematically more advanced and suitable for advanced undergraduates, postgraduates, and researchers working in the ﬁeld.
The book could thus be used as the basis of a taught course at more than one
level. A less technical course suitable for those with moderate mathematical
knowledge might cover the material of Chapters 1 to 8, while a more technical
course for advanced students might cover the material of Chapters 6 to 14 and

x

selected material thereafter. Each chapter from Part II onward is accompanied
by a selection of exercises that can be used to test the reader’s understanding
of the material.
This book has been some years in the making and many people have helped
me with it during that time. I must thank my ever-patient editor Sonke Adlung,
with whom I have worked on various book projects for more than 15 years
now, and whose constant encouragement and kind words have made working
with him and Oxford University Press a real pleasure. Thanks are also due
to Melanie Johnstone, Alison Lees, Emma Lonie, and April Warman for their
help with the ﬁnal stages of bringing the book to print.
I have beneﬁted greatly during the writing of this book from the conversation, comments, suggestions, and encouragement of many colleagues and
friends. They are, sadly, too numerous to mention exhaustively, but special
thanks must go to Steve Borgatti, Duncan Callaway, Aaron Clauset, Betsy Foxman, Linton Freeman, Michelle Girvan, Martin Gould, Mark Handcock, Petter Holme, Jon Kleinberg, Alden Klovdahl, Liza Levina, Lauren Meyers, Cris
Moore, Lou Pecora, Mason Porter, Sidney Redner, Puck Rombach, Cosma Shalizi, Steve Strogatz, Duncan Watts, Doug White, Lenka Zdeborova, and Bob
Ziff, as well as to the many students, particularly Michelle Adan, Alejandro
Balbin, Chris Fink, Ruthi Hortsch, and Jane Wang, whose feedback helped iron
out a lot of rough spots. I would also especially like to thank Brian Karrer, who
read the entire book in draft form and gave me many pages of thoughtful and
thought-provoking comments, as well as spotting a number of mistakes and
typos. Responsibility for any remaining mistakes in the book of course rests
entirely with myself, and I welcome corrections from readers.
Finally, my profound thanks go to my wife Carrie for her continual encouragement and support during the writing of this book. Without her the book
would still have been written but I would have smiled a lot less.
Mark Newman
Ann Arbor, Michigan
February 24, 2010

xi

This page intentionally left blank

C HAPTER 1

I NTRODUCTION
A short introduction to networks
and why we study them

NETWORK is, in its simplest form, a collection of points joined together
in pairs by lines. In the jargon of the ﬁeld the points are referred to as
vertices1 or nodes and the lines are referred to as edges. Many objects of interest
in the physical, biological, and social sciences can be thought of as networks
and, as this book aims to show, thinking of them in this way can often lead to
new and useful insights.
We begin, in this introductory chapter, with a discussion of why we are
interested in networks and a brief description of some speciﬁc networks of
note. All the topics in this chapter are covered in greater depth elsewhere in
the book.

A

W HY ARE WE INTERESTED IN NETWORKS ?
There are many systems of interest to scientists that are composed of individual
parts or components linked together in some way. Examples include the Internet, a collection of computers linked by data connections, and human societies,
which are collections of people linked by acquaintance or social interaction.
Many aspects of these systems are worthy of study. Some people study the
nature of the individual components—how a computer works, for instance, or
how a human being feels or acts—while others study the nature of the connections or interactions—the communication protocols used on the Internet or the
dynamics of human friendships. But there is a third aspect to these interacting
1

Singular: vertex.

1

Vertex
Edge

A small network composed
of eight vertices and ten
edges.

I NTRODUCTION

The most common network
variants are discussed in
detail in Chapter 6.

2

systems, sometimes neglected but almost always crucial to the behavior of the
system, which is the pattern of connections between components.
The pattern of connections in a given system can be represented as a network, the components of the system being the network vertices and the connections the edges. Upon reﬂection it should come as no surprise (although
in some ﬁelds it is a relatively recent realization) that the structure of such
networks, the particular pattern of interactions, can have a big effect on the
behavior of the system. The pattern of connections between computers on the
Internet, for instance, affects the routes that data take over the network and the
efﬁciency with which the network transports those data. The connections in a
social network affect how people learn, form opinions, and gather news, as
well as affecting other less obvious phenomena, such as the spread of disease.
Unless we know something about the structure of these networks, we cannot
hope to understand fully how the corresponding systems work.
A network is a simpliﬁed representation that reduces a system to an abstract structure capturing only the basics of connection patterns and little else.
Vertices and edges in a network can be labeled with additional information,
such as names or strengths, to capture more details of the system, but even
so a lot of information is usually lost in the process of reducing a full system
to a network representation. This certainly has its disadvantages but it has
advantages as well.
Scientists in a wide variety of ﬁelds have, over the years, developed an
extensive set of tools—mathematical, computational, and statistical—for analyzing, modeling, and understanding networks. Many of these tools start
from a simple network representation, a set of vertices and edges, and after
suitable calculations tell you something about the network that might well be
useful to you: which is the best connected vertex, say, or the length of a path
from one vertex to another. Other tools take the form of network models that
can make mathematical predictions about processes taking place on networks,
such as the way trafﬁc will ﬂow over the Internet or the way a disease will
spread through a community. Because they work with networks in their abstract form, these tools can in theory be applied to almost any system represented as a network. Thus if there is a system you are interested in, and it can
usefully be represented as a network, then there are hundreds of different tools
out there, already developed and well understood, that you can immediately
apply to the analysis of your system. Certainly not all of them will give useful
results—which measurements or calculations are useful for a particular system
depends on what the system is and does and on what speciﬁc questions you
are trying to answer about it. Still, if you have a well-posed question about
a networked system there will, in many cases, already be a tool available that

I NTRODUCTION

will help you address it.
Networks are thus a general yet powerful means of representing patterns
of connections or interactions between the parts of a system. In this book, we
discuss many examples of speciﬁc networks in different ﬁelds, along with techniques for their analysis drawn from mathematics, physics, the computer and
information sciences, the social sciences, biology, and elsewhere. In doing so,
we bring together a wide range of ideas and expertise from many disciplines
to give a comprehensive introduction to the science of networks.

S OME EXAMPLES OF NETWORKS
One of the best known and most widely studied examples of a network is the
Internet, the computer data network in which the vertices are computers and
the edges are physical data connections between them, such as optical ﬁber
cables or telephone lines. Figure 1.1 shows a picture of the structure of the Internet, a snapshot of the network as it was in 2003, reconstructed by observing
the paths taken across the network by a large number of Internet data packets traveling between different sources and destinations. It is a curious fact
that although the Internet is a man-made and carefully engineered network
we don’t know exactly what its structure is, since it was built by many different groups of people with only limited knowledge of each other’s actions
and little centralized control. Our best current data on its structure are derived
from experimental studies, such as the one that produced this ﬁgure, rather
than from any central repository of knowledge or coordinating authority.
There are a number of excellent practical reasons why we might want to
study the network structure of the Internet. The function of the Internet is to
transport data between computers (and other devices) in different parts of the
world, which it does by dividing the data into pieces or packets and shipping
them from vertex to vertex across the network until they reach their intended
destination. Certainly the structure of the network will affect how efﬁciently
it accomplishes this function and if we know the network structure we can
address many questions of practical relevance. How should we choose the
route by which data are transported? Is the shortest route always necessarily
the fastest? If not, then what is, and how can we ﬁnd it? How can we avoid
bottlenecks in the trafﬁc ﬂow that might slow things down? What happens
when a vertex or an edge fails (which they do with some regularity)? How can
we devise schemes to route around such failures? If we have the opportunity
to add new capacity to the network, where should it be added?
Knowledge of Internet structure also plays a central role in the development of new communications standards. New standards and protocols are

We look at the Internet in
more detail in Section 2.1.

3

I NTRODUCTION

Figure 1.1: The network structure of the Internet. (See Plate I for color version.) The vertices in this representation
of the Internet are “class C subnets”—groups of computers with similar Internet addresses that are usually under the
management of a single organization—and the connections between them represent the routes taken by Internet data
packets as they hop between subnets. The geometric positions of the vertices in the picture have no special meaning;
they are chosen simply to give a pleasing layout and are not related, for instance, to geographic position of the vertices.
The structure of the Internet is discussed in detail in Section 2.1. Figure created by the Opte Project (www.opte.org).
Reproduced with permission.

4

I NTRODUCTION

continually being devised for communication over the Internet, and old ones
are revised. The parameters of these protocols are tuned for optimal performance with the structure of the Internet in mind. In the early days of the network, rather primitive models of network structure were employed in the tuning process, but as better structural data become available it becomes possible
to better understand and improve performance.
A more abstract example of a network is the World Wide Web. In common
parlance the words “Web” and “Internet” are often used interchangeably, but
technically the two are quite distinct. The Internet is a physical network of
computers linked by actual cables (or sometimes radio links) running between
them. The Web, on the other hand, is a network of information stored on web
pages. The vertices of the World Wide Web are web pages and the edges are
“hyperlinks,” the highlighted snippets of text or push-buttons on web pages
that we click on to navigate from one page to another. A hyperlink is purely
a software construct; you can link from your web page to a page that lives on
a computer on the other side of the world just as easily as you can link to a
friend down the hall. There is no physical structure, like an optical ﬁber, that
needs to be built when you make a new link. The link is merely an address
that tells the computer where to look next when you click on it.
Abstract though it may be, the World Wide Web, with its billions of pages
and links, has proved enormously useful, not to mention proﬁtable, to many
people, and the structure of the network of links is of substantial interest. Since
people tend to add hyperlinks between pages with related content, the link
structure of the Web reveals something about the content structure. What’s
more, people tend to link more often to pages that they ﬁnd useful than to
those they do not, so that the number of links pointing to a page can be used
as a measure of its usefulness. A more sophisticated version of this idea lies
behind the operation of the popular Web search engine Google, as well as some
others.
The Web also illustrates another concept of network theory, the directed network. Hyperlinks on the Web run in one speciﬁc direction, from one web page
to another. Given an appropriate link on page A, you can click and arrive at
page B. But there is no requirement that B contains a link back to A again. (It
may contain such a link, but there is no law that says that it must and much
of the time it will not.) One says that the edges in the World Wide Web are
directed, running from the linking page to the linked.
Moving away from the technological realm, another type of network of scientiﬁc interest is the social network. A social network is, usually, a network
of people, although it may sometimes be a network of groups of people, such
as companies. The people or groups form the vertices of the network and the

The World Wide Web is discussed in more detail in
Section 4.1.

The mechanics of Web
search are discussed in
Section 19.1.

Social networks are discussed in more depth in
Chapter 3.

5

I NTRODUCTION

edges represent connections of some kind between them, such as friendship
between individuals or business relationships between companies. The ﬁeld
of sociology has perhaps the longest and best developed tradition of the empirical study of networks as they occur in the real world, and many of the
mathematical and statistical tools that are used in the study of networks are
borrowed, directly or indirectly, from sociologists.
Figure 1.2 shows a famous example of a social network
from the sociology literature, Wayne Zachary’s “karate club”
network. This network represents the pattern of friendships
among members of a karate club at a north American university. The network was constructed by direct observation
of interactions between the club’s members. As is typical of
such studies the network is small, having, in this case, only 34
vertices. Network representations of the Internet or the World
Wide Web, by contrast, can have thousands or millions of vertices. In principle there is no reason why social networks cannot be similarly large. The entire population of the world, for
example, can be regarded as a very large social network. But
in practice social network data are limited to relatively small
groups because of the effort involved in compiling them. The
Figure 1.2: Friendship network between
network of Fig. 1.2, for instance, was the product of two years
members of a club. This social network
of observations by one experimenter. In recent years a few
from a study conducted in the 1970s shows
larger social networks have been constructed by dint of enorthe pattern of friendships between the memmous effort on the part of large groups of researchers. And
bers of a karate club at an American univeronline social networking services, such as Facebook or instant
sity. The data were collected and published by
Zachary [334].
message “buddy lists,” can provide network data on a previously unreachable scale. Studies are just beginning to emerge
of the structure and properties of these larger networks.
A third realm in which networks have become important in recent years
is biology. Networks occur in a number of situations in biology. Some are
concrete physical networks like neural networks—the networks of connections
Neural networks are disbetween neurons in the brain—while others are more abstract. In Fig. 1.3 we
cussed in Section 5.2 and
show a picture of a “food web,” an ecological network in which the vertices
food webs in Section 5.3.
are species in an ecosystem and the edges represent predator–prey relationships between them. That is, pairs of species are connected by edges in this
network if one species eats the other. The study of food webs forms a substantial branch of ecology and helps us to understand and quantify many ecological phenomena, particularly concerning energy and carbon ﬂows in ecosystems. Food webs also provide us with another example of a directed network,
like the World Wide Web discussed previously. The edges in a food web are
6

I NTRODUCTION

Figure 1.3: The food web of Little Rock Lake, Wisconsin. (See Plate II for color
version.) This elegant picture summarizes the known predatory interactions between
species in a freshwater lake in the northern United States. The vertices represent the
species and the edges run between predator–prey species pairs. The vertical position of
the vertices represents, roughly speaking, the trophic level of the corresponding species.
The ﬁgure was created by Richard Williams and Neo Martinez [209].

asymmetric and are conventionally thought of as pointing from the prey to the
predator, indicating the direction of the ﬂow of energy when the prey is eaten.
(This choice of direction is only a convention and one could certainly make
the reverse choice. The important point is the asymmetry of the predator–prey
interaction.)
Another class of biological networks is that of biochemical networks, such
as metabolic networks, protein–protein interaction networks, and genetic regulatory networks. A metabolic network, for instance, is a representation of the
chemical reactions that fuel cells and organisms. The reader may have seen the
wallcharts of metabolic reactions that adorn the ofﬁces of some biochemists, incredibly detailed maps with hundreds of tiny inscriptions linked by a maze of
arrows.2 The inscriptions—the vertices in this network—are metabolites, the
substrates and products of metabolism, and the arrows—directed edges—are
reactions that turn one metabolite into another. The depiction of reactions as a
2

Biochemical networks are
discussed in detail in Section 5.1.

An example appears as Fig. 5.2 on page 83.

7

I NTRODUCTION

network is one of the ﬁrst steps towards making sense of the bewildering array
of biochemical data generated by recent and ongoing experiments in molecular
genetics.
These are just a few examples of the types of network whose study is the
focus of this book. There are many others that we will come across in later
pages. Among them some of the best known are telephone networks, road,
rail, and air networks, the power grid, citation networks, recommender networks, peer-to-peer networks, email networks, collaboration networks, disease transmission networks, river networks, and word networks.

P ROPERTIES OF NETWORKS
We have seen that a variety of systems can be represented as networks. If we
can gather data on the structure of one of these networks, what then can we
do with those data? What can they tell us about the form and function of the
system the network represents? What properties of networked systems can we
measure or model and how are those properties related to the practical issues
we care about? This, essentially, is the topic of this entire book, and we are not
going to answer it in this chapter alone. Let us, however, look brieﬂy here at
a few representative concepts, to get a feel for the kinds of ideas we will be
dealing with.
A ﬁrst step in analyzing the structure of a network is often to make a picture
of it. Figures 1.1, 1.2, and 1.3 are typical examples. Each of these was generated by a specialized computer program designed for network visualization
and there are many such programs available, both commercially and for free,
if you want to produce pictures like these for yourself. Visualization can be an
extraordinarily useful tool in the analysis of network data, allowing one to see
instantly important structural features of a network that would otherwise be
difﬁcult to pick out of the raw data. The human eye is enormously gifted at
picking out patterns, and visualizations allow us to put this gift to work on our
network problems. On the other hand, direct visualization of networks is only
really useful for networks up to a few hundreds or thousands of vertices, and
for networks that are relatively sparse, meaning that the number of edges is
quite small. If there are too many vertices or edges in a network then pictures
of the network will be too complicated for the eye to comprehend and their
usefulness becomes limited. Many of the networks that scientists are interested in today have hundreds of thousands or even millions of vertices, which
means that visualization is not of much help in their analysis and we need to
employ other techniques to determine their structural features. In response
to this need, network theory has developed a large toolchest of measures and
8

I NTRODUCTION

metrics that can help us understand what our network data are telling us, even
in cases where useful visualization is impossible.
An example of an important and useful class of network measures is that of
measures of centrality. Centrality quantiﬁes how important vertices (or edges)
are in a networked system, and social network analysts in particular have expended considerable effort studying it. There are a wide variety of mathematical measures of vertex centrality that focus on different concepts and deﬁnitions of what it means to be central in a network. A simple but very useful
example is the measure called degree. The degree of a vertex in a network is
the number of edges attached to it. In a social network of friendships between
individuals, for instance, such as the network of Fig. 1.2, the degree of an individual is the number of friends he or she has within the network. In the
Internet degree would be the number of data connections a computer, router,
or other device has. In many cases the vertices with the highest degrees in
a network, those with the most connections, also play important roles in the
functioning of the system, and hence degree can be a useful guide for focusing
our attention on the system’s most crucial elements.
In undirected networks degree is just a single number, but in directed networks vertices have two different degrees, in-degree and out-degree, corresponding to the number of edges pointing inward to and outward from those vertices. For example, the in-degree of a web page is the number of other pages
that link to it and the out-degree is the number of pages to which it links. We
have already mentioned one example of how centrality can be put to use on
the Web to answer an important practical question: by counting the number
of links a web page gets—the in-degree of the page—we (or a search engine
operating on our behalf) can make a guess about which pages are most likely
to contain information that might be of use to us.
It is an interesting observation that many networks are found to contain
a small but signiﬁcant number of “hubs”—vertices with unusually high degree. Social networks often contain a few central individuals with very many
acquaintances; there are a few websites with an extraordinarily large number
of links; there are a few metabolites that take part in almost all metabolic processes. A major topic of research in recent years has been the investigation of
the effects of hubs on the performance and behavior of networked systems.
Both empirical and theoretical results indicate that hubs can have a quite disproportionate effect, playing a central role particularly in network transport
phenomena and resilience, despite being few in number.
Another example of a network concept that arises repeatedly and has real
practical implications is the so-called small-world effect. One can deﬁne a distance, called the geodesic distance, between two vertices in a network to be the

See Chapter 7 for further discussion of centrality measures.

2
2
4
3

1

The number beside each
vertex in this small network indicates the vertex’s
degree.

Hubs are discussed further
in Section 8.3.

9

I NTRODUCTION

minimum number of edges one would have to traverse in order to get from
one vertex to the other. For instance, two friends would have geodesic distance 1 in a friendship network because there is a single edge connecting them
directly, while the friend of your friend would have distance 2 from you. As
discussed in Sections 3.6 and 8.2, it is found empirically (and can be proven
mathematically in some cases) that the mean geodesic distance, appropriately
deﬁned,3 between vertex pairs is very short, typically increasing only as the
logarithm of the number of vertices in the network. Although ﬁrst studied in
the context of friendship networks, this small-world effect appears to be very
widespread, occurring in essentially all types of networks. In popular culture
it is referred to as the “six degrees of separation,” after a successful stage play
and ﬁlm of the same name. The semi-mythological claim is that you can get
from anyone in the world to anyone else via a sequence of no more than ﬁve
intermediate acquaintances—six steps in all.
The small-world effect can have interesting repercussions. For example,
news and gossip spread over social networks. If you hear an interesting rumor
from a friend, you may pass it on to your other friends, and they in turn pass it
on to theirs, and so forth. Clearly the rumor will spread further and faster if it
only takes six steps to reach anyone in the world than if it takes a hundred, or a
million. It is a matter of common experience that indeed a suitably scandalous
rumor can reach the ears of an entire community in what seems like the blink
of an eye, and the structure of social networks has a lot to do with it.
And consider the Internet. One of the reasons the Internet functions at all
is because any computer on the network is only a few “hops” over optical and
other data lines from any other. In practice the paths taken by packets over the
Internet are typically in the range of about ten to twenty hops long. Certainly
the performance of the network would be much worse if packets had to make
a thousand hops instead.
A third example of a network concept of practical importance is provided
by clusters or communities in networks. We are most of us familiar with the
idea that social networks break up into subcommunities—tightly knit groups
of friends or acquaintances within the larger, looser network. Friendship networks, for instance, tend to contain cliques, circles, and gangs of friends within
which connections are strong and frequent but between which they are weaker
or rarer. The same is true of other kinds of social network also. For instance, in
a network of business relationships between companies one often ﬁnds clusters formed of sets of companies that operate in particular sections of the econ3
One must be careful when there are vertex pairs in the network that are connected by no path
at all. Such issues are dealt with in Section 8.2.

10

I NTRODUCTION

omy. Connections might be stronger, for instance, between a pair of computer
companies or a pair of biotech companies than between a computer company
and a biotech company. And if it is the case that communities correspond to
genuine divisions of interest or purpose in this way, then we may well learn
something by taking a network and examining it to determine what communities it contains. The way a network breaks down into communities can reveal
levels and concepts of organization that are not easy to see without network
data, and can help us to understand how a system is structured. There is a substantial research literature in social network analysis as well as in other ﬁelds
concerned with precisely these kinds of questions, and a large number of techniques have been developed to help us extract and analyze subcommunities
within larger networks. These are highly active topics of research at present,
and hold promise for exciting applications in the future.

O UTLINE OF THIS BOOK
This book is divided into ﬁve parts. In the ﬁrst part, consisting of Chapters 2
to 5, we introduce the various types of network encountered in the real world,
including technological, social, and biological networks, and the empirical
techniques used to discover their structure. Although it is not the purpose
of this book to describe any one particular network in great detail, the study
of networks is nonetheless ﬁrmly founded on empirical observations and a
good understanding of what data are available and how they are obtained is
immensely helpful in understanding the science of networks as it is practiced
today.
The second part of the book, Chapters 6 to 8, introduces the fundamental
theoretical ideas on which our current understanding of networks is based.
Chapter 6 describes the basic mathematics used to capture network ideas,
Chapter 7 describes the measures and metrics we use to quantify network
structure, and Chapter 8 describes some of the intriguing patterns and principles that emerge when we apply our mathematics and our metrics to realworld network data.
In the third part of the book, Chapters 9 to 11, we discuss computer algorithms for analyzing and understanding network data. Measurements of network properties, such as those described in Chapter 7, are typically only possible with the help of fast computers and much effort has been devoted over the
years to the development of efﬁcient algorithms for analyzing network data.
This part of the book describes in detail some of the most important of these
algorithms. A knowledge of this material will be of use to anyone who wants
to work with network data.
11

I NTRODUCTION

In the fourth part of the book, Chapters 12 to 15, we look at mathematical
models of networks. The material in these chapters forms a central part of
the canon of the ﬁeld and has been the subject of a vast amount of published
scientiﬁc research. We study both traditional models, such as random graphs
and their extensions, and newer models, such as models of growing networks
and the “small-world model.”
Finally, in the ﬁfth and last part of the book, Chapters 16 to 19, we look at
processes taking place on networks, including failure processes and resilience,
network epidemiology, dynamical systems, and network search processes. The
theory of these processes is less well developed than other aspects of the theory
of networks and there is much work still to be done. The last chapters of the
book probably raise at least as many questions as they answer, but this, surely,
is a good thing. With luck readers will feel inspired to answer some of those
questions themselves and the author looks forward to the new and exciting
results they generate when they do.

12

This page intentionally left blank

This page intentionally left blank

PART I
T HE EMPIRICAL STUDY OF
NETWORKS

15

This page intentionally left blank

C HAPTER 2

T ECHNOLOGICAL NETWORKS
A discussion of engineered networks like the Internet and
the power grid and how we determine their structure

I

N THE next four chapters we deﬁne and describe some of the most com-

monly studied networks, dividing them into four general classes—technological networks, social networks, information networks, and biological networks. We will list the most important examples in each class and then describe the techniques used to measure their structure. (The classes are not rigorously deﬁned and there is, as we will see, some overlap between them, with
some networks belonging to more than one class. Nonetheless, the division
into classes is a useful one, since networks in the same class are often treated
using similar techniques or ideas.)
It is not our intention in this book to study any one network in great detail. Plenty of other books exist that do that. Nonetheless, network science is
concerned with understanding and modeling the behavior of real-world networked systems and observational data are the starting point for essentially
all the developments of the ﬁeld, so the reader will ﬁnd it useful to have a
grasp of the types of data that are available, their strengths and limitations,
and the means used to acquire them. In this chapter we look at technological
networks, the physical infrastructure networks that have grown up over the
last century or so and form the backbone of modern technological societies.
Perhaps the most celebrated such network—and a relatively recent entry in
the ﬁeld—is the Internet, the global network of data connections, electrical,
optical, and wireless, that links computers and other information systems together. Section 2.1 is devoted to a discussion of the Internet. A number of
other important examples of technological networks, including power grids,
transportation networks, delivery and distribution networks, and telephone

17

T ECHNOLOGICAL NETWORKS

networks, are discussed in subsequent sections.

2.1
The Internet should not be
confused with the World
Wide Web, a virtual network of web pages and hyperlinks, which we discuss
in Section 4.1.

The telephone network is
discussed in Section 2.2.

T HE I NTERNET

The Internet is the worldwide network of physical data connections between
computers and related devices. The Internet is a packet switched data network,
meaning that messages sent over it are broken up into packets, small chunks of
data, that are sent separately over the network and reassembled into a complete message again at the other end. The format of the packets follows a
standard known as the Internet Protocol (IP) and includes an IP address in each
packet that speciﬁes the packet’s destination, so that it can be routed correctly
across the network.
The alternative to a packet switched network is a circuit switched network,
the classic example of which is the telephone system. In a circuit switched network, vertices request connections when needed, such as when a telephone
call is placed, and the network allocates a separate circuit for each connection,
reserved for the sole use of that connection until the connection is ended. This
works well for voice trafﬁc, which consists of discrete phone calls each with a
deﬁnite beginning and end, but it would be a poor model for a data network,
in which data transmission typically occurs in brief, intermittent bursts. Using a packet switched model for the Internet allows computers to transmit and
receive data intermittently or at varying rates without tying up capacity on
the network. By making packets reasonably small, we also allow for a certain
amount of unreliability in the network. It is not uncommon for packets to disappear on the Internet and never reach their destination, sometimes because
of hardware or software failure, but more often because packets are deliberately deleted to reduce congestion in the busiest parts of the network. If a
message is divided into several packets before transmission and a few packets
are lost, then only those that are lost need be resent to complete the message.
A software protocol called Transport Control Protocol or TCP, which runs on top
of IP, performs the necessary error checking and retransmission automatically,
without the need for intervention from computer users or other software.1
1

Most of the well-known communications protocols of the Internet are themselves built on
top of TCP, including HTTP (the World Wide Web), SMTP (email), and FTP (ﬁle transfer). Thus
communication is a three-layer process with a user-level protocol running on top of TCP, which
in turn runs on top of IP, and the user protocols automatically beneﬁt from the error-checking
features and guaranteed transmission offered by TCP. (There are lower-level transport protocols
as well, such as Ethernet, PPP, and ATM, but these will not concern us.) There are however also
some applications of Internet technology that do not require guaranteed transmission. Most of
the common examples are streaming media, such as audio and video transmissions, voice and

18

2.1

|

T HE I NTERNET

The simplest network representation of the Internet (there are others, as we
will shortly see) is one in which the vertices of the network represent computers and other devices, and the edges represent physical connections between
them, such as optical ﬁber lines. In fact, ordinary computers mostly occupy
only the vertices on the “outside” of the network, those that data ﬂows to and
from, but they do not act as intermediate points for the ﬂow of data between
others. (Indeed, most computers only have a single connection to the net, so
it would not be possible for them to lie on the path between any others.) The
“interior” nodes of the Internet are primarily routers, powerful special-purpose
computers at the junctions between data lines that receive data packets and
forward them in one direction or another towards their intended destination.
The general overall shape of the Internet is shown, in schematic form, in
Fig. 2.1. The network is composed of three levels or circles of vertices. The
innermost circle, the core of the network, is the backbone of the network, the
trunk lines that provide long-distance high-bandwidth data transport across
the globe, along with the high-performance routers and switching centers that
link them together. These trunk lines are the highways of the Internet, built
with the fastest ﬁber optic connections available (and improving all the time).
The backbone is operated by network backbone providers (NBPs), who are primarily national governments and communications companies such as AT&T,
Global Crossing, British Telecom, and others.
The second circle of the Internet is composed of Internet service providers
or ISPs—commercial companies, governments, universities, and others who
contract with NBPs for connection to the backbone and then resell or otherwise provide that connection to end users, the ultimate consumers of Internet
bandwidth, who form the third circle—businesses, government ofﬁces, academics, people in their homes, and so forth. In fact, as Fig. 2.1 shows, the ISPs
are further subdivided into regional ISPs and local or consumer ISPs, the former
being larger organizations whose primary customers are the local ISPs, who
in turn sell network connections to the end users. This distinction is somewhat blurred however, because large consumer ISPs, such as America Online
or British Telecom, often act as their own regional ISPs (and some may be backbone providers as well).
The network structure of the Internet is not dictated by any central authority. Protocols and guidelines are developed by an informal volunteer organization called the Internet Engineering Task Force, but one does not have to
apply to any central Internet authority for permission to build a new spur on
teleconferencing, and online games. An alternative protocol to TCP called User Datagram Protocol
(UDP), which provides no transmission guarantees, is used in such cases.

19

T ECHNOLOGICAL NETWORKS

Backbone

Regional Local

ISPs

End

users

Figure 2.1: A schematic depiction of the structure of the Internet. The vertices and
edges of the Internet fall into a number of different classes: the “backbone” of highbandwidth long-distance connections; the ISPs, who connect to the backbone and who
are divided roughly into regional (larger) and local (smaller) ISPs; and the end users—
home users, companies, and so forth—who connect to the ISPs.

the Internet, or to take one out of service.
One of the remarkable features of the Internet is that the scheme used for
the routing of packets from one destination to another is arrived at by automated negotiation among Internet routers using a system called the Border
Gateway Protocol (BGP). BGP is designed in such a way that if new vertices
or edges are added to the network, old ones disappear, or existing ones fail
either permanently or temporarily, routers will take note and adjust their routing policy appropriately. Some human oversight is required to keep the system
running smoothly, but no “Internet government” is needed to steer things from
on high; the system organizes itself by the combined actions of many local and
essentially autonomous computer systems.
While this is an excellent feature of the system from the point of view of robustness and ﬂexibility, it is a problem for those who want to study the structure of the Internet, because there is no central registry from which one can

20

2.1

|

T HE I NTERNET

determine that structure. There is no one whose job it is to maintain an ofﬁcial
map of the network. Instead the network’s structure must be determined by
experimental measurements. There are two primary methods for doing this.
The ﬁrst uses something called “traceroute”; the second uses BGP.
2.1.1

M EASURING I NTERNET STRUCTURE USING TRACEROUTE

It is not, at least for most of us, possible to probe the network structure of the
Internet directly. We can, however, quite easily discover the particular path
taken by data packets traveling between our own computer (or any computer
to which we have access) and most others on the Internet. The standard tool
for doing this is called traceroute.
In addition to a destination address, which says where it is going, each Internet packet also contains a source address, which says where it started from,
and a time-to-live (TTL). The TTL is a number that speciﬁes the maximum number of “hops” that the packet can make to get to its destination, a hop being the
traversal of one edge in the network. At every hop, the TTL is decreased by
one, and if ever it reaches zero the packet is discarded, meaning it is deleted
and not forwarded any further over the network. If we are using TCP, a message is also then sent back to the sender informing them that the packet was
discarded and where it got to. (This is a part of TCP’s mechanism for guaranteeing the reliable transmission of data—see above.) The TTL exists mainly as
a safeguard to prevent packets from getting lost on the Internet and wandering
around forever, but we can make use of it to track packet progress as well. The
idea is as follows.
First, we send out a TCP packet with the destination address of the network
vertex we are interested in and a TTL of 1. The packet makes a single hop to the
ﬁrst router along the way, its TTL is decreased to zero, the packet is discarded
by the router and a message is returned to us telling us, among other things,
the IP address of the router. We record this address and then repeat the process
with a TTL of 2. This time the packet makes two hops before dying and the
returned message tells us the IP address of the second router. The process is
repeated with larger and larger TTL until the destination is reached, and the
set of IP addresses received as a result speciﬁes the entire route taken to get
there.2 There are standard software tools that will perform the entire procedure
2

We are assuming that each packet takes the same route to the destination. It is possible, but
relatively rare, for different packets to take different routes, in which case the set of IP addresses
returned by the traceroute procedure will not give a correct path through the network. This can
happen, for instance, if congestion patterns along the route vary signiﬁcantly while the procedure

21

T ECHNOLOGICAL NETWORKS

See Section 6.7 for a discussion of tree networks.

automatically and print out the list of IP addresses for us. On most computers
the tool that does this is called “traceroute.”
We can use traceroute (or a similar tool) to probe the network structure of
the Internet. The idea is to assemble a large data set of traceroute paths between many different pairs of points on the Internet. With luck, most of the
edges in the network (though usually not all of them) will appear at least once
in this set, and the union of all of them should give a reasonably complete
picture of the network. Early studies, for the sake of expediency, limited themselves to just a few source computers, but more recent ones, such as the DIMES
Project,3 make use of distributed collections of thousands of sources to develop
a very complete picture of the network.
The paths from any single source to a set of destinations form a tree-like
structure as shown schematically in Fig. 2.2a, b, and c.4 The source computers
should, ideally, be well distributed over the network. If they are close together,
then there may be a substantial overlap between the traceroute paths to distant
vertices, which means that they will duplicate needlessly each other’s efforts,
rather than returning independent measurements.
Once one has a suitable set of traceroute data, a simple union of all the paths
appearing in the data set gives us our snapshot of the network structure—see
Fig. 2.2d. That is, we go through each path and record a vertex for every IP
address that appears in the path and an edge between every pair of addresses
that appear in adjacent positions. As hinted above, it is unlikely that such a
procedure will ﬁnd all the edges in the network (see Fig. 2.2d again), and for
studies based on small numbers of sources there can be quite severe biases in
the sampling of edges [3, 192]. However, better and better data sets are becoming available as time passes, and it is believed that we now have a reasonably
complete picture of the shape of the Internet.
In fact, it is rarely, if ever, done to record every IP address on the Internet as
a separate vertex. There are believed to be about 2 billion unique IP addresses
in use on the Internet at any one time, with many of those corresponding to
end-user computers that appear and disappear as the computers are turned
is being performed, causing the network to reroute packets along less congested connections. Serious Internet mapping experiments perform repeated traceroute measurements to minimize the
errors introduced by effects such as these.
3
4

See www.netdimes.org.

If there were a unique best path to every vertex, then the set of paths would be precisely a
tree, i.e., it would contain no loops. Because of the way routing algorithms work, however, this is
not in practice always the case—two routes that originate at the same point and pass through the
same vertex on the way to their ﬁnal destination can still take different routes to get to that vertex,
so that the set of paths can contain loops.

22

2.1

(a)

(b)

(c)

(d)

|

T HE I NTERNET

Figure 2.2: Reconstruction of the topology of the Internet from traceroute data. In
panels (a), (b), and (c) we show in bold the edges in three sets of traceroute paths starting from each of the three highlighted source vertices. In panel (d) we form the union of
these edges to make a picture of the overall network topology. Note that a few edges are
missing from this picture (the remaining gray edges in panel (d)) because, by chance,
they happen not to appear in any of the three individual traceroute data sets.

on or off or connections to the Internet are made or broken. Most studies of the
Internet ignore end-user computers and restrict themselves to just the routers,
in effect concentrating on the inner zones in Fig. 2.1 and ignoring the outermost
one. We will refer to such maps of the Internet as representations at the router
level. The vertices in the network are routers, and the edges between them are
network connections.
It may appear strange to ignore end-user computers, since the end users
are, after all, the entire reason for the Internet’s existence in the ﬁrst place.
However, it is the structure of the network at the router level that is responsible
for most aspects of the performance, robustness, and efﬁciency of the network,
that dictates the patterns of trafﬁc ﬂow on the network, and that forms the
focus of most work on Internet structure and design. To the extent that these
are the issues of scientiﬁc interest, therefore, it makes sense to concentrate our
efforts on the router-level structure.
An example of a study of the topology of the Internet at the router level
23

T ECHNOLOGICAL NETWORKS

is that of Faloutsos et al. [111], who looked at the “degree distribution” of the
network and discovered it to follow, approximately, a power law. We discuss
degree distributions and power laws in networks in more detail in Section 8.4.
Even after removing all or most end-user computers from the network, the
network structure at the router level may still be too detailed for our purposes.
Often we would like a more coarse-grained representation of the network that
gives us a broader overall picture of network structure. Such representations
are created by grouping sets of IP addresses together into single vertices. Three
different ways of grouping addresses are in common use giving rise to three
different coarse-grained representations, at the level of subnets, domains, and
autonomous systems.
A subnet is a group of IP addresses deﬁned as follows. IP addresses consist
of four numbers, each one in the range from 0 to 255 (eight bits in binary) and
typically written in a string separated by periods or dots. For example, the IP
address of the main web server at the author’s home institution, the University
of Michigan, is 141.211.144.190. IP addresses are allocated to organizations
in blocks. The University of Michigan, for instance, owns (among others) all
the addresses of the form 141.211.144.xxx, where “xxx” can be any number
between 0 and 255. Such a block, where the ﬁrst three numbers in the address
are ﬁxed and the last can be anything, is called a class C subnet. There are also
class B subnets, which have the form 141.211.xxx.yyy, and class A subnets,
which have the form 141.xxx.yyy.zzz.
Since all the addresses in a class C subnet are usually allocated to the same
organization, a reasonable way of coarse-graining Internet network data is to
group vertices into class C subnets. In most cases this will group together
vertices in the same organization, although larger organizations, like the University of Michigan, own more than one class C subnet, so there will still be
more than one vertex in the coarse-grained network corresponding to such organizations. Given the topology of the network at the router level, the level
of individual IP addresses, it is easy to lump together into a single vertex all
addresses in each class C subnet and place an edge between any two subnets
if any router in one has a network connection to any router in the other. Figure 1.1 on page 4 shows an example of the network structure of the Internet
represented at the level of class C subnets.
The second common type of coarse-graining is coarse-graining at the domain level. A domain is a group of computers and routers under, usually, the
control of a single organization and identiﬁed by a single domain name, normally the last two or three parts of a computer’s address when the address
is written in human-readable text form (as opposed to the raw IP addresses
considered above). For example, “umich.edu” is the domain name for the
24

2.1

|

T HE I NTERNET

University of Michigan and “oup.co.uk” is the domain name for Oxford University Press. The name of the domain to which a computer belongs can be
determined in a straightforward manner from the computer’s IP address by a
“reverse DNS lookup,” a network service set up to provide precisely this type
of information. Thus, given the router-level network topology, it is a simple
task to determine the domain to which each router belongs and group vertices
in the network according to their domain. An edge is then placed between two
vertices if any router in one has a direct network connection to any router in
the other. The study by Faloutsos et al. [111] mentioned earlier looked at the
domain-level structure of the Internet as well as the router-level structure.
The third common coarse-graining of the network is coarse-graining at the
level of autonomous systems. An autonomous system is similar to a domain:
it is a group of computers, usually under single administrative control, and
it often (though not always) coincides with a domain. Coarse-graining at the
autonomous system level is not usually used with data derived from traceroute sampling but with data derived using an alternative method based on
BGP routing tables, for which it forms the most natural unit of representation.
The BGP method and autonomous systems are discussed in detail in the next
section.
2.1.2

M EASURING I NTERNET STRUCTURE USING ROUTING TABLES

Internet routers maintain routing tables that allow them to decide in which direction incoming packets should be sent to best reach their destination. Routing tables are constructed from information shared between routers using the
Border Gateway Protocol (BGP). They consist of lists of complete paths from
the router in question to destinations on the Internet. When a packet arrives at
a router, the router examines it to determine its destination and looks up that
destination in the routing table. The ﬁrst step of the path in the appropriate
table entry tells the router how the packet should be sent on its way. Indeed,
in theory routers need store only the ﬁrst step on each path in order to route
packets correctly. However, for efﬁcient calculation of routes using BGP (the
techniques of which we will not go into here) it is highly desirable that routers
be aware of the entire path to each destination, and since the earliest days of
the Internet all routers have operated in this way. We can make use of this fact
to measure the structure of the Internet.
Routing tables in routers are represented at the level of autonomous systems
(ASes). An autonomous system is a collection of computers and routers, usually under single administrative control, within which data routing is handled
independently of the wider Internet, hence the name “autonomous system.”
25

T ECHNOLOGICAL NETWORKS

That is, when a data packet arrives at a router within an autonomous system,
destined for a speciﬁc computer within that same autonomous system, it is the
responsibility of the autonomous system to get the packet the last few steps
to its ﬁnal destination. Data passing between autonomous systems, however,
is handled by the Internet-wide mechanisms of BGP. Thus it’s necessary for
BGP to know about routing only down to the level of autonomous systems
and hence BGP tables are most conveniently represented in autonomous system terms. In practice, autonomous systems, of which there are (at the time of
writing) about twenty thousand on the Internet, often coincide with domains,
or nearly so.
Autonomous systems are assigned unique identiﬁcation numbers. A routing path consists of a sequence of these AS numbers and since router tables
consist of paths to a large number of destinations, we can construct a picture of
the Internet at the autonomous system level by examining them. The process
is very similar to that used for the traceroute method described in the previous
section and depicted in Fig. 2.2. We ﬁrst obtain a number of router tables. This
is normally done simply by the gracious cooperation of router operators at a
variety of organizations. Each router table contains a large number of paths
starting from a single source (the router), and the union of these paths gives a
good but not complete network snapshot in which the vertices are autonomous
systems and the edges are the connections between autonomous systems. As
with traceroute, it is important that the routers used be well scattered over the
network to avoid too much duplication of results, and the number of routers
used should be as large as possible to make the sampling of network edges as
complete as possible. For example, the Routeviews Project,5 a large BGP-based
Internet mapping effort based at the University of Oregon, uses (again at the
time of writing) a total of 223 source computers around the world to measure
the structure of the entire network every two hours.
Figure 2.3 shows a picture of the Internet at the AS level derived from
routing tables. Qualitatively, the picture is similar to Fig. 1.1 for the class C
subnet structure, but there are differences arising because class C subnets are
smaller units than many autonomous systems and so Fig. 1.1 is effectively a
ﬁner-grained representation than Fig. 2.3.
Using router-, subnet-, domain-, or AS-level structural data for the Internet,
many intriguing features of the net’s topology have been discovered in recent
years [57, 66, 111, 211, 262, 265], many of which are discussed in later chapters
of this book.
5

26

See www.routeviews.org.

2.1

|

T HE I NTERNET

Figure 2.3: The structure of the Internet at the level of autonomous systems. (See Plate III for color version.) The
vertices in this network representation of the Internet are autonomous systems and the edges show the routes taken by
data traveling between them. This ﬁgure is different from Fig. 1.1, which shows the network at the level of class C subnets. The picture was created by Hal Burch and Bill Cheswick. Patent(s) pending and Copyright Lumeta Corporation
2009. Reproduced with permission.

One further aspect of the Internet worth mentioning here is the geographic
location of its vertices on the surface of the Earth. In many of the networks
that we will study in this book, vertices do not exist at any particular position
in real space—the vertices of a citation network for instance are not located on

27

T ECHNOLOGICAL NETWORKS

any particular continent or in any particular town. Not so the Internet; its vertices, by and large, are quite well localized in space. Your computer sits on your
desk, a router sits in the basement of an ofﬁce building, and so forth. Things become more blurry once the network is coarse-grained. The domain umich.edu
covers large parts of the state of Michigan. The domain aol.com covers most
of North America. These are somewhat special cases, however, being unusually large domains. The majority of domains have a well-deﬁned location at
least to within a few miles. Furthermore, tools now exist for determining, at
least approximately, the geographic location of a given IP address, domain,
or autonomous system. Examples include NetGeo, NetAcuity, GeoNetMap, and
many others. Geographic locations are determined primarily by looking them
up in one of several registries that record the ofﬁcial addresses of the registered owners of domains or autonomous systems. These addresses need not
in all cases correspond to the actual location of the corresponding computer
hardware. For instance, the domain ibm.com is registered in New York City,
but IBM’s principal operations are in California. Nonetheless, an approximate
picture of the geographic distribution of the Internet can be derived by these
methods, and there has been some interest in the results [332].
Geographic localization is a feature the Internet shares with several other
technological networks, as we will see in the following sections, but rarely with
networks of other kinds.6

2.2

T HE TELEPHONE NETWORK

The Internet is the best studied example of a technological network, at least
as measured by volume of recent academic work. This is partly because data
on Internet structure are relatively easy to come by and partly because of intense interest among engineers and computer scientists and among the public
at large. Several other technological networks however are worthy of mention
here. In this and the following sections of the chapter we look brieﬂy at the
telephone network and various distribution and transportation networks. A
few other networks, such as software call graphs and electronic circuits, could
also be considered technological networks and have been studied occasionally,
but are beyond the scope of this book.
6
Social networks are perhaps the main exception—in many cases people or groups of people
can be considered to have reasonably well-deﬁned geographic locations. Relatively little work has
been done however on the effects of geographic distribution, perhaps because most social network
studies have concentrated on populations in local neighborhoods, rather than ones spread out over
signiﬁcant geographic areas.

28

2.2

|

T HE TELEPHONE NETWORK

The telephone network—meaning the network of landlines and wireless
links7 that transmits telephone calls—is one of the oldest communication networks still in use (although the postal network is certainly older), but it has
been little studied by network theorists, primarily because of a lack of good
data about its structure. Of course, the structure of the phone network is
known, but the data are largely proprietary to the telephone companies that
own the network and, while not precisely secret, they are not openly shared
with the research community in the same way that Internet data are. We hope
that this situation will change, although the issue may become moot in the not
too distant future, as telephone companies are sending an increasing amount
of voice trafﬁc over the Internet rather than over dedicated telephone lines,
and it may not be long before the two networks merge into one.
Some general principles of operation of the telephone network are clear
however. By contrast with the Internet, the traditional telephone network is,
as mentioned in Section 2.1, not packet switched. Signals sent over the phone
network are not disassembled and sent as sets of discrete packets. Instead the
telephone network is circuit switched, which means that the telephone company
has a number of lines or circuits available to carry telephone calls between different points and it assigns them to individual callers when those callers place
phone calls. In the earliest days of the telephone systems in the United States
and Europe the “lines” actually were individual wires, one each for each call
the company could carry. Increasing the capacity of the network to carry more
calls meant putting in more wires. Since the early part of the twentieth century,
however, phone companies have employed techniques for multiplexing phone
signals, i.e., sending many calls down the same wire simultaneously. The exception is the “last mile” of connection to the individual subscriber. The phone
cable entering a house usually only carries one phone call at a time, although
even that has changed in recent years as new technology has made it possible
for households to have more than one telephone number and place more than
one call at a time.
The basic form of the telephone network is relatively simple. Most countries with a mature landline (as opposed to wireless) telephone network use
7
For most of its existence, the telephone network has connected together stationary telephones
in ﬁxed locations such as houses and ofﬁces using landlines. In the last twenty years or so ﬁxed
telephones have started to be replaced by wireless phones (“mobile phones” or “cell phones”), but
it is important to realize that even calls made on wireless phones are still primarily carried over the
traditional landline telephone network. The signal from a wireless phone makes the ﬁrst step of its
journey wirelessly to a nearby transmission tower, but from there it travels over ordinary phone
lines. Thus, while the advent of wireless phones has had an extraordinary impact on society, it has
had rather less impact on the nature of the telephone network.

29

T ECHNOLOGICAL NETWORKS

Long−distance offices

Local exchanges

Telephone
subscribers

Figure 2.4: A sketch of the three-tiered structure of a traditional telephone network.
In a telephone network individual subscriber telephones are connected to local exchanges, which are connected in turn to long-distance ofﬁces. The long-distance ofﬁces
are connected amongst themselves by further lines, and there may be some connections
between local exchanges as well.

a three-tiered design. Individual telephone subscribers are connected over local lines to local telephone exchanges, which are then connected over shared
“trunk” lines to long-distance ofﬁces, sometimes also called toll-switching ofﬁces. The long-distance ofﬁces are then connected among themselves by further trunk lines. See Fig. 2.4 for a sketch of the network structure. The structure
is, in many ways, rather similar to that of the Internet (Fig. 2.1), even though
the underlying principles on which the two networks operate are quite different.
The three-level topology of the phone network is designed to exploit the
fact that most telephone calls in most countries are local, meaning they connect subscribers in the same town or region. Phone calls between subscribers
connected to the same local exchange can be handled by that exchange alone
and do not need to make use of any trunk lines at all. Such calls are usually

30

2.3

|

P OWER GRIDS

referred to as local calls, while calls that pass over trunk lines are referred to
as trunk or long-distance calls. In many cases there may also be direct connections between nearby local exchanges that allow calls to be handled locally
even when two subscribers are not technically attached to the same exchange.
The telephone network has had roughly this same topology for most of the
last hundred years and still has it today, but many of the details about how the
network works have changed. In particular, at the trunk level some telephone
networks are no longer circuit switched. Instead they are now digital packet
switched networks that work in a manner not dissimilar from the Internet,
with voice calls digitized, broken into packets, and transmitted over optical
ﬁber links. Only the “last mile” to the subscriber’s telephone is still carried on
an old-fashioned dedicated circuit, and even that is changing with the advent
of digital and Internet telephone services. Nonetheless, in terms of geometry
and topology the structure of the phone network is much the same as it has always been, being dictated in large part by the constraints of geography and the
propensity for people to talk more often to others in their geographic vicinity
than to those further away.

2.3

P OWER GRIDS

The topology of power grids has received occasional study in the networks literature [16, 323]. A power grid, in this context, is the network of high-voltage
transmission lines that provide long-distance transport of electric power within
and between countries. Low-voltage local power delivery lines are normally
excluded. The vertices in a power grid correspond to generating stations and
switching substations, and the edges correspond to the high-voltage lines. The
topology of power grids is not difﬁcult to determine. The networks are usually overseen by a single authority and complete maps of grids are readily
available. Indeed, very comprehensive data on power grids (as well as other
energy-related networks such as oil and gas pipelines) are available from specialist publishers, either on paper or in electronic form, if one is willing to pay
for them.
There is much of interest to be learned by looking at the structure of power
grids. Like the Internet, power grids have a spatial aspect; the individual vertices each have a location somewhere on the globe, and their distribution in
space is interesting from geographic, social, and economic points of view. Network statistics, both geographic and topological, may provide insight into the
global constraints governing the shape and growth of grids. Power grids also
display some unusual behaviors, such as cascading failures, which can give
rise to surprising results such as the observed power-law distribution in the
31

T ECHNOLOGICAL NETWORKS

sizes of power outages [92].
However, while there is a temptation to apply simple models of the kind
described in this book to try to explain these and other results, it is wise to
be cautious. Power grids are very complicated systems. The ﬂow of power is
governed not only by simple physical laws, but also by precise and detailed
control of the phases and voltages across transmission lines, monitored and
adjusted on rapid timescales by sophisticated computer systems and on slower
timescales by human operators. It turns out that power failures and other
power-grid phenomena are inﬂuenced relatively little by the raw topology of
the network and much more by operator actions and software design, and as
a result network theory has not, so far, been very successful at shedding light
on the behavior of power grids.

2.4

T RANSPORTATION NETWORKS

A moderate amount of work has been done on the structure and function of
transportation networks such as airline routes and road and rail networks. The
structure of these networks is not usually hard to determine, although compiling the data may be laborious. Airline networks can be reconstructed from
published airline timetables, road and rail networks from maps. Geographic
information systems (GIS) software can be useful for speeding the compilation
of transportation data, and there are also a variety of online resources providing useful information such as latitude and longitude of airports.
One of the earliest examples of a study of a transportation network is the
study by Pitts [268] of waterborne transport on Russian rivers in the Middle
Ages. There was also a movement among geographers in the 1960s and 70s to
study road and rail networks, particularly focusing on the interplay between
their economics and their physical structure. The most prominent name in the
movement was that of Karel Kansky, and his book on transportation networks
is a good point of entry into that body of literature [168].
More recently a number of authors have produced studies applying new
network analysis ideas to road, rail, and air networks [16, 136, 294]. In most
of the networks studied the vertices represent geographic locations and the
edges routes between them. For instance, in studies of road networks the vertices usually represent road intersections and the edges roads. The study by
Sen et al. [294] of the rail network of India provides an interesting counterexample. Sen et al. argue, plausibly, that in the context of rail travel what matters
to most people is whether there is a direct train to their destination or, if there
is not, how many trains they will have to take to get there. People do not care
so much about how many stops there are along the way, so long as they don’t
32

2.5

|

D ELIVERY AND DISTRIBUTION NETWORKS

have to change trains. Thus, Sen et al. argue, a useful network representation
in the case of rail travel is one in which the vertices represent locations and two
vertices are connected by an edge if a single train runs between them. Then the
distance between two vertices in the network—the number of edges you need
to traverse to get from A to B—is equal to the number of trains you would
have to take. A better representation still (although Sen et al. did not consider
it) would be a “bipartite network,” a network containing two types of vertex,
one representing the locations and the other representing train routes. Edges
in the network would then join locations to the routes that run through them.
The ﬁrst, simpler representation of Sen et al. can be derived from the bipartite
one by making a “one-mode projection” onto the locations only. Bipartite networks and their projections are discussed in greater detail in Section 6.6.

2.5

D ELIVERY AND DISTRIBUTION NETWORKS

Falling somewhere between transportation networks and power grids are the
distribution networks, about which relatively little has been written within the
ﬁeld of networks research. Distribution networks include things like oil and
gas pipelines, water and sewerage lines, and the routes used by the post ofﬁce
and package delivery and cargo companies. Figure 2.5 shows one example, the
European gas distribution network, taken from a study by Carvalho et al. [64],
who constructed the ﬁgure from data purchased from industry sources. In this
network the edges are gas pipelines and the vertices are their intersections,
including pumping, switching, and storage facilities and reﬁneries.
If one is willing to interpret “distribution” in a loose sense, then one class of
distribution networks that has been relatively well studied is river networks,
though if one wants to be precise river networks are really collection networks,
rather than distribution networks. In a river network the edges are rivers or
streams and the vertices are their intersections. Like road networks no special
techniques are necessary to gather data on the structure of river networks—the
hard work of surveying the land has already been done for us by surveyors
and cartographers, and all we need do is copy the results off their maps. See
Fig. 2.6 for an example of a river network.
The topological and geographic properties of river networks have been
studied in some detail [94, 208, 284]. Of particular note is the fact that river
networks, to an excellent approximation, take the form of trees. That is, they
contain no loops (if one disregards the occasional island midstream), a point
that we discuss in more detail in Section 6.7.
Similar in some respects to river networks are networks of blood vessels
in animals, and their equivalents in plants, such as root networks. These too
33

T ECHNOLOGICAL NETWORKS

Figure 2.5: The network of natural gas pipelines in Europe. Thickness of lines indicates the sizes of the pipes. Figure
created by R. Carvalho et al. [64]. Copyright 2009 American Physical Society. Reproduced with permission.

have been studied at some length. An early example of a mathematical result
in this area is the formula for estimating the total geometric length of all edges
in such a network by observing the number of times they intersect a regular
array of straight lines [231]. This formula, whose derivation is related to the
well-known “Buffon’s needle” experiment for determining the value of π, is
most often applied to root systems, but there is no reason it could not also be
useful in the study of river networks or, with suitable modiﬁcation, any other
34

2.5

|

D ELIVERY AND DISTRIBUTION NETWORKS

Figure 2.6: Drainage basin of the Loess Plateau. The network of rivers and streams on the Loess Plateau in the Shanxi
province of China. The tree-like structure of the network is
clearly visible—there are no loops in the network, so water at
any point in the network drains off the plateau via a single
path. Reproduced from Pelletier [266] by permission of the
American Geophysical Union.

type of geographic network.
Also of note in this area is work on the scaling relationships between the
structure of branching vascular networks in organisms and metabolic processes [26, 325, 326], an impressive example of the way in which an understanding of network structure can be parlayed into an understanding of the
functioning of the systems the networks represent. We will see many more
examples during the course of this book.

35

C HAPTER 3

S OCIAL NETWORKS
A discussion of social networks and the empirical
techniques used to probe their structure

S

OCIAL networks are networks in which the vertices are people, or some-

times groups of people, and the edges represent some form of social interaction between them, such as friendship. Sociologists have developed their
own language for discussing networks: they refer to the vertices, the people,
as actors and the edges as ties. We will sometimes use these words when discussing social networks.
We begin this chapter with a short summary of the origins and research focus of the ﬁeld of social networks, before describing in detail some of the techniques used to discover social network structure. The material in this chapter
forms the basis for understanding many of the social network examples that
appear in the rest of the book.

3.1

T HE EMPIRICAL STUDY OF SOCIAL NETWORKS

To most people the words “social network,” if they mean anything, refer to
online social networking services such as Facebook and MySpace. The study of
social networks, however, goes back far farther than the networks’ modernday computer incarnations. Indeed, among researchers who study networks,
sociologists have perhaps the longest and best established tradition of quantitative, empirical work. There are clear antecedents of social network analysis
to be found in the literature as far back as the end of the nineteenth century.
The true foundation of the ﬁeld, however, is usually attributed to psychiatrist
Jacob Moreno, a Romanian immigrant to America who in the 1930s became
interested in the dynamics of social interactions within groups of people. At a

36

3.1

|

T HE EMPIRICAL STUDY OF SOCIAL NETWORKS

Figure 3.1: Friendships between schoolchildren. This
early hand-drawn image of a social network, taken from
the work of psychiatrist Jacob Moreno, depicts friendship
patterns between the boys (triangles) and girls (circles) in a
class of schoolchildren in the 1930s. Reproduced from [228]
by kind permission of the American Society of Group Psychotherapy and Psychodrama.

medical conference in New York City in March 1933 he presented the results
of a set of studies he had performed that may have been the ﬁrst true social
network studies, and the work attracted enough attention to merit a column
in the New York Times a few days later. A year after that Moreno published a
book entitled Who Shall Survive? [228] which, though not a rigorous work by
modern standards, contained the seeds of the ﬁeld of sociometry, which later
became social network analysis.
Moreno called his diagrams of human interaction sociograms, rather than
social networks (a term not coined until about twenty years later), but in everything but name they are clearly what we now know as networks. Figure 3.1, for
instance, shows a hand-drawn ﬁgure from Moreno’s book, depicting friendships within a group of schoolchildren. The triangles and circles represent
boys and girls respectively and the ﬁgure reveals, among other things, that
there are many friendships between two boys or two girls, but few between a
boy and a girl. It is simple conclusions like this, that are both sociologically interesting and easy to see once one draws a picture of the network, that rapidly
persuaded social scientists that there was merit in Moreno’s methods.
One of the most important things to appreciate about social networks is
that there are many different possible deﬁnitions of an edge in such a network
and the particular deﬁnition one uses will depend on what questions one is
interested in answering. Edges might represent friendship between individuals, but they could also represent professional relationships, exchange of goods
or money, communication patterns, romantic or sexual relationships, or many
other types of connection. If one is interested, say, in professional interactions
37

S OCIAL NETWORKS

between the boards of directors of Fortune 500 companies, then a network of
who is dating whom or who looks at who else’s Facebook page is probably
not of much use. Moreover, the techniques one uses to probe different types
of social interaction can also be quite different, so that different kinds of social
network studies are typically needed to address different kinds of questions.
Direct questioning of experimental subjects is probably the most common
method of determining the structure of social networks. We discuss it in detail
in Section 3.2. Another important technique, the use of archival records (Sections 3.4 and 3.5), is illustrated by a different early example of a social network
study. It was, apparently, a common practice in the US in the 1930s for newspapers to report on the public appearances of society women, and Davis, Gardner, and Gardner made use of this in a study of a social network of 18 women
in a city in the American south. This study, often referred to in the literature
as the “Southern Women Study,” was described in a book by the researchers
published in 1941 [86], although it was based on data from 1939. They took a
sample of 14 social events attended by the women in question and recorded
which women attended which events. Women in this network may be considered connected if they attended a common event. An alternative and more
complete representation of the data is as an “afﬁliation network” or “bipartite
graph,” a network with two types of vertex, representing the women and the
events, with edges connecting each woman to the events she attended. A visualization of the afﬁliation network for the Southern Women Study is shown
in Fig. 3.2. One reason why this study has become so well known, in addition
to its antiquity, is that the women were found by the researchers to split into
two subgroups, tightly knit clusters of acquaintances with only rather loose
between-cluster interaction. A classic problem in social network analysis is
to devise a method or algorithm that can discover and extract such clustering
from raw network data, and quite a number of researchers have made use of
the Southern Women data as a test case for the development of such methods.
Afﬁliation networks receive further attention in Section 3.5.
Such is the power of social network analysis that its techniques have, since
Moreno and Davis et al., been applied to an extraordinary variety of different communities, issues, and problems, including friendship and acquaintance
patterns in local communities and in the population at large [36, 37, 175, 219,
311], and among students [334] and schoolchildren [112, 225, 277], contacts between business people and other professionals [78, 134], boards of directors
of companies [87, 88, 207], collaborations of scientists [145, 146, 236], movie actors [16, 323], and musicians [139], sexual contact networks [183, 198, 272, 285]
and dating patterns [34], covert and criminal networks such as networks of
drug users [289] or terrorists [191], historical networks [259], online commu38

N
ov
em
be
r2
A
ug
1
us
t3

Ju
ne
10
Fe
br
ua
ry
23
A
pr
il
7

r1
6
8

be
il
pr
A

15

em

ar
ch

Se
pt

M

19

25
M
ay

ua
ry

be
em

Fe
br

12

pt
Se

2

A
pr
il

ar
ch

M

so
en
n
da
Ro
lo
g
e
tte
rs
M
Fr
cD
an
o
ce
w
d
sA
nd
er
s
on
El
ea
no
Pe
rN
ar
lO
ye
gl
et
ho
Ru
rp
e
th
D
V
e
er
S
a
ne
nd
Sa
nd
er
so
M
n
yr
aL
K
id
at
he
de
rin
ll
eR
Sy
o
ge
lv
ia
rs
A
vo
nd
al
N
e
or
aF
ay
et
H
te
el
D
en
or
Ll
ot
hy
oy
d
M
ur
c
hi
O
liv
so
n
ia
Ca
rle
to
n
Fl
or
aP
ric
e

lle

I NTERVIEWS AND QUESTIONNAIRES

ar

Ch

Br

vi

|

dn
er

aA
es

Th
er

aM
ur

La

Ev
el

yn

Je

an

de

ffe

rs

on

Ju
ne

27

r2

6

3.2

Figure 3.2: The afﬁliation network of the “Southern Women Study.” This network
(like all afﬁliation networks) has two types of vertex, the open circles at the bottom representing the 18 women who were the subjects of the study and the shaded circles at the
top representing the social events they attended. The edges connect each woman to the
events she attended, as deduced from newspaper reports. Data courtesy of L. Freeman
and originally from Davis et al. [86].

nities such as Usenet [204, 300, 312] or Facebook [196], and social networks of
animals [205, 286, 287].
We will see some examples of these and other networks throughout this
book and we will give details as needed as we go along. The rest of the present
chapter is devoted to a discussion of the different empirical methods used to
measure social networks. The two techniques described above, namely direct
questioning of subjects and the use of archival records, are two of the most
important, but there are several others that ﬁnd regular use. This chapter does
not give a complete review of the subject—for that we refer the reader to specialized texts such as those of Wasserman and Faust [320] and Scott [293]—but
we introduce as much material as will be needed for the later chapters of the
book, while at the same time, we hope, giving some ﬂavor for the challenges
of empirical study in the ﬁeld of social networks.

3.2

I NTERVIEWS AND QUESTIONNAIRES

The most common general method for accumulating data on social networks
is simply to ask people questions. If you are interested in friendship networks,
then you ask people who their friends are. If you are interested in business
39

S OCIAL NETWORKS

relationships you ask people who they do business with, and so forth. The
asking may take the form of direct interviews with participants or the completion by participants of questionnaires, either on paper or electronically. Indeed many modern studies, particularly surveys conducted by telephone, employ a combination of both interviews and questionnaires, wherein a professional interviewer reads questions from a questionnaire to a participant. By
using a questionnaire, the designers of the study can guarantee that questions
are asked, to a good approximation, in a consistent order and with consistent wording. By employing an interviewer to do the asking the study gains
ﬂexibility and reliability: interviewees often take studies more seriously when
answering questions put to them by a human being, and interviewers may be
given some latitude to probe interviewees when they are unclear, unresponsive, or confused. These are important considerations, since misunderstanding and inconsistent interpretation of survey questions are substantial sources
of error. By making questions as uniform as possible and giving respondents
personal help in understanding them, these errors can be reduced. A good introduction to social survey design and implementation has been given by Rea
and Parker [279].
To ﬁnd out about social networks, surveys typically employ a name generator, an item or series of items that invite respondents to name others with
whom they have contact of a speciﬁed kind. For example, in their classic study
of friendship networks among schoolchildren, Rapoport and Horvath [277]
asked children to complete a questionnaire that included items worded as follows:1
My best friend at
Junior High School is:
My second-best friend at
Junior High School is:
Junior High School is:
My third-best friend at
..
.
My eighth-best friend at

Junior High School is:

” in the questionnaire were ﬁlled in with the appropriate
The blanks “
school name. The list stopped at the eighth-best friend and many children
did not complete all eight.
Ideally all students within the school would be surveyed, though Rapoport
and Horvath reported that in their case a few were absent on the day the survey was conducted. Note that the survey speciﬁcally asks children to name
1

A junior high school in the United States is a school for children aged approximately 12 to 14
years.

40

3.2

|

I NTERVIEWS AND QUESTIONNAIRES

only friends within the school. The resulting network will therefore record
friendship ties within the school but none to individuals outside. Since all
social network studies are limited to some community or portion of the population, and since it is highly unlikely that such a community will have ties
solely within the community and none outside, all surveys must make some
decision about how to deal with ties to outside individuals. Sometimes they
are recorded. Sometimes, as here, they are not. Such details can be important since statistics derived from the survey results will often depend on the
decisions made.
There are some points to notice about the data produced by name generators. First, the network ties, friendships in the case above, are determined by
one respondent nominating another by name. This is a fundamentally asymmetric process. Individual A identiﬁes individual B as their friend. In many
cases B will also identify A as their friend, but there is no guarantee that this
will happen and it is not uncommon for nomination to go only one way. We
normally think of friendship as a two-way type of relationship, but surveys
suggest that this not always the case. As a result, data derived from name
generators are often best represented as directed networks, networks in which
edges run in a particular direction from one vertex to another. If two individuals nominate each other then we have two directed edges, one pointing
in either direction. Each vertex in the network also has two degrees, an outdegree—the number of friends identiﬁed by the corresponding individual—
and an in-degree—the number of others who identiﬁed the individual as a
friend.
This brings us to a second point about name generators. It is common,
as in the example above, for the experimenter to place a limit on the number
of names a respondent can give. In the study of Rapoport and Horvath, this
limit was eight. Studies that impose such a limit are called ﬁxed choice studies.
The alternative is to impose no limit. Studies that do this are called free choice
studies.
Limits are often imposed purely for practical purposes, to reduce the work
the experimenter must do. However, they may also help respondents understand what is required of them. In surveys of schoolchildren, for instance, there
are some children who, when asked to name all their friends, will patiently
name all the other children in the entire school, even if there are hundreds of
them. Such responses are not particularly helpful in surveys—almost certainly
the children in question are employing a deﬁnition of friendship different from
that employed by most of their peers and by the investigators.
However, limiting the number of responses is for most purposes undesirable. In particular, it clearly limits the out-degree of the vertices in the net-

We encountered directed
networks previously in
Chapter 1, in our discussion of the World Wide
Web, and they are discussed in more detail in
Section 6.4.

41

S OCIAL NETWORKS

work, imposing an artiﬁcial and possibly unrealistic cut-off. As discussed in
Chapter 1, an interesting property of many networks is the existence of a small
number of vertices with unusually high degree, and it is known that in some
cases these vertices, though few in number, can have a dominant effect on the
behavior of the network as a whole. By employing a name generator that artiﬁcially cuts off the degree, any information about the existence of such vertices
is lost.
It is worth noticing, however, that even in a ﬁxed-choice study there is normally no limit on the in-degree of vertices in the network; there is no limit to
the number of times an individual can be nominated by others. And indeed in
many networks it is found that a small number of individuals are nominated
an unusually large number of times. Rapoport and Horvath [277] observed
this in their friendship networks: while most children in a school are nominated as a friend of only a few others, a small number of popular children are
nominated very many times. Rapoport and Horvath were some of the ﬁrst scientists in any ﬁeld to study quantitatively the degree distribution of a network,
reporting and commenting extensively on the in-degrees in their friendship
networks.
Not all surveys employing name generators produce directed networks.
Sometimes we are interested in ties that are intrinsically symmetric between
the two parties involved, in which case the edges in the network are properly
represented as undirected. An example is networks of sexual contact, which
are widely studied to help us understand the spread of sexually transmitted
diseases [183,198,272,285]. In such networks a tie between individuals A and B
means that A and B had sex. While participants in studies sometimes do not
remember who they had sex with or may be unwilling to talk about it, it is
at least in principal a straightforward yes-or-no question whether two people
had sex, and the answer should not depend on which of the two you ask.2 In
such networks therefore, ties are normally represented as undirected.
Surveys can and often do ask respondents not just to name those with
whom they have ties but to describe the nature of those ties as well. For instance, questions may ask respondents to name people they both like and dislike, or to name those with whom they have certain types of contact, such as
socializing together, working together, or asking for advice. For example, in a
study of the social network of a group of medical doctors, Coleman et al. [78]
asked respondents the following questions:

2
One can, by asking both, make some estimate of the accuracy of the survey. If individuals’
responses disagree too often, it is a clear sign that the reliability of the responses is poor.

42

3.2

|

I NTERVIEWS AND QUESTIONNAIRES

Who among your colleagues do you turn to most often for advice?
With whom do you most often discuss your cases in the course of an
ordinary week?
Who are the friends among your colleagues who you see most often
socially?
The names of a maximum of three doctors could be given in response to each
question. A survey such as this, which asks about several types of interactions,
effectively generates data on several different networks at once—the network
of advice, the discussion network, and so forth.
Surveys may also pose questions aimed at measuring the strength of ties,
asking for instance how often people interact or for how long, and they may
ask individuals to give a basic description of themselves: their age, income,
education, and so forth. Some of the most interesting results of social network
studies concern the extent to which people’s choice of whom they associate
with reﬂects their own background and that of their associates. For instance,
you might choose to socialize primarily with others of a similar age to yourself,
but turn for advice to those who are older than you.
The main disadvantages of network studies based on direct questioning
of participants are that they are ﬁrst laborious and second inaccurate. The
administering of interviews or questionnaires and the collation of responses is
a demanding job that has been only somewhat helped in recent years by the
increasing availability of computers and the use of online survey tools. Most
studies have been limited to a few tens or at most hundreds of respondents—
the 34-vertex social network of Fig. 1.2 is a typical example. It is a rare study
that contains more than a thousand actors, and studies such as the National
Longitudinal Study of Adolescent Health,3 which compiled responses from
over 90 000 participants, are very unusual and extraordinarily costly. Only
a substantial public interest such as, in that case, the control of disease, can
justify their funding.
Data based on direct questioning are also plagued by uncontrolled biases.
Answers given by respondents are always, to some extent, subjective. If you
ask people who their friends are, different people will interpret “friend” in different ways and thus give different kinds of answers. Investigators do their
best to pose questions and record answers in a uniform fashion, but it is inevitable that inconsistencies will be present in the ﬁnal data and anyone who
has ever conducted a survey knows this well. This problem is not unique to
social network studies. Virtually all social surveys suffer from such problems
3

See www.cpc.unc.edu/projects/addhealth.

43

S OCIAL NETWORKS

and a large body of expertise has been developed concerning techniques for
dealing with them. Nonetheless, one should bear in mind when dealing with
any social network data derived from interviews or questionnaires the possibility of uncontrolled experimental bias in the results.
3.2.1

Alters

Ego

An ego-centered network
consisting of an ego and
ﬁve alters.

E GO - CENTERED NETWORKS

Studies of the type described in the previous section, in which all or nearly all
of the individuals in a community are surveyed, are called sociometric studies,
a term coined by Jacob Moreno himself (see the discussion at the beginning of
this chapter). For the purposes of determining network structure, sociometric
studies are desirable; unless we survey all or nearly all of the population of
interest, there is no way we can reconstruct the complete network of ties within
that population. However, as discussed at the end of the preceding section,
sociometric studies also require a lot of work and for large populations may
simply be infeasible.
At the other end of the spectrum lie studies of personal networks or egocentered networks.4 An ego-centered network is the network surrounding one
particular individual, meaning, usually, the individual surveyed and his or her
immediate contacts. The individual surveyed is referred to as the ego and the
contacts as alters.
The typical survey of this kind is conducted using direct questioning techniques similar to those discussed in Section 3.2, with interviews, questionnaires, or a combination of both being the instruments of choice. One might,
for instance, select a sample of the target population at random,5 and ask them
to identify all those with whom they have a certain type of contact. Participants might also be asked to describe some characteristics both of themselves
and of their alters, and perhaps to answer some other simple questions, such
as which alters also have contact with one another.
Obviously surveys of this type, and studies of ego-centered networks in
general, cannot reveal the structure of an entire network. One receives snapshots of small local regions of the network, but in general those regions will
not join together to form a complete social network. There are cases, however, where we are primarily interested in local network properties, and ego4
Such networks are also called egocentric networks, although this term, which has its origins
in social science and psychology, has taken on a different lay meaning which prompts us to avoid
its use here.
5

This can be done, for example, by random-digit dialing, the practice of calling random telephone numbers in the target area and surveying those who answer.

44

3.2

|

I NTERVIEWS AND QUESTIONNAIRES

centered network studies can give us good data about these. For example, if
we wish to know about the degrees of vertices in a network then a study in
which a random sample of people are each asked to list their contacts can give
us reasonable degree statistics. (Studies probing vertex degrees are discussed
more below.) If we also gather data on the contacts between alters, we can estimate clustering coefﬁcients (see Section 7.9). If we have data on characteristics
of egos and alters we can measure assortative mixing (Sections 7.13 and 8.7).
An example of a study gathering ego-centered network data is the General Social Survey (GSS) [59], a large-scale survey conducted every year in the
United States since 1972 (every two years since 1994). The GSS is not primarily a social network study. The purpose of the study is to gather data about
life in the United States, how it is changing, and how it differs from or relates
to life in other societies. The study contains a large number of items ranging
from general questions probing the demographics and attitudes of the participants, to speciﬁc questions about recent events, political topics, or quality of
life. However, among these many items there are in each iteration of the survey a few questions about social networks. The precise number and wording
of these questions changes from one year to another, but here some examples
from the survey of 1998, which was fairly typical:
From time to time, most people discuss important matters with other
people. Looking back over the last six months, who are the people
with whom you discussed matters important to you? Do you feel
equally close to all these people?
Thinking now of close friends—not your husband or wife or partner
or family members, but people you feel fairly close to—how many
close friends would you say you have? How many of these close
friends are people you work with now? How many of these close
friends are your neighbors now?
And so on. By their nature these questions are of a “free choice” type, the
number of friends or acquaintances the respondent can name being unlimited,
although (and this is a criticism that has been leveled at the survey) they are
also quite vague in their deﬁnitions of friends and acquaintances, so people
may give answers of widely varying kinds.
Another example of an ego-centered network study is the study by Bernard
et al. [36, 37, 175, 213] of the degree of individuals in acquaintance networks
(i.e., the number of people that people know). It is quite difﬁcult to estimate
how many people a person knows because most people cannot recall at will all
those with whom they are acquainted and there is besides a large amount of
variation in people’s subjective deﬁnition of “knowing.” Bernard et al. came up
with an elegant experimental technique to circumvent these difﬁculties. They
45

S OCIAL NETWORKS

asked people to read through a list containing a sample of several hundred
family names drawn from a telephone directory.6 Participants counted up how
many people they knew with names appearing on the list. Each person with a
listed name was counted separately, so that two acquaintances called “Smith”
would count as two people. They were instructed to use the following precise
deﬁnition of acquaintance:
You know the person and they know you by sight or by name; you
can contact them in person by telephone or by mail; and you have
had contact with the person in the past two years.
(Of course, many other deﬁnitions are possible. By varying the deﬁnition,
one could probe different social networks.) Bernard et al. then fed the counts
reported by participants into a statistical formula to estimate the total number
of acquaintances of each participant.
Bernard et al. repeated their study with populations drawn from several different cities and the results varied somewhat from city to city, but overall they
found that the typical number of acquaintances, in the sense deﬁned above, of
the average person in the United States is on the order of about 2000. In the city
of Jacksonville, Florida, for instance, they found a ﬁgure of 1700, while in Orange County, California they found a ﬁgure of 2025. Many people ﬁnd these
numbers surprisingly high upon ﬁrst encountering them, perhaps precisely
because we are poor at recalling all of the many people we know. But repeated
studies have conﬁrmed ﬁgures of the same order of magnitude, at least in the
United States. In some other countries the ﬁgures are lower. In Mexico City,
for instance, Bernard et al. estimated that the average person knows about 570
others.

3.3

D IRECT OBSERVATION

An obvious method for constructing social networks is direct observation. Simply by watching interactions between individuals one can, over a period of
time, form a picture of the networks of unseen ties that exist between those individuals. Most of us, for instance, will be at least somewhat aware of friendships or enmities that exist between our friends or coworkers. In direct observation studies, researchers attempt to develop similar insights about the
members of the population of interest.
6

Some care must be taken in the selection of the names, since the frequency of occurrence of
names varies considerably, both from name to name, and geographically and culturally.

46

3.4

|

D ATA FROM ARCHIVAL OR THIRD - PARTY RECORDS

Direct observation tends to be a rather labor-intensive method of study,
so its use is usually restricted to rather small groups, primarily ones with
extensive face-to-face interactions in public settings. In Chapter 1 we saw
one such example, the “karate club” network of Zachary [334]. Another example is the study by Freeman et al. [131, 132] of the social interactions of
windsurfers on a beach. The experimenters simply watched the individuals
in question and recorded the length in minutes of every pairwise interaction
among them. A large number of direct-observation network data sets were
compiled by Bernard and co-workers during the 1970s and 80s as part of a
lengthy study of the accuracy of individuals’ perception of their own social
situation [38, 40, 41, 173]. These include data sets on interactions between students, faculty, and staff in a university department, on members of a university
fraternity,7 on users of a teletype service for the deaf, and several other examples.
One arena in which direct observation is essentially the only viable experimental technique is in studies of the social networks of animals—clearly animals cannot be surveyed using interviews or questionnaires. One method is
to record instances of animal pairs engaging in recognizable social behaviors
such as mutual grooming, courting, or close association and then to declare ties
to exist between the pairs that engage in these behaviors most often [205]. Not
all animal species form interesting or useful social networks, but informative
studies have been performed of, amongst others, monkeys [121, 286, 287], kangaroos [143], and dolphins [80, 205]. Networks in which the ties represent aggressive behaviors have also been reported, such as networks of baboons [214],
wolves [163, 316], and ants [77]. In cases where aggressive behaviors normally
result in one animal’s establishing dominance over another the resulting networks can be regarded as directed and are sometimes called dominance hierarchies [90, 91, 101].

3.4

D ATA FROM ARCHIVAL OR THIRD - PARTY RECORDS

An increasingly important, voluminous, and often highly reliable source of
social network data is archival records. Such records are, sometimes at least,
relatively free from the vagaries of human memory and are often impressive
in their scale, allowing us to construct networks of a size that would require
far more effort were other techniques used.
7
In American universities a “fraternity” is a semi-independent boarding house for male students.

47

S OCIAL NETWORKS

Lamberteschi
Bischeri

Peruzzi

Guadagni
Strozzi
Castellani

Tornabuoni

Ridolfi
Barbadori

Figure 3.3: Intermarriage network of the ruling families of Florence. In this network the vertices represent
ﬁfteenth century Florentine families and the edges represent ties of marriage between them. After Padgett and
Ansell [259].

Albizzi

Ginori

Medici

Acciaiuoli

Salviati

Pazzi

A well-known small example of a study based on archival records is the
study by Padgett and Ansell of the ruling families of Florence in the ﬁfteenth
century [259]. In this work, the investigators looked at contemporaneous historical records to determine which among the families had trade relations, marriage ties, or other forms of social contact with one another. Figure 3.3 shows
one of the resulting networks, a network of intermarriages between 15 of the
families. It is notable that the Medici family occupies a central position in this
network, having marriage ties with members of no fewer than six other families. Padgett and Ansell conjectured that it was by shrewd manipulation of
social ties such as these that the Medici rose to a position of dominance in Florentine society.
In recent years, with the widespread availability of computers and online
databases, many more networks have been constructed from records of various types. A number of authors, for example, have looked at email networks [103, 313]. Drawing on email logs—automatic records kept by email
servers of messages sent—it is possible to construct networks in which the
vertices are people (or more correctly email addresses) and the directed edges
between them are email messages. Exchange of email in such a network can
be taken as a proxy for acquaintance between individuals, or we may be interested in the patterns of email exchange for some other reason. For instance,
email messages can carry computer viruses and a knowledge of the structure
of the network of messages may help us to predict and control the spread of
48

3.4

|

D ATA FROM ARCHIVAL OR THIRD - PARTY RECORDS

those viruses.
Another form of email network is the network formed by email address
books. An email address book is a computer ﬁle in which a computer user
stores, for convenience, the email addresses of his or her regular correspondents. The set of all such address books can be regarded as deﬁning a network in which the vertices represent the owners of the address books, and
there is a directed edge from vertex A to vertex B if person B’s address appears
in person A’s address book. This network is again of interest in the study of
computer viruses, since some viruses search address books for the addresses of
new victims to infect and hence spread over the address book network. Similar
networks can also be constructed for other forms of electronic communication
that use address books, such as instant messaging [301].
A form of network similar to but older than the email network is the telephone call graph. In such a network the vertices represent telephone numbers
and directed edges between them represent telephone calls from one number
to another. Call graphs can be reconstructed from call logs kept by telephone
companies, although such logs are generally proprietary and not easily available outside of those companies, and call graphs have as a result only occasionally been examined in the scientiﬁc literature [1, 9, 258].
Recent years have seen the rapid emergence of online social networking
services, such as Facebook and LinkedIn, which exist primarily to promote, document, and exploit the networks of contacts between individuals. As a natural part of their operation, these services build records of connections between their participants and hence provide, at least in principle, a rich source
of archival network data. These data, however, like those for telephone calls,
are largely proprietary to the companies operating the services and hence quite
difﬁcult to get hold of. So far only a few studies have been published of online
social networks [53], but internal studies have no doubt been performed by the
companies themselves and it is only a matter of time before more data become
publicly available.
A few other online communities, not explicitly oriented towards networks,
have been studied using network techniques. For instance, Holme et al. [158]
took records of interactions between members of a Swedish dating website
and reconstructed from them the network of interactions between the site’s
members. This study was unusual in that the network was time-resolved—
the date and time of each interaction were recorded, allowing investigators to
reconstruct after the fact the timing and duration of contacts between individuals. Most of the sources of network data considered in this book are not timeresolved, but many of the networks they correspond to do nonetheless change
over time. Time-resolved network studies, or longitudinal studies, as they are

Telephone call graphs
are quite distinct from
the physical network of
telephone cables discussed
in Section 2.2. Indeed, a
call graph is to the physical
telephone network roughly
as an email network is to
the Internet.

49

S OCIAL NETWORKS

called in sociology, are certainly a growth area to watch for in the future.
Another source of network data representing online communities is the Internet newsgroup system Usenet, a worldwide online message-board system
that allows users to post messages on a large variety of topics. Messages are
date and time stamped and identiﬁed with the name or email address of the
poster along with a unique reference number that allows a poster to indicate
when a posting is a reply or follow-on to a previous posting. Thus one can
reconstruct the thread of the conversation taking place in a newsgroup, and
in particular assemble a network in which the vertices are posters and the
edges represent a response by one poster to a posting by another. Studies of
newsgroup networks of this kind have been performed by a number of authors [204, 300, 312].
Weblogs and online journals are another source of online social network
data. Online journals of various kinds have become popular on the World
Wide Web since around the turn of the century. On these websites the proprietor posts whatever thoughts he or she cares to make public, along with links
to sites maintained by others. These links form a directed network that lies,
in terms of semantic content, somewhere between a social network and the
World Wide Web; the links are often informational—the linker wishes to bring
to his or her readers’ attention the contents of the linked site—but there is a
strong social element as well, since people often link to sites operated by their
friends or acquaintances. This trend is particularly noticeable within journal
communities such as LiveJournal and among weblogs devoted to speciﬁc topics, such as science or politics. The structure of the networks of links can be
extracted using “crawlers” similar to those used to search the Web—see Section 4.1. Studies of journals and weblogs have been performed for example by
Adamic and Glance [4] and MacKinnon and Warren [206].
An interesting network that has features of both a social and a technological
network is the network of trust formed by a set of cryptographic keys. Cryptosystems or cyphers (i.e., secret codes), long associated in the public mind with
spies and skulduggery, have become a crucial part of the twenty-ﬁrst-century
economy, used to protect important data, particularly ﬁnancial data such as
credit card numbers, from theft and misuse. An important advance, central
to the widespread and convenient use of cryptography, was the development
in the 1970s of public-key cryptography. In traditional cryptosystems, two parties wishing to exchange messages must share a key that they use to encode
and decode the messages. The key is typically a large number, which is used
in combination with the chosen cryptosystem to dictate exactly how messages
are converted from their original “plain text” form into code and back again.
This key, which allows anyone possessing it to decode the messages, must be
50

3.4

|

D ATA FROM ARCHIVAL OR THIRD - PARTY RECORDS

kept secret from any malicious snoopers, and this raises the difﬁcult problem
of how the parties in question agree on the key in the ﬁrst place. Usually the
key is generated by a computer program run by one party, but then it must be
transmitted securely to the other party without anyone else seeing it. Sending the key over the Internet unencrypted would pose a signiﬁcant risk of detection. Physical transmission, for example by conventional mail, would be
reasonably secure, but would take a long time. Most customers buying goods
over the Internet would not want to wait a week for a secret key to arrive by
mail from their vendor.
These problems were solved with the invention of public-key cryptography
in the 1970s. Public-key cryptosystems make use of any of several different
asymmetric cyphers in which two different keys are used. One key, called the
public key, is employed in the computer algorithm that converts the message
from plain text into its encrypted form, but a different key, the private key, is
needed to decrypt the message. The public key cannot be used for decryption.8
The two keys are generated as a pair by one of the two parties wishing to
exchange information and the public key is sent openly over the Internet or
other channel to the second party. The private key remains the secret property
of the ﬁrst party and is not shared. The second party can then send messages
to the ﬁrst by encoding them with the public key and only the ﬁrst party can
decode them.9 Although the public key can be intercepted by a third party in
transmission, it will do the third party no good, since the public key cannot
be used to decode messages, only to encode them. Indeed, in many cases,
users of public-key systems deliberately broadcast their public keys to anyone
who might want them, inviting the world to send them encoded messages,
messages which only they can decode. It is from such practices that the name
“public-key cryptography” arises.
Some asymmetric cyphers can also be used in the reverse direction. That is,
8
Technically, the public key can be used to decrypt the message, but the calculation involved
is extraordinarily complex and would take years or even centuries of effort on the fastest modern
computers. For practical purposes, therefore, one can only decrypt the message if one has the
private key.
9
In practice it is a little more complicated than this. Asymmetric cyphers are computationally
demanding to implement, far more so than the traditional (but less secure) symmetric cyphers in
which the same key is used by both parties. To reduce demands on computer time, therefore, one
usually uses the asymmetric cypher only to transmit from one party to the other a key for use
in a symmetric cypher, and then the symmetric cypher, with that key, is used for all subsequent
communications. In this way one beneﬁts from the security of public-key cryptography without
the computational overhead. For our purposes in this section, however, this is just a technical
detail.

51

S OCIAL NETWORKS

one can encode a message with the private key and it can only be decoded with
the public key. Why would one want to do this, when everyone has the public
key? The answer is that you can use it to prove your identity. Someone talking to you over the Internet, say, may want to be certain that you are who you
claim to be (rather than some nefarious interloper) before they trust you with,
for instance, their credit card number. So they send you a speciﬁc message that
they choose, usually just a random string of digits, and ask you to encrypt it using your private key. Having done so, you send the encrypted message back to
them and they decode it with the public key. If the decoded message matches
the original one then they know that you are who you say you are, since no
one else has your private key and hence no one else could have encrypted a
message that decodes correctly with the public key.10 This “digital signature”
process is a crucial part of electronic commerce, allowing buyers and sellers to
conﬁrm each other’s identities before doing business, and is used millions of
times every day in transactions of every sort.
But there is still a fundamental problem with public-key encryption, namely
the problem of knowing that the public key you are given really was created
by the person you think it was created by. Some malicious person could create
a public/private key pair and broadcast the public key to the world, labeled
with, say, the name of a bank or retail trader, then use that key in a digital signature scheme to persuade some unsuspecting victim that they are the trader
and that the victim should send them a credit card number.
One way around this problem is to have people sign each other’s public
keys [267]. That is, party A takes a public key that claims to belong to party B,
and that A knows in fact to be genuine, and encrypts it with their own private
key. Now if you have A’s public key and you believe it to be genuine, then
you can take the encrypted key and decode it with A’s public key, thereby
recovering B’s public key, which A says is genuine. If you trust A to make this
statement, then you can now also trust that the key you have is B’s true public
key.
But now one can repeat the process. Now that you have a genuine public
key for party B, and if you trust B, then B can now sign the keys that they know
to be genuine and you will be able to verify that they are genuine also. In this
way, parties who trust each other can securely represent to one another that
keys are genuine.
10
Again, this is not completely true. One can encode a message using the public key that
will decode with the same key, but again the calculations necessary to do this are extraordinarily
lengthy, much lengthier than those using the private key, and hence for practical purposes only
the person with the private key could have created the encrypted message.

52

3.5

|

A FFILIATION NETWORKS

The act of digitally signing someone else’s public key is equivalent to saying that you know, or at least believe, the public key to be genuine, belonging
to the person it claims to belong to. That act can be represented by a directed
edge in a network. The vertices in the network represent the parties involved
and a directed edge from party A to party B indicates that A has signed B’s
public key. The resulting directed network certainly has technological aspects
but is in many ways more of a social network than anything else. People tend
to vouch for the keys of other people they know, people they have communicated with or worked with frequently, so that they have both a good idea that
the key in question is indeed genuine and a personal reason for making the
effort to sign it.
Since public keys and the digital signatures of the people who sign them
are, by necessity, public, it is relatively easy to construct a key-signing network
from widely available data. There are a number of widely used key-signing
networks associated, usually, with particular commercial cryptography products. One of the largest, for instance, is the network associated with the cryptography program PGP [267]. There have been only a small number of studies
so far of the properties of key signing networks [47, 148] but there are certainly
interesting questions awaiting answers in this area.

3.5

A FFILIATION NETWORKS

An important special case of the reconstruction of networks from archival
records is the afﬁliation network. An afﬁliation network is a network in which
actors are connected via comembership of groups of some kind. We saw one
example in the introduction to this chapter, the Southern Women Study of
Davis et al. [86], in which the authors drew their data from newspaper reports
of social events and the “groups” were the sets of individuals who attended
particular events. As we saw, the most complete representation of an afﬁliation
network is as a network with two types of vertex representing the actors and
the groups, with edges connecting actors to the groups to which they belong—
see Fig. 3.2 on page 39. In such a representation, called a “bipartite network”
or “two-mode network,” there are no edges connecting actors directly to other
actors (or groups to other groups), only actors to groups.
Many examples of afﬁliation networks can be found in the literature. Another famous case is the study by Galaskiewicz [134] of the CEOs of companies
in Chicago in the 1970s and their social interaction via clubs that they attended.
In this network the CEOs are the actors and the clubs are the groups. Also in
the business domain, quite a number of studies have been conducted of the
boards of directors of companies [87, 88, 207]. In these networks the actors are

We study bipartite networks in more detail in Section 6.6.

53

S OCIAL NETWORKS

company directors and the groups are the boards on which they sit. In addition to looking at the connections between directors in such networks, which
arise as a result of their sitting on boards together, a considerable amount of
attention has also been focused on the connections between boards (and hence
between companies) that arise as a result of their sharing a common director, a
so-called board “interlock.”
More recently, some extremely large afﬁliation networks have been studied
in the mathematics and physics literature. Perhaps the best known example is
the network of collaborations of ﬁlm actors, in which the “actors” in the network sense are actors in the dramatic sense also, and the groups to which they
belong are the casts of ﬁlms. This network is the basis, among other things,
for a well-known parlor game, sometimes called the “Six Degrees of Kevin Bacon,” in which one attempts to connect pairs of actors via chains of intermediate costars in a manner reminiscent of the small-world experiments of Stanley
Milgram, which we discuss in Section 3.6. The ﬁlm actor network has, with the
advent of the Internet, become very thoroughly documented and has attracted
the attention of many network analysts in recent years [16, 27, 323], although
it is not clear whether there are any conclusions of real scientiﬁc interest to be
drawn from its study.
Another example of a large afﬁliation network, one that holds more promise
of providing useful results, is the coauthorship network of academics. In this
network an actor is an academic author and a group is the set of authors of
a learned paper. Like the ﬁlm actor network, this network has become well
documented in the last few years with the appearance of extensive online bibliographic resources covering many areas of human endeavor. Whether one is
interested in papers published in journals or in more informal forums such as
online preprint servers, excellent records now exist in most academic ﬁelds of
authors and the papers they write, and a number of studies of the corresponding afﬁliation networks have been published [29, 89, 145, 146, 234–236].

3.6

T HE SMALL - WORLD EXPERIMENT

An unusual contribution to the social networks literature was made by the experimental psychologist Stanley Milgram in the 1960s with his now-famous
“small-world” experiments [219, 311]. Milgram was interested in quantifying
the typical distance between actors in social networks. As discussed in Chapter 1, the “geodesic distance” between two vertices in a network is the minimum number of edges that must be traversed to travel from one vertex to the
other through the network. Mathematical arguments suggest (as we will see
later in this book) that this distance should be quite small for most pairs of
54

3.6

|

T HE SMALL - WORLD EXPERIMENT

vertices in most networks, a fact that was already well known in Milgram’s
time.11 Milgram wanted to test this conjecture in real networks and to do this
he concocted the following experiment.12
Milgram sent a set of packages, 96 in all, to recipients randomly chosen
from the telephone directory in the US town of Omaha, Nebraska. The packages contained an ofﬁcial-looking booklet, or “passport,” emblazoned with the
crest of Milgram’s home institution, Harvard University. Written instructions
were included asking the recipients to attempt to get the passport to a speciﬁed
target individual, a friend of Milgram’s who lived in Boston, Massachusetts,
over a thousand miles away. The only information supplied about the target
was his name (and hence indirectly the fact that he was male), his address, and
his occupation as a stockbroker. But the passport holders were not allowed
simply to send their passport to the given address. Instead they were asked to
pass it to someone they knew on a ﬁrst-name basis and more speciﬁcally the
person in this category who they felt would stand the best chance of getting
the passport to the intended target. Thus they might decide to send it to someone they knew who lived in Massachusetts, or maybe someone who worked in
the ﬁnancial industry. The choice was up to them. Whoever they did send the
passport to was then asked to repeat the process, sending it on to one of their
acquaintances, so that after a succession of such steps the passport would, with
luck, ﬁnd its way into the hands of its intended recipient. Since every step of
the process corresponded to the passport’s changing hands between a pair of
ﬁrst-name acquaintances, the entire path taken corresponded to a path along
the edges of the social network formed by the set of all such acquaintanceships.
Thus the length of the path taken provided an upper bound on the geodesic
distance in this network between the starting and ending individuals in the
chain.
Of the 96 passports sent out, 18 found their way to the stockbroker target
in Boston. While this may at ﬁrst sound like a low ﬁgure, it is actually remarkably high—recent attempts to repeat Milgram’s work have resulted in response
rates orders of magnitude lower [93]. Milgram asked participants to record in
the passport each step of the path taken, so he knew, among other things, how
long each path was, and he found that the mean length of completed paths
11

Milgram was particularly inﬂuenced in his work by a mathematical paper by Pool and
Kochen [270] that dealt with the small-world phenomenon and had circulated in preprint form
in the social science community for some years when Milgram started thinking about the problem, although the paper was not ofﬁcially published until many years later.
12

In fact Milgram conducted several sets of small-world experiments. The one described here
is the ﬁrst and most famous, but there were others [186, 311].

55

S OCIAL NETWORKS

Funneling is discussed further in Section 8.2.

from Omaha to the target was just 5.9 steps. This result is the origin of the idea
of the “six degrees of separation,” the popular belief that there are only about
six steps between any two people in the world.13
There are of course many reasons why this result is only approximate. Milgram used only a single target in Boston, and there is no guarantee the target
was in any way typical of the population as a whole. And all the initial recipients in the study were in a single town in the same country.14 (None of the
completed chains that reached the target went outside the country.) Also there
is no guarantee that chains took the shortest possible route to the target. Probably they did not, at least in some cases, so that the lengths of the paths found
provide, as we have said, only an upper bound on the actual geodesic distance
between vertices. And most of the chains of course were never completed. The
passports were discarded or lost and never made their way to the target. It is
reasonable to suppose that the chances of getting lost were greater for passports that took longer paths, and hence that the paths that were completed
were a biased sample, having typical lengths shorter than the average.
For all these reasons and several others, Milgram’s experiments should be
taken with a large pinch of salt. Even so, the fundamental result that vertex
pairs in social networks tend on average to be connected by short paths is now
widely accepted, and has moreover been shown to extend to many other kinds
of networks as well. Enough experiments have conﬁrmed the effect in enough
networks that, whatever misgivings we may have about Milgram’s particular
technique, the general result is not seriously called into question.
Milgram’s experiments also, as a bonus, revealed some other interesting
features of acquaintance networks. For instance, Milgram found that most of
the passports that did ﬁnd their way to the stockbroker target did so via just
three of the target’s friends. That is, a large fraction of the target’s connections
to the outside world seemed to be through only a few of his acquaintances, a
phenomenon sometimes referred to as the “funneling” effect. Milgram called
such well-connected acquaintances “sociometric superstars,” and their existence has occasionally been noted in other networks also, such as collaboration
networks [234], although not in some others [93].
A further interesting corollary of Milgram’s experiment has been high13

The phrase “six degrees of separation” did not appear in Milgram’s writing. It is more recent
and comes from the title of a popular Broadway play by John Guare [149], later made into a ﬁlm,
in which the lead character discusses Milgram’s work.
14
Furthermore, it appears that some of the initial recipients may have been selected not at
random but by advertising for volunteers in the local newspaper [181], a procedure unlikely to
produce a truly random sample of the population.

56

3.6

|

T HE SMALL - WORLD EXPERIMENT

lighted by Kleinberg [177, 178]. (Milgram himself seems not to have appreciated the point.) The fact that a moderate number of the passports did ﬁnd
their way to the intended target person shows not only that short paths exist in
the acquaintance network, but also that people are good at ﬁnding those paths.
Upon reﬂection this is quite a surprising result. As Kleinberg has shown, it is
possible and indeed common for a network to possess short paths between
vertices but for them to be hard to ﬁnd unless one has complete information
about the structure of the entire network, which the participants in Milgram’s
studies did not. Kleinberg has suggested a possible explanation for how participants found the paths they did, based on conjectures about the structure of
the network. We discuss his ideas in detail in Section 19.3.
Recently the small-world experiment has been repeated by Dodds et al. [93]
using the modern medium of email. In this version of the experiment participants forwarded email messages to acquaintances in an effort to get them ultimately to a speciﬁed target person about whom they were told a few basic
facts. The experiment improved on that of Milgram in terms of sheer volume,
and also by having much more numerous and diverse target individuals and
starting points for messages: 24 000 chains were started, most (though not all)
with unique starting individuals, and with 18 different participating targets in
13 different countries. On the other hand, the experiment experienced enormously lower rates of participation than Milgram’s, perhaps because the public is by now quite jaded in its attitude towards unsolicited mail. Of the 24 000
chains, only 384, or 1.5%, reached their intended targets, compared with 19%
in Milgram’s case. Still, the basic results were similar to those of Milgram.
Completed chains had an average length of just over four steps. Because of
their better data and considerably more careful statistical analysis, Dodds et al.
were also able to compensate for biases due to unﬁnished chains and estimated
that the true average path length for the experiment was somewhere between
ﬁve and seven steps—very similar to Milgram’s result. However, Dodds et al.
observed no equivalent of the “sociometric superstars” of Milgram’s experiment, raising the question of whether their appearance in Milgram’s case was
merely a ﬂuke of the particular target individual he chose rather than a generic
property of social networks.
An interesting variant on the small-world experiment has been proposed
by Killworth and Bernard [39, 174], who were interested in how people “navigate” through social networks, and speciﬁcally how participants in the smallworld experiments decide whom to forward messages to in the effort to reach
a speciﬁed target. They conducted what they called “reverse small-world” ex-

57

S OCIAL NETWORKS

The mechanisms of network search and message
passing
are discussed
in greater detail in Section 19.3.

periments15 in which they asked participants to imagine that they were taking
part in a small-world experiment. A (ﬁctitious) message was to be communicated to a target individual and participants were asked what they wanted to
know about the target in order to make a decision about whom to forward the
message to. The actual passing of the message never took place; the experimenters merely recorded what questions participants asked about the target.
They found that three characteristics were sought overwhelmingly more often
than any others, namely the name of the target, their geographic location, and
their occupation—the same three pieces of information that Milgram provided
in his original experiment. Some other characteristics came up with moderate
frequency, particularly when the experiment was conducted in non-Western
cultures or among minorities: in some cultures, for instance, parentage or religion were considered important identifying characteristics of the target.
While the reverse small-world experiments do not directly tell us about the
structure of social networks, they do give us information about how people
perceive and deal with social networks.

3.7

S NOWBALL SAMPLING , CONTACT TRACING , AND RANDOM
WALKS

Finally in this chapter on social networks we take a look at a class of networkbased techniques for sampling hidden populations.
Studies of some populations, such as drug users or illegal immigrants,
present special problems to the investigator because the members of these
populations do not usually want to be found and are often wary of giving
interviews. Techniques have been developed, however, to sample these populations by making use of the social network that connects their members together. The most widely used such technique is snowball sampling [108, 127,
310].
Note that, unlike the other experimental techniques discussed in this chapter, snowball sampling is not intended as a technique for probing the structure
of social networks. Rather, it is a technique for studying hidden populations
that relies on social networks for its operation. It is important to keep this
distinction clear. To judge by the literature, some professional social network
analysts do not, and the results are often erroneous conclusions and bad science.
15

Also sometimes called “INDEX” experiments, which is an abbreviation for “informantdeﬁned experiment.”

58

3.7

|

S NOWBALL SAMPLING , CONTACT TRACING , AND RANDOM WALKS

Standard techniques such as telephone surveys often do not work well
when sampling hidden populations. An investigator calling a random telephone number and asking if anyone on the other end of the line uses drugs
is unlikely to receive a useful answer. The target population in such cases is
small, so the chances of ﬁnding one of its members by random search are also
small, and when you do ﬁnd one they will very likely be unwilling to discuss
the highly personal and possibly illicit topic of the survey with an investigator
they have never met before and have no reason to trust.
So investigators probe the population instead by getting some of its members to provide contact details for others. The typical survey starts off rather
like a standard ego-centered network study (Section 3.2.1). You ﬁnd one initial
member of the population of interest and interview them about themselves.
Then, upon gaining their conﬁdence, you invite them also to name other members of the target population with whom they are acquainted. Then you go and
ﬁnd those acquaintances and interview them asking them also to name further
contacts, and so forth through a succession of “waves” of sampling. Pretty
soon the process “snowballs” and you have a large sample of your target population to work with.
Clearly this is a better way of ﬁnding a hidden population than random
surveys, since each named individual is likely to be a member of the population, and you also have the advantage of an introduction to them from one
of their acquaintances, which may make it more likely that they will talk to
you. However, there are some serious problems with the method as well. In
particular, snowball sampling gives highly biased samples. In the limit of a
large number of waves, snowball sampling samples actors with probability
proportional to their “eigenvector centrality” (see Section 7.2). Unfortunately,
this limit is rarely reached in practice, and in any case the eigenvector centrality cannot be calculated without knowledge of the complete contact network,
which by deﬁnition we don’t have, making correction for the sampling bias
difﬁcult. In short, snowball sampling gives biased samples of populations and
there is little we can do about it. Nonetheless, the technique is sufﬁciently useful for ﬁnding populations that are otherwise hard to pin down that it has been
widely used, biases and all, in studies over the last few decades.
Sometimes, in the case of small target populations, a few waves of snowball sampling may ﬁnd essentially all members of a local population, in which
case the method can be regarded as returning data about the structure of the
social network. If the contacts of each interviewed participant are recorded in
the study, it should be possible to reconstruct the contact network when the
study is complete. This has occasionally been done in such studies, although
as noted above the object is more often to exploit the social network to ﬁnd the
59

S OCIAL NETWORKS

population than to study the network itself.
A technique closely related to snowball sampling is contact tracing, which
is essentially a form of snowball sampling applied to disease incidence. Some
diseases, such as tuberculosis and HIV, are considered sufﬁciently serious that,
when someone is discovered to be carrying them, an effort must be made to
track down all those who might also have been infected. Thus, in most Western
countries, when a patient tests positive for HIV, for instance, he or she will be
questioned about recent sexual contacts, and possibly about other types of potentially disease-carrying contacts, such as needle sharing if the patient is an
injection drug user. Then health authorities will make an effort to track down
those contacts and test them also for HIV. The process is repeated with any
who test positive, tracing their contacts as well, and so forth, until all leads
have been exhausted. While the primary purpose of contract tracing is to curtail disease outbreaks and safeguard the health of the population, the process
also produces data about the community through which a disease is spreading
and such data have sometimes been used in scientiﬁc studies, particularly of
sexually transmitted diseases, for which data may otherwise be hard to come
by. Population samples derived from contact tracing studies display biases
similar in type and magnitude to those seen in snowball sampling and should
be treated with the same caution. Indeed, they contain extra biases as well,
since contacts are rarely pursued when an individual tests negative for the
disease in question, so the sample is necessarily dominated by carriers of the
disease, who are themselves usually a biased sample of the population at large.
Also, as with snowball sampling, contact tracing data can provide us with an
experimental window on the structure of the contact network itself, but again
we expect the data to be strongly biased, except in cases of small target populations for which the sampling process saturates.
There is another variant of snowball sampling that deals to some extent
with the problems of bias in the sample. This is random-walk sampling [182,310].
In this method one again starts with a single member of the target community
and interviews them and determines their contacts. Then, however, instead
of interviewing all of those contacts, one chooses one of them at random and
interviews only that one at the next step. If the person in question cannot be
found or declines to be interviewed, one simply chooses another contact, and
the process is repeated. Initially it appears that this will be a more laborious
process than standard snowball sampling, since one spends a lot of time determining the names of individuals one never interviews, but this is not the
case. In either method one has to determine the contacts of each person interviewed, so the total amount of work for a sample of a given size is the same.
It is however very important that one really does determine all the contacts of
60

3.7

|

S NOWBALL SAMPLING , CONTACT TRACING , AND RANDOM WALKS

each individual, even though most of the time only one of them is pursued.
This is because for the method to work correctly one must make a random
choice among those contacts, for example by rolling a die (or some modern
electronic version thereof). To do this one must know the full set of contacts
one is choosing between.
The advantage of the random-walk sampling method is that, as shown
in Section 6.14, the asymptotic sampling probability of vertices in a random
walk is simply proportional to vertex degree (see Eq. (6.60)). What’s more, the
asymptotic regime in such studies is, unlike snowball sampling, reached quite
quickly for relatively small sample sizes.16
Knowing this, and given that we determine degree (i.e., the number of contacts an individual has) as a part of the interview process, we can easily compensate for sampling bias and make population estimates of quantities in a
way that is, in theory at least, unbiased. In practice, many sources of bias remain, particularly those associated with participant subjectivity, inability to
recall contacts, and non-participation of named contacts. Still, random-walk
sampling is a great improvement on standard snowball sampling, and should
be used more than it is. Its principal disadvantage is that it is relatively slow.
Since the participants are interviewed serially, in a chain, rather than in parallel
waves, a strict implementation of the method can take a long time to develop
a large sample. One can get around this obstacle to some extent by running
several short random walks in parallel instead of one long one, but the walks
cannot be too short or they will not reach the asymptotic regime in which sampling is proportional to degree.
Another variant of the random-walk sampling idea is used to deal with a
different problem, that of enrolling study participants. In some cases it is considered unethical to get participants to name their contacts, particularly when
the topic of the study is one of dubious legality, and permission to perform
such studies may be withheld by the authorities. To circumvent this problem
one can make use of respondent-driven sampling [289]. In this technique, participants are usually paid to take part, and enrollment is achieved by handing out
tickets to interviewees. Rather than asking people to name their contacts, the
interviewees are simply told that they should give the tickets to their friends,
and that both they and the friends will receive payment if the friend brings
the ticket to the investigator and agrees to participate in the survey. In this
16
In snowball sampling the sample size grows exponentially with the number of sampling
waves and hence one typically only performs a logarithmic number of waves, which is not enough
for the sampling process to reach equilibrium. In random walk sampling the sample size grows
only linearly.

61

S OCIAL NETWORKS

way, no one is ever asked to name names and all participants have actively
volunteered their participation. In the case where a single ticket is given to
each participant, the method is roughly equivalent to random-walk sampling
and should in theory give a less biased sample than snowball sampling for the
same reasons. In practice, a new bias is introduced because the recipient of the
ticket is not necessarily chosen at random from an individual’s acquaintances.
Also, tickets frequently get lost or their recipients decline to participate, remuneration notwithstanding, so one would normally give out more than one
ticket to each participant, which complicates the sampling process. Even so,
it is believed that respondent-driven sampling provides superior population
samples to snowball sampling, and it is the method of choice for studies in
which one cannot ask people to name their contacts.

62

C HAPTER 4

N ETWORKS OF INFORMATION
A description of networks of information or data, with a
particular focus on the World Wide Web and citation
networks

T

HIS CHAPTER focuses on networks of information, networks consisting of

items of data linked together in some way. Information networks are all,
so far as we know, man-made, with perhaps the best known example being
the World Wide Web, though many others exist and are worthy of study, particularly citation networks of various kinds. These and several other types of
information networks are discussed in this chapter.
In addition, there are some networks which could be considered information networks but which also have social aspects to them. Examples include
networks of email communications, networks on social-networking websites
such as Facebook or LinkedIn, and networks of weblogs and online journals.
These and similar examples were discussed in the previous chapter on social
networks, in Section 3.4, but they would have ﬁtted perfectly well in the present
chapter also. The classiﬁcation of networks as social networks, information
networks, and so forth is a fuzzy one, and there are plenty of examples that,
like these, straddle the boundaries.

4.1

T HE W ORLD W IDE W EB

Although by no means the ﬁrst information network created, the World Wide
Web is probably the example best known to most people and a good place to
start our discussion in this chapter.
As described in Chapter 1, the Web is a network in which the vertices are
web pages consisting of text, pictures, or other information and the edges are
the hyperlinks that allow us to navigate from page to page. Since hyperlinks
63

N ETWORKS OF INFORMATION

Figure 4.1: A network of pages on a corporate
website. The vertices in this network represent
pages on a website and the directed edges between
them represent hyperlinks.

run in one direction only, the Web is a directed network. We can picture the
network with an arrow on each edge indicating which way it runs. Some pairs
of web pages are connected by hyperlinks running in both directions, which
can be represented by two directed edges, one in each direction between the
corresponding vertices. Figure 4.1 shows a picture of a small portion of the
Web network, representing the connections between a set of web pages on a
single website.
The World Wide Web was invented in the 1980s by scientists at the CERN
high-energy physics laboratory in Geneva as a means of exchanging information among themselves and their coworkers, but it rapidly became clear that its
potential was much greater [159]. At that time there were several similar ideas
competing for dominance of the rapidly growing Internet, but the Web won
the battle, largely because its inventors decided to give away for free the software technologies on which it was based—the Hypertext Markup Language
(HTML) used to specify the appearance of pages and the Hypertext Transport
Protocol (HTTP) used to transmit pages over the Internet. The Web’s extraordinary rise is now a familiar story and most of us use its facilities at least occasionally, and in some cases daily. A crude estimate of the number of pages
on the Web puts that number at over 25 billion at the time of the writing of
this book.1 The network structure of the Web has only been studied in detail
1

64

This is only the number of reachable static pages. The number of unreachable pages is dif-

4.1

Page:

<a href="http://www.blahblah.com/index.html">

Text:

.
.
.
<a href="http://www.blahblah.com/this.html">
.
.
<a href="http://www.blahblah.com/that.html">
.
.
.
<a href="http://www.something.com/theother.html">
.
.
.

Page:

<a href="http://www.blahblah.com/this.html">

Text:

.
.
<a href="http://www.blahblah.com/index.html">
.
.
.
<a href="http://www.blahblah.com/whatever.html">
.
.
<a href="http://www.another.com/home.html">
.
.
.

|

T HE W ORLD W IDE W EB

Store
<a href="http://www.blahblah.com/this.html">
<a href="http://www.blahblah.com/that.html">
<a href="http://www.something.com/theother.html">

Figure 4.2: The operation of a web crawler. A web crawler iteratively downloads pages from the Web, starting from a
given initial page. URLs are copied from the link tags in that initial page into a store. Once all links have been copied
from the initial page, the crawler takes a URL from the store and downloads the corresponding page, then copies links
from that, and so on.

relatively recently however.
The structure of the Web can be measured using a crawler, a computer program that automatically surfs the Web looking for pages. In its simplest form,
the crawler performs a so-called breadth-ﬁrst search on the Web network, as
shown schematically in Fig. 4.2. One starts from any initial web page, downloads the text of that page over the Internet, and ﬁnds all the links in the text.
Functionally, a link consists of an identifying “tag”—a short piece of text marking the link as a link—and a Uniform Resource Locator or URL, a standardized
computer address that says how and where the linked web page can be found.
By scanning for the tags and then copying the adjacent URLs a web crawler can

Breadth-ﬁrst search is discussed at length in Section 10.3.

ﬁcult to estimate, and dynamic pages (see later) are essentially inﬁnite in number, although this
may not be a very meaningful statement since these pages don’t exist until someone asks for them.

65

N ETWORKS OF INFORMATION

rapidly extract URLs for all the links on a web page, storing them in memory
or on a disk drive. When it is done with the current page, it removes one of the
URLs from its store, uses it to locate a new page on the Web, and downloads
the text of that page, and so the process repeats. If at any point the crawler
encounters a URL that is the same as one already in its store, then that URL
is ignored and not added to the store again, to avoid duplicate entries. Only
URLs that are different from all those seen before are added to the store.
By repeating the process of downloading and URL extraction for a suitably
long period of time one can ﬁnd a signiﬁcant portion of the pages on the entire Web. In practice, however, no web crawler actually ﬁnds all the pages on
the Web. There are a number of reasons for this. First, some websites forbid
crawlers to crawl their pages. Websites can place a ﬁle called robots.txt in
their root directory that speciﬁes which ﬁles, if any, crawlers can look at and
may optionally specify that some crawlers are allowed to look at ﬁles while
others are not. Compliance with the restrictions speciﬁed in a robots.txt ﬁle
is voluntary, but in practice many crawlers do comply.
Second, many pages on the Web are dynamically generated: they are created on the ﬂy by special software using, for instance, data from a database.
Many corporate websites, as well as the web pages generated by search engines or directory services, fall into this category. The number of possible web
pages that can be displayed as a result of a search using the Google search engine, for example, is so large as to be effectively inﬁnite; it would not be possible (or sensible) for a crawler to crawl all of these pages. The crawler therefore
has to make some choice about what counts as a web page and what does not.
One choice would be to restrict oneself to static web pages—ones that are not
generated on the ﬂy. But it’s not always simple to tell which pages are static,
and besides, much useful information resides in the dynamic pages. In practice, the decisions made by crawlers about which pages to include tend to be
fairly arbitrary, and it is not easy to guess which pages will be included in a
crawl and which will not. But one can say with certainty that many will not
and in this sense the crawl is always incomplete.
However, perhaps the most important reason why web crawls do not reach
all the pages on the Web is that the network structure of the Web does not
allow it. Since the Web is a directed network, not all pages are reachable from
a given starting point. In particular, it is clear that pages that have no incoming
hyperlinks—pages that no one links to—can never be found by a crawler that
blindly follows links. Taking that idea one step further, it is also the case that
a page will never be found if it is only linked to by pages that themselves
have no incoming links. And so forth. In fact, the Web, and directed networks
in general, have a special “component” structure, which we will examine in
66

4.2

detail in Section 6.11.1, and most crawlers only ﬁnd one part of that structure,
the “giant out-component.” In the case of the World Wide Web the giant outcomponent constitutes only about a half of all web pages and the other half of
the Web is unreachable.2
Although we are interested in web crawlers as a tool for probing the structure of the Web so that we can study its network properties, this is not their
main purpose. The primary use of web crawlers is to construct directories of
web pages for search purposes. Web search engines such as Google indulge
in web crawling on a massive scale to ﬁnd web pages, parse their content,
and construct indexes of the words and pictures they contain that can later be
searched ofﬂine by fast database engines to ﬁnd pages of interest to searchers.
Because their primary interest is in indexing, rather than in reconstructing the
network structure of the Web, search engine companies don’t have any particular reason to take a good statistical sample of the Web and in network terms
their crawls are probably quite biased. Still, many of them have graciously
made their data available to academic researchers interested in web structure,
and the data are good enough to give us a rough picture of what is going on.
We will study a variety of features of the Web network in subsequent chapters.
It isn’t entirely necessary that we rely on search engine companies or other
web enterprises for data on the structure of the Web. One can also perform
one’s own web crawls. There are a number of excellent web crawlers available
for free, including wget, Nutch, GRUB, Larbin, WebSPHINX, and ht://Dig. While
most of us don’t have the time and network bandwidth to crawl billions of
web pages, these programs can be useful for crawling single websites, and
much useful insight and information can be acquired by doing so.

4.2

|

C ITATION NETWORKS

Web searching, which itself raises some interesting
network questions, is discussed in Section 19.1.

C ITATION NETWORKS

A less well-known but much older information network is the network of citations between academic papers. Most papers refer to one or more other previous papers, usually in a bibliography at the end of the paper, and one can
construct a network in which the vertices are papers and there is a directed
edge from paper A to paper B if A cites B in its bibliography. There are many
reasons why one paper might cite another—to point out information that may
2
Which web pages a crawler ﬁnds does depend on where the crawl starts. A crawler can ﬁnd
a web page with no incoming links, for instance, if (and only if) it starts at that page. In practice,
however, the starting point has remarkably little effect on what a crawler ﬁnds, since most of what
is found consists of the giant out-component mentioned above, whose content does not depend
on the starting point.

67

N ETWORKS OF INFORMATION

See Section 4.1 for a discussion of web crawlers.

68

be useful to the reader, to give credit for prior work, to indicate inﬂuences on
current work, or to disagree with the content of a paper. In general, however,
if one paper cites another it is usually an indication that the contents of the earlier paper are relevant in some way to those of the later one, and hence citation
networks are networks of relatedness of subject matter.
Quantitative studies of citation networks go back to the 1960s. The earliest
seems to be the 1965 study by Price [274] (which is also the earliest study we
know of to ﬁnd a “power-law degree distribution,” of which we talk in detail in Section 8.4). Studies such as this usually fall within the ﬁeld formerly
known as “library science” but now more often called “information science.”
The branch of information science dealing speciﬁcally with the statistical study
of publications and citations is called bibliometrics.
The most common way to assemble citation data is to do it by hand, simply typing in all the entries in the bibliographies of papers to create a database
that can then be used to assemble the network. In the 1960s when Price carried out his study, such databases were just starting to be created and he made
use of an early version of what would later become the Science Citation Index. The Science Citation Index (along with its sister publications, the Social
Science Citation Index and the Arts and Humanities Citation Index) is now
one of the primary and most widely used sources of citation data. Another
database, Scopus, provides a competing but largely similar service. Both are
hand-maintained by professional staff and their coverage of the literature is
reasonably complete and accurate, although the data are also quite expensive
to purchase. Still, if one has the money, creating a citation network is only
a matter of deciding which papers one wishes to include, using one of the
databases to ﬁnd the citations between those papers, and adding the appropriate directed edges to the network until it is complete.
More recently, automated citation indexing by computer has started to become more common. For instance, the website Citeseer, maintained by Pennsylvania State University, performs citation indexing of papers in computer
science and information science by crawling the Web to ﬁnd freely available
manuscripts of papers in electronic form, and then searching through those
manuscripts to identify citations to other papers. This is a somewhat hit-ormiss operation because many papers are not on the Web or are not freely available, citations in papers have a wide variety of different formats and may include errors, and the same paper may exist in more than one place on the Web
as well as in journals or books, and possibly in more than one different version.
Nonetheless, enough progress has been made for Citeseer to become a useful
tool in the computer science community. Other automatic citation indexing
projects include Citebase, which indexes physics papers, and Google Scholar.

4.2

As with web crawls, the primary purpose of citation indexes is not to allow
us to study the network structure of citation. Citation indexes are primarily
research tools that allow researchers to discover by whom a paper has been
cited, and hence to ﬁnd research related to a topic of interest. Nonetheless,
data from citation indices have been widely used to reconstruct the underlying
networks and study their properties.
Citation networks are in many ways similar to the World Wide Web. The
vertices of the network hold information in the form of text and pictures, just
as web pages do, and the links from one paper to another play a role similar
to hyperlinks on web pages, alerting the reader when information relevant to
the topic of one paper can be found in another.3 Papers with many citations
are often more inﬂuential and widely read than those with few, just as is the
case with web pages, and one can “surf” the citation network by following
a succession of citations from paper to paper just as computer users surf the
Web.
There is, however, at least one important difference between a citation network and the Web: a citation network is acyclic, while the Web is not. An
acyclic network is one in which there are no closed loops of directed edges. On
the World Wide Web, it is entirely possible to follow a succession of hyperlinks
and end up back at the page you started at. Indeed this happens often. On a
citation network, by contrast, it is essentially impossible. The reason is that in
order to cite a paper, that paper must already have been written. One cannot
cite a paper that doesn’t exist yet. Thus all the directed edges in a citation network point backward in time, from newer papers to older ones. If we follow a
path of such edges from paper to paper, we will therefore ﬁnd ourselves going
backward in time, but there is no way to go forward again, so we cannot close
the loop and return to where we started.4
Citation networks have some surprising statistics. About 47% of all papers
in the Science Citation Index have never been cited at all. Of the remainder, 9%
have one citation, 6% have two, and it goes down quickly after that. Only 21%
of all papers have 10 or more citations, and just 1% have 100 or more. These
ﬁgures are a consequence of the power-law degree distribution of the network
mentioned above and discussed more in Section 8.4.

|

C ITATION NETWORKS

Acyclic
networks
discussed
further
Section 6.4.2.

are
in

See Fig. 6.3 for an illustration of a small acyclic network.

3
Indeed, academic studies of the Web within the information sciences sometimes refer to hyperlinks as “citations,” a nomenclature that emphasizes the close similarities.
4
On rare occasions it occurs that an author or authors will publish two papers simultaneously
in the same volume of a journal and, with the help of the printers, arrange for each paper to cite
the other, creating a cycle of length two in the network. Thus, the citation network is not strictly
acyclic, having a small number of short cycles scattered about it.

69

N ETWORKS OF INFORMATION

The most highly cited paper in the Science Citation Index is a paper by
Lowry et al. [202], which has been cited more than a quarter of a million times.5
Like most very highly cited papers, it is a methodological paper in molecular
biology.
Citation networks of the type described so far are the simplest but not the
only possible network representation of citation patterns. An alternative and
widely studied representation is the cocitation network. Two papers are said to
be cocited if they are both cited by the same third paper. Cocitation is often
taken as an indicator that papers deal with related topics and there is good
evidence that this is a reasonable assumption in many cases.
A cocitation network is a network in which the vertices represent papers
and the edges represent cocitation of pairs of papers. By contrast with ordinary
citation networks, the edges in a cocitation network are normally considered
undirected, since cocitation is a symmetric relationship. One can also deﬁne a
strength for the cocitation between two papers as the number of other papers
that cite both and one can create weighted cocitation networks in which the
strengths of the edges are equal to this cocitation strength.
Another related concept, although one that is less often used, is bibliographic
coupling. Two papers are said to be bibliographically coupled if they cite the
same other papers (rather than being cited by the same papers). Bibliographic
coupling, like cocitation, can be taken as an indicator that papers deal with related material and one can deﬁne a strength or weight of coupling by the number of common citations between two papers. From the bibliographic coupling
ﬁgures one can then assemble a bibliographic coupling network, either weighted
or not, in which the vertices are papers and the undirected edges indicate bibliographic coupling.
Cocitation and bibliographic coupling are discussed in more detail in Section 6.4.1.
4.2.1

PATENT AND LEGAL CITATIONS

Our discussions of citation networks have so far focused on citations between
academic papers, but there are other types of citation also. Two of particular
importance are citations between patents and between legal opinions.
Patents are temporary grants of ownership for inventions, which give their
holders the right to take legal action against others who attempt to proﬁt without permission from the protected inventions. They are typically issued to
inventors—either individuals or corporations—by national governments after
5

70

And it’s been cited one more time now.

4.2

|

C ITATION NETWORKS

a review process to determine whether the invention in question is original and
has not previously been invented by someone else. In applying for a patent,
an inventor must describe his or her invention in sufﬁcient detail to make adequate review possible and present the case that the invention is worthy of
patent protection. A part of this case typically involves detailing the relationship between the invention and previously patented inventions, and in doing
so the inventor will usually cite one or more previous patents. Citations may
highlight dependencies between technologies, such as one invention depending for its operation on another, but more often patent citations are “defensive,” meaning that the inventor cites the patent for a previous technology and
then presents an argument for why the new technology is sufﬁciently different from the old one to merit its own patent. Governments, in the process of
examining patent applications, will routinely consider their similarity to previous inventions, and defensive citations are one way in which an inventor
can fend off in advance possible objections that might be raised. Typically
there are a number of rounds of communication, back and forth between the
government patent examiner and the inventor, before a patent application is
ﬁnally accepted or rejected. During this process extra citations are often added
to the application, either by the inventor or by the examiner, to document the
further points discussed in their communications.
If and when a patent is ﬁnally granted, it is published, citations and all,
so that the public may know which technologies have patent protection. These
published patents provide a source of citation data that we can use to construct
networks similar to the networks for citations between papers. In these networks the vertices are patents, each identiﬁed by a unique patent number, and
the directed edges between them are citations of one patent by another. Like
academic citation networks, patent networks are mostly acyclic, with edges
running from more recent patents to older ones, although short loops can arise
in the network in the not uncommon case that an inventor simultaneously
patents a number of mutually dependent technologies. The structure of patent
networks reﬂects the organization of human technology in much the same way
that academic citations reﬂect the structure of research knowledge. Patent networks have been studied far less than academic citation networks, but studies
have been growing in the last few years with the appearance of high-quality
data sets, particularly for US patents [161], and there are a number of important technological and legal questions, for instance concerning antitrust policy,
that can be addressed by examining their structure [69].
Another class of citation network that has begun to attract attention in recent years is that of legal citation networks. In countries where law cases can
be heard by judges rather than juries, such as civil cases or appeals in Europe
71

N ETWORKS OF INFORMATION

or the US, a judge will frequently issue an “opinion” after deciding a case, a
narrative essay explaining his or her reasoning and conclusions. It is common
practice in writing such an opinion to cite previous opinions issued in other
cases in order to establish precedent, or occasionally to argue against it. Thus,
like academic papers and patents, legal opinions form a citation network, with
opinions being the vertices and citations being the directed edges. Again the
network is approximately acyclic, as with the other networks in this section.
The legal profession has long maintained indexes of citations between opinions for use by lawyers, judges, scholars, and others, and in recent years those
indexes have made the jump to electronic form and are now available online.
In the United States, for instance, two commercial services, LexisNexis and
Westlaw,6 provide thorough and detailed data on legal opinions and their citations via online services. In the last few years a number of studies have been
published of the structure of legal citation networks using data derived from
these services [125, 126, 194].
In principle it would be possible also to construct networks of cocitation or
bibliographic coupling between either patents or legal opinions, but the author
is not aware of any studies yet published of such networks.

4.3

O THER INFORMATION NETWORKS

There are many other networks of information, although none have received
the same level of study as the Web and citation networks. In the remainder of
this chapter we brieﬂy discuss a few examples of other networks.
4.3.1

P EER - TO - PEER NETWORKS

Peer-to-peer (P2P) ﬁle-sharing networks have become popular and widespread
in the last decade or so. A peer-to-peer network is a network in which the nodes
are computers containing information in the form, usually, of discrete ﬁles, and
the edges between them are virtual links established for the purpose of sharing
the contents of those ﬁles. The links exist only in software—they indicate only
the intention of one computer to communicate with another should the need
arise.
Peer-to-peer networks are typically used as a vehicle for distributed databases, particularly for the storage and distribution, often illegally, of music and
movies, although there are substantial legal uses as well, such as local sharing
6
Westlaw is owned and operated by Thomson Reuters, the same company that owns the Science Citation Index.

72

4.3

|

O THER INFORMATION NETWORKS

of ﬁles on corporate networks or the distribution of open-source software. (The
network of router-to-router communications using the Border Gateway Protocol described in Section 2.1 is another less obvious example of a legitimate and
useful peer-to-peer network.)
The point of a peer-to-peer network is that data is transferred directly between computers belonging to two end users of the network, two “peers.”
This contrasts with the more common server–client model, such as that used
by the World Wide Web, in which central server computers supply requested
data to a large number of client machines. The peer-to-peer model is favored
particularly for illicit sharing of copyrighted material because the owners of a
centralized server can easily be obliged to turn off the server by legal or lawenforcement action, but such actions are much more difﬁcult when no central
server exists.
On most peer-to-peer networks each computer is home to some information, but no computer has all the information in the network. If the user of
a computer requires information stored on another computer, that information can be transmitted simply and directly over the Internet or over a local
area network. This is a peer-to-peer transfer, but no special infrastructure is
necessary to accomplish it—standard Internet protocols are perfectly adequate
to the task. Things get interesting, however, when one wants to ﬁnd which
other computer has the desired information. One way to do that is to have a
central server containing none of the information but just an index of which
information is on which computers. Such a system was employed by the early
ﬁle-sharing network Napster, but the central index server is, once again, susceptible to legal and other challenges, and such challenges were in the end
responsible for shutting Napster down.7
To avoid this problem, developers have turned to distributed schemes for
searching and this is where network concepts come into play. An illustrative
example of a peer-to-peer system with distributed search is the Gnutella network, which underlies a number of popular ﬁle-sharing programs including
LimeWire and the now-defunct Morpheus. In the simplest incarnation of this
system (more sophisticated ones are in use now) computers form links to some
number of their peers in such a way that all the computers form a connected
network. Again, a link here is purely a software construct—a computer’s network neighbors in the peer-to-peer sense are merely those others with which
it intends to communicate when the need arises.
When a user instructs his or her computer to search the network for a spe7
The Napster name was later bought up by the recording industry and is now the name of a
legitimate online music service, although one that does not make use of peer-to-peer technology.

73

N ETWORKS OF INFORMATION

ciﬁc ﬁle the computer sends out a message to its network neighbors asking
whether they have that ﬁle. If they do, they arrange to transmit it back to the
ﬁrst computer. If they do not, they pass the message on to their neighbors, and
so forth until the ﬁle is found. As pointed out in Section 19.2, where we discuss search strategies on peer-to-peer networks at some length, this algorithm
works, but only on relatively small networks. Since it requires messages to
be passed between many computers for each individual search, the algorithm
does not scale well as the network becomes large, the volume of network trafﬁc
eventually swamping the available data bandwidth. To get around this problem, modern peer-to-peer networks, including recent versions of Gnutella,
employ a two-tiered network topology of nodes and “supernodes,” in which
searches are performed only among the supernodes and ordinary nodes contact them directly to request searches be performed. More details are given in
Section 19.2.
So what is the structure of a peer-to-peer network like? In many cases, unfortunately, not a lot is known since the software is proprietary and its owners
are reluctant to share operational details. The Gnutella system is more promising, being so-called open-source software, meaning that the original computer
code for the software and the speciﬁcation of the protocols it uses are freely
available. By exploiting certain details of these protocols, particularly the ability for computers in the Gnutella network to “ping” one another (i.e., ask each
other to identify themselves), a number of authors have been able to discover
structures for Gnutella networks [282, 308]. The networks appear to have approximately power-law degree distributions and it has been suggested that
this property could be exploited to improve search performance [6].
4.3.2

R ECOMMENDER NETWORKS

A type of information network important for technology and commerce is the
recommender network. Recommender networks represent people’s preferences
for things, such as for certain products sold by a retailer. Online merchants,
for instance, usually keep records of which customers bought which products
and sometimes ask them whether they liked the products or not. Many large
supermarket chains record the purchases made by each of their regular customers (usually identiﬁed by a small card with a barcode on it that is scanned
when purchases are made) and so can work out which products each customer
buys frequently.
The fundamental representation of a recommender network is as a “bipartite network,” a network with two types of vertex, one representing the
products or other items and the other representing the people, with edges con74

4.3

|

O THER INFORMATION NETWORKS

necting people to the items they buy or like. One can also add strengths or
weights to the edges to indicate, for instance, how often a person has bought
an item or how much he or she likes it, or the strengths could be made negative
to indicate dislikes.
Recommender networks have been studied for many types of goods and
products, including books, music, ﬁlms, and others. The primary commercial
interest in recommender networks arises from their use in collaborative ﬁltering
systems, also sometimes called recommender systems, which are computer algorithms that attempt to guess items that people will like by comparing a person’s known preferences with those of other people. If person A likes many
of the same things as persons B, C, and D, and if persons B, C, and D all like
some further item that A has never expressed an opinion about, then maybe
(the theory goes) A would like that item too. A wide variety of computer algorithms have been developed for extracting conclusions of this type from recommender networks and are used extensively by retailers to suggest possible
purchases to their customers, in the hope of drumming up business. The website of the online bookseller Amazon.com, for instance, has a feature that lists
recommended book titles to customers based on their previously expressed
preferences and purchases. And many supermarkets now print out discount
coupons after customers have completed their purchases, coupons for products that the customer has not bought in the past but might be interested to
try.
Research on recommender networks has in the past focused mainly on the
development of new collaborative ﬁltering algorithms, but it is reasonable to
suppose that the success of these algorithms should depend to some extent on
the structure of the recommender network itself, and there is therefore good
reason to also study that structure. A few such studies have been published in
the scientiﬁc literature [63, 147], but there is clearly room for further work.
4.3.3

We encountered bipartite
networks previously in
Section 3.5 and will study
them further in Section 6.6.

K EYWORD INDEXES

Another type of information network, also bipartite in form, is the keyword
index. Consider, for instance, a set of documents containing information on
various topics. One can construct an index to that set so that one can look
up words in that index and the index will list important occurrences of those
words in the documents. Such indexes have historically appeared, of course,
in books, as guides to their content, but more recently indexes have regularly
been constructed as guides to other information collections, including sets of
academic papers and the World Wide Web. The index constructed by a web
search engine, as discussed in Section 4.1, is a good example; it consists, at a
75

N ETWORKS OF INFORMATION

minimum, of a list of words or phrases, with each word or phrase accompanied
by a list of the web pages on which it occurs.
Such indexes can be represented as a bipartite network in which one of
the two types of vertex represents words in the index and the other represents
documents or pages. Then one places an edge between each word and the
documents in which it occurs. Although such networks can be constructed for,
amongst other things, the Web or collections of academic papers, they should
not be confused with the networks of web links or citations discussed earlier
in this chapter. Those are also networks of web pages and documents, but
they are different from a keyword index. Those networks were networks of
direct links between documents. An index is a network of links between index
entries and the documents they point to.
Indexes are of practical importance as a method for searching large bodies of information. Web search engines, for example, rely heavily on them
to quickly ﬁnd web pages that correspond to a particular query. However,
indexes also have other, more sophisticated applications. They are used, for
example, as a basis for techniques that attempt to ﬁnd documents or pages
that are similar to one another. If one has a keyword index to a set of documents and ﬁnds that two documents share a lot of the same keywords, it may
be an indication that the two cover similar topics. A variety of computer algorithms for spotting such connections have been developed, typically making
use of ideas very similar to those used in the recommender systems discussed
above—the problem of ﬁnding documents with similar keywords is in many
ways similar to the problem of ﬁnding buyers who like similar products.
The identiﬁcation of similar documents can be useful, for example, when
searching through a body of knowledge. In a standard index search, one typically types in a set of keywords and gets back a list of documents containing
those words. Search engines that can tell when documents are similar to each
other may be able to respond more usefully to such queries because they can
return documents that do not in fact contain the keywords entered, but which
are similar to documents that do. In cases where a single concept is called by
more than one name, this may be a very effective strategy for ﬁnding all of the
relevant documents.
In the context of document retrieval, the classic method for determining
document similarity and performing generalized searches of this type is latent
semantic indexing, which is based on the application of the matrix technique
known as singular value decomposition to the bipartite network of keywords
and documents. The interested reader can ﬁnd a discussion of latent semantic
indexing in Ref. [193].
As with recommender systems, it is reasonable to suppose that the success
76

4.3

|

O THER INFORMATION NETWORKS

of methods for ﬁnding similar documents or improving searches using similarity information depends on the structure of the bipartite keyword/document
network, and hence that studies of that structure could generate useful insights. There has been relatively little interest in the problem within the network community so far and again there is plenty of room for future work.

77

C HAPTER 5

B IOLOGICAL NETWORKS
A discussion of various networks of interest in biology,
including biochemical networks, neural networks, and
ecological networks

N

ETWORKS are widely used in many branches of biology as a convenient

5.1

B IOCHEMICAL NETWORKS

representation of patterns of interaction between appropriate biological
elements. Molecular biologists, for example, use networks to represent the patterns of chemical reactions among chemicals in the cell, while neuroscientists
use them to represent patterns of connections between brain cells, and ecologists study the networks of interactions between species in ecosystems, such
as predation or cooperation. In this chapter we describe the commonest kinds
of biological networks and discuss methods for determining their structure.

Among the biological networks those attracting the most attention in recent
years have been biochemical networks, networks that represent the molecularlevel patterns of interaction and mechanisms of control in the biological cell.
The principal types of networks studied in this area are metabolic networks,
protein–protein interaction networks, and genetic regulatory networks.
5.1.1

M ETABOLIC NETWORKS

Metabolism is the chemical process by which cells break down food or nutrients
into usable building blocks (so-called catabolic metabolism) and then reassemble those building blocks to form the biological molecules the cell needs to
complete its other tasks (anabolic metabolism). Typically this breakdown and
reassembly involves chains or pathways, sets of successive chemical reactions
78

5.1

|

B IOCHEMICAL NETWORKS

that convert initial inputs into useful end products by a series of steps. The
complete set of all reactions in all pathways forms a metabolic network.
The vertices in a metabolic network are the chemicals produced and consumed by the reactions. These chemicals are known generically as metabolites. By convention the deﬁnition of a metabolite is limited to small molecules, meaning things like carbohydrates (such as sugars) and lipids (such as
fats), as well as amino acids and nucleotides. Amino acids and nucleotides are
themselves the building blocks for larger polymerized macromolecules such
as DNA, RNA, and proteins, but the macromolecules are not themselves considered metabolites—they are not produced by simple chemical reactions but
by more complex molecular machinery within the cell, and hence are treated
separately. (We discuss some of the mechanisms by which macromolecules are
produced in Section 5.1.3.)
Although the fundamental purpose of metabolism is to turn food into useful biomolecules, one should be wary of thinking of it simply as an assembly
line, even a very complicated one. Metabolism is not just a network of conveyor belts in which one reaction feeds another until the ﬁnal products fall out
the end; it is a dynamic process in which the concentrations of metabolites can
change widely and rapidly, and the cell has mechanisms for turning on and
off the production of particular metabolites or even entire portions of the network. Metabolism is a complex machine that reacts to conditions both within
and outside the cell and generates a broad variety of chemical responses. A
primary reason for the high level of scientiﬁc interest in metabolic networks is
their importance as a stepping stone on the path towards an understanding of
the chemical dynamics of the cell.
Generically, an individual chemical reaction in the cell involves the consumption of one or more metabolites that are broken down or combined to
produce one or more others. The metabolites consumed are called the substrates of the reaction, while those produced are called the products.
The situation is complicated by the fact that most metabolic reactions do not
occur spontaneously, or do so only at a very low rate. To make reactions occur at a usable rate, the cell employs an array of chemical catalysts, referred to
as enzymes. Unlike metabolites, enzymes are mostly macromolecules, usually
proteins but occasionally RNAs. Like all catalysts, enzymes are not consumed
in the reactions they catalyze but they play an important role in metabolism
nonetheless. Not only do they enable reactions that would otherwise be thermodynamically disfavored or too slow to be useful, but they also provide one
of the mechanisms by which the cell controls its metabolism. By increasing or
decreasing the concentration of the enzyme that catalyzes a particular reaction,
the cell can turn that reaction on or off, or moderate its speed. Enzymes tend
79

B IOLOGICAL NETWORKS

to be highly speciﬁc to the reactions they catalyze, each one enabling only one
or a small number of reactions. Thousands of enzymes are known and many
more are no doubt waiting to be discovered, and this large array of highly
speciﬁc catalysts allows for a ﬁne degree of control over the processes of the
cell.
The details of metabolic networks vary between different species of organisms but, amongst animals at least, large parts are common to all or most
species. Many important pathways, cycles, or other subportions of metabolic
networks are essentially unchanged across the entire animal kingdom. For this
reason one often refers simply to “metabolism” without specifying a particular species of interest; with minor variations, observations made in one species
often apply to others.
The most correct representation of a metabolic network is as a bipartite network. We encountered bipartite networks previously in Section 3.5 on social
afﬁliation networks and in Section 4.3.2 on recommender networks. A bipartite
network has two distinct types of vertex, with edges running only between
vertices of unlike kinds. In the case of afﬁliation networks, for example, the
two types of vertex represented people and the groups they belonged to. In
the case of a metabolic network they represent metabolites and metabolic reactions, with edges joining each metabolite to the reactions in which it participates. In fact, a metabolic network is really a directed bipartite network, since
some metabolites go into the reaction (the substrates) and some come out of
it (the products). By placing arrows on the edges we can distinguish between
the ingoing and outgoing metabolites. An example is sketched in Fig. 5.1a.1
This bipartite representation of a metabolic network does not include any
way of representing enzymes, which, though not metabolites themselves, are
still an important part of the metabolism. Although it’s not often done, one
can in principle incorporate the enzymes by introducing a third class of vertex
to represent them, with edges connecting them to the reactions they catalyze.
Since enzymes are not consumed in reactions, these edges are undirected—
running neither into nor out of the reactions they participate in. An example
of such a network is sketched in Fig. 5.1b. Technically this is now a tripartite
network, partly directed and partly undirected.2
Correct and potentially useful though they may be, however, neither of
these representations is very often used for metabolic networks. The most
1
The metabolic network is the only example of a directed bipartite network appearing in this
book, and indeed the only naturally occurring example of such a network the author has come
across, although no doubt there are others to be discovered if one looks hard enough.
2

80

Also the only such network in the book.

5.1

(a)

|

B IOCHEMICAL NETWORKS

(b)

Figure 5.1: Bipartite and tripartite representations of a portion of a metabolic network. (a) A metabolic network can be represented as a directed bipartite network with
vertices for the metabolites (circles) and reactions (squares) and directed edges indicating which metabolites are substrates (inputs) and products (outputs) of which reactions.
(b) A third type of vertex (triangles) can be introduced to represent enzymes, with undirected edges linking them to the reactions they catalyze. The resulting network is a
mixed directed/undirected tripartite network.

common representations of metabolic networks project the network onto just
one set of vertices, either the metabolites or the reactions, with the former being
the more popular choice. In one approach the vertices in the network represent
metabolites and there is an undirected edge between any two metabolites that
participate in the same reaction, either as substrates or as products. Clearly
this projection loses much of the information contained in the full bipartite network, but, as we have said, it is nonetheless widely used. Another approach,
probably the most common, is to represent the network as a directed network
with a single type of vertex representing metabolites and a directed edge from
one metabolite to another if there is a reaction in which the ﬁrst metabolite appears as a substrate and the second as a product. This representation contains
more of the information from the full network, but is still somewhat unsatisfactory since a reaction with many substrates or many products appears as
many edges, with no easy way to tell that these edges represent aspects of the
same reaction. The popularity of this representation arises from the fact that
for many metabolic reactions only one product and one substrate are known

Projections of bipartite
networks and the associated loss of information
are discussed further in
Section 6.6.

81

B IOLOGICAL NETWORKS

or are considered important, and therefore the reaction can be represented by
only a single directed edge with no confusion arising. A number of companies produce large charts showing the most important parts of the metabolic
network in this representation. An example is shown in Fig. 5.2. Such charts
have become quite popular as wall decorations in the ofﬁces of molecular biologists and biochemists, although whether they are actually useful in practice
is unclear.
The experimental measurement of metabolic networks is a complex and
laborious process, although it has been made somewhat easier in recent years
with the introduction of new techniques from molecular genetics. Experiments
tend to focus neither on whole networks nor on individual reactions but on
metabolic pathways. A number of tools are available to probe the details of
individual pathways. Perhaps the most common is the use of radioactive isotopes to trace the intermediate products along a pathway. In this technique, the
organism or cell under study is injected with a substrate for the pathway of interest in which one or more of the atoms has been replaced by a radioisotope.
Typically this has little or no effect on the metabolic chemistry, but as the reactions of the pathway proceed, the radioactive atoms move from metabolite to
metabolite. Metabolites can then be reﬁned, for example by mass spectroscopy
or chromatography, and tested for radioactivity. Those that show it can be assumed to be “downstream” products in the pathway fed by the initial radioactive substrate.
This method tells us the products along a metabolic pathway, but of itself
does not tell us the order of the reactions making up the pathway. Knowledge of the relevant biochemistry—which metabolites can be transformed into
which others by some chemical reaction—can often identify the ordering or at
least narrow down the possibilities. Careful measurement of the strength of radioactivity of different metabolites, coupled with a knowledge of the half-life
of the isotope used, can also give some information about pathway structure
as well as rates of reactions.
Notice, however, that there is no way to tell if any of the reactions discovered have substrates other than those tagged with the radioisotope. If new
substrates enter the pathway at intermediate steps (that is, they are not produced by earlier reactions in the pathway) they will not be radioactive and so
will not be measured. Similarly, if there are reaction products that by chance
do not contain the radioactive marker they too will not be measured.
An alternative approach to probing metabolic pathways is simply to increase the level of a substrate or enzyme for a particular reaction in the cell,
thereby increasing the levels of the products of that reaction and those downstream of it in the relevant pathway or pathways, increases that can be mea82

|

5.1

O
C OO -

OP C

OP P U

C H 3C H

2.4.1.17

NHAC

O
C HOH
C HOH
C H 2 OH

HO

C H 2 OH
O

C H 2 OH
O

Mannos e-1-P

HO OH

OH

UDP -G luc uronate

4.1.3.20

HO OH

5.1.3.14

OP

Mannos e-6-P

OH

C

H

OH H

C

H

C

C

H

HOC H 2

OH

1.13.99.1

OH H

OH

C

C

C

H

CO

HOC H 2

OH H

OH

C

H

OH H

OH

C

C

C

H

OH H

C HO

HOC H 2

H

C

C

C

H

OH OH

H

OH

C

C

C

C

C

H

H

OH

C HO

HOC H 2

C

H

C

H
C

H

OH H

C

C

P OC H 2

2.7.1.53

C

C HO

HOC H 2

HOC H 2

C

C

H

H

P OC H 2

2.7.1.16

H

OH H

C

C

C

H

C

HOC H 2

C

C

H

H

CO

C

H

OH

C

C

CO

C

C

C O C H 2 OH

4.1.2.-

D-Xylulos e-5-P

nt)

H

H

P OC H 2 C

C

C

C HO
P OC H 2

OH OH OH

o

H

H

H OH

C

C

C

C H 2O P
O

NH 2

PC PC

a

ADP

β

c

α

α

εε

H+

H+

α

H+

β2

ATP
β

ATP synthase
e

1: 3-bis -P -G lyc erate

OP OP

C OO

A rac hidonate 1.13.11.34

A DP

C OS C oA

C O-S -AC P

Oleoyl-C oA

C H 3 (C H 2 ) 14 C OC H 2 C OS -C oA

OH-S tearoyl-C oA

Oxos tearoyl-C oA

C hain elongation

P almitoyl-C oA
C H 3 (C H 2 ) n C H=C HC OS -C oA

1.3.1.9
2,
1.3.1.10

A C Y L -A C P

Dec anoyl-A C P

C H 3 (C H 2 ) 2 C H=C HC O-S -AC P

1.3.1.9

Hexanoyl-A C P

C H 3 C H=C HC O-S -AC P

A C Y L -C oA

G lyc erol
2.3.1.15

2.3.1.7

C H 2 O-C O-R "

2.3.1.20 glyc erol 3.1.3.4 2.7.1.107

C H 3 C H 2 C H 2 C OS C oA

4.2.1.17

2, 3-Hexenoyl-C oA
C H 3 C H=C HC OS C oA

1.3.99.2

B utanoyl-C oA

C H 3 (C H n C H(OH)C H 2 C OS C oA

4.2.1.17

2, 3-E noyl-C oA
C H 3 (C H 2 ) 2 C H=C HC OS C oA

1.1.1.35
1.1.1.35

3-OH-Hexanoyl-C oA
C H 3 C H(OH)C H 2 C OS C oA

4.2.1.55

C rotonoyl-C oA

3-OH-A c yl-C oA
C H 3 (C H 2 ) 2 C H(OH)C H 2 C OS C oA

C H 3 C OC H 2 C OS C oA

1.1.1.157

3-OH-B utanoyl-C oA

C H 3 C H 2 C H 2 C H 2 C OS C oA

C H 3 C H 2 C H=C HC OS C oA

C H 3 C H 2 C H(OH)C H 2 C OS C oA

2.3.1.9

4.1.3.5

3-Oxopentanoyl-C oA

O

C H 2 O-C O-R
OH

OH

O

-

S erine

2.7.8.8

P HOS P HA T IDY L
S E R INE

+
C H 2 O P OC H 2 C H 2 NH 3

P hos phatidyl
ethanolamine
C E P HA L IN

P hos phatidylglyc erol
O

+
C P P - OC H 2 C H 2 NH 3

O

2.7.8.1

2.7.7.14

C DP -E thanolamine

1.4.3.8

HOC H O

- L ys olec ithin 3.1.1.5

L E C IT HIN

+
NH 3
C H 3 (C H 2 ) 14 C H(OH)C HC H 2 OH

3

C H 3 (C H 2 ) 14 C OC HC H 2 OH

Dehydros phinganin
G anglios ides

3.1.4.4

2.3.1.6

2.7.7.15

C DP -c holine

2.7 .8.3

C holine-P

+
NH 3
C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O- G alac tos e

S phinganin
4-S phingenin
2.4.1.23
UDP -S ugars A c yl-C oA
3.5.1.23
UDP -G alac tos e

-

C eramide

3.1.4.12

L yc opene

(C 20)

P hytol

P las toquinone

O

11-c is -R etinol

Dark

HO
CH3

C H 2 OH

5.2.1.7

(V itamin A )

F arnes yl-P P

CH3

(C 15)

O
C H3

α-T oc opherol

P hylloquinone
(V itamin K )

C H3

H
C

N

H 3C

C H3

H 3C

C OO -

H2C

HE ME

N

H
C
H2

C H2

C H2

C OO -

C OO -

4.99.1.1

1.3.3.3

L anos terol

C H2

H
C
H2

- OOC
H 2C

C H2

C OO -

-

C oproporphyrinogen

CH2
H2NCH2C=O

C H2
C H2

C H2

H
N
C
H2

C H2
C H2
C H2

C OO -

C H2

C H2

C OO-

C OO -

4.1.1.37

Uroporphyrinogen

H 2O

COOCH2

C OO -

5-A minoC OO levulinate

β

Pi

3

α

CH 2
CH 2

H 2C
H 2C

ε

H+

H+

+
H+

AαT

α

TE

P orphobilinogen

A DP

X

4.

1.

1.

2.7. 2.11

N2

E ND

H
C

HC
OOC C

1 0 c -s ucb- u

4.2.1.52

C HC OO

4.3.1.3

2SO 4

ME T HIONINE
+
C H 3 S C H C H C H(NH )C OO
2
2
3
+

2.1.1.10
2.1.1.20

(S A M)

C H 2S H
+
OOC C H(NH 3 )C H 2 C H 2 C ONHC HC ONHC H 2 C OO

G lutathione
HOC H 2 C (C H 3 ) 2 C OC OO

Oxopantoate

1.1.1.169
HOC H 2 C (C H 3 ) 2 C H(OH)C OO

P antoate
ß-A lanine
3.5.1.22

1.2.1.25

6.3.2.1
HOC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C OO

P A NTOT HE NA T E
2.7.1.33

C H3

+
C H C H(NH 3 )C OO

P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C OO

4-P -P antothenate
C ys teine
6.3.2.5

C H 3C H 2

2.6.1.32

IS OL E UC INE
CH3

C OO
P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC HC H 2 S H

4-P -P antothenylc ys teine

1.2.1.25

C H 3 C H 2 C HC OS C oA

4.1.1.36
P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

4-P -P antetheine

H2
C

H 2C
OOC C

OOC C H 2 C H 2 C ONH
OOC C OC H 2 C H 2 C H 2 C H-C OO

LY S INE

A
C
I
D
S

C OO
NH C HC H 2 C H 2 C OO

+
C H 2 C H 2 C H 2 C H 2 C H (NH 3 ) C OO

1.5.1.9

S ac c haropine

A denos yl

C H 3 -S C H 2 C H 2 C HNH 2

+

S -A denos ylmethyl
thiopropylamine

L E G E ND
C arbohydrates
B ios ynthes is
Degradation

S permidine

L ipids
2.5.1.16

B ios ynthes is
Degradation

H 2 NC H 2 C H 2 C H 2 C H 2 NH 2

+
OHC C H 2 C H 2 C H (NH 3 ) C OO

P utres c ine

G lutamic
s emialdehyde

CH

C H 3 C OC OO

OHC C OO

NO

+ NH 2

3.5.2.10

B ios ynthes is
Degradation

V itamins C o-enzymes & Hormones
B ios ynthes is

Degradation

P entos e P hos phate P athway

C H2
C HC OO

P R OL INE
1.14.11.2
HOC H

4.1.3.16

P hotos ynthes is Dark R eac tions

4-Hydroxy2-oxoglutarate

4-Hydroxyglutamate

C HC OO
N
H

1.5.1.12

HY DR OXY
P R OL INE
NH

CO

N
C H3

CH2

HN C

C reatinine

Human Metabolis m is identified as far pos s ible by black arrows

B ios ynthes is

Degradation

C OMP A R T ME NT A T ION

2.6.1.23
+
OOC C H(OH)C H 2 C H(NH 3 )C OO

C H2

H 2C

A rgininos uc c inate

P -C reatine

B ios ynthes is
Degradation

P urines &
P yrimidines

OOC C H(OH)C H 2 C OC OO

1.5.99.8
C H2
1.5.1.2
C H2

P - HNC N(C H 3 )C H 2 C OO

A mino A c ids

P yruvate G lyoxylate

C HC OO
N

P yrroline-5c arboxylate

1.14.13.39

2.7.3.2

Diaminopimelate
5.1 .1.7
4.1. 1.20
1.5.1.7 - 10

+
H 2 N(C H 2 ) 4 C H(NH 3 )C OO

+
OHC C H 2 C H 2 C H 2 C H (NH 3 ) C OO

A
M
I
N
O

(Dec arboxylated S A M)

4.3.2.1
+ NH 2

OOC C H-C H 2 C H 2 C H 2 C HC OO
+
NH 3

3.5.1.18

N-S uc c inyl-2, 6
diaminopimelate

N 6 -T rimethyllys ine

+
OOC C H 2 C H 2 C H 2 C H (NH 3 ) C OO

NH

C reatine

OOC C HC H 2 C H 2 C H 2 C H-C OO
+
NH 3

+
+
(C H 3 ) 3 N(C H 2 ) 3 C H 2 C H(NH 3 )C OO

1.14.11.8

2.5.1.22

6.3.4.5

H 2 NC N(C H 3 )C H 2 C OO

+
NH 3

OOC C H 2 C H 2 C ONH

2.6.1.17

S permine

A R G ININE

2.1.1.2

C oenzyme A

2-Oxoadipate 2.6.1.39 2-A minoadipate 1.2.1.31 2-A minoadipate
s emialdehyde

OOC C HC H 2 C OO
N
+
H 2 NC NHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

NH 2

2.7.1.24
P -ADP - OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

(C H 3 ) 2 C HC H 2 C OS C oA

Is ovaleryl-C oA

H 2 N(C H 2 ) 4 NH (C H 2 ) 3 NH 2

2.1.3.3

+
H 2 NC NHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

Dephos pho-C oenzyme A

1.2.1.25

C H2
C H-C OO

N 6 -T rimethyl3-OH-lys ine

1.2.1.41

3.5.3.6

ADP - OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

L E UC INE

1.4.1.9

1.3.99.10

N

C H2 C H2

UR E A

2

2.6.1.6

3-Methylc rotonyl-C oA

OOC C H 2 C H 2 C H 2 C OC OO

4.1.1.17

3.5.3.1

+
(C H 3 ) 2 C HC H 2 C H(NH 3 )C OO

OH
+
+
(C H 3 ) 3 N(C H 2 ) 3 C H 2 C H(NH 3 )C OO

1.14.11.1

2.6.1.13

2.1.4.1

2.5.1.6

S -A denos yl
methionine

G lyc ine

4.1.2.12

2, 3-DihydroP iperideineN-S uc c inyldipic olinate 2, 6-dic arboxylate 2-amino-6-oxopimelate

6.3.5.5

H 2 NC ONH 2

H 2 NC NHC H 2 C OO

C H3
C H 3 C = C HC OS C oA

H 2 N(C H 2 ) 3 NH (C H 2 ) 4 NH (C H 2 ) 3 NH 2

2.1.3.3

G lyc ine +

1.2.1.32

Adenos yl

C H 3 C HC O-S C oA

C HC OC OO

1.3.1.26

G lutaryl-C oA

OR NIT HINE

s
n it

6.4.1.4

N

+
H 2 NC ONHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

+
H 2 NC H 2 C H 2 C H 2 C H (NH 3 ) C OO

G uanidoac etate
E R G O N IC R E A C T IO N

CH

C H3
+
C HC H(NH 3 )C OO
C H3

C H3

C H3
C H 3 C H=C HC OS C oA

C H2
C H-C OO

15

G lutamine

ATP
C O2

N
C
H

4.2.1.19

+
C H 3 S C H C H C H(NH )C OO
2
2
3

HC HO

(C H 3 ) 2 C HC H 2 C OC OO

C H3

+
P OOC C H2C H 2 C H (NH 3 ) C OO

+
H 2 NOC C H 2 C H 2 C H (NH 3 ) C OO

H 2 NC OO P

β

+ NH

Y

C

2.1.1.13
2.1.1.14

γ-G lutamylc ys teine

2.6.1.32

C H 3C H 2

3-Methylglutac onyl-C oA

OOC C H 2 C H 2 C H 2 C OS C oA

3.5.1.2
6.3.1.2

1.4.1.14

CH

C

C H 2 C OC H 2 OP

NH

Imidazole
ac etol-P

2.7.7.4

Adenos yl

C HC OC OO

C H3

C H 3C H 2

(G A B A )

Pi

ATP

N

Uroc anate

(A P S )

6.3 .2.3

C H3

OOC C H 2 C H 2 C H 2 NH 2

7.1
1.7. 6.4
1.6. .1
.6
18
6.3.4.16
1.

H+ H+
H+ H+

D P R OTONS

C

HC

NH
CH

A denylyls ulphate

C H 2S H
+
OOC C H(NH 3 )C H 2 C H 2 C ONHC HC OO

C H3

OOC C H 2 C = C HC OS C oA

+
OHC C H 2 C H (NH 3 )C OO

4.1.1.70

NH 4+

F0
H+

C

OH OH HN

2.6.1.9

N

B ile A c ids

C H3
C H3

4-A minobutyrate

H+

4.2.1.24

N
H

H2N

1. 11

+
OOC C H 2 C H 2 C H (NH 3 ) C OO

G L UT A MA T E

T IO N

F1

γ

P OC H 2 C

Imidazole
glyc erol-P

+
S C H 2 C H 2 C H(NH 3 )C OO

T aurine

C H 2 = C C OS C oA

C IT R UL L INE

γ

δ

RPPP

H

C
H

S -A denos yl
homoc ys teine

HO 3 S C H 2 C H 2 NH 2

C (OH)C H(OH)C OO
C H3

C H 3 C H(OH)C HC OS C oA

C arnitine

ATP

P +1 P i

H+
H+
H+
β
H+
H+

a

A

- OOC

4.3.1.8
4.2.1.75

ADP +

IV

1/ O
2 2

5.4.99.7
S qualene
1.14.99.7
(C 30)

N
H

H

H 2C

OOC

C H2

H2
C

N
H
N

C H3
C H2
C H2

C OO -

C H2

H 2C

N

C H2

C OO -

C H2

C H2

N
H

H

H 3C
C H2

C H2

P rotoporphyrinogen

C H3

H2
C

N
H
N

C H3

C H2

C OO-

H 2C

N

C H2

C H2

1.3.3.4

H3C

N
H

H

C H2
C OO -

C H2

2

CH
N
H

CH
N

C
H

C H2

C H3 C H

H2
C

H

C OO -

C H2

NA

C

N

C H2

CH
N
Fe

HC
H3C

CH

CH

H 3C

HO

H

Zymos terol

C OO -

C H2

TR A N S L O

CH

HO

Des mos terol

C HL OR OP HY L L

β

1.9.3.1

H

H
HO

C HOL E S T E R OL

C H2

C H 2.7.4.6
CH

N

C Y T IDINE triphos phate

H

RP

CH

3-Hydroxy- 4.2.1.17 Methyl 1.3.99.3 Is obutyryl-C oA
Is obutyryl-C oA
ac rylyl-C oA

2.6.1.19

C arbamoyl-P
AD

H
HO

HE MOG L OB IN

1. 29

C H3

(C H 3 ) 2 C HC HC H(OH)C OO

2-OXO A C ID
2.6.1.-

MI

NO2 -

F1

2

2e-

P roges terone
P regnenolone

os cp

AT P

6.3.4.2

P
Y
R
I
M
I
D
I
N
E
S

(C T P )

CH

4.2.1.49

Homoc ys teine

4.4.1.8

HOC H 2 C HC OS -C oA-

G lutamyl-P

F6

2H +

C

N
OC

C H 2 C H(NH 3 )C H 2 OP

+
HS C H 2 C H 2 C H(NH 3 )C OO

4.2.1.22

6.3 .2.2

C H3

+
(C H 3 ) 3 NC H 2 C H(OH)C H 2 C OO

1.6.6.1
1.7.99.4

δ

2H+ C uB Heme a 3

NH
CH

2-3-Dihydroxy 4.2.1.9 2-Oxo- 1.4.1.8 V A L INE
is ovalerate
is ovalerate

(C H 3 ) 2 C HC (OH)C H 2 C OO

1.3.99.7

NO 3 -

nth

2H+

Heme a

2.5.1.21

(V itamin E )

3.1.2.4

A s partyl
S emialdehyde
S uc c inic
s emialdehyde

1.4.1.2

4

N

C HC H 2 C H 2 C OO

2.7.1.25

+
HOC H 2 C H 2 C H(NH 3 )C OO

1.1.1.3
1.1.1.86

C OOH

UQ

e

C H 2 OH

trans -R etinol
S T E R OIDS

1. 2.

+
R -C H(NH 3 ) C OO

3

C

N

NH
CH

G lutamate

1.8.1.3

CH3

4.2.1 .18

2-A MINO A C ID

ting A
s por . 6 . 1 . 3 T P s y

HC

Imidazolone
propionate

P hos phoadenylyls ulphate

3-Is opropyl- 1.1.1.85 Oxoleuc ine
2-Is opropyl4.2.1.33
malate
malate

A s paragine

C yt.c
n
tra

N

3.5.2.7

C ys tathionine

C OOH

R -C O-C OO

+-

NH C
C
HC
N

C DP

2.7.7.3

6.4.1.3

+
H 2 NOC C H 2 C H (NH 3 C OO

2H+

C uA C uA

N

His tidinol-P

3.1.3.15
OC

C (OH)C H(OH)C OO

OOC C H 2 C H 2 C HO

1.2.1.16

as

O

2.3.1.76
3.1.1.21

OPP
C H2

C H 2 OH

O
C
CH
CH
N
R PPP

C ONH 2

2-Methylac eto-1.1.1.35 2-Methyl-3-4.2.1.17T iglyl-C oA
2 Methylbutyryl1.3.99.3
ac etyl-C oA
C oA
hydroxybutyryl-C oA

A s partyl-P

5.4.99.2

Glycine

_
UQ.

(C 20)

C H3

C H2

+
OOC C H 2C H 2 C OO C H 2 C H 2 C H(NH 3 )C OO

C OO

5-A minolevulinate

1eC yt.bH

1.10.2.2

2.5.1.10

(C oenzyme Q)

1.1.1.105

1.1.1.23

C HC H 2 C H 2 C OO

Hypotaurine

+
P OOC C H 2 C H (NH 3 )C OO

A

G eranyl-geranyl-P P
n

Ubiquinone

O

L ight

1.1.1.105

S UC C INY L -C oA

NS

C H 3O

C HO

trans -R etinal 5.2.1.3 11-c is -R etinal C HO Menaquinone

1.1. 1.31

5.1.99.1

-OOCCH2CH2COO-

S UC C INA T E

1e-

III

2eC yt.bL

CO

C H 2 C H(NH 3 )C H 2 OH

3.3.1.1

C H3
HOC H 2 C HC OO

4.2.1.18

6.3.5.4
-OOCCH2CH2CO.SCoA

2.3.1.37

C yt.c 1
2UQ

NH
CH

NH
CH

4. 1.

3-Hydroxyis obutyrate

1.1.1.3

6.2.1.4

F e-S

C

N

His tidinol

O-P hos pho- 2.7.1.39Homos erine 2.3.1.46
homos erine

.3. 18

A S P A R T A T E 2.7.2.4
4.3.1.1

UQH 2

2e- 2UQ _.

(C 10)

4.2.99.9

C OO

Methylmalonyl-C oA

4.1.1.71

2H+

1.10.2.2

4H+

2.5.1.1
C H3

CH3

C H 3 C = C HC H 2 C H 2 C = C HC H 2 O P P
C H 2O P P

G eranyl-P P

C H3

C

OH OH

C ys teate

C H 3 C OC (OH)C H 3

C H3

-

TR A

Ops in

C OO-

(C 5)

(C 5)
2.5.1.29

O
C H 3O

R etinoate
1.2.1.36

R etinol es ters

Is opentenyl-P P

C H3
C H 3 C = C HC H 2 O P P

2.5.1.32

R hodops in

1.3.5.1

F AD

II

2UQH 2

Dimethylallyl-P P

(C 40)

hv
(C 40)

Metarhodops in
1.13.11.21

2CH2COO

1.2.4.2
2.3.1.61

C H2
C H 3 C -C H 2 C H 2 O P P

HC

4.2.1.9
2-A c eto-22-Oxo-3-methyl
2: 3-Di-OHhydroxy- 1.1.1.86 3-methylvalerate
valerate
butyrate

2.1.3.1
4.1.1.41
5.1.99.1

G L UT A R A T E

UQH 2

C erebros ide

P hytoene

(C 40)

T o B rain -V IS ION

ß-C A R OT E NE

F e-S
C yt.b

UQ
4.1.1.33

C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O- G alac tos e

3.2.1.46 2.4.1.47
1.3.99.7

Diphos phomevalonate

A c yl-C oA
NHC OR

NHC OR
C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 OH

2.7.8.3

+
C H 2 C H(NH 3 )C HO

+
HO 3 S C H 2 C H(NH 3 )C OO

+
P OC H 2 C H 2 C H(NH 3 )C OO

OOC -C H-C OS C oA

+

1.17.4.1

NH 2

P ropanoyl-C oA

2-OXO-

F ADH 2

P OC H 2 C

H

RP

+
C H 2 C H(NH 3 )C OO
+
S C H 2 C H 2 C H(NH 3 )C OO

4.4.1.1

C H3

1.1.1.41

-OOCCOCH

2H+ -OOCCH=CHCOOF UMA R A T E

P s yc hos ine

2.4.1. 62

4.1.3.1

C

NH

1.8.99.2

C Y S T E INE

C H 3 C OC HC OS C oA

IS OC IT R A T E

MA L A T E
4H+
2H+ 4.2.1.2

UQH 2

+
.8 HS C H 2 C H(NH
3 )C OO

4.2.99.2

C H 3 C H 2 C OS C oA

CH(OH)COOCHCOOCH2COOC

or

C H 2 C OO

99

8

2.3. 1.16

2.6.1.1

CH3CH(OH)CH2CO.SCoA

1.6. 5.3

C H 3 C (OH)C H 2 C H 2 O P P

1.1.1.102

S P HING OMY E L IN

C HOL INE

2.7.1.32

3.1.4 .12

+
NH 3
C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 OH

+
HOC H 2 C H 2 N(C H 3 ) 3

+
OC H 2 C H 2 N(C H 3 ) 3

2F e -S
(5 C lusters)

4H+

HS O

1.8.99.1

C H 3 C OC (OH)C H 2 C H 3

F MNH2

HN
OC

2.4.2.9

P -R ibulos ylformimino
P -R ibos ylformimino
5-aminoimidazole- 5.3.1.16 5-aminoimidazolec arboxamide-R P+
c arboxamide-R P
+

HO 2 S C H 2 C H 2 NH 2

4.1.3.7
CH2COOC(OH)COOCH2COO-

4.2.1.3

Glyoxylate
Cycle

C

OH OH
O

-

C H 3 C H 2 C OC OO

C H3
OHC C HC OO

4.1.3.8

1.1.1.37

CH

H

1.13.11.20

C IT R A T E

2.7.1.36
2.7.4.2

3.1.4.3
+
C P P -O C H 2 C H 2 N(C H 3 ) 3

2.7.8.2

NHAcyl O
+
C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O P O C H 2 C H 2 N(C H 3 ) 3
O

C H C OO

2
A c etylc holine C H C (OH)C
H 2 C H 2 OH
3
3.1
.4. 2
Mevalonate

G lyc erophos phoc holine

1.1.1.23

2-A c etolac tate

4.1

-OOCCHO

2H

1.1.1.32

C H 3 C OC H 2 C H 2 N(C H 3 ) 3

+
C H 2 OP O C H 2 C H 2 N(C H 3 )
O

C

C

HC

Oxobutyrate

4.1.3.2

+

E thanolamine

C H 2 OH

C holine
plas malogen 1.3.1.35
S erine +NH

Mevaldate

+
HOC H 2 C H 2 NH 3

2.7.1. 82

E thanolamine-P

C H 2 O-C O-R
HOC H O

+
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3
2.1.1.17
O
C H 2 OC H=C HR
2.1.1.71
C H 2 O-C O-R
R -C O-OC H O
3.1.1.32
O
R '-C O-OC H
+
+
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3
O
O

2.3.1.50

+
P OC H 2 C H 2 NH 3

C H 2 C OO
C H 3 C (OH)C H 2 C HO

HN

OC N C H
RP

CH

C ys teine
s ulphinate

4.2.1.16

GTP

NAD+

O
C

CH
C -C OO
RP

d-C DP

NH 2
C
CH
CH
NH

N

OC

NH 2
N
OC
C
NH
CH
C
HC
N
N

RP

DP

2.7.4.14

C ytos ine

S uc c inylhomos erine

4.1 .3.1

Malonic
s emialdehyde

1.2.1.18

OX A L OA C E T A T E

I

4

d-C MP

N

(P A P S )

1.6.4.1

T HR E ONINE
OHC C H 2 C OO-

52

4.1.1.32

-OOCCOCH
2COO-

NA DH+H+

F MN
I

G lyc ol
aldehyde

C H 2 O-P O C H 2 C HOHC H 2 OH

-

HS

+
C H 3 C H(OH)C H(NH 3 )C OO

2.6.1.18

1.

Methylmalonyl
s emialdehyde

4.2.1 .18

1.1.1.34

Oxalate

N

H

His tidinal

4.1.1.12

LACTATE
2.

2.6.1.4 4

4.1.3.4

C H 3 C (OH)C H 2 C OS C oA

ß-OH-ß-Methylglutaryl-C oA

HOOC -C OOH

HOC H 2 C HO

1.6.5.3

C ardiolipin

1.2.3.5
HOC H 2 C OO

G lyc olate
1.2.1.21
2.7.8.5

O

O
C

OC

H

F ormimino
glutamate

1.1.1.39

4.1.3.5
C H 2 C OO

1.1.1.79

O

C DP -diac yl
glyc erol

C H 2 O-C O-R
R '-C O-OC H

O HC O-C O-R

C H 2 O-P O C H 2 C H(OH)C H 2 O-P -OC H 2
O
O

O

OHC C OO

G lyoxylate

2.7.7.41

O

C H 2 O P OC MP

Inos itol

2.7.8.11
C H 2 O-C O-R ’

C H 2 O-C O-R
R '-C O-OC H
O

4.1.1.65

C H 2 O-C O-R

R '-C O-OC H

C OO
O
+
C H 2 O P O C H 2 C HNH 3

HO OH
OH

R '-C O-OC H

C H 2 O-C O-R

R '-C O-OC H

1.3.99.7

-

8

A C E T Y L -C oA

NAD+

H

C H 2 O-C O-R

C

3.5.4.19

N

4.1.1.29

C H 3 C H(OH)C OO

NADH+H+

A c etoac etyl-C oA
C H 3 C H 2 C OC H 2 C OS C oA

1.1.1.35

3-OH-P entanoyl-C oA

P entenoyl-C oA

P OC H 2

HN

4.1.2.5

.1. 27

4.

6.4.1.1

2.6.1.4

C H 2 O-P O

4.1 .3.1

1.1

HOH
GDP
C O2

CH3COSCoA

P entanoyl-C oA

H

H

NH

3-S ulphinyl
pyruvate

A L A NINE

CH3COCOO-

1.2.4.1
2.3.1.12
3.1.3.43

2.4 .2.

CH
N

NH 2
C
CH
CH

N
OC

d-UMP

3.5.4.1

Urac il

HN

CH
C -C OO
NH

HN
OC

O
C
CH
CH
N H

HN
OC

N

CH
CH
N DP
3.5.4.12

HN
OC

2.1.1.45

T HY MIDINE -P

1.3.1.2

N
C
C

HN
H 2N C

O
C

C -C H 3
CH
N
DP

2.4.2.4

H

O
C

P
U
R
I
N
E
S

(G MP )

O
OC

CH
N RP

G UA NOS INE -P

C

.4. 9 HN

N
C
C

N

(XMP )
6.3.4.1
6.3.5.2

2.1

1.17 .4.1

2.7

OC

2.7.4.8

G DP

RP

XA NT HOS INE -P

G uanine 2.4.

.1

RP

CH
N

O
C
HN

2.4.2.1

7.4

N

(IMP )

1.1.1.205

3.5. 4.3

d-G DP

T DP

O
C

C H2
C H-C OO

NH

HIS T IDINE

4. 2.

C Y S T INE

+
C H 3 C H(NH 3 )C OO

2.6.1.2

4.1.1.9

NA D
ATP
C O2

2.3.1 .16

3-Oxohexanoyl-C oA

Odd C F atty ac ids

R '-C O-OC H O

1.4.1.1

1.2.4.1
2.3.1.12
1.8.1.4

2.3.1.38

3.1.4.6

2.7.4.6

6

C H2
C H2

OOC

HO 2 S C H 2 C OC OO

C H 3 C O-S -AC P

2.3. 1.16

3-Oxoac yl-C oA
C H 3 (C H 2 ) 2 C OC H 2 C OS C oA

6.3.4.4

s uc c inate

CH
N

N
C
C

INOS INE -P

A s partate

4.3.2.2 A denylo-

N

C

O
C

HC

4.3.1.3

4.4.1.15

A c etyl-A C P

3.1.2.11

C H 3 (C H 2 ) n C OC H 2 C OS C oA

.7.

NH

CH

C H 2 C H 2 NH 2

HS O 3-

P Y R UV A T E
C H 3 (C H 2 ) n C H=C HC OS C oA

1.3.99.3

Hexanoyl-C oA 1.3.99.3

P hos phatidyl
inos itol

P
O
R
P
H
Y
R
I
N
S

1.1.1.30

A c etoac etate

P hos phatidate

3.1.1.28

(Mitoc hondria)

C H 3 (C H 2 ) 2 C H 2 C H 2 C OS C oA

O
C

HN

O
C C
NH

3.5.4.10

4. 6

1.3.1.2 T hymine

+
C H 2 C H(NH 3 )C OO

C

N

1. 1

P Y R UV A T E

HOOC C H 2 C O-S C oA

C H 3 (C H 2 ) n C H 2 C H 2 C OS C oA

A C Y L -C oA

2.7

C C H3
CH
NH

HN
OC

OC

+
HO 2 S C H 2 C H(NH 3 )C OO

Malonyl-C o-A

C H 3 C OC H 2 C OO

C H 2O P

Diac yl

FAT

4.1.1.4

R ’-C O-OC H

C H 2 OH

T riac ylglyc erol

O-A c yl-c arnitine

C H 3 C H(OH)C H 2 C OO

H2N
HC O

C
A
T
E
C
H
O
L
A
M
I
N
E
S

F ormylamidoimidazolec arboxamide-R P

3.1. 3.5

2.4.2.1

1.1

d-C T P
GTP
T T P 2. 7.

O
C

C H-C H 3
CH2
NH

2.4.2.15

d-G T P

.7. 7

.7. 6

HIS T A MINE

+
S -C H 2 C H(NH 3 )C OO
+
S -C H 2 C H(NH 3 )C OO

4.4.1. 15

P

L
I
P
I
D

4. 1.

ATP

2

Inos ine

3.2.2 .2

CH
NH

NH
N
C
C
CH
C
HC
NH R P
N

2.7.7.7

2.7

P -R ibos yl-A MP

HC

A c etyls erine

HS

K E TONE B ODIE S
C H 3 C OC H 3

2.7.8.5

3.6.1.31

+
C H 2 C O-OC H 2 C H(NH 3 )C OO

2.7.1.40

1.
3. 7.

2.3.1.39

3-P -G lyc erol

C

4.1.1.22

.1. 30

A c etaldehyde

A DP
HOOC C H 2 C O-S -AC P

Malonyl-A C P

RP

2.1.2.3
N
C
C

F umarate N

2.7.7 .7
2.7.7.6

NH
C
H

2.3.1.41

C H 3 C OC H 2 C OS AC P

2.3.1.41

2.3.1.51
C H 2 O-C O-R

C H 2 O-C O-R
R ’-C O-OC H

R ’-C O-OC H

C

NHC OC H 2 C H 2 NH 2

C

N

2.3

2.1.3.2

C H 3 C HO

P -enolpyruvate

C H 3 (C H 2 ) 2 C OC H 2 C OS AC P

A c etone 3-OH-B utyrate

C H 2 O-C O-R

3.1.1.3

C arnitine
O-A c yl-c arnitine

C

C arnos ine

H

HC

1.2.1.4

C H 2 =C (O P ) C OO

C H 2O P

CH
N

HN

C H 3 C H 2 OH

E T HA NOL
1.1.1.1

A c etoac etyl-A C P

1.1.1.8

HOC H

2.7.1.30

NH
C

HOC H2C H(O P ) C OO

3-Oxo-Hexanoyl-A C P

1.1.1.100

C H 2 OH

C H 2 OH
HOC H
C H 2 OH

N

A denine

NH 2
N
+ C
C
N
CH
C
HC
N
N
R P (P P )

C C H 2 C HC OO

N

G lyc erate

3-Oxo-Dec anoyl-A C P

1.1.1.100

C H 3 C H(OH)C H 2 C OS -AC P

3-OH-B utanoyl-A C P

F A T T Y A C ID

(C ytos ol)

S
T
E
R
O
I
D
S

C H 3 (C H 2 ) 2 C H(OH)C H 2 C OS AC P

3-OH-Hexanoyl-A C P

4.2.1.58

C rotonoyl-A C P
3.1.2.20

P lant P igments

N
C
C

H 2N

UR IDINE UDP
Dihydro
Orotate
Orotidine-P
Uridine-P
4.1.1.23 (UMP ) 2.7.4.4
2.4.2.10
2.7.4.6 triphos phate
orotate 1.3.1.14

3.5.2.3

H

OH OH
O

HOC H2C H(OH) C OO

2-P -G lyc erate

2.3.1.41

R -C H 2 C OO

6.2.1.3

H

ACE TATE

0

4.2.1.59

2, 3-Hexenoyl-A C P

1.3.1.9

B utanoyl-A C P

C

H

P -R ibos yl-A T P

2.4.2.17

3-Oxoac yl-A C P

C H 3 C H=C HC O.S -AC P
C H 3 C H 2 C H 2 C OS AC P

P OC H 2

P OC H 2 C OC OO

2.3.1.41

3-OH-Dec anoyl-A C P
4.2 .1.6

O
C

H 2N

RP

(UT P )
H

P -Hydroxypyruvate

4.2.1.11

C H 3 (C H 2 ) 6 C H=C HC OS AC P

HC

(A MP )

O
C

O
C

HN
OC

H

C arbamoyl
as partate

C H 3C OO

Mitoc hondrial

T annins

L IG NIN

CH

N

OOC -C H-C H 2 C OO

C arbamoyl 3.5.2.2 Dihydroß-alanine
urac il

2.6.1.22

C H 3 (C H 2 ) 6 C OC H 2 C OS AC P

1.1.1.100

HN

CH
NH

A DE NOS INE -P

H 2 NC ONHC H 2 C H 2 C OO

-OOC
NH 2 C H 2
OC
C H-C OO
N

3.1.3.3

C H 3 (C H 2 ) n C OC H 2 C OS AC P

1.1.1.100

3-OH-A c yl-A C P

4.2.1 .60 C H (C H ) C H(OH)C H C OS AC P
3
2 6
2

2, 3-Dec enoyl-A C P
C H 3 (C H 2 ) 2 C H 2 C H 2 C OS AC P

C H 3 (C H 2 ) n C H(OH)C H 2 C OS AC P

4.2.1.60
4.2.1.61

3-E noyl-A C P

C H 3 (C H 2 ) 5 C H=C HC H 2 C OS AC P

3, 4-Dec enoyl-A C P

1.3 .1.9

2.7.4.3
2.7.4.4

13

3.5.1.6

O
C

N
C
C

NH

ß-Ureido 3.5.2.2 Dihydro
is obutyrate
thymine
2.
1. 1.

HC

P OC H2 C H(O P ) C OO

2, 3-Diphos pho- 5.4.2.1
glyc erate

C

H 2N

NH 2 N
C
N
C
CH
C
HC
N R P (P )
N

A DP

HN
OC

H 2 NC ONHC H 2 C HC OO

ß-A lanine

2.6.1.52

E ndoplas mic R etic ulum
C H 3 (C H 2 ) 14 C OS C oA

P almitoyl-A C P

C H 3 (C H 2 ) 6 C H 2 C H 2 C OS AC P

C H 3 (C H 2 ) n+2 C OS -C oA

I
S
O
P
R
E
N
O
I
D
S

T hromboxane B 2

C H 3 (C H 2 ) 14 C H(OH)C H 2 C OS -C oA

C H 3 (C H 2 ) 14 C OS -AC P

P
H
O
S
P
H
O
L
I
P
I
D
S

5.3.99.5

P ros taglandin P G E2

C H 3 (C H 2 ) 14 C H=C HC OS -C oA

OH

T HY R OXINE
OOC -C H-C H 2 C OO
HNC O C N

O
C

HN

3.5.1.6

H 2 NC H 2 C H 2 C OO

P hos phos erine

C H 3 (C H 2 ) 14 C OC H 2 C OS -C oA

B
I
O
S
Y
N
T
H
E
S
I
S

D
E
G
R
A
D
A
T
I
O
N

OH

HO

P almitoleoyl-A C P
Dehydros tearoyl-C oA

C OS C oA

NH

ME L A NIN

OC

2.7

C H3

4.2.1.22

+
P OC H 2 C H(NH 3 )C OO

2.7.1.31

OH

C oumarate

1.1.1.29

1.1.1.95

3-P -G lyc erate

C OO
O

HO

1.14.99.5

S tearoyl-C oA

P OC H2C HOH C OO

OH

C OO

C H=C HC OO

OH

I

1.1.1.204
1.1.3.22
Hypoxanthine
1.1.3.22 Xanthine

DNA

7

4.2.1 .20

4.1.1.11

Hydroxypyruvate

A DP

ATP

L eukotriene B 4

O

5.
1. 14 3. 99
.9 9. .3
1

1.3.1.35

+

S E R INE

HOC H 2 C OC OO

OH OH

C OO

I

RP

1.17.4.1

3-A minois obutyrate

HOC H 2 C H(NH 3 )C OO

2.6.1.51
1.4.1.7

CH
N

2.7.4.6

ATP

4.6.1.1

C H3
H 2 NC H 2 C HC OO

C HOL INE

2.7.2.3

γ-L inolenate

1.14.99.25

L inoleate

O

CO
NH

A T P 2.7.7.6 R NA

4.1.2.5

+
HOC H 2 C H 2 N (C H 3) 3

C OO

L
I
P
I
D

O

2.7 .7.

B etaine
aldehyde

P OC H 2C HOHC OO P

2.7.6.1

HO

O

C
C

d-A T P

+

P -R ibos yl-P P

HO

C innamate
Menaquinone
1.14.13.11

N

HC

2.7.4.6

F OL IC
A C ID
C1
P OOL

2.1.2.1

1.2.1.8

Pi
NA D+

NH 2

NH

C
N
H

UR A T E

A
C
I
D
S

P henylpyruvate

C H=C HC OO

O

d-A DP

1.1.99.1

CHLOROPLAST OUTER MEMBRANE

C OO

O

2.1.1.5

Pi

HN
OC

1.7.3.3

OH OH

OH

C yc lic A MP

B etaine

1.2.1.12

3.6.1.34

STROMA

O

+

1
5.3 .1.
2.7.1.28

O

NH
CO
NH

N
-O P ~O P ~O P O C H
2 O

N

O

OHC C H 2 N(C H 3 ) 3

NA DH

ATP

3

H+

THYLAKOID LUMEN

THYLAKOID MEMBRANE

O

OOC C H 2 N(C H 3 ) 3

C H 2O P
O

Fixation

ATP

C
N H
H

N
CH

Dimethylglyc ine

1.2.1.13

CO2

1

γ

OC

OC

A llantoin

1.4.4.2

2.4.2.14
6.3.4.7

β

H+

H+Protons from Water

3.5.2.5

N

N
C H2 O

O

H2N

NH

HC

P

1.5.99.2

4.1.2.13

1

Glyceraldehyde

Ribulose-1,5-bis-P

Pi

A DP

2

H+

H+ H+
H+
H+ H+ H+ H+
H+
H+ H+
H+
H+ H+
H+ H+ H+ H+ H+ H+
H+

Pi

O
O

S arc os ine

3-P -G lyc eraldehyde

(G lyc erone-P )

α

H+
H+

H+

NH 2

N

1.
2.
OOC C H 2 NHC H 3

G lyoxylate

NH 2
CO

C OO
C
N H
H

OC

OOC C H 2 N(C H 3 ) 2

C O C H 2O P

5.3 .1.

I

CH
N

H2N

RP

A
M
I
N
O

4.2.1.51

O
O

N
C
C

CH
N

C H 2 C H 2 NH 2

OH

T yramine

O

1.14.18.1

OOC

N

HC
C

2.6.1.5
4.3. 1.5

1.3.1.13

.1. 25
+

O

H 2N
RP

OH

P rephenate
C H 2 C OC OO

P HE NY L A L A NINE
4.1

C H 2 C H (NH 3 ) C OO

I

P las toquinone

C HO
NH

A llantoate

C H 2 (NH 3 )C OOH

P -R ibos yl
amine

C

2.2.1.1

Dihydroxyac etone-P

NADPH+H+

H 2N

Urea

S edoheptulos e-P P

HOC H 2 C OC H 2 OP

H 2C
C

5.4.99.5

+

Ubiquinone

HN

Dopaquinone

OC H 3

NH

1. 4
2. 6. 10
1.
20
1. 4.
1.

2.2.1.1

NADP+

H+
H+

OC -C OO

OH

C horis mate

2-A mino
muc onate

C H 2 C OC OO

A
R
O
M
A
T
I
C

1.3.1.13
1.14.16.1

T Y R OS INE

1.14.16.2

H2
C
C H-C OO
+
NH 3

O

(V itamin E )

OH

HN

H 2 NC ONH 2

OH OH OH H

D-R ibos e-5-P

H+

H+

α-T oc opherol

4-OH-3-Methoxyphenylglyc ol

RP

+

OH OH
H

OH
OH

Dopa

O

G LY C INE

F ruc tos e1: 6-bis -P

2.2.1.2

OOC

C H 2 C H(NH 3 ) C OO

C H 2 C H (NH 3 ) C OO-

4.1.1.28
1.14.18.1

C HO
NH

OH

6.3.4.13

C O C H 2O P

C

+

NH 2

OOC
OOC

4.1.3.27

C H2

O-C -C OO

OH

S hikimate-5 4.6.1.4
enolpyruvate 3-P

C H 2 C H (NH 3 ) C OO

OH

2.6.1.5

Hydroxyphenyl
pyruvate

Dopamine

C HOHC H 2 OH

HO

C

P O

2.5.1.19

1.14.12.1

NH 2

A nthranilate

C OO

1.3.1.13

OH

1.14.17.1

1. 6

3.5.3.4
H

OH

1.13.11.27

C H 2 C H 2 NH 2

NH
OC

OH OH H

OH H

1. 15

3. 4

H 2C

A DP

OH

C

P OC H 2

2. 7.

1. 4.

NHC OC H 2 NH 2

OH

2.7.1.11

3.1.3.11

C HO

P OC H 2

α
α
1

O2

H+

C

H

H

5.3.1.6

OH

C H 2O P
O

2.7.1.17

H+

H+

H+

H

OH

OH

S hikimate-3-P
PEP

1.2.1.32

C OO

2.4.2.18

N-(5-P -R ibos yl)
anthranilate

6.3.5.3
6.3.3.1
G lyc inamide- 2.1.2.2 F ormyl
F ormyl
5-A mino 4.1.1.21 5-A mino-4-imidazole 6.3.2.6 5-A mino-4-imidazole 4.3.2.2 5-A minoimidazole
c arboxylate-R P
(N-s uc c inylc arboxamide)-R P c arboxamide-R P
ribos yl-P
glyc inamide-R P glyc inamidine-R P imidazole-R P

ATP
H
P OC H 2 C

2. 1.

OC H 3

E rythros e-4-P

5.1.3.1

P O

2.7.1.71

S hikimate

OH

(Normetadrenaline)

C O C H 2 OH

C O C H 2 OH

OH OH OH

A1

Translocated protons
H+

C

D-R ibos e

Fe-S

4H +

H2O

H

C

OH OH

C H 2 OH

P700

PC

Fe-S 2e- Cyt.f

H
C

HO

C

OH OH H

F ruc tos e-6-P

OH OH

5.1.3.4

Chl.A0

.

2e-

P OC H 2

OH

C HOHC H 2 NH 2

OH

OC H
NH 2
C OO

NH 2

C H C H 2O P

O

4.1.1.48

C OO

(Noradrenaline)

4-OH-3-MethoxyD-mandelate

H

OH
OH

1.1.1.25

OH

Norepinephrine

Normetepinephrine

OH

H
P OC H 2 C

C

OH OH

H

C H 2 C OC OO

OH

OC H 3

5.3.1.9

5.3.1.8

NA DP H

HO

OH

Dehydros hikimate

C HOHC H 2 NH 2

2.1.1.28

C H(OH)C OO
OH

NADP +

2.2.1.1

C HO

3
3

2PQH2

C H 2 OH

H

C H 2 OP
O
HO OH

NADP +

C OO

C

+

P OC H 2C HOHC HO

Cyt bc
_ 2e2PQ
2PQ

2e-

C

H

C H 2 OH

*
2e-

2e-

Mn

C

C

2
2

P680
Chl.a

3.1

C C OO -

D-R ibulos e-5-P

Ferredoxin

PQ

Cyt bf

Pheophytin

OH H
C

PHOTO- H+

H+

2e-

1e-

H
C

1.1.1.44

5.1.3.1

H

8

._

PQ
1e-

H
C

C H 2O P

OC H

NH

1-(o-C arboxy phenylamino)
1-deoxyribulos e-5-P

C H 2 C OO

OH

G luc os e-6-P

OH OH H OH
6-P -G luc onate NA DP H
CO

C OO

C OO

Quinolinate

C OO

C OO
OH

HOC -C H(OH)C H(OH)C H 2 OP
CH
N

C OO

OH

OH

(A drenaline)

A DP

1.1.1.49

2.4.2.19
C OO

N

N-A c etyl-5-O-methyl-s erotonin

NH 2

NH 2

C OO

OH

O

4.2.1.10

O
C H 2 C OO

C HOHC H 2 NHC H 3

E pinephrine

2.7.1.2
2.7.1.1

O
OH

P -G luc ono
lac tone

OH

Dehydroquinate

O

O
C H 2 C OO

ATP

3.1.3.9

C OO

F umaryl 5.2.1.2 Maleyl 1.13.11.5 Homogentis ate
ac etoac etate
ac etoac etate

G L UC OS E
5.4.2.2

2.6.1.16

HO OH

1. 4

.1. 17

w

PQ

OH
C

R ibitol

c
otophosphoryla SYSTEM
n-cycli electr
tion l
No (electric curre on fl

2H+ yclic Ph
C
2H+

PQH2

H
C

HOC H 2 C

8

H+

PQH2

2. 7.

H

OH OH OH

C HO

OH H

QA

H
HOC H 2 C

OH

D-Xylulos e
H+

H+

OH

S orbitol
2.7.1.3

H

OH

HO OH

3.2.1.48

C H 2O P
O

C H 2 OH

CO

OH OH H
C H 2 OH

L -R ibulos e-5-P
HOC H 2

C

OH OH H

1.10.2.1
1.10.3.3

CO

2.7.1.47

CO

OH OH
C O C H 2 OH

C

O

4.6.1.3

O

OH

3.2.1.26

S UC R OS E
OH H

C

H

Indole-3-glyc erol-P

C OO

OH

OH

H

Quinolinatenuc leotide

NH

C H2

HOC H HC OH
C

-OOC

G luc os amine-6-P

5.3.1.8

C H 2 OH

H

P OC H 2

OH

D-Xylos e

1.1 .1.9

QB

CO

H

F ruc tos e-1-P

C

H

OH H

2.7.1.47

L -R ibulos e

L -L yxos e

2e-

C

5.5.1.4

O

C O C H 2 OH

C

L -Xylulos e-5-P

C H 2 OH

OH

OH OH

OH OH

PHOTOSYSTEM
II

OH

C

HOC H 2 C

Dehydroas c orbate

H
HOC H 2 C

C H 2 OH

Xylitol
4

CO

OH OH

CO

OH H

1.1.1.10

H

C

H

OH H

C
OH

L -Xylulos e

OH OH H

HOC H 2 C

C HO

C

HOC H 2

2, 3-Dioxogulonate

C

OH H

L -A rabinos e 5. 3. 1.
OH H

A S C OR B A T E

C O C OO -

CO

OH

H

HOC H 2 C
H

C H 2 OH

L -A rabitol
HOC H 2

H

C

1.1.1.14

CO

OH H

C

H

OH OH H

OH H

H

F ruc tos e

1.1.1 .21

C
O

D-A rabinos e 5.3.1.3 D-R ibulos e

4.1.1.34

L -Xylos e
HOC H 2

HOC H 2 C

1.1.1.130

3-Dehydrogulonate
HOC H 2

C

C

OH H

C C OO -

CO

OH

H

OH OH

C

HO

3-Deoxy-D-arabinoheptulos onate-7-P
C H 2 OH
O

NH 2

+
C O C H 2 C H(NH 3 )C OO
OH

C -C H(OH)C H(OH)C H 2 O P
CH

N

4.2.1.20

T R Y P TOP HA N

OC
P OC H 2 C H 2

OP P U

UDP -G alac tos e

G luc os e-1-P

OH

4.1.1.28

+
C OO
N RP

N

2.4.2.19
C H 2 C H 2 NHC OC H 3

C H 3O

(ME L A TONIN)

+
C O C H 2 C H(NH 3 )C OO

+
C H 2 C H(NH 3 )C OO

C OO

HO

HO OH

2.3. 1.4

OP

HO OH

C H 2O P
O

2.4.1.13

2.4.1.9

Inos itol-P

OH H

H

O

OH

3.1.3.25

Inos itol

CO

H

G ulonolac tone 1.1.3.8 2-Oxogulonolac tone
HOC H 2 C

HOC H 2

OP
HO OH

HO OH

OH
OH

G luc uronate

CO

H
O

1.1.1.45

OH

OH

HO OH

1.1.1.19
OH OH

C

C

OH
NHC OC H 3

NH

C OO

C OO

1

Nic otinatenuc leotide

2.1.1.4

N-A c etyl-s erotonin

2.4 .2.1

R ibos e- P

2.7.7.18

C H 2 C H 2 NHC OC H 3

NH

4.1.1.45
2-A minomuc onateF ormylkynurenine 3.5.1.9 K ynurenine 1.14.13.9 3-Hydroxy 3.7.1.3 3-Hydroxy 1.13.11.6 2-A mino-3-c arboxy
kynurenine
anthranilate
muc onate s emialdehyde
6-s emialdehyde
C OO
1.13.11.11
H
H
C atec hol
C OO
NH

T ryptamine

OH

OH OH H

C OO -

C

OH H

H

OH

OH

O
OH OH

C

OH

N-A c -G luc os amine-6-P

N-A c -G luc os amine-1-P
2.7.7.23

C OO
OH H
HOC H 2

HO

NHC OC H 3 5.4.2.3

UDP -N-A c -G luc os amine

C H 2 C H 2 NH 2

5-Hydroxytryptamine

NH 2

NH

4.1.99.1

2.4.1.22

OH

HO
5.1.3.2
2.7.7.10
2.7.7.12
OH

C H 2 OH
O

2.7.7.24

+
C O C H 2 C H(NH 3 )C OO
C HO

C H 2 C OC OO
NH

Indolepyruvate
OP

OH

C H 2 OH
O

2.7.7.9

HO OH HO OH

C H 2O P
O

HO OH

OP P U

NHAC

G ulonate

P
H
O
T
O
S
Y
N
T
H
E
S
I
S

5.4.2.8

C H 2 OH
O

2.7.7.34

T DP -G luc os e

C H 2O P
O

2.7.1.60

AC NH
HO OH
OH

N-A c -Mannos amine

3.1.1.18 HOC H 2

P
E
N
T
O
S
E
S

5.1.3.6

OP P U

HO

OP P U
HO

2.7.7.27

O

HO

2.3.1.5

(S E R OTONIN)

9

C H 2 OH
O

1.1.1 .22

C H 2 OH
O

2.7.1.6

HO OH

UDP -G luc os e
G alac tos e-P

4.2.1.46

2.7.1.7

4.1.1.43

G A L A C TOS E

C H 2OH
O
OH

A DP G luc os e

OH

G DP -G luc os e

MA NNOS E

2.7.7.13

HO OH HO O P

5.1.3.7

OH

OP P T

OH

HO OH HO OH

C H 2 OH
O

1.14.16.4

.1

UDP -N-A c G luc os amine
pyruvate
N-A c -Mannos amine-6-P

5.1.3.13 O

T DP -4-Oxo6-deoxygluc os e

C H 2 OH
O

G DP -Mannos e
OP P U
OH

O

2.4.1.33

HO OH HO OP P G

O
OH

UDP G alac turonate

C OO

O

Des amino-NA D

C H 2 C H 2 NH 2
NH

4.1.1.28

5-Hydroxytryptophan

Indole

Indoleac etaldehyde

3.2.1.23
2.7.1.38

OH

NH

NH

NH

OH

4.2.1.47
C OO HO

NHC OC H 3

UDP -N-A c G alac tos amine

OP P U
NHAC

C OO

2.4.1.11 HO
2.4.1.21

2.4.1.1
etc.

O

C H 2 C HO

C H 2OH
O

HO

NIC OT INA T E

+
N

R ibos e - O - P - O - P - O -Adenos ine

6.3.5.1
6.3.1.5

+
C H 2 C H(NH 3)C OO

HO

.1

HO O
C H2 C

(S ialate)
C H 2O P
O

C H3

C H 2 OH
O

5.1.3.12

OP P U

OH

1.1.1.158

3.1.3.29

N-A c -Neuraminate

3.1.3.29
AC NH
4.1.3.20
HO OH
OH

H
E
X
O
S
E
S

C H 2 OH
O C OO

OH

C OO

O

O

N

O

O

NA D( + P )

1.2.3.7

OH

L A C TOS E
2.4.1.21

+

O

O

R ibos e -O - P - O - P - O- Adenos ine(P )

NH

Indoxyl

(A uxin)
OH

OH
OH

2.4.1.29

OH OH

C OO

+

N

OH

NH

Indoleac etate

O
OH

T DP -R hamnos e

G DP Mannuronate

G DP -F uc os e

2.4.1.16

C OO
OH 2.7.7.43

HO

C H 2 C OO
C H 2 OH
O

C H 2 OH
O
HO

OP P T

HO OP P G

HO

G LY C OG E N

O

HO C H 3

O
C H3

OH

UDP -N-A c -Muramate

C MP -N-A c etyl
neuraminate

1.1.1.132

2.4.1.68
2.4.1.69
OP P U

OH

UDP Iduronate

C OO-

HO

AcNH

HO

5

O

6.3.2.7-10
6.3.2.13 HO O

2.4.99.7

5.

C OO -

C H 2 OH

6.
3.

2

O

C HOH
C HOH

AcNH

C ONH 2

S TAR CH
HY A L UR ONIC A C ID
DE R MA T A N B L OOD G R OUP A L G INA T E S O-A NT IG E NS
S UB S T A NC E S
P E P T IDOC HONDR OIT IN
P E C T IN
INUL IN
C E L L UL OS E
G LY C A N C H OHC HIT IN

G LY C OP R OT E INS
G A NG L IOS IDE S
MUC INS

1 .4

P
O
L
Y
S
A
C
C
H
A
R
I
D
E
S

B IOCHEMICAL NETWORKS

HOC H

C H2

HC

C HC OO
N

3-Hydroxypyrroline5-c arboxylate

T he "B ackbone" of metabolis m involves
G LY C OLY S IS in the C Y T OP LAS M,
the T C A C Y C LE (mainly) in the Mitochondrial matrix
and AT P F OR MAT ION s panning the
MIT OC HONDR IAL INNE R ME MB R ANE

An electron flow (an electric current) generated from
NADH and UQH2 drives the translocation of protons
from the matrix to the intermembrane space.
The retrolocation of these protons through the F0 subunits
of ATP synthase to the matrix then supplies the energy
needed to form ATP from ADP and phosphate

E lectron F low

P roton F low

1.5.1.2
S mall Numbers ( eg. 2.4.6.7) refer to the IUB MB E nzyme
C ommis s ion (E C ) R eference Numbers of E nzymes

Figure 5.2: A metabolic network. (See Plate IV for color version.) A wallchart showing
the network formed by the major metabolic pathways. Created by Donald Nicholson.
Copyright of the International Union of Biochemistry and Molecular Biology. Reproduced with permission.

83

B IOLOGICAL NETWORKS

sured to determine the constituents of the pathway. This technique has the
advantage of being able to detect products other than those that carry a particular radioactive marker inherited from a substrate, but it is still incapable of
identifying substrates other than those produced as products along the pathway.
A complementary experimental technique that can probe the substrates of
reactions is reaction inhibition, in which a reaction in a pathway is prevented
from taking place or its rate is reduced. Over time, this results in a build-up in
the cell of the substrates for that reaction, since they are no longer being used
up. By watching for this build-up one can determine the reaction substrates.
In principle the same method could also be used to determine the products
of the reaction, since their concentration would decrease because they are not
being produced any longer, but in practice this turns out to be a difﬁcult measurement and is rarely done.
The inhibition of a reaction is usually achieved by disabling or removing
an enzyme necessary for the reaction. This can be done in a couple of different
ways. One can use enzyme inhibitors, which are chemicals that bind to an enzyme and prevent it from performing its normal function as a catalyst, or one
can genetically alter the organism under study to remove or impair its ability
to produce the enzyme (a so-called knockout experiment). The same techniques
can also be used to determine which reactions are catalyzed by which enzymes
in the ﬁrst place, and hence to discover the structure of the third, enzymatic
part of the tripartite metabolic network pictured in Fig. 5.1b.
The construction of a complete or partial picture of a metabolic network
involves the combination of data from many different pathways, almost certainly derived from experiments performed by many different experimenters
using many different techniques. There are now a number of public databases
of metabolic pathway data from which one can draw to assemble networks,
the best known being KEGG and MetaCyc. Assembling the network itself is
a non-trivial task. Because the data are drawn from many sources, careful
checking against the experimental literature (or “curation,” as the lingo goes)
is necessary to insure consistent and reliable inputs to the process, and missing steps in metabolic pathways must often be ﬁlled in by guesswork based
on biochemistry and a knowledge of the genetics. A number of computer
software packages have been developed that can reconstruct networks from
raw metabolic data in an automated fashion, but the quality of the networks
they create is generally thought to be poorer than that of networks created by
knowledgeable human scientists (although the computers are much faster).

84

5.1

5.1.2

|

B IOCHEMICAL NETWORKS

P ROTEIN – PROTEIN INTERACTION NETWORKS

The metabolic networks of the previous section describe the patterns of chemical reactions that turn one chemical into another in the cell. As we have noted,
the traditional deﬁnition of metabolism is restricted to small molecules and
does not include proteins or other large molecules, except in the role of enzymes, in which they catalyze metabolic reactions but do not take part as reactants themselves.
Proteins do however interact with one another and with other
biomolecules, both large and small, but the interactions are not
purely chemical. Proteins sometimes interact chemically with other
molecules—exchanging small subgroups, for example, such as the
exchange of a phosphate group in the process known as phosphorylation. But the primary mode of protein–protein interaction—
interactions of proteins with other proteins—is physical, their complicated folded shapes interlocking to create so-called protein complexes (see Fig. 5.3) but without the exchange of particles or subunits
that deﬁnes chemical reactions.
The set of all protein–protein interactions forms a protein–protein
interaction network, in which the vertices are proteins and two vertices are connected by an undirected edge if the corresponding proteins interact. Although this representation of the network is the one
Figure 5.3: Two proteins joined to
commonly used, it omits much useful information about the interacform a protein complex. Protein moletions. Interactions that involve three or more proteins, for instance,
cules can have complicated shapes that
are represented by multiple edges, and there is no way to tell from
interlock with one another to form protein complexes.
the network itself that such edges represent aspects of the same interaction. This problem could be addressed by adopting a bipartite
representation of the network similar to the one we sketched for
metabolic networks in Fig. 5.1, with two kinds of vertex representing proteins
and interactions, and undirected edges connecting proteins to the interactions
in which they participate. Such representations, however, are rarely used.
There are a number of experimental techniques available to probe for interactions between proteins. One of the most reliable and trusted is co-immunoprecipitation. Immunoprecipitation (without the “co-”) is a technique for extracting a single protein species from a sample containing more than one. The
technique borrows from the immune system, which produces antibodies, specialized proteins that attach or bind to a speciﬁc other target protein when the
two encounter each other. The immune system uses antibodies to neutralize
proteins, complexes, or larger structures that are harmful to the body, but experimentalists have appropriated them for use in the laboratory. Immunopre-

85

B IOLOGICAL NETWORKS

Antibody

Proteins

In immunoprecipitation,
antibodies attached to a
solid surface bind to a speciﬁc protein, represented
here by the circles, pulling
it out of the solution.

Transcription factors are
discussed in more detail in
Section 5.1.3.

cipitation involves attaching an antibody to a solid surface, such as the surface
of a glass bead, then passing a solution containing the target protein (as well
as others, in most cases) over the surface. The antibody and the target protein
bind together, effectively attaching the protein to the surface via the antibody.
The rest of the solution is then washed away, leaving the target protein to be
recovered from the surface.
There are known naturally occurring antibodies for many proteins of scientiﬁc interest, but researchers also routinely create antibodies for speciﬁc proteins by injecting those proteins (or more often a portion of a protein) into an
animal to provoke its immune system to generate the appropriate antibody.
Co-immunoprecipitation is an extension of the same method to the identiﬁcation of protein interactions. An antibody is again attached to a suitable
solid surface and binds to a known protein in a sample. If that protein is attached to others, forming a protein complex, then the entire complex will end
up attached to the surface and will remain after the solution is washed away.
Then the complex can be recovered from the surface and the different proteins
that make it up individually identiﬁed, typically by testing to see if they bind
to other known antibodies (a technique known as a Western blot).
Although well-established and reliable, co-immunoprecipitation is an impractical approach for reconstructing entire interaction networks, since individual experiments, each taking days, have to be performed for every interaction identiﬁed. If appropriate antibodies also have to be created the process would take even longer; the creation of a single antibody involves weeks
or months of work, and costs a considerable amount of money too. As a result, the large-scale study of protein–protein interaction networks did not really take off until the adoption in the 1990s and early 2000s of so-called highthroughput methods for discovering interactions, methods that can identify interactions quickly and in a semi-automated fashion.
The oldest and best established of the high-throughput methods for protein
interactions is the two-hybrid screen, invented by Fields and Song in 1989 [119].3
This method relies on the actions of a specialized protein known as a transcription factor, which, if present in a cell, turns on the production of another protein, referred to as a reporter. The presence of the reporter can be detected by
the experimenter by any of a number of relatively simple means. The idea of
the two-hybrid screen is to arrange things so that the transcription factor is
created when two proteins of interest interact, thereby turning on the reporter,
which tells us that the interaction has taken place.
3
Also called a yeast two-hybrid screen or Y2HS for short, in recognition of the fact that the
technique is usually implemented inside yeast cells, as discussed later.

86

5.1

|

B IOCHEMICAL NETWORKS

The two-hybrid screen relies on the fact that transcription factors are typically composed of two distinct parts, a so-called binding domain and an activation domain. It turns out that most transcription factors do not require the
binding and activation domains to be actually attached to one another for the
transcription factor to work. If they are merely in close enough proximity production of the reporter will be activated.
In a two-hybrid screen, a cell, usually a yeast cell, is persuaded to produce
two proteins of interest, each with one of the domains of the transcription factor attached to it. This is done by introducing plasmids into the cell, fragments
of DNA that code for the proteins and domains. Then, if the two proteins in
question interact and form a complex, the two domains of the transcription
factor will be brought together and, with luck, will activate production of the
reporter.
In a typical two-hybrid experiment, the protein attached to the binding domain of the transcription factor is a known protein (called the bait protein)
whose interactions the experimenter wants to probe. Plasmids coding for a
large number of other proteins (called prey) attached to copies of the activation domain are created, resulting in a so-called library of possible interaction
targets for the bait. The plasmids for the bait and the library of prey are then
introduced into a culture of yeast cells, with the concentration of prey carefully
calibrated so that at most one prey plasmid enters each cell in most cases. Cells
observed to produce the reporter are then assumed to contain plasmids coding for prey proteins that interact with the bait and the plasmids are recovered
from those cells and analyzed to determine the proteins they correspond to.
The two-hybrid screen has two important advantages over older methods
like co-immunoprecipitation. First, one can employ a large library of prey
and hence test for interactions with many proteins in a single experiment,
and second, the method is substantially cheaper and faster than co-immunoprecipitation per interaction detected. Where co-immunoprecipitation requires
one to obtain or create antibodies for every protein tested, the two-hybrid
screen requires only the creation of DNA plasmids and their later sequence
analysis, both relatively simple operations for an experimenter armed with the
machinery of modern genetic engineering.
One disadvantage of the two-hybrid screen is that the presence of the two
domains of the transcription factor attached to the bait and prey proteins can
get in the way of their interacting with one another and prevent the formation
of a protein complex, meaning that some legitimate protein–protein interactions will not take place under the conditions of the experiment.
The principal disadvantage of the method, however, is that it is simply
unreliable. It produces high rates of both false positive results—apparent in-

See Section 5.1.3 for a discussion of DNA coding of
proteins.

87

B IOLOGICAL NETWORKS

teractions between proteins that in fact do not interact—and false negative
results—failure to detect true interactions. By some estimates the rate of false
positives may be as high as 50%, meaning that fully half of all interactions
detected by the method are not real. This has not stopped a number of researchers from performing analyses on the interaction networks reconstructed
from two-hybrid screen data, but the results should be viewed with caution. It
is certainly possible that many or even most of the conclusions of such studies
are substantially inaccurate.
An alternative and more accurate class of methods for high-throughput detection of protein interactions are the afﬁnity puriﬁcation methods (also sometimes called afﬁnity precipitation methods). These methods are in some ways
similar to the co-immunoprecipitation method described previously, but avoid
the need to develop antibodies for each protein probed. In an afﬁnity puriﬁcation method, a protein of interest is “tagged” by adding a portion of another
protein to it, typically by introducing a plasmid that codes for the protein plus
tag, in a manner similar to the introduction of plasmids in the two-hybrid
screen. Then the protein is given the opportunity to interact with a suitable
library of other proteins and a solution containing the resulting protein complexes (if any) passed over a surface to which are attached antibodies that bind
to the tag. As a result, the tag, the attached protein, and its interaction partners are bound to the surface while the rest of the solution is washed away.
Then, as in co-immunoprecipitation, the resulting complex or complexes can
be analyzed to determine the identities of the interaction partners.
The advantage of this method is that it requires only a single antibody that
binds to a known tag, and the same tag–antibody pair can be used in different
experiments to bind different proteins. Thus, as with the two-hybrid screen,
one need only generate new plasmids for each experiment, which is relatively
easy, as opposed to generating new antibodies, which is slow and difﬁcult.
Some implementations of the method have a reliability comparable to that of
co-immunoprecipitation. Of particular note is the method known as tandem
afﬁnity puriﬁcation, which combines two separate puriﬁcation stages and generates correspondingly higher-quality results. Tandem afﬁnity puriﬁcation is
the source for some of the most reliable current data for protein–protein interaction networks.
As with metabolic reactions, there are now substantial databases of protein
interactions available online, of which the most extensive are IntAct, MINT,
and DIP, and from these databases interaction networks can be constructed for
analysis. An example is shown in Fig. 5.4.

88

5.1

|

B IOCHEMICAL NETWORKS

Figure 5.4: A protein–protein interaction network for yeast. A network of interactions
between proteins in the single-celled organism Saccharomyces cerevisiae (baker’s yeast),
as determined using, primarily, two-hybrid screen experiments. From Jeong et al. [164].
Copyright Macmillan Publishers Ltd. Reproduced by permission.

5.1.3

G ENETIC REGULATORY NETWORKS

As discussed in Section 5.1.1, the small molecules needed by biological organisms, such as sugars and fats, are manufactured in the cell by the chemical
reactions of metabolism. Proteins, however, which are much larger molecules,
are manufactured in a different manner, following recipes recorded in the cell’s
genetic material, DNA.
Proteins are biological polymers, long-chain molecules formed by the concatenation of a series of basic units called amino acids. The individual amino
acids themselves are manufactured by metabolic processes, but their assembly
into complete proteins is accomplished by the machinery of genetics. There are

89

B IOLOGICAL NETWORKS

Unfolded

Folded

Figure 5.5: Protein folding. Proteins, which are long-chain polymers of amino acids,
do not naturally remain in an open state (left), but collapse upon themselves to form a
more compact folded state (right).

20 distinct amino acids that are used by all living organisms to build proteins,
and different species of proteins are distinguished from one another by the
particular sequence of amino acids that make them up. Once created, a protein does not stay in a loose chain-like form, but folds up on itself under the
inﬂuence of thermodynamic forces and mechanical constraints, reliably producing a speciﬁc folded form or conformation whose detailed shape depends on
the amino acid sequence—see Fig. 5.5. A protein’s conformation dictates the
physical interactions it can have with other molecules and can expose particular chemical groups or active sites on the surface of the protein that contribute
to its biological function within the organism.
A protein’s amino acid sequence is determined by a corresponding sequence stored in the DNA of the cell in which the protein is synthesized. This
is the primary function of DNA in living matter, to act as an information storage medium containing the sequences of proteins needed by the cell. DNA is
itself a long-chain polymer made up of units called nucleotides, of which there
are four distinct species, adenine, cytosine, guanine, and thymine, commonly
denoted A, C, G, and T, respectively.4 The amino acids in proteins are encoded in DNA as trios of consecutive nucleotides called codons, such as ACG
4
Technically, DNA is a double-stranded polymer, having two parallel chains of nucleotides
forming the famous double helix shape. However, the two strands contain essentially the same
sequence of nucleotides and so for our purposes the fact that there are two is not important (although it is very important in other circumstances, such as in the reproduction of a cell by cellular
division and in the repair of damaged DNA).

90

5.1

|

B IOCHEMICAL NETWORKS

or TTT, and a succession of such codons spells out the complete sequence of
amino acids in a protein. A single strand of DNA can code for many proteins—
hundreds or thousands of them—and two special codons, called the start and
stop codons, are used to signal the beginning and end within the larger DNA
strand of the sequence coding for a protein. The DNA code for a single protein,
from start codon to stop codon, is called a gene.
Proteins are created in the cell by a mechanism that operates in two stages.
In the ﬁrst stage, known as transcription, an enzyme called RNA polymerase
makes a copy of the coding sequence of a single gene. The copy is made
of RNA, another information-bearing biopolymer, chemically similar but not
identical to DNA. RNA copies of this type are called messenger RNAs. In the
second stage, called translation, the protein is assembled, step by step, from
the RNA sequence by an ingenious piece of molecular machinery known as a
ribosome, a complex of interacting proteins and RNA. The translation process
involves the use of transfer RNAs, short molecules of RNA that have a region
at one end that recognizes and binds to a codon in the messenger RNA and
a region at the other end that pulls the required amino acid into the correct
place in the growing protein. The end result is a protein, assembled following
the exact prescription spelled out in the corresponding gene. In the jargon of
molecular biology, one says that the gene has been expressed.
The cell does not, in general, need to produce at all times every possible
protein for which it contains a gene. Individual proteins serve speciﬁc purposes, such as catalyzing metabolic reactions, and it is important for the cell
to be able to respond to its environment and circumstances by turning on or
off the production of individual proteins as required. It does this by the use of
transcription factors, which are themselves proteins and whose job is to control
the transcription process by which DNA sequences are copied to RNA.
Transcription is performed by the enzyme RNA polymerase, which works
by attaching to a DNA strand and moving along it, copying nucleotides one
by one. The RNA polymerase doesn’t just attach spontaneously, however, but
is aided by a transcription factor. Transcription factors are speciﬁc to particular genes or sets of genes and regulate transcription in a variety of ways, but
most commonly by binding to a recognized sub-sequence in the DNA, called
a promoter region, which is adjacent to the beginning of the gene. The binding
of the transcription factor to the promoter region makes it thermodynamically
favorable for the RNA polymerase to attach to the DNA at that point and start
transcribing the gene. (The end of the gene is marked by a stop codon and
upon encountering this codon the RNA polymerase automatically detaches
from the DNA strand and transcription ends.) Thus the presence in the cell of
the transcription factor for the gene turns on or enhances the expression of that
91

B IOLOGICAL NETWORKS

gene. We encountered an example of a transcription factor previously in our
discussion of the two-hybrid screen in Section 5.1.2.
There are also transcription factors that inhibit expression by binding to a
DNA strand in such a way as to prevent RNA polymerase from attaching to
the strand and hence prevent transcription and the production of the corresponding protein.
But now here is the interesting point: being proteins, transcription factors
are themselves produced by transcription from genes. Thus the protein encoded in a given gene can act as a transcription factor promoting or inhibiting
production of one or more other proteins, which themselves can act as transcription factors for further proteins and so forth. The complete set of such
interactions forms a genetic regulatory network. The vertices in this network are
proteins or equivalently the genes that code for them and a directed edge from
gene A to gene B indicates that A regulates the expression of B. A slightly more
sophisticated representation of the network distinguishes between promoting
and inhibiting transcription factors, giving the network two distinct types of
edge.
The experimental determination of the structure of genetic regulatory networks involves identifying transcription factors and the genes that they regulate. The process has several steps. To begin with, one ﬁrst conﬁrms that a
given candidate protein does bind to DNA roughly in the region of a gene of
interest. The commonest technique for establishing the occurrence of such a
binding is the electrophoretic mobility shift assay.5 In this technique one creates
strands of DNA containing the sequence to be tested and mixes them in solution with the candidate protein. If the two indeed bind, then the combined
DNA/protein complex can be detected by gel electrophoresis, a technique in
which one measures the speed of migration of electrically charged molecules
or complexes through an agarose or polyacrylamide gel in an imposed electric
ﬁeld. In the present case the binding of the DNA and protein hinders the motion of the resulting complex through the gel, measurably reducing its speed
when compared with unbound DNA strands. Typically one runs two experiments side by side, one with protein and one without, and compares the rate
of migration to determine whether the protein binds to the DNA. One can also
run parallel experiments using many different DNA sequences to test which
(if any) bind to the protein.
An alternative though less sensitive technique for detecting binding is the
deoxyribonuclease footprinting assay. Deoxyribonucleases (also called DNases
5

92

“Assay” is biological jargon for an experimental test.

5.1

|

B IOCHEMICAL NETWORKS

for short) are enzymes that, upon encountering DNA strands, cut them into
shorter strands. There are many different DNases, some of which cut DNA
only in particular places according to the sequence of nucleotides, but the footprinting technique uses a relatively indiscriminate DNase that will cut DNA at
any point. If, however, a protein binds to a DNA strand at a particular location
it will often (though not always) prevent the DNase from cutting the DNA at
or close to that location. Footprinting makes use of this by mixing strands of
DNA containing the sequence to be tested with the DNase and observing the
resulting mix of strand lengths after the DNase has cut the DNA samples into
pieces in a variety of different ways. Repeating the experiment with the protein present will result in a different mix of strand length if the protein binds
to the DNA and prevents it from being cut in certain places. The mix is usually
determined again by gel electrophoresis (strands of different lengths move at
different speeds under the inﬂuence of the electric ﬁeld) and one again runs
side-by-side gel experiments with and without the protein to look for the effects of binding.
Both the mobility shift and footprinting assays can tell us if a protein binds
somewhere on a given DNA sequence. To pin down exactly where it binds
one typically must do some further work. For instance, one can create short
strands of DNA, called oligonucleotides, containing possible sequences that the
protein might bind to, and add them to the mix. If they bind to the protein then
this will reduce the extent to which the longer DNAs bind and visibly affect the
outcome of the experiment. By a combination of such experiments, along with
computer-aided guesswork about which oligonucleotides are likely to work
best, one can determine the precise sub-sequence to which a particular protein
binds.
While these techniques can tell us the DNA sequence to which a protein
binds, they cannot tell us which gene’s promoter region that sequence belongs
to (if any), whether the protein actually affects transcription of that gene, or, if
it does, whether the transcription is promoted or inhibited. Further investigations are needed to address these issues.
Identiﬁcation of the gene is typically done not by experiment but by computational means and requires a knowledge of the sequence of the DNA in the
region where the protein binds. If we know the DNA sequence then we can
search it for occurrences of the sub-sequence to which our protein binds, and
then examine the vicinity to determine what gene or genes are there, looking
for example for start and stop codons in the region and then recording the sequence of other codons that falls between them. Complete DNA sequences
are now known for a number of organisms as a result of sequencing experiments starting in the late 1990s, and the identiﬁcation of genes is as a result a
93

B IOLOGICAL NETWORKS

relatively straightforward task.
Finally, we need to establish whether or not our protein actually acts as
a transcription factor, which can be done either computationally or experimentally. The computational approach involves determining whether the subsequence to which the protein binds is indeed a promoter region for the identiﬁed gene. (It is possible for a protein to bind near a gene but not act as a
transcription factor because the point at which it binds has no effect on transcription.) This is a substantially harder task than simply identifying nearby
genes. The structure of promoter regions is, unfortunately, quite complex and
varies widely, but computer algorithms have been developed that can identify
them with some reliability.
Alternatively, one can perform an experiment to measure directly the concentration of the messenger RNA produced when the gene is transcribed. This
can be achieved for example by using a microarray (colloquially known as a
“DNA chip”), tiny dots of DNA strands attached in a grid-like array to a solid
surface. RNA will bind to a dot if a part of its sequence matches the sequence
of the dot’s DNA and this binding can be measured using a ﬂuorescence technique. By observing the simultaneous changes in binding on all the dots of
the microarray, one can determine with some accuracy the change in concentration of any speciﬁc RNA and hence quantify the effect of the transcription
factor. This technique can also be used to determine whether a transcription
factor is a promoter or an inhibitor, something that is currently not easy using
computational methods.
As with metabolic pathways and protein–protein interactions, there now
exist electronic databases of genes and transcription factors, such as EcoCyc,
from which it is possible to assemble snapshots of genetic regulatory networks.
Current data on gene regulation are substantially incomplete and hence so are
our networks, but more data are being added to the databases all the time.

5.2

N EURAL NETWORKS

A completely different use of networks in biology arises in the study of the
brain and central nervous system in animals. One of the main functions of the
brain is to process information and the primary information processing element is the neuron, a specialized brain cell that combines (usually) several inputs to generate a single output. Depending on the animal, an entire brain can
contain anywhere from a handful of neurons to more than a hundred billion,
wired together, the output of one cell feeding the input of another, to create a
neural network capable of remarkable feats of calculation and decision making.
Figure 5.6 shows a sketch of a typical neuron, which consists of a cell body
94

5.2

|

N EURAL NETWORKS

Dendrites

Axon terminal

Soma
Axon

Figure 5.6: The structure of a neuron. A typical neuron is composed of a cell body or
soma with many dendrites that act as inputs and a single axon that acts as an output.
Towards its tip, the axon branches to allow it to connect to the inputs of several other
neurons.

or soma, along with a number of protruding tentacles, which are essentially
wires for carrying signals in and out of the cell. Most of the wires are inputs,
called dendrites, of which a neuron may have just one or two, or as many as a
thousand or more. Most neurons have only one main output, called the axon,
which is typically longer than the dendrites and may in some cases extend
over large distances to connect the cell to others some way away. Although
there is just one axon, it usually branches near its end to allow the output of
the cell to feed the inputs of several others. The tip of each branch ends at an
axon terminal that abuts the tip of the input dendrite of another neuron. There
is a small gap, called a synapse, between terminal and dendrite across which
the output signal of the ﬁrst (presynaptic) neuron must be conveyed in order
to reach the second (postsynaptic) neuron. The synapse plays an important
role in the function of the brain, allowing transmission from cell to cell to be
regulated by chemically modifying the properties of the gap.6
The actual signals that travel within neurons are electrochemical in nature.
They consist of traveling waves of electrical voltage created by the motion of
positively charged sodium and potassium ions in and out of the cell. These
6

Neurons do sometimes have direct connections between them without synapses. These direct
connections are called gap junctions, a confusing name, since it sounds like it might be a description
of a synapse but is in reality quite different. In our brief treatment of neural networks, however,
we will ignore gap junctions.

95

B IOLOGICAL NETWORKS

A wiring diagram for a
small neural network.

96

waves are called action potentials and typically consist of voltages on the order
of tens of millivolts traveling at tens of meters per second. When an action
potential reaches a synapse, it cannot cross the gap between the axon terminal
and the opposing dendrite and the signal is instead transmitted chemically; the
arrival of the action potential stimulates the production of a chemical neurotransmitter by the terminal, and the neurotransmitter diffuses across the gap
and is detected by receptor molecules on the dendrite at the other side. This in
turn causes ions to move in and out of the dendrite, changing its voltage.
These voltage changes, however, do not yet give rise to another traveling
wave. The soma of the postsynaptic neuron sums the inputs from its dendrites
and as a result may (or may not) send an output signal down its own axon.
The neuron is stable against perturbations caused by voltages at a small number of its inputs, but if enough inputs are excited they can collectively drive
the neuron into an unstable runaway state in which it “ﬁres,” generating a
large electrochemical pulse that starts a new action potential traveling down
the cell’s axon and so a signal is passed on to the next neuron or neurons in the
network. Thus the neuron acts as a switch or gate that aggregates the signals
at its inputs and only ﬁres when enough inputs are excited.
As described, inputs to neurons are excitatory, increasing the chance of ﬁring of the neuron, but inputs can also be inhibiting—signals received at inhibiting inputs make the receiving neuron less likely to ﬁre. Excitatory and
inhibiting inputs can be combined in a single neuron and the combination allows neurons to perform quite complex information processing tasks all on
their own, while an entire brain or brain region consisting of many neurons
can perform tasks of extraordinary complexity. Current science cannot yet tell
us exactly how the brain performs the more sophisticated cognitive tasks that
allow animals to survive and thrive, but it is known that the brain constantly
changes the pattern of wiring between neurons in response to inputs and experiences, and it is presumed that this pattern—the neural network—holds
much of the secret. An understanding of the structure of neural networks is
thus crucial if we are ever to explain the higher-level functions of the brain.
At the simplest level, a neuron can be thought of as a unit that accepts
a number of inputs, either excitatory or inhibiting, combines them, and generates an output result that is sent to one or more further neurons. In network terms, a neural network can thus be represented as a set of vertices—the
neurons—connected by two types of directed edges, one for excitatory inputs
and one for inhibiting inputs. By convention, excitatory connections are denoted by an edge ending with an arrow “
”, while inhibiting connections
”.
are denoted by an edge ending with a bar “
In practice, neurons are not all the same. They come in a variety of differ-

5.2

|

N EURAL NETWORKS

ent types and even relatively small regions or circuits in the brain may contain
many types. This variation can be encoded in our network representation by
different types of vertex. Visually the types are often denoted by using different shapes for the vertices or by labeling. In functional terms, neurons can
differ in a variety of ways, including the number and type of their inputs and
outputs, the nature and speed of their response to their inputs, whether and to
what extent they can ﬁre spontaneously without receiving inputs, and many
other things besides.
Experimental determination of the structure of neural networks is difﬁcult
and the lack of straightforward experimental techniques for probing network
structure is a major impediment to current progress in neuroscience. Some useful techniques do exist, however, although their application can be extremely
laborious.
The basic tool for structure determination is microscopy, either optical or
electronic. One relatively simple approach works with cultured neurons on
ﬂat dishes. Neurons taken from animal brains at an early stage of embryonic
development can be successfully cultured in a suitable nutrient medium and
will, without prompting, grow synaptic connections to form a network. If cultured on a ﬂat surface, the network is then roughly two-dimensional and its
structure can be determined with reasonable reliability by simple optical microscopy. The advantage of this approach is that it is quick and inexpensive,
but it has the substantial disadvantage that the networks studied are not the
networks of real living animals and their structure is probably not very similar
to that of a functional brain circuit.
In this respect, studies of real brains are much more satisfactory and likely
to lead to greater insight, but they are also far harder, because real brains
are three-dimensional and we do not currently have any form of microscopy
suitable for probing such three-dimensional structures. Instead, therefore, researchers have resorted to cutting suitably preserved brains or brain regions
into thin slices, whose structure is then determined by electron microscopy.
Given the structure of an entire set of consecutive slices, one can, at least
in principle, reconstruct the three-dimensional structure, identifying different
types of neurons by their appearance, where possible. In the early days of such
studies, most reconstruction was done by hand but more recently researchers
have developed computer programs that can signiﬁcantly speed the reconstruction process. Nonetheless, studies of this kind are very laborious and
can take months or years to complete, depending on the size and complexity
of the network studied.
Figure 5.7 shows an example of a “wiring diagram” of a neural network,
reconstructed by hand from electron microscope studies of this type. The net97

B IOLOGICAL NETWORKS

Figure 5.7: A diagram of a part of the brain circuitry of a worm. A portion of the neural circuitry of the nematode
Caenorhabditis elegans, reconstructed by hand from electron micrographs of slices through the worm’s brain. Reproduced
from White et al. [328]. Copyright of the Royal Society. Reproduced by permission.

work in question is the neural network of the worm Caenorhabditis elegans, one
of the best studied organisms in biology. The brain of C. elegans is simple—it
has less than 300 neurons and essentially every specimen of the worm has the
same wiring pattern. Several types of neuron, denoted by shapes and labels,
are shown in the ﬁgure, along with a number of different types of connection,
both excitatory and inhibiting. Some of the connections run out of the ﬁgure or
enter from somewhere off the page. These are connections that run to or from
other parts of the network not shown. The original experimenters determined
the structure of the entire network and presented it as set of interconnected
wiring diagrams like this one [328].

98

5.3

5.3

|

E COLOGICAL NETWORKS

E COLOGICAL NETWORKS

The ﬁnal class of biological network that we consider in this chapter is networks of ecological interactions between species. Species in an ecosystem can
interact in a number of different ways. They can eat one another, they can parasitize one another, they can compete for resources, or they can have any of a
variety of mutually advantageous interactions, such as pollination or seed dispersal. Although in principle the patterns of interactions of all of these types
could be represented in a combined “interaction network” with several different edge types, ecologists have traditionally separated interaction types into
different networks. Food webs, for example—networks of predator–prey interactions (i.e., who eats whom)—have a long history of study. Networks of
hosts and parasites or of mutualistic interactions are less well studied, but have
nonetheless received signiﬁcant attention in recent years.
5.3.1

F OOD WEBS

The biological organisms on our planet can be divided into ecosystems, groups
of organisms that interact with one another and with elements of their environment such as sources of material, nutrients, and energy. Mountains, valleys,
lakes, islands, and larger regions of land or water can all be home to ecosystems composed of many organisms each. Within ecological theory, ecosystems are usually treated as self-contained units with no outside interactions,
although in reality perfect isolation is rare and many ecosystems are only approximately self-contained. Nonetheless, the ecosystem concept is one of signiﬁcant practical utility for understanding ecological dynamics.
A food web is a directed network that represents which species prey on
which others in a given ecosystem.7 The vertices in the network correspond to
species and the directed edges to predator–prey interactions. Figure 5.8 shows
a small example, representing predation among species living in Antarctica.
There are several points worth noticing about this ﬁgure. First, notice that not
all of the vertices actually represent single species in this case. Some of them
do—the vertices for sperm whales and humans, for instance. But some of them
represent collections of species, such as birds or ﬁsh. This is common practice
7

In common parlance, one refers to a food chain, meaning a chain of predator–prey relations between organisms starting with some lowly organism at the bottom of the chain, such as a microbe
of some kind, and working all the way up to some ultimate predator at the top, such as a lion or a
human being. Only a moment’s reﬂection, however, is enough to convince us that real ecosystems
cannot be represented by single chains, and a complete network of interactions is needed in most
cases.

99

B IOLOGICAL NETWORKS

Humans
Baleen
whales

Smaller
whales

Crab−eater
seal

Sperm
whale

Leopard
seal

Elephant
seal

Fish

Squid

Birds

Carnivorous
plankton

Krill

Herbivorous
plankton

Phyto−
plankton

Figure 5.8: A food web of species in Antarctica. Vertices in a food web represent
species or sometimes, as with some of the vertices in this diagram, groups of related
species, such as ﬁsh or birds. Directed edges represent predator–prey interactions and
run in the direction of energy ﬂow, i.e., from prey to predator.

in the network representation of food webs. If a set of species such as birds
all prey upon and are preyed on by the same other species, then the network
can be simpliﬁed by representing them as a single vertex, without losing any
information about who preys on whom. Indeed, even in cases where a set of
species only have mostly, but not exactly, the same predators and prey we still
sometimes group them, if we feel the beneﬁts of the resulting simpliﬁcation
are worth a small loss of information. A set of species with the same or similar
predators and prey is sometimes referred to as a trophic species.
Second, notice the direction of the edges in the network. One might imagine that the edges would point from predators to prey, but ecologists conven100

5.3

|

tionally draw them in the opposite direction, from prey to predator. Thus the
edge representing the eating of ﬁsh by birds runs from the ﬁsh vertex to the bird
vertex. The reason for this apparently odd choice is that ecologists view food
webs as representations of the ﬂow of energy (or sometimes carbon) within
ecosystems. The arrow from ﬁsh to birds indicates that the population of birds
gains energy from the population of ﬁsh when the birds eat the ﬁsh.
Third, notice that almost all the arrows in the ﬁgure run up the page. Directed networks with this property—that they can be drawn so that the edges
all run in one direction—are called acyclic networks. We encountered acyclic
networks previously in our discussion of citation networks in Section 4.2. Food
webs are usually only approximately acyclic. There are usually a few edges
that do not run in the right direction,8 but it is often a useful approximation to
assume that the network is acyclic.
The acyclic nature of food webs indicates that there is an intrinsic pecking
order among the species in ecosystems. Those higher up the order (which
means higher up the page in Fig. 5.8) prey on those lower down, but not vice
versa. A species’ position in this pecking order is called by ecologists its trophic
level. Species at the very bottom of the food web, of which there is just one in
our example—the phytoplankton—have trophic level 1. Those that prey on
them—krill, herbivorous plankton—have trophic level 2, and so forth all the
way up to the species at the top of the web, which have no predators at all.
In our antarctic example there are two species that have no predators, humans
and small whales. (Note however that although such species are all, in a sense,
at “the top of the food chain” they need not have the same trophic level.)
Trophic level is a useful general guide to the roles that species play in
ecosystems, those in lower trophic levels tending to be smaller, more abundant
species that are prey to other species higher up the food web, while those in
higher trophic levels are predators, usually larger-bodied and less numerous.
Calculating a species’ trophic level, however, is not always easy. In principle,
the rule is simple: a species’ trophic level is 1 greater than the trophic level of
its prey. Thus the herbivorous plankton and krill in our example have trophic
level 2, because their prey has trophic level 1, and the carnivorous plankton
have trophic level 3. On the other hand, the squid in our example prey on
species at two different levels, levels 2 and 3, so it is unclear what level they
belong to. A variety of mathematical deﬁnitions have been proposed to resolve this issue. One strategy is to deﬁne trophic level to be 1 greater than the
mean of the trophic levels of the prey. There is, however, no accepted standard

E COLOGICAL NETWORKS

Acyclic networks are discussed in more detail in
Section 6.4.2.

8
In Fig. 5.8, for example, there are edges in both directions between the ﬁsh and squid vertices,
which makes it impossible to draw the network with all edges running in the same direction.

101

B IOLOGICAL NETWORKS

deﬁnition, and the only indisputable statement one can make is that in most
food webs some species have ill-deﬁned or mixed trophic level.
The food webs appearing in the ecological literature come in two basic
types. Community food webs are complete webs for an entire ecosystem, as in
Fig. 5.8—they represent, at least in theory, every predator–prey interaction in
the system. Source food webs and sink food webs are subsets of complete webs that
focus on species connected, directly or indirectly, to a speciﬁc prey or predator. In a source food web, for instance, one records all species that derive energy from a particular source species, such as grass. Our food web of antarctic
species is, in fact, both a community food web and a source food web, since all
of the species in the network derive their energy ultimately from phytoplankton. Phytoplankton is the source in this example, and the species above it (all
of the species in this case) form the corresponding source web. A sink food
web is the equivalent construct for a particular top predator in the network.
In the antarctic example, for instance, humans consume the sperm and baleen
whales and elephant seals, which in turn derive their energy from ﬁsh, squid,
plankton, krill, and ultimately phytoplankton. This subset of species, therefore, constitutes the sink food web for humans—the web that speciﬁes through
which species or species groups the energy consumed by humans passes.
The experimental determination of the structure of food webs is typically
done in one of two different ways, or sometimes a mixture of both. The ﬁrst
and most straightforward method is direct measurement. Having settled on
the ecosystem to be studied, one ﬁrst assembles a list of the species in that
ecosystem and then determines their predator–prey interactions. For largebodied animals such as mammals, birds, or larger ﬁsh, some predation can
be established simply by observation in the ﬁeld—we see a bird eating a ﬁsh
and the presence of the corresponding edge is thereby established. More often,
however, and particularly with smaller-bodied animals, interactions are established by catching and dissecting the animals in question and examining the
contents of their stomachs to determine what they have been eating.
The second primary method of constructing food webs is by compilation
from existing literature. Many predator–prey interactions are already known
and have been recorded in the scientiﬁc literature, but not in the context of
the larger food web, and one can often reconstruct a complete or partial picture of a food web by searching the literature for such records. Many of the
currently available food web data sets were assembled in this way from preexisting data, and some others were assembled by a combination of experimental measurement and literature searches.
In some cases attempts have also been made to measure not merely the
presence (or absence) of interactions between species but also the strength of
102

5.3

|

E COLOGICAL NETWORKS

those interactions. One can quantify interaction strength by the fraction of its
energy a species derives from each of its predators, or by the total rate of energy
ﬂow between a prey species and a predator. The result is a weighted directed
network that sheds considerably more light on the ﬂow of energy through an
ecosystem than the more conventional unweighted food web. Measurements
of interaction strength are, however, time-consuming, difﬁcult, and yield uncertain results, so the current data on weighted food webs should be treated
with caution.
Food web data from a variety of sources have been assembled into publicly
available databases, starting in the late 1980s. Examples include the Ecoweb
database [73] and the web-based collection at www.foodwebs.org.
5.3.2

O THER ECOLOGICAL NETWORKS

Two other types of ecological network have received signiﬁcant attention in
the scientiﬁc literature (although less than has been paid to food webs). Host–
parasite networks are networks of parasitic relationships between organisms,
such as the relationship between a large-bodied animal and the insects and
microorganisms that live on and inside it. In a sense parasitic relations are
a form of predation—one species eating another—but in practical terms they
are quite distinct from traditional predator–prey interactions. Parasites, for
example, tend to be smaller-bodied than their hosts where predators tend to
be larger, and parasites can live off their hosts for long, sometimes indeﬁnite,
periods of time without killing them, where predation usually results in the
death of the prey.
Parasitic interactions, however, do form networks that are somewhat similar to traditional food webs. Parasites themselves frequently play host to still
smaller parasites (called “hyperparasites”), which may have their own still
smaller ones, and so forth through several levels.9 There is a modest but growing literature on host–parasite networks, much of it based on research within
the agriculture community, a primary reason for interest in parasites being
their prevalence in and effects on livestock and crop species.
The other main class of ecological networks is that of mutualistic networks,
meaning networks of mutually beneﬁcial interactions between species. Three
9

One is reminded of the schoolhouse rhyme by Augustus de Morgan:
Great ﬂeas have little ﬂeas upon their backs to bite ’em,
And little ﬂeas have lesser ﬂeas, and so ad inﬁnitum.

103

B IOLOGICAL NETWORKS

See Section 6.6 for a discussion of bipartite networks.

104

speciﬁc types of mutualistic network that have received attention in the ecological literature are networks of plants and the animals (primarily insects)
that pollinate them, networks of plants and the animals (such as birds) that
disperse their seeds, and networks of ant species and the plants that they protect and eat. Since the beneﬁt of a mutualistic interaction runs, by deﬁnition, in
both directions between a pair of species, mutualistic networks are undirected
networks (or bidirectional, if you prefer), in contrast with the directed interactions of food webs and host–parasite networks. Most mutualistic networks
studied are also bipartite, consisting of two distinct, non-overlapping sets of
species (such as plants and ants), with interactions only between members of
different sets. In principle, however, non-bipartite mutualistic networks are
also possible.

This page intentionally left blank

This page intentionally left blank

PART II
F UNDAMENTALS OF
NETWORK THEORY

107

This page intentionally left blank

C HAPTER 6

M ATHEMATICS OF NETWORKS
An introduction to the mathematical tools used in the
study of networks, tools that will be important to many
subsequent developments

I

N THE next three chapters we introduce the fundamental quantitative foun-

dations of the study of networks, concepts that are crucial for essentially all
later developments in this book. In this chapter we introduce the basic theoretical tools used to describe and analyze networks, most of which come from
graph theory, the branch of mathematics that deals with networks. Graph theory is a large ﬁeld containing many results and we describe only a small fraction of those results here, focusing on the ones most relevant to the study of
real-world networks. Readers interested in pursuing the study of graph theory
further might like to look at the books by Harary [155] or West [324].
In the two chapters after this one we look ﬁrst at measures and metrics for
quantifying network structure (Chapter 7) and then at some of the remarkable
patterns revealed in real-world networks when we apply the mathematics and
metrics we have developed to their analysis (Chapter 8).

6.1

N ETWORKS AND THEIR REPRESENTATION

To begin at the beginning, a network—also called a graph in the mathematical
literature—is, as we have said, a collection of vertices joined by edges. Vertices
and edges are also called nodes and links in computer science, sites and bonds
in physics, and actors1 and ties in sociology. Table 6.1 gives some examples of
vertices and edges in particular networks.
1
This use of the word “actor” sometimes leads to confusion: an actor need not be a person
who actually acts, and need not even be a person. In a social network of business relationships

109

M ATHEMATICS OF NETWORKS

Network
Internet
World Wide Web
Citation network
Power grid
Friendship network
Metabolic network
Neural network
Food web

Vertex
Computer or router
Web page
Article, patent, or legal case
Generating station or substation
Person
Metabolite
Neuron
Species

Edge
Cable or wireless data connection
Hyperlink
Citation
Transmission line
Friendship
Metabolic reaction
Synapse
Predation

Table 6.1: Vertices and edges in networks. Some examples of vertices and edges in particular networks.

Throughout this book we will normally denote the number of vertices in a
network by n and the number of edges by m, which is a common notation in
the mathematical literature.
Most of the networks we will study in this book have at most a single edge
between any pair of vertices. In the rare cases where there can be more than
one edge between the same pair of vertices we refer to those edges collectively
as a multiedge. In most of the networks we will study there are also no edges
that connect vertices to themselves, although such edges will occur in a few
instances. Such edges are called self-edges or self-loops.
A network that has neither self-edges nor multiedges is called a simple network or simple graph. A network with multiedges is called a multigraph.2 Figure 6.1 shows examples of (a) a simple graph and (b) a non-simple graph having both multiedges and self-edges.

6.2

T HE ADJACENCY MATRIX

There are a number of different ways to represent a network mathematically.
Consider an undirected network with n vertices and let us label the vertices
with integer labels 1 . . . n, as we have, for instance, for the network in Fig. 6.1a.
It does not matter which vertex gets which label, only that each label is unique,
so that we can use the labels to refer to any vertex unambiguously.
If we denote an edge between vertices i and j by (i, j) then the complete
between companies, for instance, the actors are the companies (and the ties are the business relationships).
2

There does not seem to be a special name given to networks with self-edges. They are just
called “networks with self-edges.”

110

6.2

Edge

2

|

T HE ADJACENCY MATRIX

2
1

1
4

3
5

6

Vertex

Multiedge

4

3
5

6

Self−edge

(a)

(b)

Figure 6.1: Two small networks. (a) A simple graph, i.e., one having no multiedges or
self-edges. (b) A network with both multiedges and self-edges.

network can be speciﬁed by giving the value of n and a list of all the edges.
For example, the network in Fig. 6.1a has n = 6 vertices and edges (1, 2), (1, 5),
(2, 3), (2, 4), (3, 4), (3, 5), and (3, 6). Such a speciﬁcation is called an edge list.
Edge lists are sometimes used to store the structure of networks on computers,
but for mathematical developments like those in this chapter they are rather
cumbersome.
A better representation of a network for present purposes is the adjacency
matrix. The adjacency matrix A of a simple graph is the matrix with elements
Aij such that

Aij =

1 if there is an edge between vertices i and j,
0 otherwise.

For example, the adjacency matrix of the network in Fig. 6.1a is
⎛
⎞
0 1 0 0 1 0
⎜1 0 1 1 0 0⎟
⎜
⎟
⎜
⎟
⎜0 1 0 1 1 1⎟
A=⎜
⎟.
⎜0 1 1 0 0 0⎟
⎜
⎟
⎝1 0 1 0 0 0⎠
0 0 1 0 0 0

(6.1)

(6.2)

Two points to notice about the adjacency matrix are that, ﬁrst, for a network
with no self-edges such as this one the diagonal matrix elements are all zero,
and second that it is symmetric, since if there is an edge between i and j then
there is an edge between j and i.
111

M ATHEMATICS OF NETWORKS

It is also possible to represent multiedges and self-edges using an adjacency matrix. A multiedge is represented by setting the corresponding matrix
element Aij equal to the multiplicity of the edge. For example, a double edge
between vertices i and j is represented by Aij = A ji = 2.
Self-edges are a little more complicated. A single self-edge from vertex i to
itself is represented by setting the corresponding diagonal element Aii of the
matrix equal to 2. Why 2 and not 1? Essentially it is because every self-edge
from i to i has two ends, both of which are connected to vertex i. We will
ﬁnd that many of our mathematical results concerning the adjacency matrix
work equally well for networks with and without self-edges, but only if we are
careful to count both ends of every edge, including the self-edges, by making
the diagonal matrix elements equal to 2 rather than 1.3
Another way to look at this is that non-self-edges appear twice in the adjacency matrix—an edge from i to j means that both Aij and A ji are 1. To count
edges equally, self-edges should also appear twice, and since there is only one
diagonal matrix element Aii , we need to record both appearances there.
To give an example, the adjacency matrix for the multigraph in Fig. 6.1b is
⎛
⎞
0 1 0 0 3 0
⎜1 2 2 1 0 0⎟
⎜
⎟
⎜
⎟
⎜0 2 0 1 1 1⎟
A=⎜
(6.3)
⎟.
⎜0 1 1 0 0 0⎟
⎜
⎟
⎝3 0 1 0 0 0⎠
0 0 1 0 0 2
One can also have multiple self-edges (or “multi-self-edges” perhaps). Such
edges are represented by setting the corresponding diagonal element of the adjacency matrix equal to twice the multiplicity of the edge.

6.3

W EIGHTED NETWORKS

Many of the networks we will study have edges that form simple on/off connections between vertices. Either they are there or they are not. In some situations, however, it is useful to represent edges as having a strength, weight, or
value to them, usually a real number. Thus in the Internet edges might have
weights representing the amount of data ﬂowing along them or their bandwidth. In a food web predator–prey interactions might have weights measur3
As discussed in the next section, this is not the case for directed networks. In directed networks, self-edges are represented by a 1 in the corresponding diagonal element of the adjacency
matrix.

112

6.3

|

W EIGHTED NETWORKS

ing total energy ﬂow between prey and predator. In a social network connections might have weights representing frequency of contact between actors.
Such weighted or valued networks can be represented by giving the elements of
the adjacency matrix values equal to the weights of the corresponding connections. Thus the adjacency matrix
⎛

0
⎝
A= 2
1

2
0
0.5

⎞
1
0.5⎠
0

(6.4)

represents a weighted network in which the connection between vertices 1
and 2 is twice as strong as that between 1 and 3, which in turn is twice as
strong as that between 2 and 3.4
We have now seen two different types of network where the adjacency matrix can have off-diagonal elements with values other than 0 and 1, networks
with weighted edges and networks with multiedges.5 Indeed, if the weights
in a weighted network are all integers it is possible to create a network with
multiedges that has the exact same adjacency matrix, by simply choosing the
multiplicities of the multiedges equal to the corresponding weights. This connection comes in handy sometimes. In some circumstances it is easier to reason
about the behavior of a multigraph than a weighted network, or vice versa, and
switching between the two can be a useful aid to analysis [242].
The weights in a weighted network are usually positive numbers, but there
is no reason in theory why they should not be negative. For example, it is common in social network theory to construct networks of social relations between
people in which positive edge weights denote friendship or other cordial relationships and negative ones represent animosity. We discuss such networks
further in Section 7.11 when we consider the concept of structural balance.
Given that edges can have weights on them, it is not a huge leap to consider
weights on vertices too, or to consider more exotic variables on either edges or
4
The values on edges also sometimes represent lengths of some kind. On a road or airline
network, for instance, edge values could represent the number of kilometers or miles the edges
cover, or they could represent travel time along the edges, which can be regarded as a kind of
length—one denominated in units of time rather than distance. Edge lengths are, in a sense, the
inverse of edge weights, since two vertices that are strongly connected can be regarded as “close”
to one another and two that are weakly connected can be regarded as far apart. Thus one could
convert between weights and lengths by taking reciprocals, although this should be regarded as
only an approximate procedure; in most cases there is no formal sense in which edge weights and
lengths are equivalent.
5
The diagonal elements are a special case, since they are equal to 0 or 2 in an undirected
network even when there are no multiedges or weighted edges.

113

M ATHEMATICS OF NETWORKS

vertices, such as vectors or discrete enumerative variables like colors. Many
such variations have been considered in the networks literature and we will
discuss some of them later in the book. There is one case of variables on edges,
however, that is so central to the study of networks that we discuss it straight
away.

6.4

D IRECTED NETWORKS

A directed network or directed graph, also called a digraph for short, is a network
in which each edge has a direction, pointing from one vertex to another. Such
edges are themselves called directed edges, and can be represented by lines with
arrows on them—see Fig. 6.2.
We encountered a number of examples of directed networks in
previous chapters, including the World Wide Web, in which hyperlinks run in one direction from one web page to another, food
webs, in which energy ﬂows from prey to predators, and citation
networks, in which citations point from one paper to another.
4
The adjacency matrix of a directed network has matrix elements

1
2
3


Aij =

5

6

Figure 6.2: A directed network. A
small directed network with arrows indicating the directions of the edges.

1 if there is an edge from j to i,
0 otherwise.

(6.5)

Notice the direction of the edge here—it runs from the second index
to the ﬁrst. This is slightly counter-intuitive, but it turns out to be
convenient mathematically and it is the convention we adopt in this
book.
As an example, the adjacency matrix of the small network in
Fig. 6.2 is
⎛
⎞
0 0 0 1 0 0
⎜0 0 1 0 0 0⎟
⎜
⎟
⎜
⎟
⎜1 0 0 0 1 0⎟
A=⎜
(6.6)
⎟.
⎜0 0 0 0 0 1⎟
⎜
⎟
⎝0 0 0 1 0 1⎠
0 1 0 0 0 0

Note that this matrix is not symmetric. In general the adjacency matrix of a
directed network is asymmetric.
We can, if we wish, think of undirected networks as directed networks in
which each undirected edge has been replaced with two directed ones running
in opposite directions between the same pair of vertices. The adjacency matrix
114

6.4

|

D IRECTED NETWORKS

for such a network is then symmetric and exactly the same as for the original
undirected network.
Like their undirected counterparts, directed networks can have multiedges
and self-edges, which are represented in the adjacency matrix by elements with
values greater than 1 and by non-zero diagonal elements, respectively. An important point however is that self-edges in a directed network are represented
by setting the corresponding diagonal element of the adjacency matrix to 1,
not 2 as in the undirected case.6 With this choice the same formulas and results, in terms of the adjacency matrix, apply for networks with and without
self-edges.
6.4.1

C OCITATION AND BIBLIOGRAPHIC COUPLING

It is sometimes convenient to turn a directed network into an undirected one
for the purposes of analysis—there are many useful analytic techniques for
undirected networks that do not have directed counterparts (or at least not
yet).
One simple way to make a directed network undirected is just to ignore
the edge directions entirely, an approach that can work in some cases, but inevitably throws out a lot of potentially useful information about the network’s
structure. A more sophisticated approach is to use “cocitation” or “bibliographic coupling,” two different but related ideas that derive their names from
their widespread use in the analysis of citation networks.
The cocitation of two vertices i and j in a directed network is the number of
vertices that have outgoing edges pointing to both i and j. In the language of
citation networks, for instance, the cocitation of two papers is the number of
other papers that cite both. Given the deﬁnition above of the adjacency matrix
of a directed network (Eq. (6.5)), we can see that Aik A jk = 1 if i and j are both
cited by k and zero otherwise. Summing over all k, the cocitation Cij of i and j
is
n

n

k =1

k =1

T
,
Cij = ∑ Aik A jk = ∑ Aik Akj

(6.7)

T
is an element of the transpose of A. We can deﬁne the cocitation
where Akj
matrix C to be the n × n matrix with elements Cij , which is thus given by

C = AA T .

We brieﬂy discussed cocitation in the context of
citation networks in Section 4.2.

(6.8)

i

j

Vertices i and j are cited by
three common papers, so
their cocitation is 3.

6

Indeed, one can understand the appearance of the 2 in the undirected case as a consequence of
the equivalence between undirected and directed networks mentioned above: an undirected selfedge can be thought of as two directed self-edges at the same vertex, each of which contributes 1
to the corresponding element of the adjacency matrix.

115

M ATHEMATICS OF NETWORKS

Note that C is a symmetric matrix, since C T = (AA T )T = AA T = C.
Now we can deﬁne a cocitation network in which there is an edge between
i and j if Cij > 0, for i = j, i.e., an edge between any two vertices that are
cocited in the original directed network. (We enforce the constraint that i = j
because the cocitation network is conventionally deﬁned to have no self-edges,
even though the diagonal elements of the cocitation matrix are in general nonzero—see below.) Better still, we can make the cocitation network a weighted
network with positive integer weights on the edges equal to the corresponding elements Cij . Then vertex pairs cited by more common neighbors have a
stronger connection than those cited by fewer. Since the cocitation matrix is
symmetric, the cocitation network is undirected, making it easier to deal with
in many respects than the original directed network from which it was constructed.
The cocitation network turns out to make a lot of sense in many cases. In
citation networks of academic papers, for instance, strong cocitation between
papers is often a good indicator of papers that deal with related topics—if two
papers are often cited together in the same bibliography they probably have
something in common. And the more often they are cited together, the more
likely it is that they are related.
The cocitation matrix thus plays a role similar to an adjacency matrix for
the cocitation network. There is however one aspect in which the cocitation
matrix differs from an adjacency matrix: its diagonal elements. The diagonal
elements of the cocitation matrix are given by
n

n

k =1

k =1

Cii = ∑ A2ik = ∑ Aik ,

i

j

Vertices i and j cite three
of the same papers and so
have a bibliographic coupling of 3.

116

(6.9)

where we have assumed that the directed network is a simple graph, with
no multiedges, so that all elements Aik of the adjacency matrix are zero or
one. Thus Cii is equal to the total number of edges pointing to i—the total
number of papers citing i in the citation network language. In constructing
the cocitation network we ignore these diagonal elements, meaning that the
network’s adjacency matrix is equal to the cocitation matrix but with all the
diagonal elements set to zero.
Bibliographic coupling is similar to cocitation. The bibliographic coupling of
two vertices in a directed network is the number of other vertices to which
both point. In a citation network, for instance, the bibliographic coupling of
two papers i and j is the number of other papers that are cited by both i and j.
Noting that Aki Akj = 1 if i and j both cite k and zero otherwise, the biblio-

6.4

|

D IRECTED NETWORKS

graphic coupling of i and j is
n

n

k =1

k =1

T
Akj ,
Bij = ∑ Aki Akj = ∑ Aik

(6.10)

and we deﬁne the bibliographic coupling matrix B to be the n × n matrix with
elements Bij so that
(6.11)
B = A T A.
The bibliographic coupling matrix is again a symmetric matrix and the offdiagonal elements can be used to deﬁne a weighted undirected network, the
bibliographic coupling network, in which there is an edge with weight Bij between
any vertex pair i, j for which Bij > 0. The diagonal elements of B are
n

n

k =1

k =1

Bii = ∑ A2ki = ∑ Aki .

(6.12)

Thus Bii is equal to the number of other vertices that vertex i points to—the
number of papers i cites, in the citation language.
Bibliographic coupling, like cocitation, can be a useful measure of connection between vertices. In a citation network, for example, if two papers cite
many of the same other papers it is often a good indication that they deal with
similar subject matter, and the number of common papers cited can be an indicator of how strongly they overlap.
Although cocitation and bibliographic coupling are mathematically similar measures they can in practice give noticeably different results. In particular, they are affected strongly by the number of ingoing and outgoing edges
that vertices have. For two vertices to have strong cocitation—to be pointed
to by many of the same other vertices—they must both have a lot of incoming edges in the ﬁrst place. In a citation network, for instance, two papers
can only have strong cocitation if they are both well cited and hence strong
cocitation is limited to inﬂuential papers, review articles, books, and similar
highly cited items. Conversely, two papers can only have strong bibliographic
coupling if they both cite many others, i.e., if they have large bibliographies.
In practice, the sizes of bibliographies vary less than the number of citations
papers receive, and hence bibliographic coupling is a more uniform indicator
of similarity between papers than cocitation. The Science Citation Index, for
example, makes use of bibliographic coupling in its “Related Records” feature,
which allows users to ﬁnd papers similar to a given paper. Cocitation would
be less appropriate in this situation, since it tends not to work well for papers
with few citations.

117

M ATHEMATICS OF NETWORKS

Bibliographic coupling also has the advantage that it can be computed as
soon as a paper is published and the contents of the paper’s bibliography are
known. Cocitation, on the other hand, cannot be computed until a paper has
been cited by other papers, which usually doesn’t happen until at least a few
months after publication, and sometimes years. Furthermore, the cocitation of
two papers can change over time as the papers receive new citations, whereas
bibliographic coupling is ﬁxed from the moment the papers are published.
(This could be an advantage or a disadvantage—there are situations in which
changes in cocitation could reveal interesting information about the papers
that cannot be gleaned from an unchanging measure like bibliographic coupling.)
In addition to their use as measures of vertex similarity, the cocitation and
bibliographic coupling matrices are also used in search algorithms for directed
networks, and in particular in the so-called HITS algorithm, which we describe
in Section 7.5.
6.4.2

A cycle in a directed network.

A CYCLIC DIRECTED NETWORKS

A cycle in a directed network is a closed loop of edges with the arrows on each
of the edges pointing the same way around the loop. Networks like the World
Wide Web have many such cycles in them. Some directed networks however
have no cycles and these are called acyclic networks.7 Ones with cycles are
called cyclic. A self-edge—an edge connecting a vertex to itself—counts as a
cycle, and so an acyclic network also has no self-edges.
The classic example of an acyclic directed network is a citation network of
papers, as discussed in Section 4.2. When writing a paper you can only cite
another paper if it has already been written, which means that all the directed
edges in a citation network point backward in time. Graphically we can depict
such a network as in Fig. 6.3, with the vertices time-ordered—running from
bottom to top of the picture in this case—so that all the edges representing
the citations point downward in the picture.8 There can be no closed cycles in
such a network because any cycle would have to go down the picture and then
come back up again to get back to where it started and there are no upward
7
In the mathematical literature one often sees the abbreviation DAG, which is short for directed
acyclic graph.
8
As discussed in Section 4.2, there are in real citation networks rare instances in which two
papers both cite each other, forming a cycle of length two in the citation network, for instance
if an author publishes two related papers in the same issue of a journal. Citation networks are,
nonetheless, acyclic to a good approximation.

118

6.4

9

8

7

6

5
4

1

3
2

|

D IRECTED NETWORKS

Figure 6.3: An acyclic directed network. In this
network the vertices are laid out in such a way
that all edges point downward. Networks that
can be laid out in this way are called acyclic, since
they possess no closed cycles of edges. An example of an acyclic network is a citation network
of citations between papers, in which the vertical
axis would represent date of publication, running
up the ﬁgure, and all citations would necessarily
point from later papers to earlier ones.

edges with which to achieve this.
It is less obvious but still true that if a network is acyclic it can be drawn in
the manner of Fig. 6.3 with all edges pointing downward. The proof that this
can be done turns out to be useful, because it also provides us with a method
for determining whether a given network is acyclic.
Suppose we have an acyclic directed network of n vertices. There must
be at least one vertex somewhere on the network that has ingoing edges only
and no outgoing ones. To see this consider starting from any vertex in the
network and making a path across the network by following edges, each in
the correct direction denoted by its arrow. Either such a path will eventually
encounter a vertex with no outgoing edges, in which case we are done, or each
vertex it encounters has one or more outgoing edges, in which case we choose
one such edge and continue our path. If the path never reaches a vertex with
no outgoing edges, then it must eventually arrive back at a vertex that has
been visited previously—at most we can visit all n vertices in the network once
before the path either terminates or we are forced to revisit a vertex. However
if we revisit a vertex then we have gone around a cycle in the network, which
cannot be since the network is acyclic. Thus we must always in the end ﬁnd
a vertex with no outgoing edges and hence at least one such vertex always
exists.
In practice, it is not necessary to actually construct the paths through the
network to ﬁnd a vertex with no outgoing edges—since we know that such
a vertex exists, we can simply look through each vertex in turn until we ﬁnd
one.
We now take this vertex with no outgoing edges and draw it at the bottom
of our picture. We remove this vertex from the network, along with any edges
attached to it, and repeat the process, ﬁnding another vertex with no outgoing
edges in the remaining network. We draw this second vertex above the ﬁrst

119

M ATHEMATICS OF NETWORKS

one in the ﬁgure, remove it from the network and repeat again. And so forth.
When we have drawn all vertices, we then add the directed edges between
them to the picture. Since each edge, by deﬁnition, has incoming edges only
from vertices drawn after it—and therefore above it—all edges in the ﬁnal picture must be pointing downward. Note that the particular order in which we
draw the vertices, and hence the picture we produce, is not necessarily unique.
If at any stage in the process of drawing the vertices there is more than one
vertex with no outgoing edges then we have a choice about which one we pick
and hence a choice between overall vertex orders.
This process is a useful one for visualizing acyclic networks. Most computer algorithms for drawing such networks work by arranging the vertices in
order along one axis in just this way, and then moving them around along the
other axis to make the network structure as clear and visually pleasing as possible (which usually means minimizing the number of times that edges cross).
The process is useful for another reason too: it will break down if the network is cyclic, and therefore it gives us a way to test whether a given network
is acyclic. If a network contains a cycle, then none of the vertices in that cycle
will ever be removed during our process: none of them will be without outgoing edges until one of the others in the cycle is removed, and hence none of
them can ever be removed. Thus, if the network contains a cycle there must
come a point in our process where there are still vertices left in the network
but all of them have outgoing edges. So a simple algorithm for determining
whether a network is acyclic is:
1. Find a vertex with no outgoing edges.
2. If no such vertex exists, the network is cyclic. Otherwise, if such a vertex
does exist, remove it and all its ingoing edges from the network.
3. If all vertices have been removed, the network is acyclic. Otherwise go
back to step 1.
The adjacency matrix of an acyclic directed network has interesting properties. Suppose we construct an ordering of the vertices of an acyclic network as
described above, so that all edges point in one direction, and suppose we then
label the vertices in that order. Then there can be an edge from vertex j to vertex i only if j > i. Put another way, the adjacency matrix A (whose element Aij
records the presence of an edge from j to i) has all its non-zero elements above
the diagonal—it is upper triangular. For instance, the adjacency matrix of the

120

6.4

network shown in Fig. 6.3 is
⎛
0 0
⎜0 0
⎜
⎜0 0
⎜
⎜0 0
⎜
⎜
A = ⎜0 0
⎜
⎜0 0
⎜
⎜0 0
⎜
⎝0 0
0 0

1
1
0
0
0
0
0
0
0

0
0
0
0
0
0
0
0
0

1
0
0
1
0
0
0
0
0

0
1
1
0
0
0
0
0
0

0
0
0
0
1
1
0
0
0

0
0
0
1
0
0
1
0
0

⎞
0
0⎟
⎟
0⎟
⎟
0⎟
⎟
⎟
1⎟ .
⎟
0⎟
⎟
1⎟
⎟
0⎠

|

D IRECTED NETWORKS

(6.13)

0

Note also that the diagonal elements of the adjacency matrix are necessarily
zero, since an acyclic network has no self-edges. Triangular matrices with zeros
on the diagonal are called strictly triangular.
If the vertices of an acyclic network are not numbered in order as described
above, then the adjacency matrix will not be triangular. (Imagine swapping
rows and columns of the matrix above, for instance.) However, we can say
that for every acyclic directed network there exists at least one labeling of the
vertices such that the adjacency matrix will be strictly upper triangular.
The adjacency matrix also has the property that all of its eigenvalues are
zero if and only if the network is acyclic. To demonstrate this, we must demonstrate the correspondence in both directions, i.e., that the adjacency matrix of
an acyclic network has all eigenvalues zero and also that a network is acyclic
if its adjacency matrix has all eigenvalues zero.
The former is the easier to prove. If a network is acyclic then we can order
and label the vertices as described above and hence write the adjacency matrix
in strictly upper triangular form. The diagonal elements of a triangular matrix,
however, are its eigenvalues, and since these are all zero it follows immediately
that all eigenvalues are zero for an acyclic network.
To show the converse, that the network is acyclic if the eigenvalues are all
zero, it sufﬁces to demonstrate that any cyclic network must have at least one
non-zero eigenvalue. To demonstrate this we make use of a result derived in
Section 6.10. There we show that the total number Lr of cycles of length r in a
network is
n

Lr = ∑ κir ,

(6.14)

i =1

where κi is the ith eigenvalue of the adjacency matrix. Suppose a network is
cyclic. Let r be the length of one of the cycles it contains. Then by deﬁnition
Lr > 0 for this network. However, this can only be the case if at least one of
the terms in the sum on the right-hand side of Eq. (6.14) is greater than zero,
121

M ATHEMATICS OF NETWORKS

1

2

4

3

5
1

(a)

2

3

4

5

(b)

Figure 6.4: A hypergraph and corresponding bipartite graph. These two networks
show the same information—the membership of ﬁve vertices in four different groups.
(a) The hypergraph representation in which the groups are represented as hyperedges,
denoted by the loops circling sets of vertices. (b) The bipartite representation in which
we introduce four new vertices (open circles) representing the four groups, with edges
connecting each vertex to the groups to which it belongs.

and hence the adjacency matrix has at least one non-zero eigenvalue. If all
eigenvalues are zero, therefore, the network cannot be cyclic.
Matrices with all eigenvalues zero are called nilpotent matrices. Thus one
could also say that a network is acyclic if and only if it has a nilpotent adjacency
matrix.

6.5

H YPERGRAPHS

In some kinds of network the links join more than two vertices at a time. For
example, we might want to create a social network representing families in
a larger community of people. Families can have more than two people in
them and the best way to represent family ties in such families is to use a
generalized kind of edge that joins more than two vertices.9 Such an edge
is called a hyperedge and a network with hyperedges is called a hypergraph.
Figure 6.4a shows a small example of a hypergraph in which the hyperedges
are denoted by loops.
9
We could just use ordinary edges joining vertex pairs to represent our family ties, placing an
edge between any two vertices that correspond to individuals in the same family. This, however,
doesn’t explicitly tell us when two edges correspond to ties within the same family, and there
is no single object in the network that corresponds to a family the way a hyperedge does in the
hypergraph. In a number of ways, therefore, the hypergraph is more convenient.

122

6.6

Network
Film actors
Coauthorship
Boards of directors
Social events
Recommender system
Keyword index
Rail connections
Metabolic reactions

Vertex
Actor
Author
Director
People
People
Keywords
Stations
Metabolites

|

B IPARTITE NETWORKS

Group
Cast of a ﬁlm
Authors of an article
Board of a company
Participants at social event
Those who like a book, ﬁlm, etc.
Pages where words appear
Train routes
Participants in a reaction

Section
3.5
3.5
3.5
3.1
4.3.2
4.3.3
2.4
5.1.1

Table 6.2: Hypergraphs and bipartite graphs. Examples of networks that can be represented as hypergraphs or equivalently as bipartite graphs. The last column gives the section of this book in which each network is discussed.

Many of the networks that we will encounter in this book can be presented as hypergraphs. In particular, any network in which the vertices are
connected together by common membership of groups of some kind can be
represented in this way. In sociology such networks are called “afﬁliation networks” and we saw several examples of them in Section 3.5. Directors sitting
on the boards of companies, scientists coauthoring papers, and ﬁlm actors appearing together in ﬁlms are all examples of such networks (see Table 6.2).
We will however talk very little about hypergraphs in this book, because
there is another way of representing the same information that is more convenient for our purposes—the bipartite network.

6.6

B IPARTITE NETWORKS

The membership of vertices in groups represented by hyperedges in a hypergraph can equally and often more conveniently be represented as a bipartite
network, also called a two-mode network in the sociology literature. In such a
network there are two kinds of vertices, one representing the original vertices
and the other representing the groups to which they belong. We discussed bipartite networks previously in the context of afﬁliation networks in Section 3.5
and of recommender networks in Section 4.3.2. For example, we can represent
the network of ﬁlm actors discussed in Section 3.5 as a bipartite network in
which the two types of vertex are the actors themselves and the ﬁlms in which
they appear. The edges in a bipartite network run only between vertices of unlike types: in the ﬁlm network they would run only between actors and ﬁlms,
and each actor would be connected by an edge to each ﬁlm in which he or she
appeared. A small example of a bipartite network is shown in Fig. 6.4b. This
123

M ATHEMATICS OF NETWORKS

example network in fact portrays exactly the same set of group memberships
as the hypergraph of Fig. 6.4a; the two are entirely equivalent.
Bipartite networks occur occasionally in contexts other than membership of
groups. For example, if we were to construct a network of who is or has been
married to whom within a population, that network would be bipartite, the
two kinds of vertex corresponding to men and women and the edges between
them marriages.10
The equivalent of an adjacency matrix for a bipartite network is a rectangular matrix called an incidence matrix. If n is the number of people or other
participants in the network and g is the number of groups, then the incidence
matrix B is a g × n matrix having elements Bij such that

Bij =

1 if vertex j belongs to group i,
0 otherwise.

(6.15)

For instance, the 4 × 5 incidence matrix of the network shown in Fig. 6.4b is
⎛

1
⎜1
B=⎜
⎝0
0

0
1
1
0

0
1
1
1

1
1
0
1

⎞
0
0⎟
⎟.
1⎠

(6.16)

1

Although a bipartite network may give the most complete representation of
a particular network it is often convenient to work with direct connections between vertices of just one type. We can use the bipartite network to infer such
connections, creating a one-mode projection from the two-mode bipartite form.
As an example, consider again the case of the ﬁlms and actors. We can perform a projection onto the actors alone by constructing the n-vertex network
in which the vertices represent actors and two actors are connected by an edge
if they have appeared together in a ﬁlm. The corresponding one-mode projection onto the ﬁlms would be the g-vertex network where the vertices represent
ﬁlms and two ﬁlms are connected if they share a common actor. Figure 6.5
shows the two one-mode projections of a small bipartite network.
When we form a one-mode projection each group in the bipartite network
results in a cluster of vertices in the one-mode projection that are all connected
to each other—a “clique” in network jargon (see Section 7.8.1). For instance,
if a group contains four members in the bipartite network, then each of those
four is connected to each of the others in the one-mode projection by virtue of
10

In countries such as Spain or Canada, where same-sex marriages are permitted, the network
would not be truly bipartite because there would be some edges between like kinds of vertex.

124

6.6

A

1

A

B

C

D

B

2

3

C

4

5

|

B IPARTITE NETWORKS

D

6

7
7

2

5

1

6
3

4

Figure 6.5: The two one-mode projections of a bipartite network. The central portion of this ﬁgure shows a bipartite network with four vertices of one type (open circles labeled A
to D) and seven of another (ﬁlled circles, 1 to 7). At the top
and bottom we show the one-mode projections of the network onto the two sets of vertices.

common membership in that group. (Such a clique of four vertices is visible in
the center of the lower projection in Fig. 6.5.) Thus the projection is, generically,
the union of a number of cliques, one for each group in the original bipartite
network. The same goes for the other projection onto the groups.
The one-mode projection, as we have described it, is often useful and is
widely employed, but its construction discards a lot of the information present
in the structure of the original bipartite network and hence it is, in a sense, a
less powerful representation of our data. For example, the projection loses any
information about how many groups two vertices share in common. In the
case of the actors and ﬁlms, for instance, there are some pairs of actors who
have appeared in many ﬁlms together—Fred Astaire and Ginger Rogers, say,
or William Shatner and Leonard Nimoy—and it’s reasonable to suppose this
indicates a stronger connection than between actors who appeared together
only once.
We can capture information of this kind in our projection by making the
projection weighted, giving each edge between two vertices in the projected
125

M ATHEMATICS OF NETWORKS

network a weight equal to the number of common groups the vertices share.
This weighted network still does not capture all the information in the bipartite
original—it doesn’t record the number of groups or the exact membership of
each group for instance—but it is an improvement on the unweighted version
and is quite widely used.
Mathematically the projection can be written in terms of the incidence matrix B as follows. The product Bki Bkj will be 1 if and only if i and j both belong
to the same group k in the bipartite network. Thus, the total number Pij of
groups to which both i and j belong is
g

g

k =1

k =1

Pij = ∑ Bki Bkj = ∑ BikT Bkj ,

(6.17)

where BikT is an element of the transpose B T of B. The n × n matrix P = B T B
is similar to an adjacency matrix for the weighted one-mode projection onto
the n vertices. Its off-diagonal elements are equal to the weights in that network, the number of common groups shared by each vertex pair. P is not quite
an adjacency matrix, however, since its diagonal elements are non-zero, even
though the network itself, by deﬁnition, has no self-edges. (In this respect P
is somewhat similar to the cocitation matrix of Section 6.4.1.) The diagonal
elements have values
g

g

k =1

k =1

2
= ∑ Bki ,
Pii = ∑ Bki

(6.18)

where we have made use of the fact that Bki only takes the values 0 or 1. Thus
Pii is equal to the number of groups to which vertex i belongs.
Thus to derive the adjacency matrix of the weighted one-mode projection,
we would calculate the matrix P = B T B and set the diagonal elements equal
to zero. And to derive the adjacency matrix of the unweighted projection, we
would take the adjacency matrix of the weighted version and replace every
non-zero matrix element with a 1.
The other one-mode projection, onto the groups, can be represented by a
g × g matrix P = BB T , whose off-diagonal element Pij gives the number of
common members of groups i and j, and whose diagonal element Pii gives the
number of members of group i.
One occasionally also comes across bipartite networks that are directed. For
example, the metabolic networks discussed in Section 5.1.1 can be represented
as directed bipartite networks—see Fig. 5.1a. A variety of more complex types
of projection are possible in this case, although their use is rare and we won’t
spend time on them here. Weighted bipartite networks are also possible in
principle, although no examples will come up in this book.
126

6.7

(a)

|

T REES

(b)

Figure 6.6: Two sketches of the same tree. The two panels here show two different
depictions of a tree, a network with no closed loops. In (a) the vertices are positioned
on the page in any convenient position. In (b) the tree is a laid out in a “rooted” fashion,
with a root node at the top and branches leading down to “leaves” at the bottom.

6.7

T REES

A tree is a connected, undirected network that contains no closed loops—see
Fig. 6.6a.11 By “connected” we mean that every vertex in the network is reachable from every other via some path through the network. A network can also
consist of two or more parts, disconnected from one another,12 and if an individual part has no loops it is also called a tree. If all the parts of the network
are trees, the complete network is called a forest.
Trees are often drawn in a rooted manner, as shown in Fig. 6.6b, with a
root node at the top and a branching structure going down. The vertices at the
bottom that are connected to only one other vertex are called leaves.13 Topologically, a tree has no particular root—the same tree can be drawn with any node,
11
In principle, one could put directions on the edges of a tree and make it a directed network,
but the deﬁnition of a tree as a loopless network ignores directions if there are any. This means
that a tree is not the same thing as a directed acyclic graph (Section 6.4.2). A directed tree is always
a directed acyclic graph, but the reverse is not also true, since the deﬁnition of a loop in a directed
acyclic graph takes the directions of the edges into account. A directed acyclic graph may well
have loops if we ignore directions (see for example Fig. 6.3).
12

Such parts are called “components”—see Section 6.11.

13

This is a slightly odd way of drawing trees, with the root at the top and the leaves at the
bottom. The more familiar trees of the wooden kind are, of course, the other way up. The upsidedown orientation has, however, become conventional in mathematics and computer science, and
we here bow to this convention.

127

M ATHEMATICS OF NETWORKS

including a leaf, as the root node, but in some applications there are other reasons for designating a root. A dendrogram is one example (see below).
Not very many of the real-world networks that we will encounter in this
book are trees, although a few are. A river network is an example of a naturally occurring tree (see Fig. 2.6, for instance). Trees do nonetheless play several important roles in the study of networks. In Chapter 12 for instance we
will study the network model known as the “random graph.” In this model local groups of vertices—the so-called small components in the network—form
trees, and we can exploit this property to derive a variety of mathematical results about random graphs. In Section 11.11.1 we introduce the “dendrogram,”
a useful tool that portrays a hierarchical decomposition of a network as a tree.
Trees also occur commonly in computer science, where they are used as a basic
building block for data structures such as AVL trees and heaps (see Sections 9.5
and 9.7 and Refs. [8, 81]) and in other theoretical contexts like minimum spanning trees [81], Cayley trees or Bethe lattices [269], and hierarchical models of
networks (see Section 19.3.2 and Refs. [70, 179, 322]).
Perhaps the most important property of trees for our purposes is that, since
they have no closed loops, there is exactly one path between any pair of vertices. (In a forest there is at most one path, but there may be none.) This is clear
since if there were two paths between a pair of vertices A and B then we could
go from A to B along one path and back along the other, making a loop, which
is forbidden.
This property of trees makes certain kinds of calculation particularly simple, and trees are sometimes used as a basic model of a network for this reason. For instance, the calculation of a network’s diameter (Section 6.10.1), the
betweenness centrality of a vertex (Section 7.7), and certain other properties
based on shortest paths are all relatively easy with a tree.
Another useful property of trees is that a tree of n vertices always has exactly n − 1 edges. To see this, consider building up a tree by adding vertices
one by one. Starting with a single vertex and no edges, we add a second vertex
and one edge to connect it to the ﬁrst. Similarly when we add a third vertex
we need at least one edge to connect it one of the others, and so forth. For every vertex we must add at least one edge to keep the network connected. This
means that the number of edges must always be at least one less than the number of vertices. In mathematical terms, n − 1 is a lower bound on the number
of edges.
But it is also an upper bound, because if we add more than one edge when
we add a new vertex then we create a loop: the ﬁrst edge connects the added
vertex to the rest of the network and the second then connects together two
vertices that are already part of the network. But adding an edge between two
128

6.8

vertices that are already connected via the network necessarily creates a loop.
Hence we are not allowed to add more than one edge per vertex if the network
is to remain free of loops.
Thus the number of edges in a tree cannot be either more or less than n − 1,
and hence is exactly n − 1.
The reverse is also true, that any connected network with n vertices and
n − 1 edges is a tree. If such a network were not a tree then there must be a loop
in the network somewhere, implying that we could remove an edge without
disconnecting any part of the network. Doing this repeatedly until no loops are
left, we would end up with a tree, but one with less than n − 1 edges, which
cannot be. Hence we must have had a tree to begin with. As a corollary, this
implies that the connected network on n vertices with the minimum number
of edges is always a tree, since no connected network has less than n − 1 edges
and all networks with n − 1 edges are trees.

6.8

|

P LANAR NETWORKS

Adding an extra edge
(gray) between any two
vertices of a tree creates a
loop.

P LANAR NETWORKS

A planar network is a network that can be drawn on a plane without having
any edges cross.14 Figure 6.7a shows a small planar network. Note that it is in
most cases possible to ﬁnd a way to draw a planar network so that some edges
do cross (Fig. 6.7b). The deﬁnition of planarity only speciﬁes that at least one
arrangement of the vertices exists that results in no crossing.
Most of the networks we will encounter in this book are not planar, either because there is no relevant two-dimensional geometry to which the network is conﬁned (e.g., citation networks, metabolic networks, collaboration
networks), or else there is but there is nothing to stop edges from crossing on
it (e.g., the Internet, airline route maps, email networks). However, there are
a few important examples of networks that are planar. First of all, all trees are
planar. For some trees, such as river networks, this is obvious. Rivers never
cross one another; they only ﬂow together. In other cases, such as the trees
used in computer data structures, there is no obvious two-dimensional surface
onto which the network falls but it is planar nonetheless.
Among non-tree-like networks, some are planar for physical reasons. A
good example is a road network. Because roads are conﬁned to the Earth’s
surface they form a roughly planar network. It does happen sometimes that
roads meet without intersecting, one passing over the other on a bridge, so that
14
A plane is a ﬂat surface with open boundaries. One can deﬁne a generalization of a planar
network for other types of two-dimensional surface, such as the torus, which wraps around on
itself. A standard planar network, however, does not wrap around.

129

M ATHEMATICS OF NETWORKS

(a)

(b)

Figure 6.7: Two drawings of a planar graph. (a) A small planar graph with four vertices
and six edges. It is self-evident that the graph is planar, since in this depiction it has
no edges that cross. (b) The same graph redrawn with two of its edges crossing. Even
though the edges cross, the graph is still planar—a graph is planar if it can be drawn
without crossing edges.

in fact, if one wishes to be precise, the road network is not planar. However,
such instances are rare (in the sense that there are far more places where roads
intersect than there are bridges where they don’t) and the network is planar to
a good approximation.
Another example is the network of shared borders between countries, states,
or provinces—see Fig. 6.8. We can take a map depicting any set of contiguous
regions, represent each by a vertex, and draw an edge between any two that
share a border. It is easy to see that the resulting network can always be drawn
without crossing edges provided the regions in question are formed of contiguous landmasses.
Networks of this type, representing regions on a map, play an important
role in the four-color theorem, a theorem that states that it is possible to color
any set of regions on a two-dimensional map, real or imagined, with at most
four colors such that no two adjacent regions have the same color, no matter
how many regions there are or of what size or shape.15 By constructing the
network corresponding to the map in question, this problem can be converted
into a problem of coloring the vertices of a planar graph in such a way that
no two vertices connected by an edge have the same color. The number of
colors required to color a graph in this way is called the chromatic number of the
graph and many mathematical results are known about chromatic numbers.
15
The theorem only applies for a map on a surface with topological genus zero, such as a ﬂat
plane or a sphere. A map on a torus (which has genus 1) can require as many as seven colors.

130

6.8

|

P LANAR NETWORKS

Figure 6.8: Graph of the adjacencies of the lower 48 United States. In this network
each of the lower 48 states in the US is represented as a vertex and there is an edge
between any two vertices if the corresponding states share a border. The resulting graph
is planar, and indeed any set of states, countries, or other regions on a two-dimensional
map can be turned into a planar graph in this way.

The proof of the four-color theorem—the proof that the chromatic number of a
planar graph is always four or less—is one of the triumphs of traditional graph
theory and was ﬁrst given by Appel and Haken [20–22] in 1976 after more than
a hundred years of valiant effort within the mathematics community.16
An important question that arises in graph theory is how to determine,
given a particular network, whether that network is planar or not. For a small
network it is a straightforward matter to draw a picture and play around with
the positions of the vertices to see if one can ﬁnd an arrangement in which
no edges cross, but for a large network this is impractical and a more general
method of determining planarity is needed. Luckily a straightforward one
exists. We will only describe the method here, not prove why it works, since
the proof is long and technical and not particularly relevant to the study of
real-world networks. For those interested in seeing a proof, one is given by
West [324].
Figure 6.9 shows two small networks, conventionally denoted K5 and UG,
16
Appel and Haken’s proof is an interesting one and was controversial at the time of its publication because it made extensive use of a computer to check large numbers of special cases. On
the one hand, the proof was revolutionary for being the ﬁrst proof of a major mathematical result
generated in this fashion. On the other hand a number of people questioned whether it could
really be considered a proof at all, given that it was far too large for a human being to check its
correctness by hand.

131

M ATHEMATICS OF NETWORKS

(a) K5

(b) UG

Figure 6.9: The fundamental non-planar graphs K5 and UG employed in Kuratowski’s theorem. These two small graphs are non-planar and Kuratowski’s theorem states
that any non-planar graph contains at least one subgraph that is an expansion of K5 or
UG.

An expansion of K5 .

that are deﬁnitely not planar.17 Neither of these networks can be drawn without edges crossing. It immediately follows that any network that contains a
subset of vertices, or subgraph, in the form of K5 or UG, is also not planar.
An expansion is a network derived by adding extra vertices in the middle
of edges in another network. No such added vertices, however numerous,
will ever make a non-planar network planar, so it is also the case that any
expansion of K5 or UG is non-planar, and hence that any network containing
an expansion of K5 or UG, is also non-planar.
Kuratowski’s theorem (sometimes also called the Kuratowski reduction theorem)
states that the converse is also true:
Every non-planar network contains at least one subgraph that is an
expansion of K5 or UG.
“Expansion” should be taken here to include the null expansions, i.e., the
graphs K5 and UG themselves.
This theorem, ﬁrst proved by Pontryagin in 1927 but named after Kuratowski who gave an independent proof a few years later,18 provides us with a way
of determining whether a graph is planar. If it contains a subgraph that is an
17
In graph theory Kn denotes the complete graph with n vertices, i.e., the graph of n vertices
with all (n2 ) possible single edges present. UG stands for “utility graph.” UG is the complete
bipartite graph on two groups of three vertices.
18
See Kennedy et al. [170] for an interesting history of the theorem and references to the original
papers.

132

6.9

|

D EGREE

expansion of K5 or UG it is not, otherwise it is.
Kuratowski’s theorem is not, however, particularly useful for the analysis of real-world networks, because such networks are rarely precisely planar.
(And if they are, then, as in the case of the shared border network of countries
or states, it is usually clear for other reasons that they are planar and hence
Kuratowski’s theorem is unnecessary.) More often, like the road network, they
are very nearly planar, but have a few edge crossings somewhere in the network. For such a network, Kuratowski’s theorem would tell us, correctly, that
the network was not planar, but we would be missing the point.
What we would really like is some measure of the degree of planarity of a
network, a measure that could tell us, for example, that the road network of a
country is 99% planar, even though there are a few bridges or tunnels here and
there. One possible such measure is the minimum number of edge crossings
with which the network can be drawn. This however would be a difﬁcult
measure to determine since, at least in the simplest approach, its evaluation
would require us to try every possible way of drawing the network. Perhaps
another approach would be to look at the number of subgraphs in a network
that are expansions of K5 or UG. So far, however, no widely accepted metric
for degree of planarity has emerged. If such a measure were to gain currency
it might well ﬁnd occasional use in the study of real-world networks.

6.9

D EGREE

The degree of a vertex in a graph is the number of edges connected to it. We
will denote the degree of vertex i by k i . For an undirected graph of n vertices
the degree can be written in terms of the adjacency matrix as19
n

k i = ∑ Aij .

(6.19)

j =1

Every edge in an undirected graph has two ends and if there are m edges in
total then there are 2m ends of edges. But the number of ends of edges is also
equal to the sum of the degrees of all the vertices, so
n

2m = ∑ k i ,

(6.20)

i =1

19
Notice that this expression still gives the correct result if there are self-edges in the graph,
provided each such edge is represented by a diagonal element Aii = 2 as discussed earlier, and
not 1.

133

M ATHEMATICS OF NETWORKS

or

n

m = 12 ∑ k i = 12 ∑ Aij ,
i =1

(6.21)

ij

a result that we will use many times throughout this book.
The mean degree c of a vertex in an undirected graph is
c=

1 n
ki ,
n i∑
=1

(6.22)

and combining this with Eq. (6.20) we get
c=

2m
.
n

(6.23)

This relation too will come up repeatedly throughout the book.
The maximum possible number of edges in a simple graph (i.e., one with
no multiedges or self-edges) is (n2 ) = 21 n(n − 1). The connectance or density ρ of
a graph is the fraction of these edges that are actually present:
ρ=

m
2m
c
,
=
n =
n−1
n ( n − 1)
(2)

(6.24)

where we have made use of Eq. (6.23).20 The density lies strictly in the range
0 ≤ ρ ≤ 1. Most of the networks we are interested in are sufﬁciently large that
Eq. (6.24) can be safely approximated as ρ = c/n.
A network for which the density ρ tends to a constant as n → ∞ is said
to be dense. In such a network the fraction of non-zero elements in the adjacency matrix remains constant as the network becomes large. A network in
which ρ → 0 as n → ∞ is said to be sparse, and the fraction of non-zero elements in the adjacency matrix also tends to zero. In particular, a network is
sparse if c tends to a constant as n becomes large. These deﬁnitions of dense
and sparse networks can, however, be applied only if one can actually take the
limit n → ∞, which is ﬁne for theoretical model networks but doesn’t work
in most practical situations. You cannot for example take the limit as an empirical metabolic network or food web becomes large—you are stuck with the
network nature gives you and it can’t easily be changed.
In some cases real-world networks do change their sizes and by making
measurements for different sizes we can make a guess as to whether they are
best regarded as sparse or dense. The Internet and the World Wide Web are two
20
Occasionally connectance is deﬁned as ρ = m/n2 , which for large networks differs from
Eq. (6.24) by about a factor of 2. With that deﬁnition 0 ≤ ρ < 12 .

134

6.9

examples of networks whose growth over time allows us to say with some conviction that they are best regarded as sparse. In other cases there may be independent reasons for regarding a network to be sparse or dense. In a friendship
network, for instance, it seems unlikely that the number of a person’s friends
will double solely because the population of the world doubles. How many
friends a person has is more a function of how much time they have to devote
to the maintenance of friendships than it is a function of how many people are
being born. Friendship networks therefore are usually regarded as sparse.
In fact, almost of all of the networks we consider in this book are considered
to be sparse networks. This will be important when we look at the expected
running time of network algorithms in Chapters 9 to 11 and when we construct
mathematical models of networks in Chapters 12 to 15. One possible exception
to the pattern is food webs. Studies comparing ecosystems of different sizes
seem to show that the density of food webs is roughly constant, regardless of
their size, indicating that food webs may be dense networks [102, 210].
Occasionally we will come across networks in which all vertices have the
same degree. In graph theory, such networks are called regular graphs. A regular graph in which all vertices have degree k is sometimes called k-regular. An
example of a regular graph is a periodic lattice such as a square or triangular
lattice. On the square lattice, for instance, every vertex has degree four.
Vertex degrees are more complicated in directed networks. In a directed
network each vertex has two degrees. The in-degree is the number of ingoing
edges connected to a vertex and the out-degree is the number of outgoing edges.
Bearing in mind that the adjacency matrix of a directed network has element
Aij = 1 if there is an edge from j to i, in- and out-degrees can be written
n

|

D EGREE

An inﬁnite square lattice is
an example of a 4-regular
graph.

n

kin
i = ∑ Aij ,

kout
= ∑ Aij .
j

j =1

(6.25)

i =1

The number of edges m in a directed network is equal to the total number of
ingoing ends of edges at all vertices, or equivalently to the total number of
outgoing ends of edges, so
n

n

i =1

j =1

out
= ∑ Aij .
m = ∑ kin
i = ∑ kj

(6.26)

ij

Thus the mean in-degree cin and the mean out-degree cout of every directed
network are equal:
cin =

1 n in
1 n
k i = ∑ kout
= cout .
∑
n i =1
n j =1 j

(6.27)

135

M ATHEMATICS OF NETWORKS

For simplicity we will just denote both by c, and combining Eqs. (6.26) and
(6.27) we get
m
(6.28)
c= .
n
Note that this differs by a factor of two from the equivalent result for an undirected network, Eq. (6.23).

6.10

A path of length three in a
network.

PATHS

A path in a network is any sequence of vertices such that every consecutive
pair of vertices in the sequence is connected by an edge in the network. In
layman’s terms a path is a route across the network that runs from vertex to
vertex along the edges of the network. Paths can be deﬁned for both directed
and undirected networks. In a directed network, each edge traversed by a
path must be traversed in the correct direction for that edge. In an undirected
network edges can be traversed in either direction.
In general a path can intersect itself, visiting again a vertex it has visited
before, or even running along an edge or set of edges more than once. Paths
that do not intersect themselves are called self-avoiding paths and are important
in some areas of network theory. Geodesic paths and Hamiltonian paths are
two special cases of self-avoiding paths that we will study in this book.
The length of a path in a network is the number of edges traversed along
the path (not the number of vertices). Edges can be traversed more than once,
and if they are they are counted separately each time they are traversed. Again
in layman’s terms, the length of a path is the number of “hops” the path makes
from vertex to adjacent vertex.
It is straightforward to calculate the number of paths of a given length r
on a network. For either a directed or an undirected simple graph the element
Aij is 1 if there is an edge from vertex j to vertex i, and 0 otherwise. (We will
consider only simple graphs for now, although the developments generalize
easily to non-simple graphs.) Then the product Aik Akj is 1 if there is a path of
(2)

length 2 from j to i via k, and 0 otherwise. And the total number Nij of paths
of length two from j to i, via any other vertex, is
(2)

n

Nij = ∑ Aik Akj = A2 ij ,

(6.29)

k =1

where [. . .]ij denotes the ijth element of a matrix.
Similarly the product Aik Akl Alj is 1 if there is a path of length three from j
to i via l and k, in that order, and 0 otherwise, and hence the total number of

136

6.10

|

PATHS

paths of length three is
n

(3)

Nij = ∑ Aik Akl Alj = A3 ij .

(6.30)

k,l =1

Generalizing to paths of arbitrary length r, we see that21
(r )

Nij = [Ar ]ij .

(6.31)

A special case of this result is that the number of paths of length r that start
and end at the same vertex i is [Ar ]ii . These paths are just loops in the network,
what we called “cycles” in our discussion of acyclic graphs in Section 6.1. The
total number Lr of loops of length r anywhere in a network is the sum of this
quantity over all possible starting points i:
n

Lr = ∑ [Ar ]ii = Tr Ar .

(6.32)

i =1

Note that this expression counts separately loops consisting of the same vertices in the same order but with different starting points.22 Thus the loop
1 → 2 → 3 → 1 is considered different from the loop 2 → 3 → 1 → 2. The
expression also counts separately loops that consist of the same vertices but
traversed in opposite directions, so that 1 → 2 → 3 → 1 and 1 → 3 → 2 → 1
are distinct.
Equation (6.32) can also be expressed in terms of the eigenvalues of the
adjacency matrix. Let us consider the case of an undirected graph ﬁrst. In
this case, the adjacency matrix is symmetric, which means that it has n real
non-negative eigenvalues, the eigenvectors have real elements, and the matrix
can always be written in the form A = UKU T , where U is the orthogonal
matrix of eigenvectors and K is the diagonal matrix of eigenvalues. Then Ar =
(UKUT )r = UKr UT and the number of loops is
Lr = Tr(UKr U T ) = Tr(U T UKr ) = Tr Kr

= ∑ κir ,

(6.33)

i

21

( r −1)

For a rigorous proof we can use induction. If there are Nik

paths of length r − 1 from i

(r )
( r −1)
to k, then by arguments similar to those above there are Nij = ∑k Nik Akj paths of length r from
(r )
(
r)
(
r −1)
(
r)
i to j, or in matrix notation N = N
A, where N is the matrix with elements Nij . This
implies that if N(r−1) = Ar−1 then N(r) = Ar and with the initial case N(1) = A we have N(r) = Ar

for all r. Taking the ijth element of both sides then gives Eq. (6.31).
22

If we wish to count each loop only once, we should roughly speaking divide by r, but this
does not allow for paths that have symmetries under a change of starting points, such as paths
that consist of the same subloop traversed repeatedly. Counting such symmetric paths properly is
a complex problem that can be solved exactly in only a few cases.

137

M ATHEMATICS OF NETWORKS

where κi is the ith eigenvalue of the adjacency matrix and we have made use of
the fact that the trace of a matrix product is invariant under cyclic permutations
of the product.
For directed networks the situation is more complicated. In some cases the
same line of proof works and we can again demonstrate that Eq. (6.33) is true,
but in other cases the proof breaks down. Recall that directed graphs have, in
general, asymmetric adjacency matrices, and some asymmetric matrices cannot be diagonalized.23 An example is the matrix
1
0

1
,
1

which describes the graph

.

This matrix has only a single (right) eigenvector (1, 0), and thus one cannot
form an orthogonal matrix of eigenvectors with which to diagonalize it. Nonetheless Eq. (6.33) is still true even in such cases, but a different method of proof
is needed, as follows.
Every real matrix, whether diagonalizable or not, can be written in the form
A = QTQ T , where Q is an orthogonal matrix and T is an upper triangular
matrix. This form is called the Schur decomposition of A [217].
Since T is triangular, its diagonal elements are its eigenvalues. Furthermore
those eigenvalues are the same as the eigenvalues of A. To see this, let x be a
right eigenvector of A with eigenvalue κ. Then QTQ T x = Ax = κx, and
multiplying throughout by Q T , bearing in mind that Q is orthogonal, gives
TQ T x = κQ T x,

(6.34)

and hence Q T x is an eigenvector of T with the same eigenvalue κ as the adjacency matrix.24 Then
Lr = Tr Ar = Tr(QTr Q T ) = Tr(Q T QTr ) = Tr Tr

= ∑ κir ,

(6.35)

i

the ﬁnal equality following because the diagonal elements of any power of a
triangular matrix T are T’s diagonal elements raised to the same power.
This demonstration works for any graph, whatever the properties of its
adjacency matrix, and hence Eq. (6.35) is always true. We used this result in
23
Such matrices have multiple or “degenerate” eigenvalues and technically have a non-zero
nilpotent part in their Jordan decomposition.
24
Indeed, any mapping A → Q−1 AQ of a matrix preserves its eigenvalues. Such mappings are
called similarity transformations.

138

6.10

|

PATHS

Eq. (6.14) to show that the graph described by a nilpotent adjacency matrix
(i.e., a matrix whose eigenvalues are all zero) must be acyclic. (All such matrices are non-diagonalizable, so one must use Eq. (6.35) in that case.)
Since the adjacency matrix of a directed graph is, in general, asymmetric it
may have complex eigenvalues. But the number of loops Lr above is nonetheless always real, as it must be. The eigenvalues of the adjacency matrix are
the roots of the characteristic polynomial det(κI − A), which has real coefﬁcients, and all roots of such a polynomial are either themselves real or come in
complex-conjugate pairs. Thus, while there may be complex terms in the sum
in Eq. (6.33), each such term is complemented by another that is its complex
conjugate and the sum itself is always real.
6.10.1

G EODESIC PATHS

A geodesic path, also called simply a shortest path, is a path between two vertices
such that no shorter path exists:

A geodesic path of length two between
two vertices.

The length of a geodesic path, often called the geodesic distance or shortest distance, is thus the shortest network distance between the vertices in question.
In mathematical terms, the geodesic distance between vertices i and j is the
smallest value of r such that [Ar ]ij > 0. In practice however there are much
better ways of calculating geodesic distances than by employing this formula.
We will study some of them in Section 10.3.
It is possible for there to be no geodesic path between two vertices if the
vertices are not connected together by any route though the network (i.e., if
they are in different “components”—see Section 6.11). In this case one sometimes says that the geodesic distance between the vertices is inﬁnite, although
this is mostly just convention—it doesn’t really mean very much beyond the
fact that the vertices are not connected.
Geodesic paths are necessarily self-avoiding. If a path intersects itself then
it contains a loop and can be shortened by removing that loop while still connecting the same start and end points, and hence self-intersecting paths are
never geodesic paths.

139

M ATHEMATICS OF NETWORKS

i

j

Figure 6.10: Vertices i and j have three
geodesic paths between them of length
three.

Geodesic paths are not necessarily unique, however. It is perfectly possible
to have two or more paths of equal length between a given pair of vertices.
The paths may even overlap along some portion of their length—see Fig. 6.10.
The diameter of a graph is the length of the longest geodesic path between
any pair of vertices in the network for which a path actually exists. (If the
diameter were merely the length of the longest geodesic path then it would be
formally inﬁnite in a network with more than one component if we adopted
the convention above that vertices connected by no path have inﬁnite geodesic
distance. One can also talk about the diameters of the individual components
separately, this being a perfectly well-deﬁned concept whatever convention we
adopt for unconnected vertices.)
6.10.2

Examples of Eulerian and
Hamiltonian paths in a
small network.

140

E ULERIAN AND H AMILTONIAN PATHS

An Eulerian path is a path that traverses each edge in a network exactly once.
A Hamiltonian path is a path that visits each vertex exactly once. A network
can have one or many Eulerian or Hamiltonian paths, or none. A Hamiltonian
path is by deﬁnition self-avoiding, but an Eulerian path need not be. Indeed if
there are any vertices of degree greater than two in a network an Eulerian path
will have to visit those vertices more than once in order to traverse all their
edges.
Eulerian paths form the basis of one of the oldest proofs in graph theory,
which dates from 1736. Around that time the great mathematician Leonard
Euler became interested the mathematical riddle now known as the Königsberg
Bridge Problem. The city of Königsberg (now Kaliningrad) was built on the
banks of the river Pregel, and on two islands that lie midstream. Seven bridges
connected the land masses, as shown in Fig. 6.11a. The riddle asked, “Does
there exist any walking route that crosses all seven bridges exactly once each?”
Legend has it that the people of Königsberg spent many fruitless hours trying to ﬁnd such a route, before Euler proved the impossibility of its exis-

6.10

(a)

|

PATHS

(b)

Figure 6.11: The Königsberg bridges. (a) In the eighteenth century the Prussian city of Königsberg, built on four
landmasses around the river Pregel, was connected by seven bridges as shown. (b) The topology of the landmasses and
bridges can be represented as a multigraph with four vertices and seven edges.

tence.25 The proof, which perhaps seems rather trivial now, but which apparently wasn’t obvious in 1736, involved constructing a network (technically
a multigraph) with four vertices representing the four land masses and seven
edges joining them in the pattern of the Königsberg bridges (Fig. 6.11b). Then
the bridge problem becomes a problem of ﬁnding an Eulerian path on this network (and indeed the Eulerian path is named in honor of Euler for his work
on this problem). Euler observed that, since any Eulerian path must both enter
and leave every vertex it passes through except the ﬁrst and last, there can at
most be two vertices in the network with odd degree if such a path is to exist.
Since all four vertices in the Königsberg network have odd degree, the bridge
problem necessarily has no solution.
More precisely a network can have an Eulerian path only if there are exactly
two or zero vertices of odd degree—zero in the case where the path starts and
ends at the same vertex. This is not a sufﬁcient condition for an Eulerian path,
however. One can easily ﬁnd networks that satisfy it and yet have no Eulerian
path. The general problem of ﬁnding either an Eulerian or Hamiltonian path
on a network, or proving that none exists, is a hard one and signiﬁcant work is
still being done on particular cases.
Eulerian and Hamiltonian paths have a number of practical applications in
computer science, in job sequencing, “garbage collection,” and parallel pro25

No cheating: you’re not allowed to swim or use a boat.

141

M ATHEMATICS OF NETWORKS

gramming [81]. A Hamiltonian path problem was also, famously, the ﬁrst
problem solved using a DNA-based computer [7].

6.11

C OMPONENTS

It is possible for there to be no path at all between a given pair of vertices in
a network. The network shown in Fig. 6.12, for example, is divided into two
subgroups of vertices, with no connections between the two, so that there is
no path from any vertex in the left subgroup to any vertex in the right. For
instance, there is no path from the vertex labeled A to the vertex labeled B.
A network of this kind is said to be disconnected. Conversely, if there is a path
from every vertex in a network to every other the network is connected.
The subgroups in a network like that of Fig. 6.12 are called components.
Technically a component is a subset of the vertices of a network such that there
exists at least one path from each member of that subset to each other member,
and such that no other vertex in the network can be added to the subset while
preserving this property. (Subsets like this, to which no other vertex can be
added while preserving a given property, are called maximal subsets.) The network in Fig. 6.12 has two components of three and four vertices respectively.
A connected network necessarily has only one component. A singleton vertex
that is connected to no others is considered to be a component of size one, and
every vertex belongs to exactly one component.
The adjacency matrix of a network with more than one component can be
written in block diagonal form, meaning that the non-zero elements of the matrix are conﬁned to square blocks along the diagonal of the matrix, with all
other elements being zero:
⎛
⎜
⎜
⎜
⎜
A=⎜
⎜
⎜
⎜
⎝

⎞

0
0
..
.

..
.

···⎟
⎟

⎟
⎟
⎟.
···⎟
⎟
⎟
⎠

(6.36)

...

Note, however, that the vertex labels must be chosen correctly to produce this
form. The visual appearance of blocks in the adjacency matrix depends on the
vertices of each component being represented by adjacent rows and columns
and choices of labels that don’t achieve this will produce non-block-diagonal
matrices, even though the choice of labels has no effect on the structure of the
network itself. Thus, depending on the labeling, it may not always be imme142

6.11

A

B

|

C OMPONENTS

Figure 6.12: A network with two components. This undirected network contains
two components of three and four vertices
respectively. There is no path between
pairs of vertices like A and B that lie in different components.

diately obvious from the adjacency matrix that a network has separate components. There do, however, exist computer algorithms, such as the “breadthﬁrst search” algorithm described in Section 10.3, that can take a network with
arbitrary vertex labels and quickly determine its components.
6.11.1

C OMPONENTS IN DIRECTED NETWORKS

When we look at directed networks the deﬁnition of components becomes
more complicated. The situation is worth looking at in some detail, because
it assumes some practical importance in networks like the World Wide Web.
Consider the directed network shown in Fig. 6.13. If we ignore the directed nature of the edges, considering them instead to be undirected, then the network
has two components of four vertices each. In the jargon of graph theory these
are called weakly connected components. Two vertices are in the same weakly
connected component if they are connected by one or more paths through the
network, where paths are allowed to go either way along any edge.
In many practical situations, however, this is not what we care about. For
example, the edges in the World Wide Web are directed hyperlinks that allow
Web users to surf from one page to another, but only in one direction. This
means it is possible to reach one web page from another by surﬁng only if there
is a directed path between them, i.e., a path in which we follow edges only in
the forward direction. It would be useful to deﬁne components for directed
networks based on such directed paths, but this raises some problems. It is
certainly possible for there to be a directed path from vertex A to vertex B but
no path back from B to A. Should we then consider A and B to be connected?
Figure 6.13: Components in a directed
network. This network has two weakly
connected components of four vertices
each, and ﬁve strongly connected components (shaded).

143

M ATHEMATICS OF NETWORKS

Are they in the same component or not?
Clearly there are various answers one could give to these questions. One
possibility is that we deﬁne A and B to be connected if and only if there exists
both a directed path from A to B and a directed path from B to A. A and B
are then said to be strongly connected. We can deﬁne components for a directed
network using this deﬁnition of connection and these are called strongly connected components. Technically, a strongly connected component is a maximal
subset of vertices such that there is a directed path in both directions between
every pair in the subset. The strongly connected components of the network in
Fig. 6.13 are highlighted by the shaded regions. Note that there can be strongly
connected components consisting of just a single vertex and, as with the undirected case, each vertex belongs to exactly one strongly connected component. Note also that every strongly connected component with more than one
vertex must contain at least one cycle. Indeed every vertex in such a component must belong to at least one cycle, since there is by deﬁnition a directed
path from that vertex to every other in the component and a directed path back
again, and the two paths together constitute a cycle. (A corollary of this observation is that acyclic directed graphs have no strongly connected components
with more than one vertex, since if they did they wouldn’t be acyclic.)
Strongly and weakly connected components are not the only useful deﬁnitions of components in a directed network. On the Web it could be useful
to know what pages you can reach by surﬁng from a given starting point, but
you might not care so much whether it’s possible to surf back the other way.
Considerations of this kind lead us to deﬁne the out-component, which is the set
of vertices that are reachable via directed paths starting at a speciﬁed vertex A,
and including A itself.
An out-component has the property that edges connecting it to other vertices (ones not in the out-component) only point inward towards the members of component, and never outward (since if they pointed outward then
the vertices they connected to would by deﬁnition be members of the outcomponent).
Note that the members of an out-component depend on the choice of the
starting vertex. Choose a different starting vertex and the set of reachable vertices may change. Thus an out-component is a property of the network structure and the starting vertex, and not (as with strongly and weakly connected
components) of the network structure alone. This means, among other things,
that a vertex can belong to more than one different out-component. In Fig. 6.14,
for instance, we show the out-components of two different starting vertices,
A and B. Vertices X and Y belong to both.
A few other points are worth noticing. First, it is self-evident that all the
144

6.12

|

I NDEPENDENT PATHS , CONNECTIVITY, AND CUT SETS

X

X
B

A

Y
(a)

B

A

Y
(b)

Figure 6.14: Out-components in a directed network. (a) The out-component of vertex A, which is the subset of vertices reachable by directed paths from A. (b) The outcomponent of vertex B. Vertices X and Y belong to both out-components.

members of the strongly connected component to which a vertex A belongs are
also members of A’s out-component. Furthermore, all vertices that are reachable from A are necessarily also reachable from all the other vertices in the
strongly connected component. Thus it follows that the out-components of all
members of a strongly connected component are identical. It would be reasonable to say that out-components really “belong” not to individual vertices, but
to strongly connected components.
Very similar arguments apply to vertices from which a particular vertex can
be reached. The in-component of a speciﬁed vertex A is the set of all vertices
from which there is a directed path to A, including A itself. In-components
depend on the choice of the speciﬁed vertex, and a vertex can belong to more
than one in-component, but all vertices in the same strongly connected component have the same in-component. Furthermore, the strongly connected component to which a vertex belongs is a subset of its in-component, and indeed
a vertex that is in both the in- and out-components of A is necessarily in the
same strongly connected component as A (since paths exist in both directions)
and hence A’s strongly connected component is equal to the intersection of its
in- and out-components.

6.12

Out
A

In

The
inand
outcomponents of a vertex A in a small directed
network.

I NDEPENDENT PATHS , CONNECTIVITY, AND CUT SETS

A pair of vertices in a network will typically be connected by many paths of
many different lengths. These paths will usually not be independent however. That is, they will share some vertices or edges, as in Fig. 6.10 for instance
(page 140). If we restrict ourselves to independent paths, then the number of
145

M ATHEMATICS OF NETWORKS

C

C
A

B

(a)

A

B

(b)

Figure 6.15: Edge independent paths. (a) There are two edge-independent paths from A to B in this ﬁgure, as denoted
by the arrows, but there is only one vertex-independent path, because all paths must pass through the center vertex C.
(b) The edge-independent paths are not unique; there are two different ways of choosing two independent paths from
A to B in this case.

paths between a given pair of vertices is much smaller. The number of independent paths between vertices gives a simple measure of how strongly the
vertices are connected to one another, and has been the topic of much study in
the graph theory literature.
There are two species of independent path: edge-independent and vertexindependent. Two paths connecting a given pair of vertices are edge-independent
if they share no edges. Two paths are vertex-independent (or node-independent) if
they share no vertices other than the starting and ending vertices. If two paths
are vertex-independent then they are also edge-independent, but the reverse
is not true: it is possible to be edge-independent but not vertex-independent.
For instance, the network shown in Fig. 6.15a has two edge-independent paths
from A to B, as denoted by the arrows, but only one vertex-independent path—
the two edge-independent paths are not vertex-independent because they share
the intermediate vertex C.
Independent paths are also sometimes called disjoint paths, primarily in
the mathematical literature. One also sees the terms edge-disjoint and vertexdisjoint, describing edge and vertex independence.
The edge- or vertex-independent paths between two vertices are not necessarily unique. There may be more than one way of choosing a set of independent paths. For instance Fig. 6.15b shows the same network as Fig. 6.15a, but
with the two paths chosen a different way, so that they cross over as they pass
through the central vertex C.
It takes only a moment’s reﬂection to convince oneself that there can be
only a ﬁnite number of independent paths between any two vertices in a ﬁnite
network. Each path must contain at least one edge and no two paths can share

146

6.12

|

I NDEPENDENT PATHS , CONNECTIVITY, AND CUT SETS

an edge, so the number of independent paths cannot exceed the number of
edges in the network.
The number of independent paths between a pair of vertices is called the
connectivity of the vertices.26 If we wish to be explicit about whether we are
considering edge- or vertex-independence, we refer to edge or vertex connectivity. The vertices A and B in Fig. 6.15 have edge connectivity 2 but vertex
connectivity 1 (since there is only one vertex-independent path between them).
The connectivity of a pair of vertices can be thought of as a measure of
how strongly connected those vertices are. A pair that have only a single independent path between them are perhaps more tenuously connected than a
pair that have many paths. This idea is sometimes exploited in the analysis
of networks, for instance in algorithmic methods for discovering clusters or
communities of strongly linked vertices within networks [122].
Connectivity can also be visualized in terms of “bottlenecks” between vertices. Vertices A and B in Fig. 6.15, for instance, are connected by only one
vertex-independent path because vertex C forms a bottleneck through which
only one path can go. This idea of bottlenecks is formalized by the notion of
cut sets as follows.
Consider an undirected network. (In fact the developments here apply
equally to directed ones, but for simplicity let us stick with the undirected case
for now.) A cut set, or more properly a vertex cut set, is a set of vertices whose
removal will disconnect a speciﬁed pair of vertices. For example, the central
vertex C in Fig. 6.15 forms a cut set of size 1 for the vertices A and B. If it is
removed, there will be no path from A to B. There are also other cut sets for A
and B in this network, although all the others are larger than size 1.
An edge cut set is the equivalent construct for edges—it is a set of edges
whose removal will disconnect a speciﬁed pair of vertices.
A minimum cut set is the smallest cut set that will disconnect a speciﬁed
pair of vertices. In Fig. 6.15 the single vertex C is a minimum vertex cut set for
vertices A and B. A minimum cut set need not be unique. For instance, there
is a variety of minimum vertex cut sets of size two between the vertices A and
B in this network:

26

The word “connectivity” is occasionally also used in the networks literature as a synonym
for “degree.” Given that the word also has the older meaning discussed here, however, this seems
an imprudent thing to do, and we avoid it in this book.

147

M ATHEMATICS OF NETWORKS

W

X

A

B
Y

Z

{W,Y}, {W,Z}, {X,Y}, and {X,Z} are all minimum cut sets for this network.
(There are also many different minimum edge cut sets.) Of course all the minimum cut sets must have the same size.
An important early theorem in graph theory addresses the size of cut sets.
Menger’s theorem states:
If there is no cut set of size less than n between a given pair of vertices,
then there are at least n independent paths between the same vertices.
The theorem applies both to edges and to vertices and was ﬁrst proved by Karl
Menger [216] for the vertex case, although many other proofs have been given
since. A simple one can be found in Ref. [324].
To understand why Menger’s theorem is important, consider the following
argument. If the minimum vertex cut set between two vertices has size n,
Menger’s theorem tells us that there must be at least n vertex-independent
paths between those vertices. That is, the number of vertex-independent paths
is greater than or equal to the size of the minimum cut set. Conversely, if we
know there to be exactly n vertex-independent paths between two vertices,
then, at the very least, we have to remove one vertex from each path in order
to disconnect the two vertices, so the size of the minimum cut set must be
at least n. We thus conclude that the number of vertex-independent paths
must be both greater than or equal to and less than or equal to the size of the
minimum cut set, which can only be true if the two are in fact equal. Thus
Menger’s theorem implies that:
The size of the minimum vertex cut set that disconnects a given pair
of vertices in a network is equal to the vertex connectivity of the same
vertices.
Given that Menger’s theorem also applies for edges, a similar argument can
be used to show that the same result also applies for edge cut sets and edge
connectivity.
The edge version of Menger’s theorem has a further corollary that will be
of some importance to us when we come to study computer algorithms for
analyzing networks. It concerns the idea of maximum ﬂow. Imagine a network
of water pipes in the shape of some network of interest. The edges of the
148

6.12

|

I NDEPENDENT PATHS , CONNECTIVITY, AND CUT SETS

network correspond to the pipes and the vertices to junctions between pipes.
Suppose that there is a maximum rate r, in terms of volume per unit time,
at which water can ﬂow through any pipe. What then is the maximum rate at
which water than can ﬂow through the network from one vertex, A, to another,
B? The answer is that this maximum ﬂow is equal to the number of edgeindependent paths times the pipe capacity r.
We can construct a proof of this result starting from Menger’s theorem.
First, we observe that if there are n independent paths between A and B, each
of which can carry water at rate r, then the network as a whole can carry a ﬂow
of at least nr between A and B, i.e., nr is a lower bound on the maximum ﬂow.
At the same time, by Menger’s theorem, we know that there exists a cut set
of n edges between A and B. If we push the maximum ﬂow (whatever it is)
through the network from A to B and then remove one of the edges in this cut
set, the maximum ﬂow will be reduced by at most r, since that is the maximum
ﬂow an edge can carry. Thus if we remove all n edges in the cut set one by one,
we remove at most nr of ﬂow. But, since the cut set disconnects the vertices
A and B, this removal must stop all of the ﬂow. Hence the total capacity is at
most nr, i.e., nr is an upper bound on the maximum ﬂow.
Thus nr is both an upper and a lower bound on the maximum ﬂow, and
hence the maximum ﬂow must in fact be exactly equal to nr.
This in outline is a proof of the max-ﬂow/min-cut theorem, in the special case
in which each pipe can carry the same ﬁxed ﬂow. The theorem says that the
maximum ﬂow between two vertices is always equal to the size of the minimum cut set times the capacity of a single pipe. The full max-ﬂow/min-cut
theorem applies also to weighted networks in which individual pipes can have
different capacities. We look at this more general case in the following section.
In combination, Menger’s theorem for edges and the max-ﬂow/min-cut
theorem show that for a pair of vertices in an undirected network three quantities are all numerically equal to each other: the edge connectivity of the pair
(i.e., the number of edge-independent paths connecting them), the size of the
minimum edge cut set (i.e., the number of edges that must be removed to disconnect them), and the maximum ﬂow between the vertices if each edge in the
network can carry at most one unit of ﬂow. Although we have stated these
results for the undirected case, nothing in any of the proofs demands an undirected network, and these three quantities are equal for directed networks as
well.
The equality of the maximum ﬂow, the connectivity, and the cut set size has
an important practical consequence. There are simple computer algorithms,
such as the augmenting path algorithm of Section 10.5.1, that can calculate
maximum ﬂows quite quickly (in polynomial time) for any given network, and
149

M ATHEMATICS OF NETWORKS

the equality means that we can use these same algorithms to quickly calculate
a connectivity or the size of a cut set as well. Maximum ﬂow algorithms are
now the standard numerical method for connectivities and cut sets.
6.12.1

M AXIMUM FLOWS AND CUT SETS ON WEIGHTED NETWORKS

As discussed in Section 6.3, networks can have weights on their edges that
indicate that some edges are stronger or more prominent than others. In some
cases these weights can represent capacities of the edges to conduct a ﬂow of
some kind. For example, they might represent maximum trafﬁc throughput
on the roads of a road network or maximum data capacity of Internet lines.
We can ask questions about network ﬂows on such networks similar to those
we asked in the last section, but with the added twist that different edges can
now have different capacities. For example, we can ask what the maximum
possible ﬂow is between a speciﬁed pair of vertices. We can also ask about cut
sets. An edge cut set is deﬁned as before to be a set of edges whose removal
from the network would disconnect the speciﬁed pair of vertices. A minimum
edge cut set is deﬁned as being a cut set such that the sum of the weights on
the edges of the set has the minimum possible value. Note that it is not now
the number of edges that is minimized, but their weight. Nonetheless, this
deﬁnition is a proper generalization of the one we had before—we can think
of the unweighted case as being a special case of the weighted one in which
the weights on all edges are equal, and the sum of the weights in the cut set is
then simply proportional to the number of edges in the set.
Maximum ﬂows and minimum cut sets on weighted networks are related
by the max-ﬂow/min-cut theorem in its most general form:
The maximum ﬂow between a given pair of vertices in a network is
equal to the sum of the weights on the edges of the minimum edge
cut set that separates the same two vertices.
We can prove this theorem using the results of the previous section.27
Consider ﬁrst the special case in which the capacities of all the edges in our
network are integer multiples of some ﬁxed capacity r. We then transform our
network by replacing each edge of capacity kr (with k integer) by k parallel
edges of capacity r each. For instance, if r = 1 we would have something like
this:
27
For a ﬁrst principles proof that is not based on Menger’s theorem see, for instance,
Ahuja et al. [8].

150

6.12

2

1
1

|

I NDEPENDENT PATHS , CONNECTIVITY, AND CUT SETS

1
3

1

2

It is clear that the maximum ﬂow between any two vertices in the transformed network is the same as that between the corresponding vertices in the
original. At the same time the transformed network now has the form of a
simple unweighted network of the type considered in Section 6.12, and hence,
from the results of that section, we can immediately say that the maximum
ﬂow in the network is equal to the size in unit edges of the minimum edge cut
set.
We note also that the minimum cut set on the transformed network must
include either all or none of the parallel edges between any adjacent pair of
vertices; there is no point cutting one such edge unless you cut all of the others
as well—you have to cut all of them to disconnect the vertices. Thus the minimum cut set on the transformed network is also a cut set on the original network. And it is a minimum cut set on the original network, because every cut
set on the original network is also a cut set with the same weight on the transformed network, and if there were any smaller cut set on the original network
then there would be a corresponding one on the transformed network, which,
by hypothesis, there is not.
Thus the maximum ﬂows on the two networks are the same, the minimum
cuts are also the same, and the maximum ﬂow and minimum cut are equal
on the transformed network. It therefore follows that the maximum ﬂow and
minimum cut are equal on the original network.
This demonstrates the theorem for the case where all edges are constrained
to have weights that are integer multiples of r. This constraint can now be
removed, however, by simply allowing r to tend to zero. This makes the units
in which we measure edge weights smaller and smaller, and in the limit r →
0 the edges can have any weight—any weight can be represented as a (very
large) integer multiple of r—and hence the max-ﬂow/min-cut theorem in the
form presented above must be generally true.
Again there exist efﬁcient computer algorithms for calculating maximum
ﬂows on weighted networks, so the max-ﬂow/min-cut theorem allows us to
calculate minimum cut weights efﬁciently also, and this is now the standard
way of performing such calculations.28
28

Another interesting and slightly surprising computational use of the max-ﬂow/min-cut the-

151

M ATHEMATICS OF NETWORKS

6.13

T HE GRAPH L APLACIAN

Section 6.2 introduced an important quantity, the adjacency matrix, which captures the entire structure of a network and whose matrix properties can tell us
a variety of useful things about networks. There is another matrix, closely related to the adjacency matrix but differing in some important respects, that can
also tell us much about network structure. This is the graph Laplacian.
6.13.1

D IFFUSION

Diffusion is, among other things, the process by which gas moves from regions
of high density to regions of low, driven by the relative pressure (or partial
pressure) of the different regions. One can also consider diffusion processes on
networks, and such processes are sometimes used as a simple model of spread
across a network, such as the spread of an idea or the spread of a disease.
Suppose we have some commodity or substance of some kind on the vertices
of a network and there is an amount ψi of it at vertex i. And suppose that the
commodity moves along the edges, ﬂowing from one vertex j to an adjacent
one i at a rate C (ψj − ψi ) where C is a constant called the diffusion constant.
That is, in a small interval of time the amount of ﬂuid ﬂowing from j to i is
C (ψj − ψi ) dt. Then the rate at which ψi is changing is given by
dψi
= C ∑ Aij (ψj − ψi ).
dt
j

(6.37)

The adjacency matrix in this expression insures that the only terms appearing in the sum are those that correspond to vertex pairs that are actually connected by an edge. Equation (6.37) works equally well for both undirected and
directed networks, but let us focus here on undirected ones.29 We will also
consider our networks to be simple (i.e., to have at most a single edge between
any pair of vertices and no self-edges).
orem is in the polynomial-time algorithm for ﬁnding ground states of the thermal random-ﬁeld
Ising model [257], an interesting cross-fertilization between network theory and physics: it is relatively common for physics ideas to ﬁnd application in network theory, but the reverse has been
considerably rarer.
29
In fact, the graph Laplacian matrix for undirected networks deﬁned in this section does not
have a clean generalization for directed networks, although several possible candidates have been
suggested. Most of the results in the remaining sections of this chapter do not generalize easily to
the directed case.

152

6.13

|

T HE GRAPH L APLACIAN

Splitting the two terms in Eq. (6.37), we can write
dψi
= C ∑ Aij ψj − Cψi ∑ Aij = C ∑ Aij ψj − Cψi k i
dt
j
j
j

= C ∑( Aij − δij k i )ψj ,

(6.38)

j

where k i is the degree of vertex i as usual and we have made use of the result
k i = ∑ j Aij —see Eq. (6.19). (And δij is the Kronecker delta, which is 1 if i = j
and 0 otherwise.)
Equation (6.38) can be written in matrix form as
dψ
= C (A − D)ψ,
dt

(6.39)

where ψ is the vector whose components are numbers ψi , A is the adjacency
matrix, and D is the diagonal matrix with the vertex degrees along its diagonal:
⎛
⎞
k1 0 0 · · ·
⎜ 0 k2 0 · · ·⎟
⎜
⎟
D = ⎜ 0 0 k · · ·⎟ .
(6.40)
3
⎝
⎠
.. .. .. . .
.
. . .
It is common to deﬁne the new matrix
L = D − A,

(6.41)

dψ
+ CLψ = 0,
dt

(6.42)

so that Eq. (6.38) takes the form

which has the same form as the ordinary diffusion equation for a gas, except
that the Laplacian operator ∇2 that appears in that equation has been replaced
by the matrix L. The matrix L is for this reason called the graph Laplacian,
although its importance stretches much further than just diffusion processes.
The graph Laplacian, as we will see, turns up in a variety of different places,
including random walks on networks, resistor networks, graph partitioning,
and network connectivity.30
30
In fact the graph Laplacian doesn’t occupy quite the same position as ∇2 does in the normal
diffusion equation—there is a plus sign in Eq. (6.42) where a minus sign appears in the normal
equation. We could easily get rid of this discrepancy by reversing the sign of the deﬁnition in
Eq. (6.41), but the deﬁnition as given has become the standard one and so for consistency we will
stick with it.

153

M ATHEMATICS OF NETWORKS

Written out in full, the elements of the Laplacian matrix are
⎧
⎨ ki
Lij = −1
⎩
0

if i = j,
if i = j and there is an edge (i, j),
otherwise,

(6.43)

so it has the degrees of the vertices down its diagonal and a −1 element for
every edge. Alternatively we can write
Lij = δij k i − Aij .

(6.44)

We can solve the diffusion equation (6.42) by writing the vector ψ as a linear
combination of the eigenvectors vi of the Laplacian thus:
ψ ( t ) = ∑ ai ( t ) vi ,

(6.45)

i

with the coefﬁcients ai (t) varying over time. Substituting this form into (6.42)
and making use of Lvi = λi vi , where λi is the eigenvalue corresponding to the
eigenvector vi , we get
dai
(6.46)
∑ dt + Cλi ai vi = 0.
i
But the eigenvectors of a symmetric matrix such as the Laplacian are orthogonal, and so, taking the dot product of this equation with any eigenvector v j ,
we get
dai
+ Cλi ai = 0,
(6.47)
dt
for all i, which has the solution
ai (t) = ai (0) e−Cλi t .

(6.48)

Given an initial condition for the system, as speciﬁed by the quantities ai (0),
therefore, we can solve for the state at any later time, provided we know the
eigenvalues and eigenvectors of the graph Laplacian.
6.13.2

E IGENVALUES OF THE GRAPH L APLACIAN

This is the ﬁrst of many instances in which the eigenvalues of the Laplacian
will arise, so it is worth spending a little time understanding their properties.
The Laplacian is a symmetric matrix, and so has real eigenvalues. However, we
can say more than this about them. In fact, as we now show, all the eigenvalues
of the Laplacian are also non-negative.
154

6.13

|

T HE GRAPH L APLACIAN

Consider an undirected network with n vertices and m edges and let us
arbitrarily designate one end of each edge to be end 1 and the other to be end 2.
It doesn’t matter which end is which, only that they have different labels.
Now let us deﬁne an m × n matrix B with elements as follows:
⎧
if end 1 of edge i is attached to vertex j,
⎨ +1
Bij = −1
(6.49)
if end 2 of edge i is attached to vertex j,
⎩
0
otherwise.
Thus each row of the matrix has exactly one +1 and one −1 element.
The matrix B is called the edge incidence matrix. It bears some relation to,
but is distinct from, the incidence matrix for a bipartite graph deﬁned in Section 6.6.
Now consider the sum ∑k Bki Bkj . If i = j, then the only non-zero terms
in the sum will occur if both Bik and Bjk are non-zero, i.e., if edge k connects
vertices i and j, in which case the product will have value −1. For a simple
network, there is at most one edge between any pair of vertices and hence at
most one such non-zero term, so the value of the entire sum will be −1 if there
is an edge between i and j and zero otherwise.
2
, which has a term +1 for every edge connected
If i = j then the sum is ∑k Bki
to vertex i, so the whole sum is just equal to the degree k i of vertex i.
Thus the sum ∑k Bki Bkj is precisely equal to an element of the Laplacian
∑k Bki Bkj = Lij —the diagonal terms Lii are equal to the degrees k i and the offdiagonal terms Lij are −1 if there is an edge (i, j) and zero otherwise. (See
Eq. (6.43).) In matrix form we can write
L = B T B,

(6.50)

where B T is the transpose of B.
Now let vi be an eigenvector of L with eigenvalue λi . Then
viT B T Bvi = viT Lvi = λi viT vi = λi ,

(6.51)

where we assume that the eigenvector vi is normalized so that its inner product
with itself is 1.
Thus any eigenvalue λi of the Laplacian is equal to (viT B T )(Bvi ). But this
quantity is itself just the inner product of a real vector (Bvi ) with itself. In
other words, it is the sum of the squares of the (real) elements of that vector
and hence it cannot be negative. The smallest value it can have is zero:
λi ≥ 0

(6.52)

for all i.
155

M ATHEMATICS OF NETWORKS

This is an important physical property of the Laplacian. It means, for instance, that the solution, Eq. (6.48), of the diffusion equation on any network
contains only decaying exponentials or constants and not growing exponentials, so that the solution tends to an equilibrium value as t → ∞, rather than
diverging.31
While the eigenvalues of the Laplacian cannot be negative, they can be zero,
and in fact the Laplacian always has at least one zero eigenvalue. Consider the
vector 1 = (1, 1, 1, . . .). If we multiply this vector by the Laplacian, the ith
element of the result is given by

∑ Lij × 1 = ∑(δij ki − Aij ) = ki − ∑ Aij = ki − ki
j

j

j

= 0,

(6.53)

where we have made use of Eqs. (6.19) and (6.44). In vector notation, L · 1 =
0. Thus the vector 1 is always an eigenvector of the graph Laplacian with
eigenvalue zero.32 Since there are no negative eigenvalues, this is the lowest
of the eigenvalues of the Laplacian. Following convention, we number the n
eigenvalues of the Laplacian in ascending order: λ1 ≤ λ2 ≤ . . . ≤ λn . So we
always have λ1 = 0.
Note that the presence of a zero eigenvalue implies that the Laplacian has
no inverse: the determinant of the matrix is the product of its eigenvalues, and
hence is always zero for the Laplacian, so that the matrix is singular.
6.13.3

See the discussion of block
diagonal matrices in Section 6.11.

C OMPONENTS AND THE ALGEBRAIC CONNECTIVITY

Suppose we have a network that is divided up into c different components of
sizes n1 , n2 , . . . , nc . To make the notation simple let us number the vertices of
the network so that the ﬁrst n1 vertices are those of the ﬁrst component, the
next n2 are those of the second component, and so forth. With this choice the
Laplacian of the network will be block diagonal, looking something like this:
31
This is clearly the right answer from a physical point of view, since the ﬂuid in our diffusion
process is conserved—there is a ﬁxed, ﬁnite amount of it—so it is impossible for the amount on
any vertex to become inﬁnite.
32
It is not a properly normalized eigenvector. The properly normalized vector would be
√
(1, 1, 1, . . .)/ n.

156

6.14

R ANDOM WALKS

⎞

⎛
⎜
⎜
⎜
⎜
L=⎜
⎜
⎜
⎜
⎝

|

0
0
..
.

..
.

···⎟
⎟

⎟
⎟
⎟.
···⎟
⎟
⎟
⎠

..

(6.54)

.

What is more, each block in the Laplacian is, by deﬁnition, the Laplacian of the
corresponding component: it has the degrees of the vertices in that component
along its diagonal and −1 in each position corresponding to an edge within
that component. Thus we can immediately write down c different vectors that
are eigenvectors of L with eigenvalue zero: the vectors that have ones in all
positions corresponding to vertices in a single component and zero elsewhere.
For instance, the vector
v = ( 1, 1, 1, . . . , 0, 0, 0, . . . ),
     
zeros
n1 ones

(6.55)

is an eigenvector with eigenvalue zero.
Thus in a network with c components there are always at least c eigenvectors with eigenvalue zero. In fact, it can be shown that the number of zero
eigenvalues is always exactly equal to the number of components [324]. (Note
that the vector 1 of all ones is just equal to the sum of the c other eigenvectors,
so it is not an independent eigenvector.) An important corollary of this result
is that the second eigenvalue of the graph Laplacian λ2 is non-zero if and only
if the network is connected, i.e., consists of a single component. The second
eigenvalue of the Laplacian is called the algebraic connectivity of the network.33
It will come up again in Section 11.5 when we look at the technique known as
spectral partitioning.

6.14

R ANDOM WALKS

Another context in which the graph Laplacian arises is in the study of random
walks on networks. A random walk is a path across a network created by taking
repeated random steps. Starting at some speciﬁed initial vertex, at each step
of the walk we choose uniformly at random between the edges attached to
the current vertex, move along the chosen edge to the vertex at its other end,
and repeat. Random walks are normally allowed to go along edges more than
33

Occasionally λ2 is also called the spectral gap.

157

M ATHEMATICS OF NETWORKS

once, visit vertices more than once, or retrace their steps along an edge just
traversed. Self-avoiding walks, which do none of these things, are also studied
sometimes, but we will not discuss them here.
Random walks arise, for instance, in the random walk sampling method for
social networks discussed in Section 3.7 and in the random walk betweenness
measure of Section 7.7.
Consider a random walk that starts at a speciﬁed vertex and takes t random
steps. Let pi (t) be the probability that the walk is at vertex i at time t. If the
walk is at vertex j at time t − 1, the probability of taking a step along any
particular one of the k j edges attached to j is 1/k j , so on an undirected network
pi (t) is given by
Aij
p j ( t − 1),
(6.56)
pi ( t ) = ∑
kj
j
or p(t) = AD−1 p(t − 1) in matrix form where p is the vector with elements pi
and, as before, D is the diagonal matrix with the degrees of the vertices down
its diagonal.
There are a couple of other useful ways to write this relation. One is to
√
deﬁne D1/2 to be the matrix with the square roots k i of the degrees down the
diagonal, so that
D−1/2 p(t) = D−1/2 AD−1/2 D−1/2 p(t − 1) .

(6.57)

This form is convenient in some situations because the matrix D−1/2 AD−1/2
is a symmetric one. This
√ matrix is called the reduced adjacency matrix and has
elements equal to 1/ k i k j if there is an edge between i and j and zero otherwise. Equation (6.57) tells us that the vector D−1/2 p gets multiplied by one
factor of the reduced adjacency matrix at each step of the random walk, and
so the problem of understanding the random walk can be reduced to one of
understanding the effects of repeated multiplication by a simple symmetric
matrix.
For our purposes, however, we take a different approach. In the limit as
t → ∞ the probability distribution over vertices is given by setting t = ∞:
pi (∞) = ∑ j Aij p j (∞)/k j , or in matrix form:
p = AD−1 p.

(6.58)

Rearranging, this can also be written as

(I − AD−1 )p = (D − A)D−1 p = LD−1 p = 0.
Thus D−1 p is an eigenvector of the Laplacian with eigenvalue 0.
158

(6.59)

6.14

|

R ANDOM WALKS

On a connected network, for instance—one with only a single component—
we know (Section 6.13.3) that there is only a single eigenvector with eigenvalue
zero, the vector whose components are all equal. Thus, D−1 p = a1, where a
is a constant and 1 is the vector whose components are all ones. Equivalently
p = aD1, so that pi = ak i . Then on a connected network the probability that a
random walk will be found at vertex i in the limit of long time is simply proportional to the degree of that vertex. If we choose the value of a to normalize
pi properly, this gives
ki
ki
,
(6.60)
=
pi =
2m
∑j k j
where we have used Eq. (6.20).
The simple way to understand this result is that vertices with high degree are more likely to be visited by the random walk because there are more
ways of reaching them. We used Eq. (6.60) in Section 3.7 in our analysis of the
random-walk sampling method for social networks.
An important question about random walks concerns the ﬁrst passage time.
The ﬁrst passage time for a random walk from a vertex u to another vertex v
is the number of steps before a walk starting at u ﬁrst reaches v. Since the
walk is random, the ﬁrst passage time between two vertices is not ﬁxed; if we
repeat the random walk process more than once it can take different values on
different occasions. But we can ask for example what the mean ﬁrst passage
time is.
To answer this question, we modify our random walk slightly to make it
into an absorbing random walk. An absorbing walk is one that has one or more
absorbing states, meaning vertices that the walk can move to, but not leave
again. We will consider just the simplest case of a single absorbing vertex v.
Any walk that arrives at vertex v must stay there ever afterwards, but on the
rest of the network the walk is just a normal random walk. We can answer
questions about the ﬁrst passage time by considering the probability pv (t) that
a walk is at vertex v after a given amount of time, since this is also the probability that the walk has a ﬁrst passage time to v that is less than or equal to t. And
the probability that a walk has ﬁrst passage time exactly t is pv (t) − pv (t − 1),
which means that the mean ﬁrst passage time τ is34
∞

τ = ∑ t p v ( t ) − p v ( t − 1) .

(6.61)

t =0

34
One might think that this equation could be simpliﬁed by reordering the terms so that most
of them cancel out, but this is not allowed. The sum viewed as individual terms is not absolutely
convergent and hence does not have a unique limit. Only the complete sum over t as written is
meaningful and a reordering of the terms will give the wrong answer.

159

M ATHEMATICS OF NETWORKS

To calculate the probability pv (t) we could apply Eq. (6.56) (or (6.58)) repeatedly to ﬁnd p(t) and substitute the result into Eq. (6.61). Note, however,
that since the random walk can move to vertex v but not away from it, the adjacency matrix A has elements Aiv = 0 for all i but Avi can still be non-zero. Thus
in general A is asymmetric. Although we can work with such an asymmetric
matrix, the computations are harder than for symmetric matrices and in this
case there is no need. Instead we can use the following trick.
Consider Eq. (6.56) for any i = v:
pi ( t ) = ∑
j

Aij
Aij
p j ( t − 1) = ∑
p j ( t − 1),
kj
kj
j=v

(6.62)

where the second equality applies since Aiv = 0 and hence the terms with j = v
don’t contribute to the sum. But if i = v then there are no terms in Avj in the
sum either. This allows us to write the equation in the matrix form
p (t) = A D−1 p (t − 1),

(6.63)

where p is p with the vth element removed and A and D are A and D with
their vth row and column removed. Note that A and D are symmetric matrices, since the rows and columns containing the asymmetric elements have
been removed. Iterating Eq. (6.63), we now get
t

p (t) = A D−1 p (0).

(6.64)

Since we have removed the element pv from the vector p, we cannot calculate its value directly using this equation, but we can calculate it indirectly by
noting that ∑i pi (t) = 1 at all times. Thus
p v ( t ) = 1 − ∑ p i ( t ) = 1 − 1 · p  ( t ),

(6.65)

i=v

where again 1 = (1, 1, 1, . . .). Using Eqs. (6.61), (6.64), and (6.65) we then have
a mean ﬁrst passage time of
∞

τ = ∑ t 1 · p (t − 1) − p (t) = 1 · I − A D−1

−1

t =0

· p  (0),

(6.66)

where I is the identity matrix and we have made use of the result that
∞

∑ t ( M t −1 − M t ) = [ I − M ] −1 ,

t =0

for any matrix M (assuming the sum actually converges).
160

(6.67)

6.14

|

R ANDOM WALKS

We can simplify Eq. (6.66) by writing

so that

[I − A D−1 ]−1 = D [D − A ]−1 = D L−1 ,

(6.68)

τ = 1 · D L−1 · p (0),

(6.69)

where the symmetric matrix L is the graph Laplacian with the vth row and
column removed. L is called the vth reduced Laplacian. Note that, even though,
as we noted in Section 6.13.2, the Laplacian has no ﬁnite inverse, the reduced
Laplacian can have an inverse. The eigenvector (1, 1, 1, . . .) whose zero eigenvalue causes the determinant of the Laplacian to be zero is, in general, not an
eigenvector of the reduced matrix.
For convenience, we now introduce the symmetric matrix Λ(v) , which is
equal to L−1 with a vth row and column reintroduced having elements all
zero:
⎧
0
if i = v or j = v,
⎪
⎪
⎪
−1
⎪
⎪
L
if i < v and j < v,
⎪
ij
⎨
−
1
(v)
L
if i > v and j < v,
Λij =
(6.70)
i −1,j
⎪
⎪
−
1
⎪ L
if
i
<
v
and
j
>
v,
⎪
i,j−1
⎪
⎪
⎩ L−1
if i > v and j > v.
i −1,j−1

Then we observe that for a walk starting at vertex u, the initial probability
distribution p (0) has all elements 0 except the one corresponding to vertex u,
which is 1. Thus, combining Eqs. (6.69) and (6.70), the mean ﬁrst passage time
for a random walk from u to v is given by
(v)

τ = ∑ k i Λiu ,

(6.71)

i

where we have made use of the fact that the non-zero elements of the diagonal
matrix D are the degrees k i of the vertices. Thus if we can calculate the inverse
of the vth reduced Laplacian then a sum over the elements in the uth column
immediately gives us the mean ﬁrst passage time for a random walk from u
to v. And sums over the other columns give us the ﬁrst passage times from
other starting vertices to the same target vertex v—we get n ﬁrst passage times
from a single matrix inversion.
6.14.1

R ESISTOR NETWORKS

There are interesting mathematical connections between random walks on networks and the calculation of current ﬂows in networks of resistors. Suppose
161

M ATHEMATICS OF NETWORKS

s

t

I

Figure 6.16: A resistor network with applied voltage. A network in which the edges
are resistors and the vertices are electrical junctions between them, with a voltage applied between vertices s and t so as to generate a total current I.

we have a network in which the edges are identical resistors of resistance R and
the vertices are junctions between resistors, as shown in Fig. 6.16, and suppose
we apply a voltage between two vertices s and t such that a current I ﬂows
from s to t through the network. What then is the current ﬂow through any
given resistor in the network?
The currents in the network obey Kirchhoff’s current law, which is essentially a statement that electricity is conserved, so that the net current ﬂowing in
or out of any vertex is zero. Let Vi be the voltage at vertex i, measured relative
to any convenient reference potential. Then Kirchhoff’s law says that

∑ Aij
j

Vj − Vi
+ Ii = 0,
R

(6.72)

where Ii represents any current injected into vertex i by an external current
source. In our case this external current is non-zero only for the two vertices s
and t connected to the external voltage:
⎧
for i = s,
⎨ +I
Ii = − I
(6.73)
for i = t,
⎩
0
otherwise.
(In theory there’s no reason why one could not impose more complex current source arrangements by applying additional voltages to the network and
making more elements Ii non-zero, but let us stick to our simple case in this
discussion.)
162

6.14

|

R ANDOM WALKS

Noting that ∑ j Aij = k i , Eq. (6.72) can also be written as k i Vi − ∑ j Aij Vj =
RIi or
(6.74)
∑(δij ki − Aij )Vj = RIi ,
j

which in matrix form is
LV = RI,

(6.75)

where L = D − A is once again the graph Laplacian.
As discussed in Section 6.13.2, the Laplacian has no inverse because it always has at least one eigenvalue that is zero, so we cannot simply invert
Eq. (6.75) to get the voltage vector V. We can, however, solve for V by once
again making use of the reduced Laplacian of Section 6.14.
The reason why we cannot invert Eq. (6.75) is that the equation does not in
fact ﬁx the absolute value of the voltages Vi . We can add any multiple of the
vector 1 = (1, 1, 1, . . .) to the solution of this equation and get another solution,
since 1 is an eigenvector of L with eigenvalue zero:
L(V + c1) = LV + L1 = LV = RI.

(6.76)

In physical terms these different solutions correspond to different choices of
the reference potential against which we measure our voltages. The actual
currents ﬂowing around the system are identical no matter what reference potential we choose. If we ﬁx our reference potential at a particular value, then
we will ﬁx the solution for the voltages as well, and our equation for V will
become solvable.
Let us choose, arbitrarily, to set our reference potential equal to the potential at the target vertex t where the current exits the network. (We could choose
any other vertex just as well, but this choice is the simplest.) That is, the voltage at this vertex is chosen to be zero and all others are measured in terms of
their potential difference from vertex t. But now we can remove the element
Vt = 0 from V in Eq. (6.75), along with the corresponding column t in the
Laplacian, without affecting the result, since they contribute zero to the matrix
multiplication anyway. And we can also remove row t from both sides of the
equation, since we already know the value of Vt , so there’s no need to calculate
it. That leaves us with a modiﬁed equation L V = RI , with L being the tth
reduced Laplacian, which in general has a well-deﬁned inverse. Then
V = RL

−1 

I,

(6.77)

and once we have the voltages we can calculate in a straightforward manner
any other quantity of interest, such as the current along a given edge in the
network.
163

M ATHEMATICS OF NETWORKS

Note that, for the simple case discussed here in which current is injected
into the network at just one vertex and removed at another, I has only one
non-zero element. (The other one, It , has been removed.) Thus the vector V
on the left-hand side of Eq. (6.77) is simply proportional to the column of the
inverse reduced Laplacian corresponding to vertex s. To use the notation of
Section 6.14, if Λ(t) is the inverse of the tth reduced Laplacian with the tth row
and column reintroduced having elements all zero (see Eq. (6.70)), then
(t)

Vi = RIΛis .

(6.78)

P ROBLEMS
6.1

Consider the following two networks:
1
1

2

2

3

4

5

3

1

4

2

3

4

5

(a)

(b)

Network (a) is a directed network. Network (b) is undirected but bipartite. Write down:
a) the adjacency matrix of network (a);
b) the cocitation matrix of network (a);
c) the incidence matrix of network (b);
d) the projection matrix (Eq. (6.17)) for the projection of network (b) onto its black
vertices.
6.2 Let A be the adjacency matrix of an undirected network and 1 be the column vector
whose elements are all 1. In terms of these quantities write expressions for:
a) the vector k whose elements are the degrees k i of the vertices;
b) the number m of edges in the network;
c) the matrix N whose element Nij is equal to the number of common neighbors of
vertices i and j;

164

P ROBLEMS

d) the total number of triangles in the network, where a triangle means three vertices,
each connected by edges to both of the others.
6.3 Consider an acyclic directed network of n vertices, labeled i = 1 . . . n, and suppose
that the labels are assigned in the manner of Fig. 6.3 on page 119, such that all edges
run from vertices with higher labels to vertices with lower.
a) Find an expression for the total number of edges ingoing to vertices 1 . . . r and
another for the total number of edges outgoing from vertices 1 . . . r, in terms of
out
the in- and out-degrees kin
of the vertices.
i and k i
b) Hence ﬁnd an expression for the total number of edges running to vertices 1 . . . r
from vertices r + 1 . . . n.
c) Show that in any acyclic network the in- and out-degrees must satisfy
r −1 

out
≤ ∑ kin
kout
,
r
i − ki
i =1

for all r.
6.4 Consider a bipartite network, with its two types of vertex, and suppose that there
are n1 vertices of type 1 and n2 vertices of type 2. Show that the mean degrees c1 and c2
of the two types are related by
n1
c1 .
c2 =
n2
6.5 Using Kuratowski’s theorem, prove that this network is not planar:

6.6 Consider a connected planar network with n vertices and m edges. Let f be the
number of “faces” of the network, i.e., areas bounded by edges when the network is
drawn in planar form. The “outside” of the network, the area extending to inﬁnity on
all sides, is also considered a face. The network can have multiedges and self-edges:

165

M ATHEMATICS OF NETWORKS

Face
Fa
c

e

Face

Face

Face

a) Write down the values of n, m, and f for a network with a single vertex and no
edges.
b) How do n, m, and f change when we add a single vertex to the network along
with a single edge attaching it to another vertex?
c) How do n, m, and f change when we add a single edge between two extant vertices (or a self-edge attached to just one vertex), in such a way as to maintain the
planarity of the network?
d) Hence by induction prove a general relation between n, m, and f for all connected
planar networks.
e) Now suppose that our network is simple (i.e., it contains no multiedges or selfedges). Show that the mean degree c of such a network is strictly less than six.
6.7 Consider the set of all paths from vertex s to vertex t on an undirected graph with
adjacency matrix A. Let us give each path a weight equal to αr , where r is the length of
the path.
a) Show that the sum of the weights of all the paths from s to t is given by Zst which
is the st element of the matrix Z = (I − αA)−1 , where I is the identity matrix.
b) What condition must α satisfy for the sum to converge?
c) Hence, or otherwise, show that the length st of a geodesic path from s to t, if there
is one, is
∂ log Zst
.
st = lim
α→0 ∂ log α
6.8 What is the difference between a 2-component and a 2-core? Draw a small network
that has one 2-core but two 2-components.
6.9 In Section 5.3.1, we gave one possible deﬁnition of the trophic level xi of a species
in a (directed) food web as the mean of the trophic levels of the species’ prey, plus one.
a) Show that xi , when deﬁned in this way, is the ith element of the vector

 −1
x = D − A D · 1,
where D is the diagonal matrix of in-degrees, A is the (asymmetric) adjacency
matrix, and 1 = (1, 1, 1, . . .).

166

P ROBLEMS

b) This expression does not work for autotrophs—species with no prey—because the
corresponding vector element diverges. Such species are usually given a trophic
level of one. Suggest a modiﬁcation of the calculation that will correctly assign
trophic levels to these species, and hence to all species.
6.10

What is the size k of the minimum vertex cut set between s and t in this network?

s

t

Prove your result by ﬁnding one possible cut set of size k and one possible set of k
independent paths between s and t. Why do these two actions constitute a proof that
the minimum cut set has size k?

167

C HAPTER 7

M EASURES AND METRICS
An introduction to some standard measures and metrics
for quantifying network structure, many of which were
introduced ﬁrst in the study of social networks, although
they are now in wide use in many other areas

I

F WE KNOW the structure of a network we can calculate from it a variety of

useful quantities or measures that capture particular features of the network topology. In this chapter we look at some of these measures. Many of the
most important ideas in this area come from the social sciences, from the discipline of social network analysis, which was developed to aid our understanding of social network data such as those described in Chapter 3, and much
of the language used to describe these ideas reﬂects their sociological origin.
Nonetheless, the methods described are now widely used in areas outside the
social sciences, including computer science, physics, and biology, and form an
important part of the basic network toolbox.1
In the chapter following this one we will apply some of the measures developed here to the analysis of network data from a variety of ﬁelds and in the
process reveal some intriguing features and patterns that will play an important role in later developments.

7.1

D EGREE CENTRALITY

A large volume of research on networks has been devoted to the concept of
centrality. This research addresses the question, “Which are the most important
or central vertices in a network?” There are of course many possible deﬁnitions
1
For those interested in traditional social network analysis, introductions can be found in the
books by Scott [293] and by Wasserman and Faust [320].

168

7.2

|

E IGENVECTOR CENTRALITY

of importance, and correspondingly many centrality measures for networks.
In this and the following several sections we describe some of the most widely
used such measures.
Perhaps the simplest centrality measure in a network is just the degree of a
vertex, the number of edges connected to it (see Section 6.9). Degree is sometimes called degree centrality in the social networks literature, to emphasize its
use as a centrality measure. In directed networks, vertices have both an indegree and an out-degree, and both may be useful as measures of centrality in
the appropriate circumstances.
Although degree centrality is a simple centrality measure, it can be very
illuminating. In a social network, for instance, it seems reasonable to suppose
that individuals who have connections to many others might have more inﬂuence, more access to information, or more prestige than those who have fewer
connections. A non-social network example is the use of citation counts in
the evaluation of scientiﬁc papers. The number of citations a paper receives
from other papers, which is simply its in-degree in the citation network, gives
a crude measure of whether the paper has been inﬂuential or not and is widely
used as a metric for judging the impact of scientiﬁc research.

7.2

E IGENVECTOR CENTRALITY

A natural extension of the simple degree centrality is eigenvector centrality. We
can think of degree centrality as awarding one “centrality point” for every network neighbor a vertex has. But not all neighbors are equivalent. In many
circumstances a vertex’s importance in a network is increased by having connections to other vertices that are themselves important. This is the concept behind eigenvector centrality. Instead of awarding vertices just one point for each
neighbor, eigenvector centrality gives each vertex a score proportional to the
sum of the scores of its neighbors. Here’s how it works.
Let us make some initial guess about the centrality xi of each vertex i. For
instance, we could start off by setting xi = 1 for all i. Obviously this is not
a useful measure of centrality, but we can use it to calculate a better one xi ,
which we deﬁne to be the sum of the centralities of i’s neighbors thus:
xi = ∑ Aij x j ,

(7.1)

j

where Aij is an element of the adjacency matrix. We can also write this expression in matrix notation as x = Ax, where x is the vector with elements xi .
Repeating this process to make better estimates, we have after t steps a vector

169

M EASURES AND METRICS

of centralities x(t) given by
x ( t ) = A t x (0).

(7.2)

Now let us write x(0) as a linear combination of the eigenvectors vi of the
adjacency matrix thus:
(7.3)
x (0) = ∑ c i v i ,
i

for some appropriate choice of constants ci . Then
x ( t ) = A ∑ ci vi = ∑
t

i



ci κit vi = κ1t

i

κi
∑ ci κ1
i

t
vi ,

(7.4)

where the κi are the eigenvalues of A, and κ1 is the largest of them. Since
κi /κ1 < 1 for all i = 1, all terms in the sum other than the ﬁrst decay exponentially as t becomes large, and hence in the limit t → ∞ we get x(t) → c1 κ1t v1 .
In other words, the limiting vector of centralities is simply proportional to the
leading eigenvector of the adjacency matrix. Equivalently we could say that
the centrality x satisﬁes
(7.5)
Ax = κ1 x.
This then is the eigenvector centrality, ﬁrst proposed by Bonacich [49] in 1987.
As promised the centrality xi of vertex i is proportional to the sum of the centralities of i’s neighbors:
(7.6)
xi = κ1−1 ∑ Aij x j ,
j

which gives the eigenvector centrality the nice property that it can be large
either because a vertex has many neighbors or because it has important neighbors (or both). An individual in a social network, for instance, can be important, by this measure, because he or she knows lots of people (even though
those people may not be important themselves) or knows a few people in high
places.
Note also that the eigenvector centralities of all vertices are non-negative.
To see this, consider what happens if the initial vector x(0) happens to have
only non-negative elements. Since all elements of the adjacency matrix are also
non-negative, multiplication by A can never introduce any negative elements
to the vector and x(t) in Eq. (7.2) must have all elements non-negative.2
2
Technically, there could be more than one eigenvector with eigenvalue κ1 , only one of which
need have all elements non-negative. It turns out, however, that this cannot happen: the adjacency
matrix has only one eigenvector of eigenvalue κ1 . See footnote 2 on page 346 for a proof.

170

7.2

|

E IGENVECTOR CENTRALITY

Equation (7.5) does not ﬁx the normalization of the eigenvector centrality,
although typically this doesn’t matter because we care only about which vertices have high or low centrality and not about absolute values. If we wish,
however, we can normalize the centralities by, for instance, requiring that they
sum to n (which insures that average centrality stays constant as the network
gets larger).
In theory eigenvector centrality can be calculated for either unB
directed or directed networks. It works best however for the undirected case. In the directed case other complications arise. First
of all, a directed network has an adjacency matrix that is, in genA
eral, asymmetric (see Section 6.4). This means that it has two sets of
eigenvectors, the left eigenvectors and the right eigenvectors, and
hence two leading eigenvectors. So which of the two should we use
to deﬁne the centrality? In most cases the correct answer is to use
the right eigenvector. The reason is that centrality in directed networks is usually bestowed by other vertices pointing towards you,
rather than by you pointing to others. On the World Wide Web, for
Figure 7.1: A portion of a directed netinstance, the number and stature of web pages that point to your
work. Vertex A in this network has
page can give a reasonable indication of how important or useful
only outgoing edges and hence will
your page is. On the other hand, the fact that your page might point
have eigenvector centrality zero. Verto other important pages is neither here nor there. Anyone can set
tex B has outgoing edges and one inup a page that points to a thousand others, but that does not make
going edge, but the ingoing one originates at A, and hence vertex B will also
the page important.3 Similar considerations apply also to citation
have centrality zero.
networks and other directed networks. Thus the correct deﬁnition
of eigenvector centrality for a vertex i in a directed network makes
it proportional to the centralities of the vertices that point to i thus:
xi = κ1−1 ∑ Aij x j ,

(7.7)

j

which gives Ax = κ1 x in matrix notation, where x is the right leading eigenvector.
However, there are still problems with eigenvector centrality on directed
networks. Consider Fig. 7.1. Vertex A in this ﬁgure is connected to the rest
of the network, but has only outgoing edges and no incoming ones. Such a
vertex will always have centrality zero because there are no terms in the sum
3

This is not entirely true, as we will see in Section 7.5. Web pages that point to many others are
often directories of one sort or another and can be useful as starting points for web surﬁng. This is
a different kind of importance, however, from that highlighted by the eigenvector centrality and a
different, complementary centrality measure is needed to quantify it.

171

M EASURES AND METRICS

in Eq. (7.7). This might not seem to be a problem: perhaps a vertex that no
one points to should have centrality zero. But then consider vertex B, which
has one ingoing edge, but that edge originates at vertex A, and hence B also
has centrality zero, because the one term in its sum in Eq. (7.7) is zero. Taking
this argument further, we see that a vertex may be pointed to by others that
themselves are pointed to by many more, and so on through many generations,
but if the progression ends up at a vertex or vertices that have in-degree zero,
it is all for nothing—the ﬁnal value of the centrality will still be zero.
In mathematical terms, only vertices that are in a strongly connected component of two or more vertices, or the out-component of such a component,
can have non-zero eigenvector centrality.4 In many cases, however, it is appropriate for vertices with high in-degree to have high centrality even if they
are not in a strongly-connected component or its out-component. Web pages
with many links, for instance, can reasonably be considered important even if
they are not in a strongly connected component. Recall also that acyclic networks, such as citation networks, have no strongly connected components of
more than one vertex (see Section 6.11.1), so all vertices will have centrality
zero. Clearly this make the standard eigenvector centrality completely useless
for acyclic networks.
A variation on eigenvector centrality that addresses these problems is the
Katz centrality, which is the subject of the next section.

7.3

K ATZ CENTRALITY

One solution to the issues of the previous section is the following: we simply give each vertex a small amount of centrality “for free,” regardless of its
position in the network or the centrality of its neighbors. In other words, we
deﬁne
(7.8)
xi = α ∑ Aij x j + β,
j

where α and β are positive constants. The ﬁrst term is the normal eigenvector
centrality term in which the centralities of the vertices linking to i are summed,
and the second term is the “free” part, the constant extra term that all vertices
receive. By adding this second term, even vertices with zero in-degree still get
centrality β, and once they have a non-zero centrality, then the vertices they
point to derive some advantage from being pointed to. This means that any
vertex that is pointed to by many others will have a high centrality, although
4

172

For the left eigenvector it would be the in-component.

7.3

|

K ATZ CENTRALITY

those that are pointed to by others with high centrality themselves will still do
better.
In matrix terms, Eq. (7.8) can be written
x = αAx + β1,

(7.9)

where 1 is the vector (1, 1, 1 . . .). Rearranging for x, we ﬁnd that x = β(I −
αA)−1 · 1. As we have said, we normally don’t care about the absolute magnitude of the centrality, only about which vertices have high or low centrality
values, so the overall multiplier β is unimportant. For convenience we usually
set β = 1, giving
(7.10)
x = (I − αA)−1 · 1.
This centrality measure was ﬁrst proposed by Katz in 1953 [169] and we will
refer to it as the Katz centrality.
The Katz centrality differs from ordinary eigenvector centrality in the important respect of having a free parameter α, which governs the balance between the eigenvector term and the constant term in Eq. (7.8). If we wish to
make use of the Katz centrality we must ﬁrst choose a value for this constant.
In doing so it is important to understand that α cannot be arbitrarily large. If
we let α → 0, then only the constant term survives in Eq. (7.8) and all vertices
have the same centrality β (which we have set to 1). As we increase α from
zero the centralities increase and eventually there comes a point at which they
diverge. This happens at the point where (I − αA)−1 diverges in Eq. (7.10),
i.e., when det(I − αA) passes through zero. Rewriting this condition as
det(A − α−1 I) = 0,

(7.11)

we see that it is simply the characteristic equation whose roots α−1 are equal to
the eigenvalues of the adjacency matrix.5 As α increases, the determinant ﬁrst
crosses zero when α−1 = κ1 , the largest eigenvalue of A, or alternatively when
α = 1/κ1 . Thus, we should choose a value of α less than this if we wish the
expression for the centrality to converge.6
Beyond this, however, there is little guidance to be had as to the value that
α should take. Most researchers have employed values close to the maximum
of 1/κ1 , which places the maximum amount of weight on the eigenvector term
5
The eigenvalues being deﬁned by Av = κv, we see that (A − κI)v = 0, which has non-zero
solutions for v only if (A − κI) cannot be inverted, i.e., if det(A − κI) = 0, and hence this equation
gives the eigenvalues κ.
6
Formally one recovers ﬁnite values again when one moves past 1/κ1 to higher α, but in practice these values are meaningless. The method returns good results only for α < 1/κ1 .

173

M EASURES AND METRICS

and the smallest amount on the constant term. This returns a centrality that is
numerically quite close to the ordinary eigenvector centrality, but gives small
non-zero values to vertices that are not in the strongly connected components
or their out-components.
The Katz centrality can be calculated directly from Eq. (7.10) by inverting
the matrix on the right-hand side, but often this isn’t the best way to do it.
Inverting a matrix on a computer takes an amount of time proportional to n3 ,
where n is the number of vertices. This makes direct calculation of the Katz
centrality prohibitively slow for large networks. Networks of more than a
thousand vertices or so present serious problems.
A better approach in many cases is to evaluate the centrality directly from
Eq. (7.8) (or equivalently, Eq. (7.9)). One makes an initial estimate of x—
probably a bad one, such as x = 0—and uses that to calculate a better estimate
x = αAx + β1.

(7.12)

Repeating the process many times, x converges to a value close to the correct
centrality. Since A has m non-zero elements, each iteration requires m multiplication operations and the total time for the calculation is proportional to rm,
where r is the number of iterations necessary for the calculation to converge.
Unfortunately, r depends on the details of the network and on the choice of α,
so we cannot give a general guide to how many iterations will be necessary.
Instead one must watch the values of xi to observe when they converge to constant values. Nonetheless, for large networks it is almost always worthwhile
to evaluate the centrality this way rather than by inverting the matrix.
We have presented the Katz centrality as a solution to the problems encountered with ordinary eigenvector centrality in directed networks. However, there is no reason in principle why one cannot use Katz centrality in undirected networks as well, and there are times when this might be useful. The
idea of adding a constant term to the centrality so that each vertex gets some
weight just by virtue of existing is a natural one. It allows a vertex that has
many neighbors to have high centrality regardless of whether those neighbors
themselves have high centrality, and this could be desirable in some applications.
A possible extension of the Katz centrality is to consider cases in which the
additive constant term in Eq. (7.8) is not the same for all vertices. One could
deﬁne a generalized centrality measure by
xi = α ∑ Aij x j + β i ,

(7.13)

j

where β i is some intrinsic, non-network contribution to the centrality for each
174

7.4

|

PAGE R ANK

vertex. For example, in a social network the importance of an individual might
depend on non-network factors such as their age or income and if we had information about these factors we could incorporate it into the values of the β i .
Then the vector x of centralities is given by
x = (I − αA)−1 β,

(7.14)

where β is the vector whose elements are the β i . One nice feature of this approach is that the difﬁcult part of the calculation—the inversion of the matrix—
only has to be done once for a given network and choice of α. For difference
choices of the β i we need not recalculate the inverse, but simply multiply the
inverse into different vectors β.

7.4

PAGE R ANK

The Katz centrality of the previous section has one feature that can be undesirable. If a vertex with high Katz centrality points to many others then those
others also get high centrality. A high-centrality vertex pointing to one million others gives all one million of them high centrality. One could argue—and
many have—that this is not always appropriate. In many cases it means less
if a vertex is only one among many that are pointed to. The centrality gained
by virtue of receiving an edge from a prestigious vertex is diluted by being
shared with so many others. For instance, the famous Yahoo! web directory
might contain a link to my web page, but it also has links to millions of other
pages. Yahoo! is an important website, and would have high centrality by any
sensible measure, but should I therefore be considered very important by association? Most people would say not: the high centrality of Yahoo! will get
diluted and its contribution to the centrality of my page should be small because my page is only one of millions.
We can allow for this by deﬁning a variation on the Katz centrality in which
the centrality I derive from my network neighbors is proportional to their centrality divided by their out-degree. Then vertices that point to many others pass
only a small amount of centrality on to each of those others, even if their own
centrality is high.
In mathematical terms this centrality is deﬁned by
xj
xi = α ∑ Aij out + β.
k
j
j

(7.15)

This gives problems however if there are vertices in the network with outdegree kout
= 0. If there are any such vertices then the ﬁrst term in Eq. (7.15)
i
175

M EASURES AND METRICS

is indeterminate—it is equal to zero divided by zero (because Aij = 0 for all i).
This problem is easily ﬁxed however. It is clear that vertices with no out-going
edges should contribute zero to the centrality of any other vertex, which we
= 1 for all such vertices. (In fact, we
can contrive by artiﬁcially setting kout
i
out
could set k i to any non-zero value and the calculation would give the same
answer.)
In matrix terms, Eq. (7.15), is then
x = αAD−1 x + β1,

(7.16)

with 1 being again the vector (1, 1, 1, . . .) and D being the diagonal matrix with
−1 −1 · 1,
elements Dii = max(kout
i , 1). Rearranging, we ﬁnd that x = β ( I − αAD )
and thus, as before, β plays the role only of an unimportant overall multiplier
for the centrality. Conventionally we set β = 1, giving
x = (I − αAD−1 )−1 1 = D(D − αA)−1 1.

Web search is discussed in
more detail in Section 19.1.

176

(7.17)

This centrality measure is commonly known as PageRank, which is the trade
name given it by the Google web search corporation, which uses it as a central part of their web ranking technology [55]. The aim of the Google web
search engine is to generate lists of useful web pages from a preassembled
index of pages in response to text queries. It does this by ﬁrst searching the
index for pages matching a given query using relatively simple criteria such
as text matching, and then ranking the answers according to scores based on
a combination of ingredients of which PageRank is one. Google returns useful
answers to queries not because it is better at ﬁnding relevant pages, but because it is better at deciding what order to present its ﬁndings in: its perceived
accuracy arises because the results at the top of the list of answers it returns
are often highly relevant to the query, but it is possible and indeed likely that
many irrelevant answers also appear on the list, lower down.
PageRank works on the Web precisely because having links to your page
from important pages elsewhere is a good indication that your page may be
important too. But the added ingredient of dividing by the out-degrees of
pages insures that pages that simply point to an enormous number of others
do not pass much centrality on to any of them, so that, for instance, network
hubs like Yahoo! do not have a disproportionate inﬂuence on the rankings.
As with the Katz centrality, the formula for PageRank, Eq. (7.17), contains
one free parameter α, whose value must be chosen somehow before the algorithm can be used. By analogy with Eq. (7.11) and the argument that follows
it, we can see that the value of α should be less than the inverse of the largest
eigenvalue of AD−1 . For an undirected network this largest eigenvalue turns

7.4

|

PAGE R ANK

out to be 1 and the corresponding eigenvector is (k1 , k2 , k3 , . . .), where k i is the
degree of the ith vertex.7 Thus α should be chosen less than 1. For a directed
network, this result does not follow and in general the leading eigenvalue will
be different from 1, although in practical cases it is usually still roughly of order 1.
The Google search engine uses a value of α = 0.85 in its calculations, although it’s not clear that there is any rigorous theory behind this choice. More
likely it is just a shrewd guess based on experimentation to ﬁnd out what
works well.
As with the Katz centrality we can generalize PageRank to the case where
the additive constant term in Eq. (7.15) is different for different vertices:
xj
xi = α ∑ Aij out + β i .
kj
j

(7.18)

In matrix form this gives a solution for the centrality vector of
x = D(D − αA)−1 β.

(7.19)

One could, for instance, use this for ranking web pages, giving β i a value based
perhaps on textual relevance to a search query. Pages that contained the word
or words being searched for more often or in more prominent places could
be given a higher intrinsic centrality than others, thereby pushing them up
the rankings. The author is not aware, however, of any cases in which this
technique has been implemented in practice.
Finally, one can also imagine a version of PageRank that did not have the
additive constant term in it at all:
xi = α ∑ Aij
j

xj
,
kj

(7.20)

which is similar to the original eigenvector centrality introduced back in Section 7.2, but now with the extra division by k j . For an undirected network,
however, this measure is trivial: it is easy to see that it gives simply xi = k i
7

It is easy to conﬁrm that this vector is indeed an eigenvector with eigenvalue 1. That there
is no eigenvalue larger than 1 is less obvious. It follows from a standard result in linear algebra,
the Perron–Frobenius theorem, which states that the largest eigenvalue of a matrix such as AD−1
that has all elements non-negative is unique—there is only one eigenvector with this eigenvalue—
that the eigenvector also has all elements non-negative, and that it is the only eigenvector with all
elements non-negative. Combining these results, it is clear that the eigenvalue 1 above must be
the largest eigenvalue of the matrix AD−1 . For a discussion of the Perron–Frobenius theorem see
Ref. [217] and the two footnotes on page 346 of this book.

177

M EASURES AND METRICS

divide by
out-degree
no division

with constant term
x = D(D − αA)−1 · 1
PageRank
x = (I − αA)−1 · 1
Katz centrality

without constant term
x = AD−1 x
degree centrality
x = κ1−1 Ax
eigenvector centrality

Table 7.1: Four centrality measures. The four matrix-based centrality measures discussed in the text are distinguished by whether or not they include an additive constant
term in their deﬁnition and whether they are normalized by dividing by the degrees of
neighboring vertices. Note that the diagonal matrix D, which normally has elements
Dii = k i , must be deﬁned slightly differently for PageRank, as Dii = max(1, k i )—see
Eq. (7.15) and the following discussion. Each of the measures can be applied to directed
networks as well as undirected ones, although only three of the four are commonly used
in this way. (The measure that appears in the top right corner of the table is equivalent
to degree centrality in the undirected case but takes more complicated values in the
directed case and is not widely used.)

and therefore is just the same as ordinary degree centrality. For a directed network, on the other hand, it does not reduce to any equivalent simple value
and it might potentially be of use, although it does not seem to have found
use in any prominent application. (It does suffer from the same problem as
the original eigenvector centrality, that it gives non-zero scores only to vertices
that fall in a strongly connected component of two or more vertices or in the
out-component of such a component. All other vertices get a zero score.)
In Table 7.1 we give a summary of the different matrix centrality measures
we have discussed, organized according to their deﬁnitions and properties. If
you want to use one of these measures in your own calculations and ﬁnd the
many alternatives bewildering, eigenvector centrality and PageRank are probably the two measures to focus on initially. They are the two most commonly
used measures of this type. The Katz centrality has found widespread use in
the past but has been favored less in recent work, while the PageRank measure without the constant term, Eq. (7.20), is the same as degree centrality for
undirected networks and not in common use for directed ones.

7.5

H UBS AND AUTHORITIES

In the case of directed networks, there is another twist to the centrality measures introduced in this section. So far we have considered measures that
accord a vertex high centrality if those that point to it have high centrality.
178

7.5

|

H UBS AND AUTHORITIES

However, in some networks it is appropriate also to accord a vertex high centrality if it points to others with high centrality. For instance, in a citation network a paper such as a review article may cite other articles that are authoritative sources for information on a particular subject. The review itself may
contain relatively little information on the subject, but it tells us where to ﬁnd
the information, and this on its own makes the review useful. Similarly, there
are many examples of web pages that consist primarily of links to other pages
on a given topic or topics and such a page of links could be very useful even if
it does not itself contain explicit information on the topic in question.
Thus there are really two types of important node in these networks: authorities are nodes that contain useful information on a topic of interest; hubs
are nodes that tell us where the best authorities are to be found. An authority
may also be a hub, and vice versa: review articles often contain useful discussions of the topic at hand as well as citations to other discussions. Clearly hubs
and authorities only exist in directed networks, since in the undirected case
there is no distinction between pointing to a vertex and being pointed to.
One can imagine deﬁning two different types of centrality for directed networks, the authority centrality and the hub centrality, which quantify vertices’
prominence in the two roles. This idea was ﬁrst put forward by Kleinberg [176]
and developed by him into a centrality algorithm called hyperlink-induced topic
search or HITS.
The HITS algorithm gives each vertex i in a network an authority centrality xi and a hub centrality yi . The deﬁning characteristic of a vertex with high
authority centrality is that it is pointed to by many hubs, i.e., by many other
vertices with high hub centrality. And the deﬁning characteristic of a vertex
with high hub centrality is that it points to many vertices with high authority
centrality.
Thus an important scientiﬁc paper (in the authority sense) would be one
cited in many important reviews (in the hub sense). An important review is
one that cites many important papers. Reviews, however, are not the only
publications that can have high hub centrality. Ordinary papers can have high
hub centrality too if they cite many other important papers, and papers can
have both high authority and high hub centrality. Reviews too may be cited
by other hubs and hence have high authority centrality as well as high hub
centrality.
In Kleinberg’s approach, the authority centrality of a vertex is deﬁned to be
proportional to the sum of the hub centralities of the vertices that point to it:
xi = α ∑ Aij y j ,

(7.21)

j

179

M EASURES AND METRICS

where α is a constant. Similarly the hub centrality of a vertex is proportional
to the sum of the authority centralities of the vertices it points to:
yi = β ∑ A ji x j ,

(7.22)

j

with β another constant. Notice that the indices on the matrix element A ji are
swapped around in this second equation: it is the vertices that i points to that
deﬁne its hub centrality.
In matrix terms these equations can be written as
x = αAy,

y = βA T x,

(7.23)

A T Ay = λy,

(7.24)

or, combining the two,
AA T x = λx,

where λ = (αβ)−1 . Thus the authority and hub centralities are respectively
given by eigenvectors of AA T and A T A with the same eigenvalue. By an argument similar to the one we used for the standard eigenvector centrality in
Section 7.1 we can show that we should in each case take the eigenvector corresponding to the leading eigenvalue.
A crucial condition for this approach to work, is that AA T and A T A have
the same leading eigenvalue λ, otherwise we cannot satisfy both conditions in
Eq. (7.24). It is easily proved, however, that this is the case, and in fact that all
eigenvalues are the same for the two matrices. If AA T x = λx then multiplying
both sides by AT gives
(7.25)
A T A ( A T x ) = λ ( A T x ),
and hence A T x is an eigenvector of A T A with the same eigenvalue λ. Comparing with Eq. (7.24) this means that
y = A T x,

(7.26)

which gives us a fast way of calculating the hub centralities once we have
the authority ones—there is no need to solve both the eigenvalue equations
in Eq. (7.24) separately.
Note that AA T is precisely the cocitation matrix deﬁned in Section 6.4.1
(Eq. (6.8)) and the authority centrality is thus, roughly speaking, the eigenvector centrality for the cocitation network.8 Similarly A T A is the bibliographic
8
This statement is only approximately correct since, as discussed in Section 6.4.1, the cocitation
matrix is not precisely equal to the adjacency matrix of the cocitation network, having non-zero
elements along its diagonal where the adjacency matrix has none.

180

7.6

|

C LOSENESS CENTRALITY

coupling matrix, Eq. (6.11), and hub centrality is the eigenvector centrality for
the bibliographic coupling network.
A nice feature of the hub and authority centralities is that they circumvent the problems that ordinary eigenvector centrality has with directed networks, that vertices outside of strongly connected components or their outcomponents always have centrality zero. In the hubs and authorities approach
vertices not cited by any others have authority centrality zero (which is reasonable), but they can still have non-zero hub centrality. And the vertices that they
cite can then have non-zero authority centrality by virtue of being cited. This
is perhaps a more elegant solution to the problems of eigenvector centrality
in directed networks than the more ad hoc method of introducing an additive
constant term as we did in Eq. (7.8). We can still introduce such a constant
term into the HITS algorithm if we wish, or employ any of the other variations
considered in previous sections, such as normalizing vertex centralities by the
degrees of the vertices that point to them. Some variations along these lines
are explored in Refs. [52, 256], but we leave the pursuit of such details to the
enthusiastic reader.
The HITS algorithm is an elegant construction that should in theory provide more information about vertex centrality than the simpler measures of
previous sections, but in practice it has not yet found much application. It is
used as the basis for the web search engines Teoma and Ask.com, and will perhaps in future ﬁnd further use, particularly in citation networks, where it holds
clear advantages over other eigenvector measures.

7.6

C LOSENESS CENTRALITY

An entirely different measure of centrality is provided by the closeness centrality, which measures the mean distance from a vertex to other vertices. In Section 6.10.1 we encountered the concept of the geodesic path, the shortest path
through a network between two vertices. Suppose dij is the length of a geodesic
path from i to j, meaning the number of edges along the path.9 Then the mean
geodesic distance from i to j, averaged over all vertices j in the network, is

i =

1
dij .
n∑
j

(7.27)

9
Recall that geodesic paths need not be unique—vertices can be joined by several shortest
paths of the same length. The length dij however is always well deﬁned, being the length of any
one of these paths.

181

M EASURES AND METRICS

This quantity takes low values for vertices that are separated from others by
only a short geodesic distance on average. Such vertices might have better access to information at other vertices or more direct inﬂuence on other vertices.
In a social network, for instance, a person with lower mean distance to others
might ﬁnd that their opinions reach others in the community more quickly
than the opinions of someone with higher mean distance.
In calculating the average distance some authors exclude from the sum
in (7.27) the term for j = i, so that

i =

1
dij ,
n − 1 j(∑
=i )

(7.28)

which is a reasonable strategy, since a vertex’s inﬂuence on itself is usually not
relevant to the working of the network. On the other hand, the distance dii
from i to itself is zero by deﬁnition, so this term in fact contributes nothing to
the sum. The only difference the change makes to i is in the leading divisor,
which becomes 1/(n − 1) instead of 1/n, meaning that i changes by a factor
of n/(n − 1). Since this factor is independent of i and since, as we have said,
we usually care only about the relative centralities of different vertices and not
about their absolute values, we can in most cases ignore the difference between
Eqs. (7.27) and (7.28). In this book we use (7.27) because it tends to give slightly
more elegant analytic results.
The mean distance i is not a centrality measure in the same sense as the
others in this chapter, since it gives low values for more central vertices and
high values for less central ones, which is the opposite of our other measures.
In the social networks literature, therefore, researchers commonly calculate the
inverse of i rather than i itself. This inverse is called the closeness centrality Ci :
Ci =

1
n
=
.
i
∑ j dij

(7.29)

Closeness centrality is a very natural measure of centrality and is often used
in social and other network studies. But it has some problems. One issue
is that its values tend to span a rather small dynamic range from largest to
smallest. As discussed in Sections 3.6, 8.2, and 12.7, geodesic distances dij between vertices in most networks tend to be small, the typical distance increasing only logarithmically with the size of the entire network. This means that
the ratio between the smallest distance, which is 1, and the largest, which is of
order log n, is itself only of order log n, which is small. But the smallest and
largest distances provide lower and upper bounds on the average distance i ,
and hence the range of values of i and similarly of Ci is also small. In a typical
182

7.6

|

C LOSENESS CENTRALITY

network the values of Ci might span a factor of ﬁve or less. What this means
in practice is that it is difﬁcult to distinguish between central and less central
vertices using this measure: the values tend to be cramped together with the
differences between adjacent values showing up only when you examine the
trailing digits. This means that even small ﬂuctuations in the structure of the
network can change the order of the values substantially.
For example, it has become popular in recent years to rank ﬁlm actors according to their closeness centrality in the network of who has appeared in
ﬁlms with who else [323]. Using data from the Internet Movie Database,10 we
ﬁnd that in the largest component of the network, which includes more than
98% of all actors, the smallest closeness centrality of any actor is 2.4138 for
the actor Christopher Lee,11 while the largest is 8.6681 for an Iranian actress
named Leia Zanganeh. The ratio of the two is just 3.6 and about half a million
other actors lie in between. As we can immediately see, the values must be
very closely spaced. The second best centrality score belongs to actor Donald
Pleasence, who scores 2.4164, just a tenth of a percent less than winner Lee.
Because of the close spacing of values, the leaders under this dubious measure
of superiority change frequently as the small details of the ﬁlm network shift
when new ﬁlms are made or old ones added to the database. In an analysis
using an earlier version of the database, Watts and Strogatz [323] proclaimed
Rod Steiger to be the actor with the lowest closeness centrality. Steiger falls in
sixth place in our analysis and it is entirely possible that the rankings will have
changed again by the time you read this. Other centrality measures, including
degree centrality and eigenvector centrality, typically don’t suffer from this
problem because they have a wider dynamic range and the centrality values,
particular those of the leaders, tend to be widely separated.
The closeness centrality has another problem too. If, as discussed in Section 6.10.1, we deﬁne the geodesic distance between two vertices to be inﬁnite
if the vertices fall in different components of the network, then i is inﬁnite
for all i in any network with more than one component and Ci is zero. There
are two strategies for getting around this. The most common one is simply
to average over only those vertices in the same component as i. Then n in
Eq. (7.29) becomes the number of vertices in the component and the sum is
over only that component. This gives us a ﬁnite measure, but one that has its
own problems. In particular, distances tend to be smaller between vertices in
small components, so that vertices in such components get lower values of i
10

www.imdb.com

11

Perhaps most famous for his role as the evil wizard Saruman in the ﬁlm version of The Lord
of the Rings.

183

M EASURES AND METRICS

and higher closeness centrality than their counterparts in larger components.
This is usually undesirable: in most cases vertices in small components are
considered less well connected than those in larger ones and should therefore
be given lower centrality.
Perhaps a better solution, therefore, is to redeﬁne closeness in terms of the
harmonic mean distance between vertices, i.e., the average of the inverse distances:
1
1
.
(7.30)
Ci =
∑
n − 1 j(=i) dij
(Notice that we are obliged in this case to exclude from the sum the term for
j = i, since dii = 0 which would make this term inﬁnite. This means that the
sum has only n − 1 terms in it, hence the leading factor of 1/(n − 1).)
This deﬁnition has a couple of nice properties. First, if dij = ∞ because i and
j are in different components, then the corresponding term in the sum is simply zero and drops out. Second, the measure naturally gives more weight to
vertices that are close to i than to those far away. Intuitively we might imagine
that the distance to close vertices is what matters in most practical situations—
once a vertex is far away in a network it matters less exactly how far away it
is, and Eq. (7.30) reﬂects this, having contributions close to zero from all such
vertices.
Despite its desirable qualities, however, Eq. (7.30) is rarely used in practice.
We have seen it employed only occasionally.
An interesting property of entire networks, which is related to the closeness
centrality, is the mean geodesic distance between vertices. In Section 8.2 we
will use measurements of mean distance in networks to study the so-called
“small-world effect.”
For a network with only one component, the mean distance between pairs
of vertices, conventionally denoted just  (now without the subscript), is

=

1
1
dij = ∑ i .
n2 ∑
n
ij
i

(7.31)

In other words  is just the mean of i over all vertices.
For a network with more than one component we run into the same problems as before, that dij is inﬁnite when i and j are in different components
and hence  is also inﬁnite. The most common way around this problem is to
average only over paths that run between vertices in the same component. Let
{Cm } be the set of components of a network, with m = 1, 2 . . . Then we deﬁne

=
184

∑m ∑ij∈Cm dij
,
∑m n2m

(7.32)

7.7

|

B ETWEENNESS CENTRALITY

where nm is the number of vertices in component Cm . This measure is now
ﬁnite for all networks, although it is not now equal to a simple average over
the values of i for each vertex.
An alternative and perhaps better approach would be to use the trick from
Eq. (7.30) and deﬁne a harmonic mean distance  according to
1
1
1
1
=
= ∑ Ci ,
n ( n − 1) ∑
n

d
i
i = j ij
or equivalently

 =

n
,
∑i Ci

(7.33)

(7.34)

where Ci is the harmonic mean closeness of Eq. (7.30). (Note that, as in (7.30),
we exclude from the ﬁrst sum in (7.33) the terms for i = j, which would be
inﬁnite since dii = 0.)
Equation (7.34) automatically removes any contributions from vertex pairs
for which dij = ∞. Despite its elegance, however, Eq. (7.34), like Eq. (7.30), is
hardly ever used.

7.7

B ETWEENNESS CENTRALITY

A very different concept of centrality is betweenness centrality, which measures
the extent to which a vertex lies on paths between other vertices. The idea of
betweenness is usually attributed to Freeman [128] in 1977, although as Freeman himself has pointed out [129], it was independently proposed some years
earlier by Anthonisse [19] in an unpublished technical report.
Suppose we have a network with something ﬂowing around it from vertex
to vertex along the edges. For instance, in a social network we might have messages, news, information, or rumors being passed from one person to another.
In the Internet we have data packets moving around. Let us initially make
the simple assumption that every pair of vertices in the network exchanges a
message with equal probability per unit time (more precisely every pair that
is actually connected by a path) and that messages always take the shortest
(geodesic) path though the network, or one such path, chosen at random, if
there are several. Then let us ask the following question: if we wait a suitably
long time until many messages have passed between each pair of vertices, how
many messages, on average, will have passed through each vertex en route to
their destination? The answer is that, since messages are passing down each
geodesic path at the same rate, the number passing through each vertex is
simply proportional to the number of geodesic paths the vertex lies on. This
185

M EASURES AND METRICS

number of geodesic paths is what we call the betweenness centrality, or just
betweenness for short.
Vertices with high betweenness centrality may have considerable inﬂuence
within a network by virtue of their control over information passing between
others. The vertices with highest betweenness in our message-passing scenario
are the ones through which the largest number of messages pass, and if those
vertices get to see the messages in question as they pass, or if they get paid
for passing the messages along, they could derive a lot of power from their
position within the network. The vertices with highest betweenness are also
the ones whose removal from the network will most disrupt communications
between other vertices because they lie on the largest number of paths taken
by messages. In real-world situations, of course, not all vertices exchange communications with the same frequency, and in most cases communications do
not always take the shortest path. Nonetheless, betweenness centrality may
still be an approximate guide to the inﬂuence vertices have over the ﬂow of
information between others.
Having seen the basic idea of betweenness centrality, let us make things
more precise. For the sake of simplicity, suppose for the moment that we have
an undirected network in which there is at most one geodesic path between
any pair of vertices. (There may be zero paths if the vertices in question are
in different components.) Consider the set of all geodesic paths in such a network. Then the betweenness centrality of a vertex i is deﬁned to be the number
of those paths that pass through i.
Mathematically, let nist be 1 if vertex i lies on the geodesic path from s to t
and 0 if it does not or if there is no such path (because s and t lie in different
components of the network). Then the betweenness centrality xi is given by
xi = ∑ nist .

(7.35)

st

Note that this deﬁnition counts separately the geodesic paths in either direction between each vertex pair. Since these paths are the same on an undirected
network this effectively counts each path twice. One could compensate for this
by dividing xi by 2, and often this is done, but we prefer the deﬁnition given
here for a couple of reasons. First, it makes little difference in practice whether
one divides the centrality by 2, since one is usually concerned only with the relative magnitudes of the centralities and not with their absolute values. Second,
as discussed below, Eq. (7.35) has the advantage that it can be applied unmodiﬁed to directed networks, in which the paths in either direction between a
vertex pair can differ.
Note also that Eq. (7.35) includes paths from each vertex to itself. Some
186

7.7

|

B ETWEENNESS CENTRALITY

people prefer to exclude such paths from the deﬁnition, so that xi = ∑s=t nist ,
but again the difference is typically not important. Each vertex lies on one
path from itself to itself, so the inclusion of these terms simply increases the
betweenness by 1, but does not change the rankings of the vertices—which
ones have higher or lower betweenness—relative to one another.
There is also a choice to be made about whether the path from s to t should
be considered to pass through the vertices s and t themselves. In the social networks literature it is usually assumed that it does not. We prefer the deﬁnition
where it does: it seems reasonable to deﬁne a vertex to be on a path between
itself and someone else, since normally a vertex has control over information
ﬂowing from itself to other vertices or vice versa. If, however, we exclude the
endpoints of the path as sociologists commonly do, the only effect is to reduce
the number of paths through each vertex by twice the size of the component
to which the vertex belongs. Thus the betweennesses of all vertices within a
single component are just reduced by an additive constant and the ranking of
vertices within the component is again unchanged. (The rankings of vertices
in different components can change relative to one another, but this is rarely an
issue because betweenness centrality is not typically used to compare vertices
in different components, since such vertices are not competing for inﬂuence in
the same arena.)
These developments are all for the case in which there is at most one geodesic path between each vertex pair. More generally, however, there may be
more than one. The standard extension of betweenness to this case gives each
path a weight equal to the inverse of the number of paths. For instance, if
there are two geodesic paths between a given pair of vertices, each of them
gets weight 12 . Then the betweenness of a vertex is deﬁned to be the sum of the
weights of all geodesic paths passing through that vertex.
Note that the geodesic paths between a pair of vertices need not be vertexindependent, meaning they may pass through some of the same vertices (see
ﬁgure). If two or more paths pass through the same vertex then the betweenness sum includes contributions from each of them. Thus if there are, say, three
geodesic paths between a given pair of vertices and two of them pass through
a particular vertex, then they contribute 23 to that vertex’s betweenness.
Formally, we can express the betweenness for a general network by redeﬁning nist to be the number of geodesic paths from s to t that pass through i. And
we deﬁne gst to be the total number of geodesic paths from s to t. Then the
betweenness centrality of vertex i is
nist
,
st gst

xi = ∑

B
C
A
Vertices A and B are connected by two geodesic
paths. Vertex C lies on both
paths.

(7.36)

187

M EASURES AND METRICS

where we adopt the convention that nist /gst = 0 if both nist and gst are zero. This
deﬁnition is equivalent to our message-passing thought experiment above, in
which messages pass between all pairs of vertices in a network at the same
average rate, traveling along shortest paths, and in the case of several shortest
paths between a given pair of vertices they choose at random between those
several paths. Then xi is proportional to the average rate at which trafﬁc passes
though vertex i.
Betweenness centrality can be applied to directed networks as well. In a
directed network the shortest path between two vertices depends, in general,
on the direction you travel in. The shortest path from A to B is different from
the shortest path from B to A. Indeed there may be a path in one direction and
no path at all in the other. Thus it is important in a directed network explicitly
to include the path counts in either direction between each vertex pair. The
deﬁnition in Eq. (7.36) already does this and so, as mentioned above, we can
use the same deﬁnition without modiﬁcation for the directed case. This is one
reason why we prefer this deﬁnition to other slight variants that are sometimes
used.
Although the generalization of betweenness to directed networks is straightforward, however, it is rarely if ever used, so we won’t discuss it further here,
concentrating instead on the much more common undirected case.
Betweenness centrality differs from the other centrality
measures we have considered in being not principally a measure of how well-connected a vertex is. Instead it measures
A
how much a vertex falls “between” others. Indeed a vertex
Group 1
Group 2
can have quite low degree, be connected to others that have
low degree, even be a long way from others on average, and
still have high betweenness. Consider the situation depicted
in Fig. 7.2. Vertex A lies on a bridge between two groups
Figure 7.2: A low-degree vertex with high bewithin a network. Since any shortest path (or indeed any
tweenness. In this sketch of a network, verpath whatsoever) between a vertex in one group and a vertex A lies on a bridge joining two groups of
tex in the other must pass along this bridge, A acquires very
other vertices. All paths between the groups
high betweenness, even though it is itself on the periphery of
must pass through A, so it has a high betweenboth groups and in other respects may be not well connected:
ness even though its degree is low.
probably A would not have particularly impressive values for
eigenvector or closeness centrality, and its degree centrality is
only 2, but nonetheless it might have a lot of inﬂuence in the network as a result of its control over the ﬂow of information between others. Vertices in roles

188

7.7

|

B ETWEENNESS CENTRALITY

like this are sometimes referred to in the sociological literature as brokers.12
Betweenness centrality also has another interesting property: its values are
typically distributed over a wide range. The maximum possible value for the
betweenness of a vertex occurs when the vertex lies on the shortest path between every other pair of vertices. This occurs for the central vertex in a star
graph, a network composed of a vertex attached to n − 1 others by single edges.
In this situation the central vertex lies on all n2 shortest paths between vertex
pairs except for the n − 1 paths from the peripheral vertices to themselves.
Thus the betweenness centrality of the central vertex is n2 − n + 1. At the
other end of the scale, the smallest possible value of betweenness in a network
with a single component is 2n − 1, since at a minimum each vertex lies on every path that starts or ends with itself. (There are n − 1 paths from a vertex to
others, n − 1 paths from others to the vertex, and one path from the vertex to
itself, for a total of 2(n − 1) + 1 = 2n − 1.) This situation occurs, for instance,
when a network has a “leaf” attached to it, a vertex connected to the rest of the
network by just a single edge.
Thus the ratio of largest and smallest possible betweenness values is
n2 − n + 1
≃ 12 n,
2n − 1

A star graph.

(7.37)

where the equality becomes exact in the limit of large n. Thus in theory there
could be a factor of almost 12 n between the largest and smallest betweenness
centralities, which could become very large for large networks. In real networks the range is usually considerably smaller than this, but is nonetheless
large and typically increasing with increasing n.
Taking again the example of the network of ﬁlm actors from the previous
section, the individual with the highest betweenness centrality in the largest
component of the actor network is the great Spanish actor Fernando Rey, most
famous in the English-speaking world for his 1971 starring role next to Gene
Hackman in The French Connection.13 Rey has a betweenness score of 7.47 × 108 ,
12
Much of sociological literature concerns power or “social capital.” It may seem ruthless to
think of individuals exploiting their control over other people’s information to gain the upper
hand on them, but it may also be realistic. At least in situations where there is a signiﬁcant pay-off
to having such an upper hand (like business relationships, for example), it is reasonable to suppose
that notions of power derived from network structure really do play into people’s manipulations
of the world around them.
13
It is perhaps no coincidence that the highest betweenness belongs to an actor who appeared
in both European and American ﬁlms, played roles in several different languages, and worked
extensively in both ﬁlm and television, as well as on stage. Rey was the archetypal “broker,” with
a career that made him a central ﬁgure in several different arms of the entertainment business that
otherwise overlap relatively little.

189

M EASURES AND METRICS

while the lowest score of any actor14 in the large component is just 8.91 × 105 .
Thus there is a ratio of almost a thousand between the two limits—a much
larger dynamic range than the ratio of 3.6 we saw in the case of closeness centrality. One consequence of this is that there are very clear winners and losers
in the betweenness centrality competition. The second highest betweenness
in the actor network is that of Christopher Lee (again), with 6.46 × 108 , a 14%
percent difference from winner Fernando Rey. Although betweenness values
may shift a little as new movies are made and new actors added to the network, the changes are typically small compared with these large gaps between
the leaders, so that the ordering at the top of the list changes relatively infrequently, giving betweenness centrality results a robustness not shared by those
for closeness centrality.
The values of betweenness calculated here are raw path counts, but it is
sometimes convenient to normalize betweenness in some way. Several of the
standard computer programs for network analysis, such as Pajek and UCINET,
perform such normalizations. One natural choice is to normalize the path
count by dividing by the total number of (ordered) vertex pairs, which is n2 , so
that betweenness becomes the fraction (rather than the number) of paths that
run through a given vertex:15
xi =

1
nist
.
∑
n2 st gst

(7.38)

With this deﬁnition, the values of the betweenness lie strictly between zero and
one.
Some other variations on the betweenness centrality idea are worth mentioning. Betweenness gets at an important idea in network analysis, that of
the ﬂow of information or other trafﬁc and of the inﬂuence vertices might
have over that ﬂow. However, betweenness as deﬁned by Freeman is based
on counting only the shortest paths between vertex pairs, effectively assuming
that all or at least most trafﬁc passes along those shortest paths. In reality traf14
This score is shared by many actors. It is the minimum possible score of 2n − 1 as described
above.
15
Another possibility, proposed by Freeman [128] in his original paper on betweenness, is to
divide by the maximum possible value that betweenness can take on any network of size n, which,
as mentioned above, occurs for the central vertex in a star graph. The resulting expression for
between is then
1
nist
xi = 2
.
n −n+1 ∑
st gst

We, however, prefer Eq. (7.38), which we ﬁnd easier to interpret, although the difference between
the two becomes small anyway in the limit of large n.

190

7.7

|

B ETWEENNESS CENTRALITY

ﬁc ﬂows along paths other than the shortest in many networks. Most of us, for
instance, will have had the experience of hearing news about one of our friends
not from that friend directly but from another mutual acquaintance—the message has passed along a path of length two via the mutual acquaintance, rather
than along the direct (geodesic) path of length one.
A version of betweenness centrality that makes some allowance for effects
like this is the ﬂow betweenness, which was proposed by Freeman et al. [130]
See Section 6.12 for a disand is based on the idea of maximum ﬂow. Imagine each edge in a network
cussion of maximum ﬂow
as a pipe that can carry a unit ﬂow of some ﬂuid. We can ask what the maxiin networks.
mum possible ﬂow then is between a given source vertex s and target vertex t
through these pipes. In general the answer is that more than a single unit of
ﬂow can be carried between source and target by making simultaneous use of
several different paths through the network. The ﬂow betweenness of a vertex i is deﬁned according to Eq. (7.35), but with nist being now the amount of
ﬂow through vertex i when the maximum ﬂow is transmitted from s to t.
As we saw in Section 6.12, the maximum ﬂow between vertices s and t
is also equal to the number of edge-independent paths between them. Thus
another way equivalent to look at the ﬂow betweenness would be to consider
nist to be the number of independent paths between s and t that run through
vertex i.
A slight problem arises because the independent paths between
a given pair of vertices are not necessarily unique. For instance,
A
the network shown in Fig. 7.3 has two edge-independent paths between s and t but we have two choices about what those paths are,
s
t
either the paths denoted by the solid arrows, or those denoted by
the dashed ones. Furthermore, our result for the ﬂow betweenness
will depend on which choice we make; the vertices labeled A and B
B
fall on one set of paths but not the other. To get around this problem,
Freeman et al. deﬁne the ﬂow through a vertex for their purposes to
be the maximum possible ﬂow over all possible choices of paths, or
Figure 7.3: Edge-independent paths in
equivalently the maximum number of independent paths. Thus in
a small network. The vertices s and t
the network of Fig. 7.3, the contribution of the ﬂow between s and t
in this network have two independent
to the betweenness of vertex A would be 1, since this is the maxipaths between them, but there are two
mum value it takes over all possible choices of ﬂow paths.
distinct ways of choosing those paths,
represented by the solid and dashed
In terms of our information analogy, one can think of ﬂow becurves.
tweenness as measuring the betweenness of vertices in a network in
which a maximal amount of information is continuously pumped
between all sources and targets. Flow betweenness takes account of more than
just the geodesic paths between vertices, since ﬂow can go along non-geodesic
paths as well as geodesic ones. (For example, the paths through vertices A
191

M EASURES AND METRICS

See Section 6.14 for a discussion of random walks.

and B in the example above are not geodesic.) Indeed, in some cases none of the
paths that appear in the solution of the maximum ﬂow problem are geodesic
paths, so geodesic paths may not be counted at all by this measure.
But this point highlights a problem with ﬂow betweenness: although it
typically counts more paths than the standard shortest-path betweenness, ﬂow
betweenness still only counts a subset of possible paths, and some important
ones (such as geodesic paths) may be missed out altogether. One way to look at
the issue is that both shortest-path betweenness and ﬂow betweenness assume
ﬂows that are optimal in some sense—passing only along shortest paths in the
ﬁrst case and maximizing total ﬂow in the second. Just as there is no reason to
suppose that information or other trafﬁc always takes the shortest path, there
is no reason in general to suppose it should act to maximize ﬂow (although of
course there may be special cases in which it does).
A betweenness variant that does count all paths is the random-walk betweenness [243]. In this variant trafﬁc between vertices s and t is thought of as performing an (absorbing) random walk that starts at vertex s and continues until it reaches vertex t. The betweenness is deﬁned according to xi = ∑st nist
but with nist now being the number of times that the random walk from s to t
passes through i on its journey, averaged over many repetitions of the walk.
Note that in this case nist = nits in general, even on an undirected network.
For instance, consider this portion of a network:

A

s

t

A random walk from s to t may pass through vertex A before returning to s and
stepping thence to t, but a walk from t to s will never pass through A because
its ﬁrst step away from t will always take it to s and then the walk will ﬁnish.
Since every possible path from s to t occurs in a random walk with some
probability (albeit a very small one) the random-walk betweenness includes
contributions from all paths.16 Note, however, that different paths appear in
general with different probabilities, so paths do not contribute equally to the
16

All paths, that is, that terminate at the target vertex t the ﬁrst time they reach it. Since we use
an absorbing random walk, paths that visit the target, move away again, and then return are not
included in the random-walk betweenness.

192

7.8

|

G ROUPS OF VERTICES

betweenness scores, longer paths typically making smaller contributions than
shorter ones, a bias that is plausible in some but by no means all cases.
Random walk betweenness would be an appropriate betweenness measure
for trafﬁc that traverses a network with no idea of where it is going—it simply wanders around at random until it reaches its destination. Shortest-path
betweenness is the exact opposite. It is the appropriate measure for information that knows exactly where it is going and takes the most direct path to get
there. It seems likely that most real-world situations fall somewhere in between these two extremes. However, it is found in practice [243] that the two
measures often give quite similar results, in which case one can with reasonable justiﬁcation assume that the “correct” answer, the one lying between the
limits set by the shortest-path and random-walk measures, is similar to both.
In cases where the two differ by a considerable margin, however, we should
be wary of attributing too much authority to either measure—there is no guarantee that either is telling us a great deal about true information ﬂow in the
network.
Other generalizations of betweenness are also possible, based on other models of diffusion, transmission, or ﬂow along network edges. We refer the interested reader to the article by Borgatti [51], which draws together many of the
possibilities into a broad general framework for betweenness measures.

7.8

G ROUPS OF VERTICES

Many networks, including social and other networks, divide naturally into
groups or communities. Networks of people divide into groups of friends,
coworkers, or business partners; the World Wide Web divides into groups of
related web pages; biochemical networks divide into functional modules, and
so forth. The deﬁnition and analysis of groups within networks is a large and
fruitful area of network theory. In Chapter 11 we discuss some of the sophisticated computer methods that have been developed for detecting groups, such
as hierarchical clustering and spectral partitioning. In this section we discuss
some simpler concepts of network groups which can be useful for probing and
describing the local structure of networks. The primary constructs we look at
are cliques, plexes, cores, and components.
7.8.1

C LIQUES , PLEXES , AND CORES

A clique is a maximal subset of the vertices in an undirected network such that
every member of the set is connected by an edge to every other. The word
“maximal” here means that there is no other vertex in the network that can
193

M EASURES AND METRICS

A clique of four vertices
within a network.

A

B
Two overlapping cliques.
Vertices A and B in this network both belong to two
cliques of four vertices.

be added to the subset while preserving the property that every vertex is connected to every other. Thus a set of four vertices in a network would be a clique
if (and only if) each of the four is directly connected by edges to the other three
and if there is no other vertex anywhere in the network that could be added to
make a group of ﬁve vertices all connected to each other. Note that cliques can
overlap, meaning that they can share one or more of the same vertices.
The occurrence of a clique in an otherwise sparse network is normally an
indication of a highly cohesive subgroup. In a social network, for instance, one
might encounter a set of individuals each of whom was acquainted with each
of the others, and such a clique would probably indicate that the individuals
in question are closely connected—a set of coworkers in an ofﬁce for example
or a group of classmates in a school.
However, it’s also the case that many circles of friends form only nearcliques, rather than perfect cliques. There may be some members of the group
who are unacquainted, even if most members know one another. The requirement that every possible edge be present within a clique is a very stringent
one, and it seems natural to consider how we might relax this requirement.
One construct that does this is the k-plex. A k-plex of size n is a maximal subset
of n vertices within a network such that each vertex is connected to at least
n − k of the others. If k = 1, we recover the deﬁnition of an ordinary clique—a
1-plex is the same as a clique. If k = 2, then each vertex must be connected
to all or all-but-one of the others. And so forth.17 Like cliques, k-plexes can
overlap one another; a single vertex can belong to more than one k-plex.
The k-plex is a useful concept for discovering groups within networks: in
real life many groups in social and other networks form k-plexes. There is
no solid rule about what value k should take. Experimentation starting from
small values is the usual way to proceed. Smaller values of k tend to be meaningful for smaller groups, whereas in large groups the smaller values impose
too stringent a constraint but larger values often give useful results. This suggests another possible generalization of the clique idea: one could specify that
each member be connected to a certain fraction of the others, say 75% or 50%.
(As far as we know, this variant doesn’t have a name and it is not in wide use,
but perhaps it should be.)
Many other variations on the clique idea have been proposed in the literature. For instance Flake et al. [122] proposed a deﬁnition of a group as a subset
17
This deﬁnition is slightly awkward to remember, since the members of a k-plex are allowed
to be unconnected to k − 1 other members and not k. It would perhaps have been more sensible to
deﬁne k such that a 0-plex was equivalent to a normal clique, but for better or worse we are stuck
with the deﬁnition we have.

194

7.8

|

G ROUPS OF VERTICES

of vertices such that each has at least as many connections to vertices inside the
group as to vertices outside. Radicchi et al. [276] proposed a weaker deﬁnition
of a group as a subset of vertices such that the total number of connections of
all vertices in the group to others in the group is greater than the total number
of connections to vertices outside.18
Another concept closely related to the k-plex is the k-core. A k-core is a
maximal subset of vertices such that each is connected to at least k others in
the subset.19 It should be obvious (or you can easily prove it for yourself) that
a k-core of n vertices is also an (n − k )-plex. However, the set of all k-cores
for a given value of k is not the same as the set of all k-plexes for any value
of k, since n, the size of the group, can vary from one k-core to another. Also,
unlike k-plexes (and cliques), k-cores cannot overlap, since by their deﬁnition
two k-cores that shared one or more vertices would just form a single larger
k-core.
The k-core is of particular interest in network analysis for the practical reason that it is very easy to ﬁnd the set of all k-cores in a network. A simple
algorithm is to start with your whole network and remove from it any vertices
that have degree less than k, since clearly such vertices cannot under any circumstances be members of a k-core. In so doing, one will normally also reduce
the degrees of some other vertices in the network—those that were connected
to the vertices just removed. So we then go through the network again to see
if there are any more vertices that now have degree less than k and if there are
we remove those too. And so we proceed, repeatedly pruning the network to
remove vertices with degree less than k until no such vertices remain.20 What
is left over will, by deﬁnition, be a k-core or a set of k-cores, since each vertex is
connected to at least k others. Note that we are not necessarily left with a single
k-core—there’s no guarantee that the network will be connected once we are
done pruning it, even if it was connected to start with.
Two other generalizations of cliques merit a brief mention. A k-clique is a
maximal subset of vertices such that each is no more than a distance k away
from any of the others via the edges of the network. For k = 1 this just recovers
18
Note that for the purposes of this latter deﬁnition, an edge between two vertices A and B
within the group counts as two connections, one from A to B and one from B to A.
19
We have to be careful about the meaning of the word “maximal” here. It is possible to have a
group of vertices such that each is connected to at least k others and no single vertex can be added
while retaining this property, but it may be possible to add more than one vertex. Such groups,
however, are not considered to be k-cores. A group is only a k-core if it is not a subset of any larger
group that is a k-core.
20

A closely related process, bootstrap percolation, has also been studied in statistical physics,
principally on regular lattices.

195

M EASURES AND METRICS

The outlined set of three
vertices in this network
constitute a 2-clique, but
one that is not connected
via paths within the 2clique.

the deﬁnition of an ordinary clique. For larger k it constitutes a relaxation
of the stringent requirements of the usual clique deﬁnition. Unfortunately it
is not a very well-behaved one, since a k-clique by this deﬁnition need not
be connected via paths that run within the subset (see ﬁgure). If we restrict
ourselves to paths that run only within the subset then the resulting object is
known as either a k-clan or a k-club. (The difference between the two lies in
whether we impose the restriction that paths stay within the group from the
outset, or whether we ﬁrst ﬁnd k-cliques and then discard those with outside
paths. The end results can be different in the two cases. For more details see
Wasserman and Faust [320].).
7.8.2

C OMPONENTS AND k- COMPONENTS

In Section 6.11 we introduced the concept of a component. A component in an
undirected network is a maximal subset of vertices such that each is reachable
by some path from each of the others. A useful generalization of this concept
is the k-component. A k-component (sometimes also called a k-connected component) is a maximal subset of vertices such that each is reachable from each of
the others by at least k vertex-independent paths—see Fig. 7.4. (Recall that two
paths are said to be vertex-independent if they share none of the same vertices,
except the starting and ending vertices—see Section 6.12.) For the common
special cases k = 2 and k = 3, k-components are also called bicomponents and
tricomponents respectively.
A 1-component by this deﬁnition is just an ordinary component—there is
at least one path between every pair of vertices—and k-components for k ≥ 2
are nested within each other. A 2-component or bicomponent, for example, is
necessarily a subset of a 1-component, since any pair of vertices that are connected by at least two paths are also connected by at least one path. Similarly
a tricomponent is necessarily a subset of a bicomponent, and so forth. (See
Fig. 7.4 again.)
As discussed in Section 6.12, the number of vertex-independent paths between two vertices is equal to the size of the vertex cut set between the same
two vertices, i.e., the number of vertices that would have to be removed in order to disconnect the two. So another way of deﬁning a k-component would
be to say that it is a maximal subset of vertices such that no pair of vertices can
be disconnected from each other by removing less than k vertices.
A variant of the k-component can also be deﬁned using edge-independent
paths, so that vertices are in the same k-component if they are connected by k or
more edge-independent paths, or equivalently if they cannot be disconnected
by the removal of less than k edges. In principal this variant could be useful in
196

7.8

|

G ROUPS OF VERTICES

1−component
2−component
3−component
Figure 7.4: The k-components in a small network. The shaded regions denote the kcomponents in this small network, which has a single 1-component, two 2-components,
one 3-component, and no k-components for any higher value of k. Note that the
k-components are nested within one another, the 2-components falling inside the 1component and the 3-component falling inside one of the 2-components.

certain circumstances but in practice it is rarely used.
The idea of a k-component is a natural one in network analysis, being connected with the idea of network robustness. For instance, in a data network
such as the Internet, the number of vertex-independent paths between two
vertices is also the number of independent routes that data might take between the same two vertices, and the size of the cut set between them is the
number of vertices in the network—typically routers—that would have to fail
or otherwise be knocked out to sever the data connection between the two endpoints. Thus a pair of vertices connected by two independent paths cannot be
disconnected from one another by the failure of any single router. A pair of
vertices connected by three paths cannot be disconnected by the failure of any
two routers. And so forth. A k-component with k ≥ 2 in a network like the
Internet is a subset of the network that has robust connectivity in this sense.
One would hope, for instance, that most of the network backbone—the system
of high volume world-spanning links that carry long-distance data (see Section 2.1)—is a k-component with high k, so that it would be difﬁcult for points
on the backbone to lose connection with one another.
Note that for k ≥ 3, the k-components in a network can be non-contiguous
(see ﬁgure). Ordinary components (1-components) and bicomponents, by contrast, are always contiguous. Within the social networks literature, where noncontiguous components are often considered undesirable, k-components are

The two highlighted vertices in this network form a
tricomponent, even though
they are not directly connected to each other. The
other three vertices are not
in the tricomponent.

197

M EASURES AND METRICS

sometimes deﬁned slightly differently: a k-component is deﬁned to be a maximal subset of vertices such that every pair in the set is connected by at least k
vertex-independent paths that themselves are contained entirely within the subset.
This deﬁnition rules out non-contiguous k-components, but it is also mathematically and computationally more difﬁcult to work with than the standard
deﬁnition. For this reason, and because there are also plenty of cases in which
it is appropriate to count non-contiguous k-components, the standard deﬁnition remains the most widely used one in ﬁelds other than sociology.

7.9

T RANSITIVITY

A property very important in social networks, and useful to a lesser degree in
other networks too, is transitivity. In mathematics a relation “◦” is said to be
transitive if a ◦ b and b ◦ c together imply a ◦ c. An example would be equality.
If a = b and b = c, then it follows that a = c also, so “=” is a transitive relation.
Other examples are “greater than,” “less than,” and “implies.”
In a network there are various relations between pairs of vertices, the simplest of which is “connected by an edge.” If the “connected by an edge” relation were transitive it would mean that if vertex u is connected to vertex v,
and v is connected to w, then u is also connected to w. In common parlance,
“the friend of my friend is also my friend.” Although this is only one possible kind of network transitivity—other network relations could be transitive
too—it is the only one that is commonly considered, and networks showing
this property are themselves said to be transitive. This deﬁnition of network
transitivity could apply to either directed or undirected networks, but let us
take the undirected case ﬁrst, since it’s simpler.
Perfect transitivity only occurs in networks where each component is a
fully connected subgraph or clique, i.e., a subgraph in which all vertices are
connected to all others.21 Perfect transitivity is therefore pretty much a useless
concept in networks. However, partial transitivity can be very useful. In many
networks, particularly social networks, the fact that u knows v and v knows w
21
To see this suppose we have a component that is perfectly transitive but not a clique, i.e., there
is at least one pair of vertices u, w in the component that are not directly connected by an edge.
Since u and w are in the same component they must therefore be connected by some path of length
greater than one, u, v1 , v2 , v3 , . . . , w. Consider the ﬁrst two links in this path. Since u is connected
by an edge to v1 and v1 to v2 it follows that u must be connected to v2 if the network is perfectly
transitive. Then consider the next two links. Since u is connected to v2 and v2 to v3 it follows that
u must be connected to v3 . Repeating the argument all the way along the path, we can then see
that u must be connected by an edge to w. But this violates the hypothesis that u and w are not
directly connected. Hence no perfectly transitive components exist that are not cliques.

198

7.9

doesn’t guarantee that u knows w, but makes it much more likely. The friend
of my friend is not necessarily my friend, but is far more likely to be my friend
than some randomly chosen member of the population.
We can quantify the level of transitivity in a network as follows. If u knows
v and v knows w, then we have a path uvw of two edges in the network. If u
also knows w, we say that the path is closed—it forms a loop of length three,
or a triangle, in the network. In the social network jargon, u, v, and w are said
to form a closed triad. We deﬁne the clustering coefﬁcient22 to be the fraction of
paths of length two in the network that are closed. That is, we count all paths
of length two, and we count how many of them are closed, and we divide the
second number by the ﬁrst to get a clustering coefﬁcient C that lies in the range
from zero to one:
C=

(number of closed paths of length two)
.
(number of paths of length two)

|

T RANSITIVITY

u

w

v

The path uvw (solid edges)
is said to be closed if the
third edge directly from u
to w is present (dashed
edge).

(7.39)

C = 1 implies perfect transitivity, i.e., a network whose components are all
cliques. C = 0 implies no closed triads, which happens for various topologies,
such as a tree (which has no closed loops of any kind—see Section 6.7) or a
square lattice (which has closed loops with even numbers of vertices only and
no closed triads).
Note that paths in networks, as deﬁned in Section 6.10 have a direction and
two paths that traverse the same edges but in opposite directions are counted
separately in Eq. (7.39). Thus uvw and wvu are distinct paths and are counted
separately. Similarly, closed paths are counted separately in each direction.23
An alternative way to write the clustering coefﬁcient is
C=

(number of triangles) × 6
.
(number of paths of length two)

(7.40)

Why the factor of six? It arises because each triangle in the network gets
counted six times over when we count up the number of closed paths of length
two. Suppose we have a triangle uvw. Then there are six paths of length two
22
It’s not entirely clear why the clustering coefﬁcient has the name it has. The name doesn’t
appear to be connected with the earlier use of the word clustering in social network analysis to
describe groups or clusters of vertices (see Section 11.11.2). The reader should be careful to avoid
confusing these two uses of the word.
23
In fact, we could count each path just in one direction, provided we did it for both the numerator and denominator of Eq. (7.39). Doing so would decrease both counts by a factor of two,
but the factors would cancel and the end result would be the same. In most cases, and particularly
when writing computer programs, it is easier to count paths in both directions—it avoids having
to remember which paths you have counted before.

199

M EASURES AND METRICS

in it: uvw, vwu, wuv, wvu, vuw, and uwv. Each of these six is closed, so the
number of closed paths is six times the number of triangles.
Yet another way to write the clustering coefﬁcient would be to note that
if we have a path of length two, uvw, then it is also true to say that vertices
u and w have a common neighbor in v—they share a mutual acquaintance
in social network terms. If the triad uvw is closed then u and w are themselves acquainted, so the clustering coefﬁcient can be thought of also as the
fraction of pairs of people with a common friend who are themselves friends
or equivalently as the mean probability that two people with a common friend
are themselves friends. This is perhaps the most common way of deﬁning the
clustering coefﬁcient. In mathematical notation:
C=

A triangle contains six distinct paths of length two,
all of them closed.

200

(number of triangles) × 3
.
(number of connected triples)

(7.41)

Here a “connected triple” means three vertices uvw with edges (u, v) and (v, w).
(The edge (u, w) can be present or not.) The factor of three in the numerator
arises because each triangle gets counted three times when we count the connected triples in the network. The triangle uvw for instance contains the triples
uvw, vwu, and wuv. In the older social networks literature the clustering coefﬁcient is sometimes referred to as the “fraction of transitive triples,” which is a
reference to this deﬁnition of the coefﬁcient.
Social networks tend to have quite high values of the clustering coefﬁcient.
For example, the network of ﬁlm actor collaborations discussed earlier has
been found to have C = 0.20 [241]; a network of collaborations between biologists has been found to have C = 0.09 [236]; a network of who sends email
to whom in a large university has C = 0.16 [103]. These are typical values for
social networks. Some denser networks have even higher values, as high as 0.5
or 0.6. (Technological and biological networks by contrast tend to have somewhat lower values. The Internet at the autonomous system level, for instance,
has a clustering coefﬁcient of only about 0.01. This point is discussed in more
detail in Section 8.6.)
In what sense are these clustering coefﬁcients for social networks high?
Well, let us assume, to make things simple, that everyone in a network has
about the same number c of friends. Consider one of my friends in this network and suppose they pick their friends completely at random from the whole
population. Then the chance that one of their c friends happens to be a particular one of my other friends would be c/n, where n is the size of the network.
Thus in this network the probability of two of my friends being acquainted,
which is by deﬁnition the clustering coefﬁcient, would be just c/n. Of course
it is not the case that everyone in a network has the same number of friends,

7.9

and we will see how to perform better calculations of the clustering coefﬁcient
later (Section 13.4), but this crude calculation will serve our purposes for the
moment.
For the networks cited above, the value of c/n is 0.0003 (ﬁlm actors), 0.00001
(biology collaborations), and 0.00002 (email messages). Thus the measured
clustering coefﬁcients are much larger than this estimate based on the assumption of random network connections. Even though the estimate ignores, as
we have said, any variation in the number of friends people have, the disparity between the calculated and observed values of the clustering coefﬁcient
is so large that it seems unlikely it could be eliminated just by allowing the
number of friends to vary. A much more likely explanation is that our other
assumption, that people pick their friends at random, is seriously ﬂawed. The
numbers suggest that there is a much greater chance that two people will be
acquainted if they have another common acquaintance than if they don’t.
Although this argument is admittedly crude, we will see in Section 8.6 how
to make it more accurate and so show that our basic conclusion is indeed correct.
Some social networks, such as the email network above, are directed networks. In calculating clustering coefﬁcients for direct networks, scientists have
typically just ignored their directed nature and applied Eq. (7.41) as if the edges
were undirected. It is however possible to generalize transitivity to take account of directed links. If we have a directed relation between vertices such
as “u likes v” then we can say that a triple of vertices is closed or transitive if
u likes v, v likes w, and also u likes w. (Note that there are many distinct ways
for such a triple to be transitive, depending on the directions of the edges. The
example given here is only one of six different possibilities.) One can calculate
a clustering coefﬁcient or fraction of transitive triples in the obvious fashion for
the directed case, counting all directed paths of length two that are closed and
dividing by the total number of directed paths of length two. For some reason,
however, such measurements have not often appeared in the literature.
7.9.1

|

T RANSITIVITY

u

w

v
A transitive triple of vertices in a directed network.

L OCAL CLUSTERING AND REDUNDANCY

We can also deﬁne a clustering coefﬁcient for a single vertex. For a vertex i, we
deﬁne24
Ci =

(number of pairs of neighbors of i that are connected)
.
(number of pairs of neighbors of i)

(7.42)

24
The notation Ci is used for both the local clustering coefﬁcient and the closeness centrality
and we should be careful not to confuse the two.

201

M EASURES AND METRICS

Structural holes

When the neighbors of a
node are not connected to
one another we say the network contains “structural
holes.”

202

That is, to calculate Ci we go through all distinct pairs of vertices that are neighbors of i in the network, count the number of such pairs that are connected to
each other, and divide by the total number of pairs, which is 12 k i (k i − 1) where
k i is the degree of i,. Ci is sometimes called the local clustering coefﬁcient and it
represents the average probability that a pair of i’s friends are friends of one
another.
Local clustering is interesting for several reasons. First, in many networks
it is found empirically to have a rough dependence on degree, vertices with
higher degree having a lower local clustering coefﬁcient on average. This point
is discussed in detail in Section 8.6.1.
Second, local clustering can be used as a probe for the existence of so-called
“structural holes” in a network. While it is common in many networks, especially social networks, for the neighbors of a vertex to be connected among
themselves, it happens sometimes that these expected connections between
neighbors are missing. The missing links are called structural holes and were
ﬁrst studied in this context by Burt [60]. If we are interested in efﬁcient spread
of information or other trafﬁc around a network, as we were in Section 7.7,
then structural holes are a bad thing—they reduce the number of alternative
routes information can take through the network. On the other hand structural
holes can be a good thing for the central vertex i whose friends lack connections, because they give i power over information ﬂow between those friends.
If two friends of i are not connected directly and their information about one
another comes instead via their mutual connection with i then i can control the
ﬂow of that information. The local clustering coefﬁcient measures how inﬂuential i is in this sense, taking lower values the more structural holes there are
in the network around i. Thus local clustering can be regarded as a type of
centrality measure, albeit one that takes small values for powerful individuals
rather than large ones.
In this sense, local clustering can also be thought of as akin to the betweenness centrality of Section 7.7. Where betweenness measures a vertex’s control
over information ﬂowing between all pairs of vertices in its component, local clustering is like a local version of betweenness that measures control over
ﬂows between just the immediate neighbors of a vertex. One measure is not
necessarily better than another. There may be cases in which we want to take
all vertices into account and others where we want to consider only immediate neighbors—the choice will depend on the particular questions we want to
answer. It is worth pointing out however that betweenness is much more computationally intensive to calculate than local clustering (see Section 10.3.6), and
that in practice betweenness and local clustering are strongly correlated [60].
There may in many cases be little to be gained by performing the more costly

7.9

|

T RANSITIVITY

full calculation of betweenness and much to be saved by sticking with clustering, given that the two contain much the same information.25
In his original studies of structural holes, Burt [60] did not in fact
make use of the local clustering coefﬁcient as a measure of the presence of holes.26 Instead, he used another measure, which he called
redundancy. The original deﬁnition of redundancy was rather complicated, but Borgatti [50] has shown that it can be simpliﬁed to the
following: the redundancy Ri of a vertex i is the mean number of
connections from a neighbor of i to other neighbors of i. Consider
the example shown in Fig. 7.5 in which vertex i has four neighbors.
Figure 7.5: Redundancy. The neighEach of those four could be acquainted with any of the three others,
bors of the central vertex in this ﬁgure have 0, 1, 1, and 2 connections to
but in this case none of them is connected to all three. One is conother neighbors respectively. The renected to none of the others, two are connected to one other, and
dundancy is the mean of these values:
the last is connected to two others. The redundancy is the average
Ri = 14 (0 + 1 + 1 + 2) = 1.
of these numbers Ri = 14 (0 + 1 + 1 + 2) = 1. The minimum possible value of the redundancy of a vertex is zero and the maximum is
k i − 1, where k i is the degree of vertex i.
It’s probably obvious that Ri is related to the local clustering Ci . To see
precisely what the relation is, we note that if the average number of connections from a friend of i to other friends is Ri , then the total number of connections between friends is 12 k i Ri . And the total number of pairs of friends of i is
1
2 k i ( k i − 1). The local clustering coefﬁcient, Eq. (7.42), is the ratio of these two
quantities:
1
k i Ri
Ri
.
(7.43)
=
Ci = 1 2
k
i −1
2 k i ( k i − 1)
Given that k i − 1 is the maximum value of Ri , the local clustering coefﬁcient
can be thought of as simply a version of the redundancy rescaled to have a
maximum value of 1. Applying Eq. (7.43) to the example of Fig. 7.5 implies
that the local clustering coefﬁcient for the central vertex should be Ci = 13 , and
the reader can easily verify that this is indeed the case.
A third context in which the local clustering coefﬁcient arises is in the calculation of the global clustering coefﬁcient itself. Watts and Strogatz [323] proposed calculating a clustering coefﬁcient for an entire network as the mean of
25
As an example, in Section 11.11.1 we study methods for partitioning networks into clusters
or communities and we will see that effective computer algorithms for this task can be created
based on betweenness measures, but that almost equally effective and much faster algorithms can
be created based on local clustering.
26
Actually, the local clustering coefﬁcient hadn’t yet been invented. It was ﬁrst proposed to this
author’s knowledge by Watts [321] a few years later.

203

M EASURES AND METRICS

the local clustering coefﬁcients for each vertex:
CWS =

1 n
Ci ,
n i∑
=1

(7.44)

where n is the number of vertices in the network. This is a different deﬁnition for the clustering coefﬁcient from the one given earlier, Eq. (7.41), and
the two deﬁnitions are not equivalent. Furthermore, they can give substantially different numbers for a given network and because both deﬁnitions are
in reasonably common use this can give rise to confusion. We favor our ﬁrst
deﬁnition for C, Eq. (7.41), because it has a simple interpretation and because
it is normally easier to calculate. Also the second deﬁnition, Eq. (7.44), tends
to be dominated by vertices with low degree, since they have small denominators in Eq. (7.42), and the measure thus gives a rather poor picture of the
overall properties of any network with a signiﬁcant number of such vertices.27
It’s worth noting, however, that the deﬁnition of Eq. (7.44) was actually proposed before Eq. (7.41) and, perhaps because of this, it ﬁnds moderately wide
use in network studies. So you need at least to be aware of both deﬁnitions
and clear which is being used in any particular situation.

7.10

A loop of length two in a
directed network.

R ECIPROCITY

The clustering coefﬁcient of Section 7.9 measures the frequency with which
loops of length three—triangles—appear in a network. Of course, there is
no reason why one should concentrate only on loops of length three, and
people have occasionally looked at the frequency of loops of length four or
more [44,61,133,140,238]. Triangles occupy a special place however because in
an undirected simple graph the triangle is the shortest loop we can have (and
usually the most commonly occurring). However, in a directed network this is
not the case. In a directed network, we can have loops of length two—a pair of
vertices between which there are directed edges running in both directions—
and it is interesting to ask about the frequency of occurrence of these loops
also.
The frequency of loops of length two is measured by the reciprocity, and tells
you how likely it is that a vertex that you point to also points back at you. For
instance, on the World Wide Web if my web page links to your web page, how
likely is it, on average, that yours link back again to mine? In general, it’s found
27
As discussed in Section 8.6.1, vertices with low degree tend to have high values of Ci in most
networks and this means that CWS is usually larger than the value given by Eq. (7.41), sometimes
much larger.

204

7.10

|

R ECIPROCITY

that you are much more likely to link to me if I link to you than if I don’t. (That
probably isn’t an Earth-shattering surprise, but it’s good to know when the
data bear out one’s intuitions.) Similarly in friendship networks, such as the
networks of schoolchildren described in Section 3.2 where respondents were
asked to name their friends, it is much more likely that you will name me if I
name you than if I do not.
If there is a directed edge from vertex i to vertex j in a directed network and
there is also an edge from j to i then we say the edge from i to j is reciprocated.
(Obviously the edge from j to i is also reciprocated.) Pairs of edges like this are
also sometimes called co-links, particularly in the context of the World Wide
Web [104].
The reciprocity r is deﬁned as the fraction of edges that are reciprocated.
Noting that the product of adjacency matrix elements Aij A ji is 1 if and only if
there is an edge from i to j and an edge from j to i and is zero otherwise, we
can sum over all vertex pairs i, j to get an expression for the reciprocity:
r=

1
1
Aij A ji = Tr A2 ,
m
m∑
ij

(7.45)

where m is, as usual, the total number of (directed) edges in the network.
Consider for example this small network of four vertices:

There are seven directed edges in this network and four of them are reciprocated, so the reciprocity is r = 47 ≃ 0.57. In fact, this is about the same value as
seen on the World Wide Web. There is about a 57% percent chance that if web
page A links to web page B then B also links back to A.28 As another example,
in a study of a network of who has whom in their email address book it was
found that the reciprocity was about r = 0.23 [248].
28
This ﬁgure is an unusually high one among directed networks, but there are reasons for it.
One is that many of the links between web pages are between pages on the same website, and it is
common for such pages to link to each other. If you exclude links between pages on the same site
the value of the reciprocity is lower.

205

M EASURES AND METRICS

7.11

S IGNED EDGES AND STRUCTURAL BALANCE

In some social networks, and occasionally in other networks, edges are allowed to be either “positive” or “negative.” For instance, in an acquaintance
network we could denote friendship by a positive edge and animosity by a
negative edge:

Friends

Enemies

One could also consider varying degrees of friendship or animosity—networks
with more strongly positive or negative edges in them—but for the moment
let’s stick to the simple case where each edge is in just one of two states, positive or negative, like or dislike. Such networks are called signed networks and
their edges are called signed edges.
It is important to be clear here that a negative edge is not the same as the
absence of an edge. A negative edge indicates, for example, two people who
interact regularly but dislike each other. The absence of an edge represents two
people who do not interact. Whether they would like one another if they did
interact is not recorded.
Now consider the possible conﬁgurations of three edges in a triangle in a
signed network, as depicted in Fig. 7.6. If “+” and “−” represent like and
dislike, then we can imagine some of these conﬁgurations creating social problems if they were to arise between three people in the real world. Conﬁguration (a) is ﬁne: everyone likes everyone else. Conﬁguration (b) is probably also
ﬁne, although the situation is more subtle than (a). Individuals u and v like one
another and both dislike w, but the conﬁguration can still be regarded as stable in the sense that u and v can agree over their dislike of w and get along just
ﬁne, while w hates both of them. No one is conﬂicted about their allegiances.
Put another way, w is u’s enemy and v is w’s enemy, but there is no problem
with u and v being friends if one considers that the “enemy of my enemy is my
friend.”
Conﬁguration (c) however could be problematic. Individual u likes individual v and v likes w, but u thinks w is an idiot. This is going to place a strain
on the friendship between u and v because u thinks v’s friend is an idiot. Alternatively, from the point of view of v, v has two friends, u and w and they don’t
get along, which puts v in an awkward position. In many real-life situations
of this kind the tension would be resolved by one of the acquaintances being
206

7.11

w

u

w

v
(a)

u

S IGNED EDGES AND STRUCTURAL BALANCE

w

w

v
(b)

|

u

v
(c)

u

v
(d)

Figure 7.6: Possible triad conﬁgurations in a signed network. Conﬁgurations (a) and
(b) are balanced and hence relatively stable, but conﬁgurations (c) and (d) are unbalanced and liable to break apart.

broken, i.e., the edge would be removed altogether. Perhaps v would simply
stop talking to one of his friends, for instance.
Conﬁguration (d) is somewhat ambiguous. On the one hand, it consists
of three people who all dislike each other, so no one is in doubt about where
things stand: everyone just hates everyone else. On the other hand, the “enemy of my enemy” rule does not apply here. Individuals u and v might like to
form an alliance in recognition of their joint dislike of w, but ﬁnd it difﬁcult to
do so because they also dislike each other. In some circumstances this might
cause tension. (Think of the uneasy alliance of the US and Russia against Germany during World War II, for instance.) But what one can say deﬁnitely is
that conﬁguration (d) is often unstable. There may be little reason for the three
to stay together when none of them likes the others. Quite probably three enemies such as these would simply sever their connections and go their separate
ways.
The feature that distinguishes the two stable conﬁgurations in Fig. 7.6 from
the unstable ones is that they have an even number of minus signs around the
loop.29 One can enumerate similar conﬁgurations for longer loops, of length
four or greater, and again ﬁnd that loops with even numbers of minus signs
appear stable and those with odd numbers unstable.
This alone would be an observation of only slight interest, where it not
for the intriguing fact that this type of stability really does appear have an
effect on the structure of networks. In surveys it is found that the unstable
conﬁgurations in Fig. 7.6, the ones with odd numbers of minus signs, occur

Two stable conﬁgurations
in loops of length four.

29
This is similar in spirit to the concept of “frustration” that arises in the physics of magnetic
spin systems.

207

M EASURES AND METRICS

far less often in real social networks than the stable conﬁgurations with even
numbers of minus signs.
Networks containing only loops with even numbers of minus signs are
said to show structural balance, or sometimes just balance. An important consequence of balance in networks was proved by Harary [154]:
A balanced network can be divided into connected groups of vertices
such that all connections between members of the same group are
positive and all connections between members of different groups are
negative.
Note that the groups in question can consist of a single vertex or many vertices,
and there may be only one group or there may be very many. Figure 7.7 shows
a balanced network and its division into groups. Networks that can be divided
into groups like this are said to be clusterable. Harary’s theorem tells us that all
balanced networks are clusterable.
Harary’s theorem is straightforward to prove, and the proof is
“constructive,” meaning that it shows not only when a network is
clusterable but also tells us what the groups are.30 We consider initially only networks that are connected—they have just one component. In a moment we will relax this condition. We will color in the
vertices of the network each in one of two colors, denoted by the
open and ﬁlled circles in Fig. 7.7, for instance. We start with any
vertex we please and color it with whichever color we please. Then
Figure 7.7: A balanced, clusterable
we color in the others according to the following algorithm:
network. Every loop in this network
1. A vertex v connected by a positive edge to another u that has
contains an even number of minus
already been colored gets colored the same as u.
signs. The dotted lines indicate the di2.
A
vertex v connected by a negative edge to another u that has
vision of the network into clusters such
already been colored gets colored the opposite color from u.
that all acquaintances within clusters
For most networks it will happen in the course of this coloring prohave positive connections and all acquaintances in different clusters have
cess that we sometimes come upon a vertex whose color has already
negative connections.
been assigned. When this happens there is the possibility of a conﬂict arising between the previously assigned color and the one that
we would like to assign to it now according to the rules above. However, as
we now show, this conﬂict only arises if the network as a whole is unbalanced.
If in coloring in a network we come upon a vertex that has already been
colored in, it immediately implies that there must be another path by which
that vertex can be reached from our starting point and hence that there is at
least one, and possibly more than one, loop in the network to which this ver30

208

The proof we give is not Harary’s proof, which was quite different and not constructive.

u
v
(a)

|

Even number of
minus signs

Odd number of
minus signs

7.11

S IGNED EDGES AND STRUCTURAL BALANCE

u
v
(b)

Figure 7.8: Proof that a balanced network is clusterable. If we fail to color a network in
two colors as described in the text, then there must exist a loop in the network that has
one or other of the two conﬁgurations shown here, both of which have an odd number
of minus signs around them (counting the one between the vertices u and v), and hence
the network is not balanced.

tex belongs—the loop consisting of the two paths between the starting point
and the vertex. Since the network is balanced, every loop to which our vertex belongs must have an even number of negative edges around it. Now let
us suppose that the color already assigned to the vertex is in conﬂict with the
one we would like to assign it now. There are two ways in which this could
happen, as illustrated in Fig. 7.8. In case (a), we color in a vertex u and then
move onto its neighbor v, only to ﬁnd that v has already been colored the opposite color to u, even though the edge between them is positive. This presents
a problem. But if u and v are opposite colors, then around any loop containing them both there must be an odd number of minus signs, so that the color
changes an odd number of times and ends up the opposite of what it started
out as. And if there is an odd number of minus signs around the loop, then the
network is not balanced.
In case (b) vertices u and v have the same color but the edge between them
is negative. Again we have a problem. But if u and v are the same color then
there must be an even number of negative edges around the rest of the loop
connecting them which, along with the negative edge between u and v, gives
us again an odd total number of negative edges around the entire loop, and
hence the network is again not balanced.
Either way, if we ever encounter a conﬂict about what color a vertex should
have then the network must be unbalanced. If the network is balanced, therefore, we will never encounter such a conﬂict and we will be able to color the
entire network with just two colors while obeying the rules.
Once we have colored the network in this way, we can immediately deduce
the identity of the groups that satisfy Harary’s theorem: we simply divide
209

M EASURES AND METRICS

the network into contiguous clusters of vertices that have the same color—see
Fig. 7.7 again. In every such cluster, since all vertices have the same color,
they must be joined by positive edges. Conversely, all edges that connected
different clusters must be negative, since the clusters have different colors. (If
they did not have different colors they would be considered the same cluster.)
Thus Harary’s theorem is proved and at the same time we have deduced a
method for constructing the clusters.31 It only remains to extend the proof to
networks that have more than one component, but this is trivial, since we can
simply repeat the proof above for each component separately.
The practical importance of Harary’s result rests on the fact that, as mentioned earlier, many real social networks are found naturally to be in a balanced or mostly balanced state. In such cases it would be possible, therefore,
for the network to form into groups such that everyone likes others within
their group with whom they have contact and dislikes those in other groups.
It is widely assumed in social network theory that this does indeed often happen. Structural balance and clusterability in networks are thus a model for
cliquishness or insularity, with people tending to stick together in like-minded
groups and disdaining everyone outside their immediate community.
It is worth asking whether the inverse of Harary’s clusterability theorem
is also true. Is it also the case that a network that is clusterable is necessarily
balanced? The answer is no, as this simple counter-example shows:

31

As an interesting historical note, we observe that while Harary’s proof of his theorem is perfectly correct, his interpretation of it was, in this author’s opinion, erroneous. In his 1953 paper [154], he describes the meaning of the theorem in the following words: “A psychological interpretation of Theorem 1 is that a ‘balanced group’ consists of two highly cohesive cliques which
dislike each other.” (Harary is using the word “clique” in a non-technical sense here to mean a
closed group of people, rather than in the graph theoretical sense of Section 7.8.1.) However, just
because it is possible to color the network in two colors as described above does not mean the network forms two groups. Since the vertices of a single color are not necessarily contiguous, there
are in general many groups of each color, and it seems unreasonable to describe these groups as
forming a single “highly cohesive clique” when in fact they have no contact at all. Moreover, it is
neither possible nor correct to conclude that the members of two groups of opposite colors dislike
each other unless there is at least one edge connecting the two. If two groups of opposite colors
never actually have any contact then it might be that they would get along just ﬁne if they met.
It’s straightforward to prove that such an occurrence would lead to an unbalanced network, but
Harary’s statement says that the present balanced network implies dislike, and this is untrue. Only
if the network were to remain balanced upon addition of one or more edges between groups of
unlike colors would his conclusion be accurate.

210

7.12

|

S IMILARITY

In this network all three vertices dislike each other, so there is an odd number
of minus signs around the loop, but there is no problem dividing the network
into three clusters of one vertex each such that everyone dislikes the members
of the other clusters. This network is clusterable but not balanced.

7.12

S IMILARITY

Another central concept in social network analysis is that of similarity between
vertices. In what ways can vertices in a network be similar, and how can we
quantify that similarity? Which vertices in a given network are most similar
to one another? Which vertex v is most similar to a given vertex u? Answers
to questions like these can help us tease apart the types and relationships of
vertices in social networks, information networks, and others. For instance,
one could imagine that it might be useful to have a list of web pages that are
similar—in some appropriate sense—to another page that we specify. In fact,
several web search engines already provide a feature like this: “Click here for
pages similar to this one.”
Similarity can be determined in many different ways and most of them
have nothing to do with networks. For example, commercial dating and matchmaking services try to match people with others to whom they are similar by
using descriptions of people’s interests, background, likes, and dislikes. In effect, these services are computing similarity measures between people based
on personal characteristics. Our focus in this book, however, is on networks,
so we will concentrate on the more limited problem of determining similarity between the vertices of a network using the information contained in the
network structure.
There are two fundamental approaches to constructing measures of network similarity, called structural equivalence and regular equivalence. The names
are rather opaque, but the ideas they represent are simple enough. Two vertices in a network are structurally equivalent if they share many of the same
network neighbors. In Fig. 7.9a we show a sketch depicting structural equivalence between two vertices i and j—the two share, in this case, three of the
same neighbors, although both also have other neighbors that are not shared.
Regular equivalence is more subtle. Two regularly equivalent vertices do
not necessarily share the same neighbors, but they have neighbors who are
211

M EASURES AND METRICS

i

i

j

(a) Structural equivalence

j

(b) Regular equivalence

Figure 7.9: Structural equivalence and regular equivalence. (a) Vertices i and j are
structurally equivalent if they share many of the same neighbors. (b) Vertices i and j
are regularly equivalent if their neighbors are themselves equivalent (indicated here by
the different shades of vertices).

themselves similar. Two history students at different universities, for example,
may not have any friends in common, but they can still be similar in the sense
that they both know a lot of other history students, history instructors, and so
forth. Similarly, two CEOs at two different companies may have no colleagues
in common, but they are similar in the sense that they have professional ties to
their respective CFO, CIO, members of the board, company president, and so
forth. Regular equivalence is illustrated in Fig. 7.9b.
In the next few sections we describe some mathematical measures that
quantify these ideas of similarity. As we will see, measures for structural
equivalence are considerably better developed than those for regular equivalence.
7.12.1

C OSINE SIMILARITY

We start by looking at measures of structural equivalence and we will concentrate on undirected networks. Perhaps the simplest and most obvious measure of structural equivalence would be just a count of the number of common
neighbors two vertices have. In an undirected network the number nij of common neighbors of vertices i and j is given by
nij = ∑ Aik Akj ,

(7.46)

k

which is the ijth element of A2 . This quantity is closely related to the “cocitation” measure introduced in Section 6.4.1. Cocitation is deﬁned for directed
212

7.12

|

S IMILARITY

networks whereas we are here considering undirected ones, but otherwise it is
essentially the same thing.
However, a simple count of common neighbors for two vertices is not on
its own a very good measure of similarity. If two vertices have three common
neighbors is that a lot or a little? It’s hard to tell unless we know, for instance,
what the degrees of the vertices are, or how many common neighbors other
pairs of vertices share. What we need is some sort of normalization that places
the similarity value on some easily understood scale. One strategy might be
simply to divide by the total number of vertices in the network n, since this is
the maximum number of common neighbors two vertices can have in a simple
graph. (Technically the maximum is actually n − 2, but the difference is small
when n is large.) However, this unduly penalizes vertices with low degree: if
a vertex has degree three, then it can have at most three neighbors in common
with another vertex, but the two vertices would still receive a small similarity
value if the divisor n were very large. A better measure would allow for the
varying degrees of vertices. Such a measure is the cosine similarity, sometimes
also called Salton’s cosine.
In geometry, the inner or dot product of two vectors x and y is given by
x · y = |x| |y| cos θ, where |x| is the magnitude of x and θ is the angle between
the two vectors. Rearranging, we can write the cosine of the angle as
cos θ =

x·y
.
|x| |y|

(7.47)

Salton [290] proposed that we regard the ith and jth rows (or columns) of the
adjacency matrix as two vectors and use the cosine of the angle between them
as our similarity measure. Noting that the dot product of two rows is simply
∑k Aik Akj for an undirected network, this gives us a similarity
σij = cos θ = 

∑k Aik Akj
.

∑k A2ik ∑k A2jk

(7.48)

Assuming our network is an unweighted simple graph, the elements of the
adjacency matrix take only the values 0 and 1, so that A2ij = Aij for all i, j. Then
∑k A2ik = ∑k Aik = k i , where k i is the degree of vertex i (see Eq. (6.19)). Thus
σij =

nij
∑k Aik Akj
√
= √
.
ki k j
ki k j

(7.49)

The cosine similarity of i and j is therefore the number of common neighbors
of the two vertices divided by the geometric mean of their degrees. For the

213

M EASURES AND METRICS

vertices i and j depicted in Fig. 7.9a, for instance, the cosine similarity would
be
3
= 0.671 . . .
(7.50)
σij = √
4×5
Notice that the cosine similarity is technically undeﬁned if one or both of the
vertices has degree zero, but by convention we normally say in that case that
σij = 0.
The cosine similarity provides a natural scale for our similarity measure.
Its value always lies in the range from 0 to 1. A cosine similarity of 1 indicates
that two vertices have exactly the same neighbors. A cosine similarity of zero
indicates that they have none of the same neighbors. Notice that the cosine
similarity can never be negative, being a sum of positive terms, even though
cosines in general can of course be negative.
7.12.2

P EARSON COEFFICIENTS

An alternative way to normalize the count of common neighbors is to compare
it with the expected value that count would take on a network in which vertices choose their neighbors at random. This line of argument leads us to the
Pearson correlation coefﬁcient.
Suppose vertices i and j have degrees k i and k j respectively. How many
common neighbors should we expect them to have? This is straightforward to
calculate if they choose their neighbors purely at random. Imagine that vertex i
chooses k i neighbors uniformly at random from the n possibilities open to it (or
n − 1 on a network without self-loops, but the distinction is slight for a large
network), and vertex j similarly chooses k j neighbors at random. For the ﬁrst
neighbor that j chooses there is a probability of k i /n that it will choose one of
the ones k i chose, and similarly for each succeeding choice. (We neglect the
possibility of choosing the same neighbor twice, since it is small for a large
network.) Then in total the expected number of common neighbors between
the two vertices will be k j times this, or k i k j /n.
A reasonable measure of similarity between two vertices is the actual number of common neighbors they have minus the expected number that they

214

7.12

|

S IMILARITY

would have if they chose their neighbors at random:
ki k j

1

∑ Aik A jk − n = ∑ Aik A jk − n ∑ Aik ∑ A jl
k

k

k

l

= ∑ Aik A jk − n Ai A j
k

= ∑ Aik A jk − Ai A j
k

= ∑( Aik − Ai )( A jk − A j ),

(7.51)

k

where Ai denotes the mean n−1 ∑k Aik of the elements of the ith row of the
adjacency matrix. Equation (7.51) will be zero if the number of common neighbors of i and j is exactly what we would expect on the basis of random chance.
If it is positive, then i and j have more neighbors than we would expect by
chance, which we take as an indication of similarity between the two. Equation (7.51) can also be negative, indicating that i and j have fewer neighbors
than we would expect, a possible sign of dissimilarity.
Equation (7.51) is simply n times the covariance cov( Ai , A j ) of the two rows
of the adjacency matrix. It is common to normalize the covariance, as we did
with the cosine similarity, so that its maximum value is 1. The maximum value
of the covariance of any two sets of quantities occurs when the sets are exactly
the same, in which case their covariance is just equal to the variance of either
set, which we could write as σi2 or σj2 , or in symmetric form as σi σj . Normalizing by this quantity then gives us the standard Pearson correlation coefﬁcient:
rij =

cov( Ai , A j )
∑k ( Aik − Ai )( A jk − A j )

= 
.
σi σj
∑k ( Aik − Ai )2 ∑k ( A jk − A j )2

(7.52)

This quantity lies strictly in the range −1 ≤ rij ≤ 1.
The Pearson coefﬁcient is a widely used measure of similarity. It allows
us to say when vertices are both similar or dissimilar compared with what we
would expect if connections in the network were formed at random.
7.12.3

O THER MEASURES OF STRUCTURAL EQUIVALENCE

There are many other possible measures of structural equivalence. For instance, one could also normalize the number nij of common neighbors by dividing by (rather than subtracting) the expected value of k i k j /n. That would
give us a similarity of
nij
∑k Aik A jk
=n
.
(7.53)
k i k j /n
∑k Aik ∑k A jk
215

M EASURES AND METRICS

This quantity will be 1 if the number of common neighbors is exactly as expected on the basis of chance, greater than one if there are more common
neighbors than that, and less than one for dissimilar vertices with fewer common neighbors than we would expect by chance. It is never negative and has
the nice property that it is zero when the vertices in question have no common
neighbors. This measure could be looked upon as an alternative to the cosine
similarity: the two differ in that one has the product of the degrees
√ k i k j in the
denominator while the other has the square root of the product k i k j . It has
been suggested that Eq. (7.53) may in some cases be a superior measure to the
cosine similarity because, by normalizing with respect to the expected number
of common neighbors rather than the maximum number, it allows us to easily identify statistically surprising coincidences between the neighborhoods of
vertices, which cosine similarity does not [195].
Another measure of structural equivalence is the so-called Euclidean distance,32 which is equal to the number of neighbors that differ between two
vertices. That is, it is the number of vertices that are neighbors of i but not of j,
or vice versa. Euclidean distance is really a dissimilarity measure, since it is
larger for vertices that differ more.
In terms of the adjacency matrix the Euclidean distance dij between two
vertices can be written
(7.54)
dij = ∑( Aik − A jk )2 .
k

As with our other measures it is sometimes convenient to normalize the Euclidean distance by dividing by its possible maximum value. The maximum
value of dij occurs when two vertices have no neighbors in common, in which
case the distance is equal to the sum of the degrees of the vertices: dij = k i + k j .
Dividing by this maximum value the normalized distance is
nij
∑ ( Aik + A jk − 2Aik A jk )
∑k ( Aik − A jk )2
= k
= 1−2
,
ki + k j
ki + k j
ki + k j

(7.55)

where we have made use of the fact that A2ij = Aij because Aij is always zero or
one, and nij is again the number of neighbors that i and j have in common. To
within additive and multiplicative constants, this normalized Euclidean distance can thus be regarded as just another alternative normalization of the
number of common neighbors.
32
This is actually a bad name for it—it should be called Hamming distance, since it is essentially
the same as the Hamming distance of computer science and has nothing to do with Euclid.

216

|

7.12

7.12.4

S IMILARITY

R EGULAR EQUIVALENCE

The similarity measures discussed in the preceding sections are all measures of
structural equivalence, i.e., they are measures of the extent to which two vertices share the same neighbors. The other main type of similarity considered
in social network analysis is regular equivalence. As described above, regularly equivalent vertices are vertices that, while they do not necessarily share
neighbors, have neighbors who are themselves similar—see Fig. 7.9b again.
Quantitative measures of regular equivalence are less well developed than
measures of structural equivalence. In the 1970s social network analysts came
up with some rather complicated computer algorithms, such as the “REGE”
algorithm of White and Reitz [320, 327], that were intended to discover regular
equivalence in networks, but the operation of these algorithms is involved and
not easy to interpret. More recently, however, some simpler algebraic measures
have been developed that appear to work reasonably well. The basic idea [45,
162, 195] is to deﬁne a similarity score σij such that i and j have high similarity
if they have neighbors k and l that themselves have high similarity. For an
undirected network we can write this as
σij = α ∑ Aik A jl σkl ,

(7.56)

kl

or in matrix terms σ = αAσA. Although it may not be immediately clear,
this expression is a type of eigenvector equation, where the entire matrix σ of
similarities is the eigenvector. The parameter α is the eigenvalue (or more correctly, its inverse) and, as with the eigenvector centrality of Section 7.2, we are
normally interested in the leading eigenvalue, which can be found by standard
methods.
This formula however has some problems. First, it doesn’t necessarily give
a high value for the “self-similarity” σii of a vertex to itself, which is counterintuitive. Presumably, all vertices are highly similar to themselves! As a consequence of this, Eq. (7.56) also doesn’t necessarily give a high similarity score to
vertex pairs that have a lot of common neighbors, which in the light of our examination of structural equivalence in the preceding few sections we perhaps
feel it should. If we had high self-similarity scores for all vertices, on the other
hand, then Eq. (7.56) would automatically give high similarity also to vertices
with many common neighbors.
We can ﬁx these problems by introducing an extra diagonal term in the
similarity thus:
(7.57)
σij = α ∑ Aik A jl σkl + δij ,

k

l

i

j

Vertices i and j are considered similar (dashed line) if
they have respective neighbors k and l that are themselves similar.

See Section 11.1 for a discussion of computer algorithms for ﬁnding eigenvectors.

kl

217

M EASURES AND METRICS

or in matrix notation
σ = αAσA + I.

(7.58)

However, while expressions like this have been proposed as similarity measures, they still suffer from some problems. Suppose we evaluate Eq. (7.58) by
repeated iteration, taking a starting value, for example, of σ (0) = 0 and using
it to compute σ (1) = αAσA + I, and then repeating the process many times
until σ converges. On the ﬁrst few iterations we will get the following results:
σ (1) = I,

(7.59a)

σ (2) = αA2 + I,
σ

k
i

j

In the modiﬁed deﬁnition
of regular equivalence vertex i is considered similar
to vertex j (dashed line) if
it has a neighbor k that is itself similar to j.

(3)

(7.59b)

= α A + αA + I.
2

4

2

(7.59c)

The pattern is clear: in the limit of many iterations, we will get a sum over
even powers of the adjacency matrix. However, as discussed in Section 6.10,
the elements of the rth power of the adjacency matrix count paths of length r
between vertices, and hence this measure of similarity is a weighted sum over
the numbers of paths of even length between pairs of vertices.
But why should we consider only paths of even length? Why not consider
paths of all lengths? These questions lead us to a better deﬁnition of regular
equivalence as follows: vertices i and j are similar if i has a neighbor k that is
itself similar to j.33 Again we assume that vertices are similar to themselves,
which we can represent with a diagonal δij term in the similarity, and our similarity measure then looks like
σij = α ∑ Aik σkj + δij ,

(7.60)

σ = αAσ + I,

(7.61)

k

or
in matrix notation. Evaluating this expression by iterating again starting from
σ (0) = 0, we get
σ (1) = I,

33

(7.62a)

σ

(2)

= αA + I,

(7.62b)

σ

(3)

= α A + αA + I.

(7.62c)

2

2

This deﬁnition is not obviously symmetric with respect to i and j but, as we see, does in fact
give rise to an expression for the similarity that is symmetric.

218

7.12

|

S IMILARITY

In the limit of a large number of iterations this gives
∞

σ = ∑ (αA)m = (I − αA)−1 ,

(7.63)

m =0

which we could also have deduced directly by rearranging Eq. (7.61). Now
our similarity measure includes counts of paths at all lengths, not just even
paths. In fact, we can see now that this similarity measure could be deﬁned
a completely different way, as a weighted count of all the paths between the
vertices i and j with paths of length r getting weight αr . So long as α < 1,
longer paths will get less weight than shorter ones, which seems sensible: in
effect we are saying that vertices are similar if they are connected either by a
few short paths or by very many long ones.
Equation (7.63) is reminiscent of the formula for the Katz centrality, Eq.
(7.10). We could call Eq. (7.63) the “Katz similarity” perhaps, although Katz
himself never discussed it. The Katz centrality of a vertex would then be simply the sum of the Katz similarities of that vertex to all others. Vertices that
are similar to many others would get high centrality, a concept that certainly
makes intuitive sense. As with the Katz centrality, the value of the parameter
α is undetermined—we are free to choose it as we see ﬁt—but it must satisfy
α < 1/κ1 if the sum in Eq. (7.63) is to converge, where κ1 is the largest eigenvalue of the adjacency matrix.
In a sense, this regular equivalence measure can be seen as a generalization
of our structural equivalence measures in earlier sections. With those measures
we were counting the common neighbors of a pair of vertices, but the number
of common neighbors is also of course the number of paths of length two between the vertices. Our “Katz similarity” measure merely extends this concept
to counting paths of all lengths.
Some variations of this similarity measure are possible. As deﬁned it tends
to give high similarity to vertices that have high degree, because if a vertex
has many neighbors it tends to increase the number of those neighbors that
are similar to any other given vertex and hence increases the total similarity
to that vertex. In some cases this might be desirable: maybe the person with
many friends should be considered more similar to others than the person with
few. However, in other cases it gives an unwanted bias in favor of high-degree
nodes. Who is to say that two hermits are not “similar” in an interesting sense?
If we wish, we can remove the bias in favor of high degree by dividing by
vertex degree thus:
α
(7.64)
σij = ∑ Aik σkj + δij ,
ki k

219

M EASURES AND METRICS

or in matrix notation σ = αD−1 Aσ + I, where, as previously, D is the diagonal
matrix with elements Dii = k i . This expression can be rearranged to read:34
σ = (I − αD−1 A)−1 = (D − αA)−1 D.

(7.65)

Another useful variant is to consider cases where the last term in Eqs. (7.60)
or (7.64) is not simply diagonal, but includes off-diagonal terms too. Such
a generalization would allow us to specify explicitly that particular pairs of
vertices are similar, based on some other (probably non-network) information
that we have at our disposal. Going back to the example of CEOs at companies that we gave at the beginning of Section 7.12, we might, for example, want
to state explicitly that the CFOs and CIOs and so forth at different companies
are similar, and then our similarity measure would, we hope, correctly deduce
from the network structure that the CEOs are similar also. This kind of approach is particularly useful in the case of networks that consist of more than
one component, so that some pairs of vertices are not connected at all. If, for
instance, we have two separate components representing people in two different companies, then there will be no paths of any length between individuals
in different companies, and hence a measure like (7.60) or (7.64) will never assign a non-zero similarity to such individuals. If however, we explicitly insert
some similarities between members of the different companies, our measure
will then be able to generalize and extend those inputs to deduce similarities
between other members.
This idea of generalizing from a few given similarities arises in other contexts too. For example, in the ﬁelds of machine learning and information retrieval there is a considerable literature on how to generalize known similarities between a subset of the objects in a collection of, say, text documents to
the rest of the collection, based on network data or other information.

7.13

H OMOPHILY AND ASSORTATIVE MIXING

Consider Fig. 7.10, which shows a friendship network of children at an American school, determined from a questionnaire of the type discussed in Section 3.2.35 One very clear feature that emerges from the ﬁgure is the division of
34

It is interesting to note that when we expand this measure in powers of the adjacency matrix,
as we did in Eq. (7.63), the second-order (i.e., path-length two) term is the same as the structural
equivalence measure of Eq. (7.53), which perhaps lends further credence to both expressions as
natural measures of similarity.
35

The study used a “name generator”—students were asked to list the names of others they
considered to be their friends. This results in a directed network, but we have neglected the edge

220

7.13

|

H OMOPHILY AND ASSORTATIVE MIXING

Black
White
Other
Figure 7.10: Friendship network at a US high school. The vertices in this network represent 470 students at a US
high school (ages 14 to 18 years). The vertices are color coded by race as indicated in the key. Data from the National
Longitudinal Study of Adolescent Health [34, 314].

the network into two groups. It turns out that this division is principally along
lines of race. The different shades of the vertices in the picture correspond to
students of different race as denoted in the legend, and reveal that the school is
sharply divided between a group composed principally of black children and
a group composed principally of white.
This is not news to sociologists, who have long observed and discussed
such divisions [225]. Nor is the effect speciﬁc to race. People are found to
form friendships, acquaintances, business relations, and many other types of
tie based on all sorts of characteristics, including age, nationality, language, income, educational level, and many others. Almost any social parameter you
directions in the ﬁgure. In our representation there is an undirected edge between vertices i and j
if either of the pair considers the other to be their friend (or both).

221

M EASURES AND METRICS

can imagine plays into people’s selection of their friends. People have, it appears, a strong tendency to associate with others whom they perceive as being
similar to themselves in some way. This tendency is called homophily or assortative mixing.
More rarely, one also encounters disassortative mixing, the tendency for people to associate with others who are unlike them. Probably the most widespread
and familiar example of disassortative mixing is mixing by gender in sexual
contact networks. The majority of sexual partnerships are between individuals of opposite sex, so they represent connections between people who differ
in their gender. Of course, same-sex partnerships do also occur, but they are a
much smaller fraction of the ties in the network.
Assortative (or disassortative) mixing is also seen in some nonsocial networks. Papers in a citation network, for instance, tend to cite other papers in
the same ﬁeld more than they do papers in different ﬁelds. Web pages written
in a particular language tend to link to others in the same language.
In this section we look at how assortative mixing can be quantiﬁed. Assortative mixing by discrete characteristics such as race, gender, or nationality
is fundamentally different from mixing by a scalar characteristic like age or
income, so we treat the two cases separately.
7.13.1

A SSORTATIVE MIXING BY ENUMERATIVE CHARACTERISTICS

Suppose we have a network in which the vertices are classiﬁed according to
some characteristic that has a ﬁnite set of possible values. The values are
merely enumerative—they don’t fall in any particular order. For instance, the
vertices could represent people and be classiﬁed according to nationality, race,
or gender. Or they could be web pages classiﬁed by what language they are
written in, or biological species classiﬁed by habitat, or any of many other possibilities.
The network is assortative if a signiﬁcant fraction of the edges in the network run between vertices of the same type, and a simple way to quantify
assortativity would be to measure that fraction. However, this is not a very
good measure because, for instance, it is 1 if all vertices belong to the same
single type. This is a trivial sort of assortativity: all friends of a human being, for example, are also human beings,36 but this is not really an interesting
statement. What we would like instead is a measure that is large in non-trivial
cases but small in trivial ones.
A good measure turns out to be the following. We ﬁnd the fraction of edges
36

222

Ignoring, for the purposes of argument, dogs, cats, imaginary friends, and so forth.

7.13

|

H OMOPHILY AND ASSORTATIVE MIXING

that run between vertices of the same type, and then we subtract from that ﬁgure the fraction of such edges we would expect to ﬁnd if edges were positioned
at random without regard for vertex type. For the trivial case in which all vertices are of a single type, for instance, 100% of edges run between vertices of
the same type, but this is also the expected ﬁgure, since there is nowhere else
for the edges to fall. The difference of the two numbers is then zero, telling us
that there is no non-trivial assortativity in this case. Only when the fraction of
edges between vertices of the same type is signiﬁcantly greater than we would
expect on the basis of chance will our measure give a positive score.
In mathematical terms, let us denote by ci the class or type of vertex i, which
is an integer 1 . . . nc , with nc being the total number of classes. Then the total
number of edges that run between vertices of the same type is

∑ δ(ci , c j ) = 12 ∑ Aij δ(ci , c j ),

edges (i,j)

(7.66)

ij

where δ(m, n) is the Kronecker delta and the factor of 12 accounts for the fact
that every vertex pair i, j is counted twice in the second sum.
Calculating the expected number of edges between vertices if edges are
placed at random takes a little more work. Consider a particular edge attached
to vertex i, which has degree k i . There are by deﬁnition 2m ends of edges in
the entire network, where m is as usual the total number of edges, and the
chances that the other end of our particular edge is one of the k j ends attached
to vertex j is thus k j /2m if connections are made purely at random.37 Counting
all k i edges attached to i, the total expected number of edges between vertices i
and j is then k i k j /2m, and the expected number of edges between all pairs of
vertices of the same type is
1
2

ki k j

∑ 2m δ(ci , c j ),

(7.67)

ij

where the factor of 12 , as before, prevents us from double-counting vertex pairs.
Taking the difference of (7.66) and (7.67) then gives us an expression for the
difference between the actual and expected number of edges in the network
37

Technically, we are making connections at random while preserving the vertex degrees. We
could in principle ignore vertex degrees and make connections truly at random, but in practice
this is found to give much poorer results.

223

M EASURES AND METRICS

that join vertices of like types:
1
2

ki k j

ki k j

∑ Aij δ(ci , c j ) − 12 ∑ 2m δ(ci , c j ) = 12 ∑ Aij − 2m
ij

ij

δ ( c i , c j ).

ij

(7.68)
Conventionally, one calculates not the number of such edges but the fraction,
which is given by this same expression divided by the number m of edges:
Q=

ki k j
1
Aij −
2m ∑
2m
ij

δ ( c i , c j ).

(7.69)

This quantity Q is called the modularity [239,250] and is a measure of the extent
to which like is connected to like in a network. It is strictly less than 1, takes
positive values if there are more edges between vertices of the same type than
we would expect by chance, and negative ones if there are less.
For Fig. 7.10, for instance, where the types are the three ethnic classiﬁcations “black,” “white,” and “other,” we ﬁnd a modularity value of Q = 0.305,
indicating (positive) assortative mixing by race in this particular network.38
Negative values of the modularity indicate disassortative mixing. We might
see a negative modularity, for example, in a network of sexual partnerships
where most partnerships were between individuals of opposite sex.
The quantity
ki k j
(7.70)
Bij = Aij −
2m
in Eq. (7.69) appears in a number of situations in the study of networks. We will
encounter it, for instance, in Section 11.8 when we study community detection
in networks. In some contexts it is useful to consider Bij to be an element of a
matrix B, which itself is called the modularity matrix.
The modularity, Eq. (7.69), is always less than 1 but in general it does not
achieve the value Q = 1 even for a perfectly mixed network, one in which
every vertex is connected only to others of the same type. Depending on the
sizes of the groups and the degrees of vertices, the maximum value of Q can
be considerably less than 1. This is in some ways unsatisfactory: how is one to
38
An alternative measure of assortativity has been proposed by Gupta et al. [152]. That measure
however gives equal weight to each group of vertices, rather than to each edge as the modularity
does. With this measure if one had a million vertices of each of two types, which mixed with
one another entirely randomly, and ten more vertices of a third type that connected only among
themselves, one would end up with a score of about 0.5 [239], which appears to imply strong
assortativity when in fact almost all of the network mixes randomly. For most purposes therefore,
the measure of Eq. (7.69) gives results more in line with our intuitions.

224

7.13

|

H OMOPHILY AND ASSORTATIVE MIXING

know when one has strong assortative mixing and when one doesn’t? To rectify the problem, we can normalize Q by dividing by its value for the perfectly
mixed network. With perfect mixing all edges fall between vertices of the same
type and hence δ(ci , c j ) = 1 whenever Aij = 1. This means that the ﬁrst term
in the sum in Eq. (7.69) sums to 2m and the modularity for the perfectly mixed
network is
ki k j
1
2m − ∑
δ ( ci , c j ) .
(7.71)
Qmax =
2m
2m
ij
Then the normalized value of the modularity is given by
∑ij ( Aij − k i k j /2m)δ(ci , c j )
Q
=
.
Qmax
2m − ∑ij (k i k j /2m)δ(ci , c j )

(7.72)

This quantity, sometimes called an assortativity coefﬁcient, now takes a maximum value of 1 on a perfectly mixed network.
Although it can be a useful measure in some circumstances, however, Eq.
(7.72) is only rarely used. Most often, the modularity is used in its unnormalized form, Eq. (7.69).
An alternative form for the modularity, which is sometimes useful in practical situations, can be derived in terms of the quantities
ers =

1
Aij δ(ci , r ) δ(c j , s),
2m ∑
ij

(7.73)

which is the fraction of edges that join vertices of type r to vertices of type s,
and
1
k i δ ( c i , r ),
(7.74)
ar =
2m ∑
i
which is the fraction of ends of edges attached to vertices of type r. Then,
noting that
(7.75)
δ ( c i , c j ) = ∑ δ ( c i , r ) δ ( c j , r ),
r

we have, from Eq. (7.69)
ki k j
1
Aij −
δ ( ci , r ) δ ( c j , r )
2m ∑
2m ∑
r
ij


1
1
1
Aij δ(ci , r )δ(c j , r ) −
k i δ ( ci , r )
k j δ(c j , r )
=∑
2m ∑
2m ∑
2m ∑
r
ij
i
j


(7.76)
= ∑ err − a2r .

Q=

r

225

M EASURES AND METRICS

This form can be useful, for instance, when we have network data in the form
of a list of edges and the types of the vertices at their ends, but no explicit data
on vertex degrees. In such a case ers and ar are relatively easy to calculate,
while Eq. (7.69) is quite awkward.
7.13.2

A sketch of stratiﬁed
network in which most
connections run between
vertices at or near the same
“level” in the network,
with level along the vertical axis in this case and
also denoted by the shades
of the vertices.

A SSORTATIVE MIXING BY SCALAR CHARACTERISTICS

We can also have homophily in a network according to scalar characteristics
like age or income. These are characteristics whose values come in a particular
order, so that it is possible say not only when two vertices are exactly the same
according to the characteristic but also when they are approximately the same.
For instance, while two people can certainly be of exactly the same age—born
on the same day even—they can also be approximately the same age—born
within a couple of years of one another, say—and people could (and in fact often do) choose who they associate with on the basis of such approximate ages.
There is no equivalent approximate similarity for the enumerative characteristics of the previous section: there is no sense in which people from France and
Germany, say, are more nearly of the same nationality than people from France
and Spain.39
If network vertices with similar values of a scalar characteristic tend to be
connected together more often that those with different values then the network is considered assortatively mixed according to that characteristic. If, for
example, people are friends with others around the same age as them, then the
network is assortatively mixed by age. Sometimes you may also hear it said
that the network is stratiﬁed by age, which means the same thing—one can
think of age as a one-dimensional scale or axis, with individuals of different
ages forming connected “strata” within the network.
Consider Fig. 7.11, which shows friendship data for the same set of US
schoolchildren as Fig. 7.10 but now as a function of age. Each dot in the ﬁgure
corresponds to one pair of friends and the position of the dot along the two
axes gives the ages of the friends, with ages measured by school grades.40 As
the ﬁgure shows, there is substantial assortative mixing by age among the students: many dots lie within the boxes close to the diagonal line that represent
39
Of course, one could make up some measure of national differences, based say on geographic
distance, but if the question we are asked is, “Are these two people of the same nationality?” then
under normal circumstances the only answers are “yes” and “no.” There is nothing in between.
40

In the US school system there are 12 grades of one year each and to begin grade g students
normally must be at least of age g + 5. Thus the 9th grade corresponds to children of age 14 and
15.

226

7.13

|

H OMOPHILY AND ASSORTATIVE MIXING

Age (grade)

12

11

10

9

9

10

11

12

Age (grade)

Figure 7.11: Ages of pairs of friends in high school. In this scatter plot each dot corresponds to one of the edges in Fig. 7.10, and its position along the horizontal and
vertical axes gives the ages of the two individuals at either end of that edge. The ages
are measured in terms of the grades of the students, which run from 9 to 12. In fact,
grades in the US school system don’t correspond precisely to age since students can
start or end their high-school careers early or late, and can repeat grades. (Each student
is positioned at random within the interval representing their grade, so as to spread the
points out on the plot. Note also that each friendship appears twice, above and below
the diagonal.)

friendships between students in the same grade. There is also, in this case, a
notable tendency for students to have more friends of a wider range of ages
as their age increases so there is a lower density of points in the top right box
than in the lower left one.
One could make a crude measure of assortative mixing by scalar characteristics by adapting the ideas of the previous section. One could group the
vertices into bins according to the characteristic of interest (say age) and then
treat the bins as separate “types” of vertex in the sense of Section 7.13.1. For instance, we might group people by age in ranges of one year or ten years. This
however misses much of the point about scalar characteristics, since it considers vertices falling in the same bin to be of identical types when they may
227

M EASURES AND METRICS

be only approximately so, and vertices falling in different bins to be entirely
different when in fact they may be quite similar.
A better approach is to use a covariance measure as follows. Let xi be the
value for vertex i of the scalar quantity (age, income, etc.) that we are interested
in. Consider the pairs of values ( xi , x j ) for the vertices at the ends of each
edge (i, j) in the network and let us calculate their covariance over all edges as
follows. We deﬁne the mean μ of the value of xi at the end of an edge thus:
μ=

∑ij Aij xi
1
∑ k i xi
= i
=
k i xi .
2m ∑
∑ij Aij
∑i k i
i

(7.77)

Note that this is not simply the mean value of xi averaged over all vertices. It
is an average over edges, and since a vertex with degree k i lies at the ends of k i
edges it appears k i times in the average (hence the factor of k i in the sum).
Then the covariance of xi and x j over edges is
cov( xi , x j ) =

∑ij Aij ( xi − μ)( x j − μ)
∑ij Aij

=

1
Aij ( xi x j − μxi − μx j + μ2 )
2m ∑
ij

=

1
Aij xi x j − μ2
2m ∑
ij

=

1
1
Aij xi x j −
k i k j xi x j
∑
2m ij
(2m)2 ∑
ij

=

ki k j
1
xi x j ,
Aij −
∑
2m ij
2m

(7.78)

where we have made use of Eqs. (6.21) and (7.77). Note the strong similarity between this expression and Eq. (7.69) for the modularity—only the delta
function δ(ci , c j ) in (7.69) has changed, being replaced by xi x j .
The covariance will be positive if, on balance, values xi , x j at either end of
an edge tend to be both large or both small and negative if they tend to vary in
opposite directions. In other words, the covariance will be positive when we
have assortative mixing and negative for disassortative mixing.
Just as with the modularity measure of Section 7.13.1, it is sometimes convenient to normalize the covariance so that it takes the value 1 in a perfectly
mixed network—one in which all edges fall between vertices with precisely
equal values of xi (although in most cases such an occurrence would be extremely unlikely in practice). Putting x j = xi in Eq. (7.78) gives a perfect mix228

7.13

|

H OMOPHILY AND ASSORTATIVE MIXING

ing value of
ki k j 2
ki k j
1
1
xi =
Aij −
∑ ki δij − 2m xi x j ,
2m ∑
2m
2m
ij
ij

(7.79)

and the normalized measure, sometimes called an assortativity coefﬁcient, is the
ratio of the two:
∑ij ( Aij − k i k j /2m) xi x j
.
(7.80)
r=
∑ij (k i δij − k i k j /2m) xi x j
Although it may not be immediately obvious, this is in fact an example of a
(Pearson) correlation coefﬁcient, having a covariance in its numerator and a
variance in the denominator. We encountered another example in a different
context in Section 7.12.2. The correlation coefﬁcient varies in value between a
maximum of 1 for a perfectly assortative network and a minimum of −1 for a
perfectly disassortative one. A value of zero implies that the values of xi at the
ends of edges are uncorrelated.41
For the data of Fig. 7.11 the correlation coefﬁcient is found to take a value
of r = 0.616, indicating that the student friendship network has signiﬁcant
assortative mixing by age—students tend to be friends with others who have
ages close to theirs.
It would be possible in principle also to have assortative (or disassortative)
mixing according to vector characteristics, with vertices whose vectors have
similar values, as measured by some appropriate metric, being more (or less)
likely to be connected by an edge. One example of such mixing is the formation of friendships between individuals according to their geographic locations, location being speciﬁed by a two-dimensional vector of, for example,
latitude/longitude coordinates. It is certainly the case that in general people
tend to be friends with others who live geographically close to them, so one
would expect mixing of this type to be assortative. Formal treatments of vector assortative mixing, however, have not been much pursued in the network
literature so far.
41
There could be non-linear correlations in such a network and we could still have r = 0; the
correlation coefﬁcient detects only linear correlations. For instance, we could have vertices with
high and low values of xi connected predominantly to vertices with intermediate values. This is
neither assortative nor disassortative by the conventional deﬁnition and would give a small value
of r, but might nonetheless be of interest. Such non-linear correlations could be discovered by
examining a plot such as Fig. 7.11 or by using alternative measures of correlation such as information theoretic measures. Thus it is perhaps wise not to rely solely on the value of r in investigating
assortative mixing.

229

M EASURES AND METRICS

7.13.3

A SSORTATIVE MIXING BY DEGREE

A special case of assortative mixing according to a scalar quantity, and one of
particular interest, is that of mixing by degree. In a network that shows assortative mixing by degree the high-degree vertices will be preferentially connected
to other high-degree vertices, and the low to low. In a social network, for example, we have assortative mixing by degree if the gregarious people are friends
with other gregarious people and the hermits with other hermits. Conversely,
we could have disassortative mixing by degree, which would mean that the
gregarious people were hanging out with hermits and vice versa.
The reason this particular case is interesting is because, unlike age or income, degree is itself a property of the network structure. Having one structural property (the degrees) dictate another (the positions of the edges) gives
rise to some interesting features in networks. In particular, in an assortative
network, where the high-degree nodes tend to stick together, one expects to
get a clump or core of such high-degree nodes in the network surrounded by
a less dense periphery of nodes with lower-degree. This core/periphery structure
is a common feature of social networks, many of which are found to be assortatively mixed by degree. Figure 7.12a shows a small assortatively mixed
network in which the core/periphery structure is clearly visible.
On the other hand, if a network is disassortatively mixed by degree then
high-degree vertices tend to connected to low-degree ones, creating star-like
features in the network that are often readily visible. Figure 7.12b shows an
example of a small disassortative network. Disassortatively networks do not
usually have a core/periphery split but are instead more uniform.
Assortative mixing by degree can be measured in the same way as mixing
according to any other scalar quantity. We deﬁne a covariance of the type
described by Eq. (7.78), but with xi now equal to the degree k i :
cov(k i , k j ) =

ki k j
1
ki k j ,
Aij −
∑
2m ij
2m

(7.81)

or if we wish we can normalize by the maximum value of the covariance to get
a correlation coefﬁcient or assortativity coefﬁcient:
r=

∑ij ( Aij − k i k j /2m)k i k j
∑ij (k i δij − k i k j /2m)k i k j

.

(7.82)

We give examples of the application of this formula to a number of networks
in Section 8.7.
One point to notice is that the evaluation of Eq. (7.81) or Eq. (7.82) requires
only the structure of the network and no other information (unlike the calcu230

P ROBLEMS

(a)

(b)

Figure 7.12: Assortative and disassortative networks. These two small networks are not real networks—they were
computer generated to display the phenomenon of assortativity by degree. (a) A network that is assortative by degree,
displaying the characteristic dense core of high-degree vertices surrounded by a periphery of lower-degree ones. (b) A
disassortative network, displaying the star-like structures characteristic of this case. Figure from Newman and Girvan [249]. Copyright 2003 Springer-Verlag Berlin Heidelberg. Reproduced with kind permission of Springer Science
and Business Media.

lations for other forms of assortative mixing). Once we know the adjacency
matrix (and hence the degrees) of all vertices we can calculate r. Perhaps for
this reason mixing by degree is one of the most frequently studied types of
assortative mixing.

P ROBLEMS
7.1 Consider a k-regular undirected network (i.e., a network in which every vertex has
degree k).

231

M EASURES AND METRICS

a) Show that the vector 1 = (1, 1, 1, . . .) is an eigenvector of the adjacency matrix
with eigenvalue k.
b) By making use of the fact that eigenvectors are orthogonal (or otherwise), show
that there is no other eigenvector that has all elements positive. The Perron–
Frobenius theorem says that the eigenvector with the largest eigenvalue always
has all elements non-negative (see footnote 2 on page 346), and hence the eigenvector 1 gives, by deﬁnition, the eigenvector centrality of our k-regular network
and the centralities are the same for every vertex.
c) Find the Katz centralities of all vertices in a k-regular network.
d) You should have found that, as with the eigenvector centrality, the Katz centralities of all vertices in the network are the same. Name a centrality measure that
could give different centrality values for different vertices in a regular network.
7.2 Suppose a directed network takes the form of a tree with all edges pointing inward
towards a central vertex:

What is the PageRank centrality of the central vertex in terms of the single parameter α
appearing in the deﬁnition of PageRank and the geodesic distances di from each vertex i
to the central vertex?
7.3 Consider an undirected tree of n vertices. A particular edge in the tree joins vertices 1 and 2 and divides the tree into two disjoint regions of n1 and n2 vertices as
sketched here:

n1

1

2
n2

232

P ROBLEMS

Show that the closeness centralities C1 and C2 of the two vertices, deﬁned according to
Eq. (7.29), are related by
1
n1
1
n2
+
=
+ .
C2
C1
n
n
7.4 Consider an undirected (connected) tree of n vertices. Suppose that a particular
vertex in the tree has degree k, so that its removal would divide the tree into k disjoint
regions, and suppose that the sizes of those regions are n1 . . . nk .
a) Show that the unnormalized betweenness centrality x of the vertex, as deﬁned in
Eq. (7.36), is
k

x = n2 − ∑ n2m .
m =1

b) Hence, or otherwise, calculate the betweenness of the ith vertex from the end of a
“line graph” of n vertices, i.e., n vertices in a row like this:

7.5 Consider these three networks:

A

B

a) Find a 3-core in the ﬁrst network.
b) What is the reciprocity of the second network?
c) What is the cosine similarity of vertices A and B in the third network?
7.6 Among all pairs of vertices in a directed network that are connected by an edge or
edges, suppose that half are connected in only one direction and the rest are connected
in both directions. What is the reciprocity of the network?
7.7 In this network + and − indicate pairs of people who like each other or don’t,
respectively:

233

M EASURES AND METRICS

a) Is the network structurally balanced and why?
b) Is it clusterable and, if so, what are the clusters?

Men

7.8 In a survey of couples in the US city of San Francisco, Catania et al. [65] recorded,
among other things, the ethnicity of their interviewees and calculated the fraction of
couples whose members were from each possible pairing of ethnic groups. The fractions were as follows:

Black
Hispanic
White
Other
Total

Black
0.258
0.012
0.013
0.005
0.289

Women
Hispanic White
0.016
0.035
0.157
0.058
0.023
0.306
0.007
0.024
0.204
0.423

Other
0.013
0.019
0.035
0.016
0.084

Total
0.323
0.247
0.377
0.053

Assuming the couples interviewed to be a representative sample of the edges in the
undirected network of relationships for the community studied, and treating the vertices as being of four types—black, Hispanic, white, and other—calculate the numbers
err and ar that appear in Eq. (7.76) for each type. Hence calculate the modularity of the
network with respect to ethnicity.

234

C HAPTER 8

T HE LARGE - SCALE STRUCTURE OF
NETWORKS
A discussion of some of the recurring patterns and
structures revealed when we apply the concepts
developed in previous chapters to the study of real-world
networks

I

N PREVIOUS chapters of this book we have looked at different types of nat-

ural and man-made networks and techniques for determining their structure (Chapters 2 to 5), the mathematics used to represent networks formally
(Chapter 6), and the measures and metrics used to quantify network structure
(Chapter 7). In this chapter we combine what we have learned so far, applying
our theoretical ideas and measures to empirical network data to get a picture
of what networks look like in the real world.
As we will see, there are a number of common recurring patterns seen in
network structures, patterns that can have a profound effect on the way networked systems work. Among other things, we discuss in this chapter component sizes, path lengths and the small-world effect, degree distributions and
power laws, and clustering coefﬁcients.

8.1

C OMPONENTS

We begin our discussion of the structure of real-world networks with a look
at component sizes. In an undirected network, we typically ﬁnd that there
is a large component that ﬁlls most of the network—usually more than half
and not infrequently over 90%—while the rest of the network is divided into a
large number of small components disconnected from the rest. This situation
is sketched in Fig. 8.1. (The large component is often referred to as the “giant
235

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Figure 8.1: Components in an undirected network. In most undirected networks there
is a single large component occupying a majority, or at least a signiﬁcant fraction, of
the network, along with a number of small components, typically consisting of only a
handful of vertices each.

See Section 6.11.1 for the
deﬁnition of a weakly connected component.

236

component,” although this is a slightly sloppy usage. As discussed in Section 12.5, the words “giant component” have a speciﬁc meaning in network
theory and are not precisely synonymous with “largest component.” In this
book we will be careful to distinguish between “largest” and “giant.”)
A typical example of this kind of behavior is the network of ﬁlm actors
discussed in Section 3.5. In this network the vertices represent actors in movies
and there is an edge between two actors if they have ever appeared in the same
movie. In a version of the network from May 2000 [253], it was found that
440 971 out of 449 913 actors were connected together in the largest component,
or about 98%. Thus just 2% of actors were not part of the largest component.
Table 8.1 summarizes the properties of many of the networks discussed in
this chapter, and gives, among other things, the size S of the largest component
in each case as a fraction of total network size. (For the directed networks in the
table it is the size of the largest weakly connected component that is quoted.
Component sizes in directed networks are discussed further in the following
section.) As we can see from the table our ﬁgure for the actor network is quite
typical for the networks listed and not unusually large.
As the table also shows, there are quite a few networks for which the largest
component ﬁlls the entire network so that S = 1, i.e., the network has only a
single component and no smaller components. In the cases where this happens

Social
Information
Technological
Biological

Network
Film actors
Company directors
Math coauthorship
Physics coauthorship
Biology coauthorship
Telephone call graph
Email messages
Email address books
Student dating
Sexual contacts
WWW nd.edu
WWW AltaVista
Citation network
Roget’s Thesaurus
Word co-occurrence
Internet
Power grid
Train routes
Software packages
Software classes
Electronic circuits
Peer-to-peer network
Metabolic network
Protein interactions
Marine food web
Freshwater food web
Neural network

Type
Undirected
Undirected
Undirected
Undirected
Undirected
Undirected
Directed
Directed
Undirected
Undirected
Directed
Directed
Directed
Directed
Undirected
Undirected
Undirected
Undirected
Directed
Directed
Undirected
Undirected
Undirected
Undirected
Directed
Directed
Directed

n
449 913
7 673
253 339
52 909
1 520 251
47 000 000
59 812
16 881
573
2 810
269 504
203 549 046
783 339
1 022
460 902
10 697
4 941
587
1 439
1 376
24 097
880
765
2 115
134
92
307

m
25 516 482
55 392
496 489
245 300
11 803 064
80 000 000
86 300
57 029
477

c
113.43
14.44
3.92
9.27
15.53
3.16
1.44
3.38
1.66

S
0.980
0.876
0.822
0.838
0.918


3.48
4.60
7.57
6.19
4.92

0.952
0.590
0.503

4.95
5.22
16.01

1 497 135
1 466 000 000
6 716 198
5 103
16 100 000
31 992
6 594
19 603
1 723
2 213
53 248
1 296
3 686
2 240
598
997
2 359

5.55
7.20
8.57
4.99
66.96
5.98
2.67
66.79
1.20
1.61
4.34
1.47
9.64
2.12
4.46
10.84
7.68

1.000
0.914

11.27
16.18

0.977
1.000
1.000
1.000
1.000
0.998
1.000
1.000
0.805
0.996
0.689
1.000
1.000
0.967

4.87
3.31
18.99
2.16
2.42
5.40
11.05
4.28
2.56
6.80
2.05
1.90
3.97

α
2.3
–
–
–
–
2.1
1.5/2.0
–
–
3.2
2.1/2.4
2.1/2.7
3.0/–
–
2.7
2.5
–
–
1.6/1.4
–
3.0
2.1
2.2
2.4
–
–
–

C
0.20
0.59
0.15
0.45
0.088

CWS
0.78
0.88
0.34
0.56
0.60

r
0.208
0.276
0.120
0.363
0.127

0.17
0.005

0.16
0.13
0.001

0.092
−0.029

0.11

0.29

−0.067

0.13

0.15
0.44
0.39
0.080
0.69
0.082
0.012
0.030
0.011
0.67
0.071
0.23
0.087
0.28

0.157

0.035
0.10
0.070
0.033
0.010
0.012
0.090
0.072
0.16
0.20
0.18

−0.189
−0.003
−0.033
−0.016
−0.119
−0.154
−0.366
−0.240
−0.156
−0.263
−0.326
−0.226

Ref(s).
16, 323
88, 253
89, 146
234, 236
234, 236
9, 10
103
248
34
197, 198
13, 28
56
280
184
97, 116
66, 111
323
294
239
315
115
6, 282
166
164
160
209
323, 328

Table 8.1: Basic statistics for a number of networks. The properties measured are: type of network, directed or undirected; total
number of vertices n; total number of edges m; mean degree c; fraction of vertices in the largest component S (or the largest weakly
connected component in the case of a directed network); mean geodesic distance between connected vertex pairs ; exponent α
of the degree distribution if the distribution follows a power law (or “–” if not; in/out-degree exponents are given for directed
graphs); clustering coefﬁcient C from Eq. (7.41); clustering coefﬁcient CWS from the alternative deﬁnition of Eq. (7.44); and the degree
correlation coefﬁcient r from Eq. (7.82). The last column gives the citation(s) for each network in the bibliography. Blank entries
indicate unavailable data.

T HE LARGE - SCALE STRUCTURE OF NETWORKS

there is usually a good reason. For instance, the Internet is a communication
network—its reason for existence is to provide connections between its nodes.
There must be at least one path from your vertex to your friend’s vertex if the
network is to serve its purpose of allowing your and your friend to communicate. To put it another way, there would be no point in being a part of the
Internet if you are not part of its largest component, since that would mean that
you are disconnected from and unable to communicate with almost everyone
else. Thus there is a strong pressure on every vertex of the Internet to be part
of the largest component and thus for the largest component to ﬁll the entire
network. In other cases the largest component ﬁlls the network because of the
way the network is measured. The ﬁrst Web network listed in the table, for
instance, is derived from a single web crawl, as described in Section 4.1. Since
a crawler can only ﬁnd a web page if that page is linked to by another page, it
follows automatically that all pages found by a single crawl will be connected
into a single component. A Web network may, however, have more than one
component if, like the “AltaVista” network in the table, it is assembled using
several web crawls starting from different locations.
Can a network have two or more large components that ﬁll a sizable fraction of the entire graph? Usually the answer to this question is no. We will
study this point in more detail in Section 12.6, but the basic argument is this. If
we had a network of n vertices that was divided into two large components of
about 12 n vertices each, then there would be 14 n2 possible pairs of vertices such
that one vertex was in one large component and the other vertex in the other
large component. If there is an edge between any of these pairs of vertices,
then the two components are joined together and are in fact just one component. For example, in our network of movie actors, with half a million vertices,
there would about 50 billion pairs, only one of which would have to be joined
by an edge to join the two large components into one. Except in very special
cases, it is highly unlikely that not one such pair would be connected, and
hence also highly unlikely that we will have two large components.
And what about networks with no large component? It is certainly possible for networks to consist only of small components, small groups of vertices
connected among themselves but not connected to the rest of the world. An
example would be the network of immediate family ties, in which two people
are considered connected if they are family members living under the same
roof. Such a network is clearly broken into many small components consisting
of individual families, with no large component at all. In practice, however,
situations like this arise rather infrequently in the study of networks for the
anthropocentric reason that people don’t usually bother to represent such situations by networks at all. Network representations of systems are normally
238

8.1

|

C OMPONENTS

only useful if most of the network is connected together. If a network is so
sparse as to be made only of small components, then there is normally little
to be gained by applying techniques like those described in this book. Thus,
essentially all of the networks we will be looking at do contain a large component (and certainly all those in Table 8.1, although for some of them the size of
that component has not been measured and the relevant entry in the table is
blank).
So the basic picture we have of the structure of most networks is that of
Fig. 8.1, of a large component ﬁlling most of the network, sometimes all of it,
and perhaps some other small components that are not connected to the bulk
of the network.
8.1.1

C OMPONENTS IN DIRECTED NETWORKS

As discussed in Section 6.11, the component structure of directed networks
is more complicated than for undirected ones. Directed graphs have weakly
and strongly connected components. The weakly connected components correspond closely to the concept of a component in an undirected graph, and
the typical situation for weakly connected components is similar to that for
undirected graphs: there is usually one large weakly connected component
plus, optionally, other small ones. Figures for the sizes of the largest weakly
connected components in several directed network are given in Table 8.1.
A strongly connected component, as described in Section 6.11, is a maximal
subset of vertices in a network such that each can reach and is reachable from
all of the others along a directed path. As with weakly connected components,
there is typically one large strongly connected component in a directed network and a selection of small ones. The largest strongly connected component
of the World Wide Web, for instance, ﬁlls about a quarter of network [56].
Associated with each strongly connected component is an out-component
(the set of all vertices that can be reached from any starting point in the strongly
connected component along a directed path) and an in-component (the set of
vertices from which the strongly connected component can be reached). By
their deﬁnition, in- and out-components are supersets of the strongly connected component to which they belong and if there is a large strongly connected component then the corresponding in- and out-components will often
contain many vertices that lie outside the strongly connected component. In
the Web, for example, the portion of the in- and out-components that lie outside the largest strongly connected component each also occupy about a quarter of the network [56].
Each of the small strongly connected components will have its own in- and
239

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Other components
(30%)

(21%)

Strongly
connected
component
(28%)

(21%)

In−component
Out−component

Figure 8.2: The “bow tie” diagram of components in a directed network. The typical
directed network consists of one large strongly connected component and many small
ones, each with an in-component and an out-component. Note that by deﬁnition each
in-component includes the corresponding strongly connected component as a subset,
as does each out-component. The largest strongly connected component and its inand out-components typically occupy a signiﬁcant fraction of the whole network. The
percentages shown here indicate how much of the network is taken up by each part of
the bow tie in the case of the World Wide Web. After Broder et al. [56].

out-components also. Often these will themselves be small, but they need not
be. It can happen that a small strongly connected component C is connected
by a directed path to the large strongly connected component, in which case
the out-component of the large strongly connected component belongs to (and
probably forms the bulk of) C ’s out-component. Notice that the large outcomponent can be reachable from many small components in this way—the
out-components of different strongly connected components can overlap in
directed networks and any vertex can and usually does belong to many outcomponents. Similar arguments apply, of course, for in-components as well.
The overall picture for a directed network can be represented using the
“bow tie” diagram introduced by Broder and co-workers [56]. In Fig. 8.2 we
show the bow tie for the case of the World Wide Web, including percentages
(from Ref. [56]) for the fraction of the network occupied by its different parts.
Not all directed networks have a large strongly connected component. In
particular, any acyclic directed network has no strongly connected components
of size greater than one since if two vertices belong to the same strongly con-

240

8.2

|

S HORTEST PATHS AND THE SMALL - WORLD EFFECT

nected component then by deﬁnition there exists a directed path through the
network in both directions between them, and hence there is a cycle from one
vertex to the other and back. Thus if there are no cycles in a network there
can be no strongly connected components with two or more vertices. Real-life
networks are not usually perfectly acyclic, but some, such as citation networks
(Section 4.2) are approximately so. Such networks typically have a few small
strongly connected components of two or perhaps three vertices each, but no
large ones.

8.2

S HORTEST PATHS AND THE SMALL - WORLD EFFECT

One of the most remarkable and widely discussed of network phenomena
is the small-world effect, the ﬁnding that in many—perhaps most—networks
the typical network distances between vertices are surprisingly small. In Section 3.6 we discussed Stanley Milgram’s letter-passing experiment in the 1960s,
in which people were asked to get a letter from an initial holder to a distant target person by passing it from acquaintance to acquaintance through the social
network. The letters that made it to the target did so in a remarkably small
number of steps, around six on average. Milgram’s experiment is a beautiful and powerful demonstration of the small-world effect, although also a
rather poorly controlled one. But with the very complete network data we
have for many networks these days it is now possible to measure directly the
path lengths between vertices and verify the small-world effect explicitly.
In Section 7.6 we deﬁned the mean distance  between vertices in a network (see Eqs. (7.31) and (7.32)). In mathematical terms, the small-world effect
is the hypothesis that this mean distance is small, in a sense that will be deﬁned shortly. In Table 8.1 we list the value of  for each of the networks in the
table, and we see that indeed it takes quite small values, always less than 20
and usually less than 10, even though some of the networks have millions of
vertices.
One can well imagine that the small-world effect could have substantial
implications for networked systems. Suppose a rumor is spread over a social
network for instance (or a disease for that matter). Clearly it will reach people
much faster if it is only about six steps from any person to any other than if it is
a hundred, or a million. Similarly, the speed with which one can get a response
from another computer on the Internet depends on how many steps or “hops”
data packets have to make as they traverse the network. Clearly a network
in which the typical number of hops is only ten or twenty will perform much
better than one in which it is ten times as much. (While this point was not
articulated by the original designers of the Internet in the 1960s, they must
241

T HE LARGE - SCALE STRUCTURE OF NETWORKS

i

j

The shortest path from i
to j in this network has
length 1, but the shortest path from j to i has
length 2.

242

have had some idea of its truth, even if only vaguely, to believe that a network
like the Internet could be built and made to work.)
In fact, once one looks more deeply into the mathematics of networks,
which we will do in later chapters, one discovers that the small-world effect
is not so surprising after all. As we will see in Section 12.7, mathematical models of networks suggest that path lengths in networks should typically scale as
log n with the number n of network vertices, and should therefore tend to remain small even for large networks because the logarithm is a slowly growing
function of its argument.
One can ask about path lengths on directed networks as well, although the
situation is more complicated there. Since in general the path from vertex i
to vertex j is different in a directed network from the path from j to i, the
two paths can have different lengths. Our average distance  should therefore
include terms for both distances separately. It’s also possible for there to be no
path in one direction between two vertices, which we would conventionally
denote by setting dij = ∞. As before we could get around the problems caused
by the inﬁnite values by deﬁning  as an average over only the ﬁnite ones, as in
Eq. (7.32). Values calculated in this way are given for the directed networks in
Table 8.1. One could also (and perhaps more elegantly) use a harmonic mean
as in Eq. (7.34), although this is rarely done.
One can also examine the diameter of a network, which, as described in
Section 6.10.1, is the length of the longest ﬁnite geodesic path anywhere in the
network. The diameter is usually found to be relatively small as well and calculations using network models suggest that it should scale logarithmically
with n just as the average distance does. The diameter is in general a less useful measure of real-world network behavior than mean distance, since it really
only measures the distance between one speciﬁc pair of vertices at the extreme
end of the distribution of distances. Moreover, the diameter of a network could
be affected substantially by a small change to only a single vertex or a few
vertices, which makes it a poor indicator of the behavior of the network as
a whole. Nonetheless, there are cases where it is of interest. In Section 8.4
we discuss so-called “scale-free” networks, i.e., networks with power-law degree distributions. Such networks are believed to have an unusual structure
consisting of a central “core” to the network that contains most of the vertices and has a mean geodesic distance between vertex pairs that scales only
as log log n with network size, and not as log n, making the mean distance for
the whole network scale as log log n also. Outside of this core there are longer
“streamers” or “tendrils” of vertices attached to the core like hair, which have
length typically of order log n, making the diameter of the network of order
log n [67, 75]. This sort of behavior could be detected by measuring separately

8.3

|

the mean geodesic distance and diameter of networks of various sizes to conﬁrm that they vary differently with n. (It’s worth noting, however, that behavior of the form log log n is very difﬁcult to conﬁrm in real-world data because
log log n is a very slowly varying function of n.)
Another interesting twist on the small-world effect was discussed by Milgram in his original paper on the problem. He noticed, in the course of his
letter-passing experiments, that most of the letters destined for a given target
person passed through just one or two acquaintances of the target. Thus, it appeared, most people who knew the target person knew him through these one
or two people. This idea, that one or two of your acquaintances are especially
well connected and responsible for most of the connection between you and
the rest of the world has been dubbed funneling, and it too is something we
can test against complete networks with the copious data available to us today. If, for instance, we focus on geodesic paths between vertices, as we have
been doing in this section, then we could measure what fraction of the shortest
paths between a vertex i and every other reachable vertex go through each of
i’s neighbors in the network. For many networks, this measurement does reveal a funneling effect. For instance, in the coauthorship network of physicists
from Table 8.1 it is found that, for physicists having ﬁve or more collaborators, 48% of geodesic paths go through one neighbor of the average vertex, the
remaining 52% being distributed over the other four or more neighbors. A similar result is seen in the Internet. Among nodes having degree ﬁve or greater
in a May 2005 snapshot of Internet structure at the autonomous system level,
an average of 49% of geodesic paths go through one neighbor of the average
vertex. It is tempting to draw conclusions about the routing of Internet packets
from this latter result—perhaps that the network will tend to overload a small
number of well-connected nodes rather than distributing load more evenly—
but it is worth noticing that, although Internet packets tended to be routed
along shortest paths during the early days of the Internet, much more sophisticated routing strategies are in place today, so statistics for shortest paths may
not reﬂect actual packet ﬂows very closely.

8.3

D EGREE DISTRIBUTIONS

Milgram referred to these
people as “sociometric superstars.” We discussed
them previously in Section 3.6.

D EGREE DISTRIBUTIONS

In this section, we look at one of the most fundamental of network properties,
the frequency distribution of vertex degrees. This distribution will come up
time and again throughout this book as a deﬁning characteristic of network
structure.
As described in Section 6.9, the degree of a vertex is the number of edges
attached to it. Let us ﬁrst consider undirected networks. We deﬁne pk to be the
243

T HE LARGE - SCALE STRUCTURE OF NETWORKS

fraction of vertices in such a network that have degree k. For example, consider
this network:

It has n = 10 vertices, of which 1 has degree 0, 2 have degree 1, 4 have degree 2,
2 have degree 3, and 1 has degree 4. Thus the values of pk for k = 0, . . . , 4 are
p0 =

1
,
10

p1 =

2
,
10

p2 =

4
,
10

p3 =

2
,
10

p4 =

1
,
10

(8.1)

and pk = 0 for all k > 4. The quantities pk represent the degree distribution of
the network.
The value pk can also be thought of as a probability: it is the probability that
a randomly chosen vertex in the network has degree k. This will be a useful
viewpoint when we study theoretical models of networks in Chapters 12 to 15.
Sometimes, rather than the fraction of vertices with a given degree, we will
want the total number of such vertices. This is easily calculated from the degree distribution, being given simply by npk , where n is as usual the total number of vertices.
Another construct containing essentially the same information as the degree distribution is the degree sequence, which is the set {k1 , k2 , k3 , . . .} of degrees for all the vertices. For instance, the degree sequence of the small graph
above is {0, 1, 1, 2, 2, 2, 2, 3, 3, 4}. (The degree sequence need not necessarily be
given in ascending order of degrees as here. For instance, in many cases the
vertices are given numeric labels and their degrees are then listed in the order
of the labels.)
It is probably obvious, but bears saying anyway, that a knowledge of the
degree distribution (or degree sequence) does not, in most cases, tell us the
complete structure of a network. For most choices of vertex degrees there is
more than one network with those degrees. These two networks, for instance,
are different but have the same degrees:

244

Fraction pk of vertices with degree k

8.3

|

D EGREE DISTRIBUTIONS

0.4

0.2

0

0

5

10

15

20

Degree k

Figure 8.3: The degree distribution of the Internet. A histogram of the degree distribution of the vertices of the Internet graph at the level of autonomous systems.

Thus we cannot tell the complete structure of a network from its degrees alone.
The degree sequence certainly gives us very important information about a
network, but it doesn’t give us complete information.
It is often illuminating to make a plot of the degree distribution of a large
network as a function of k. Figure 8.3 shows an example of such a plot for
the Internet at the level of autonomous systems. The ﬁgure reveals something
interesting: most of the vertices in the network have low degree—one or two
or three—but there is a signiﬁcant “tail” to the distribution, corresponding to
vertices with substantially higher degree.1 The plot cuts off at degree 20, but
in fact the tail goes much further than this. The highest degree vertex in the
network has degree 2407. Since there are, for this particular data set, a total
of 19 956 vertices in the network, that means that the most highly connected
vertex is connected to about 12% of all other vertices in the network. We call
such a well-connected vertex a hub.2 Hubs will play an important role in the
1

For the Internet there are no vertices of degree zero, since a vertex is not considered part of
the Internet unless it is connected to at least one other.
2
We used the word hub in a different and more technical sense in Section 7.5 to describe vertices in directed networks that point to many “authorities.” Both senses are common in the net-

245

Fraction of vertices

T HE LARGE - SCALE STRUCTURE OF NETWORKS

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0

5

10

In-degree

15

20

0

0

5

10

15

20

Out-degree

Figure 8.4: The degree distributions of the World Wide Web. Histograms of the distributions of in- and out-degrees
of pages on the World Wide Web. Data are from the study by Broder et al. [56].

developments of the following chapters.
In fact, it turns out that almost all real-world networks have degree distributions with a tail of high-degree hubs like this. In the language of statistics
we say that the degree distribution is right-skewed. Right-skewed degree distributions are discussed further in Section 8.4, and will reappear repeatedly
throughout this book.
One can also calculate degree distributions for directed networks. As discussed in Section 6.9, directed networks have two different degrees for each
vertex, the in-degree and the out-degree, which are, respectively, the number
of edges ingoing and outgoing at the vertex of interest. There are, correspondingly, two different degree distributions in a directed network, the in-degree
and out-degree distributions, and one can make a plot of either, or both. Figure 8.4, for example, shows the degree distributions for the World Wide Web.
If we wish to be more sophisticated, we might observe that the true degree
distribution of a directed network is really a joint distribution of in- and outworks literature, and in many cases the reader must deduce from the context which is being used.
In this book we will mostly use the word in the less technical sense introduced here, of a vertex with unusually high degree. When we use it in the other sense of Section 7.5 we will say so
explicitly.

246

8.4

|

P OWER LAWS AND SCALE - FREE NETWORKS

degrees. We can deﬁne p jk to be the fraction of vertices having simultaneously
an in-degree j and an out-degree k. This is a two-dimensional distribution that
cannot be plotted as a simple histogram, although it could be plotted as a twodimensional density plot or as a surface plot. By using a joint distribution in
this way we can allow for the possibility that the in- and out-degrees of vertices
might be correlated. For instance, if vertices with high in-degree also tended
to have high out-degree, then we would see this reﬂected in large values of p jk
when both j and k were large. If we only have the separate distributions of inand out-degree individually, but not the joint distribution, then there is no way
of telling whether the network contains such correlations.
In practice, the joint in/out degree distribution of directed networks has
rarely been measured or studied, so there is relatively little data on it. This
is, in some ways, a pity, since many of our theories of directed networks depend on a knowledge of the joint distribution to give accurate answers (see
Section 13.11), while others make predictions about the joint distribution that
we would like to test against empirical data. For the moment, however, this is
an area awaiting more thorough exploration.

8.4

P OWER LAWS AND SCALE - FREE NETWORKS

Returning to the Internet, another interesting feature of its degree distribution
is shown in Fig. 8.5, where we have replotted the histogram of Fig. 8.3 using
logarithmic scales. (That is, both axes are logarithmic. We have also made
the range of the bins bigger in the histogram to make the effect clearer—they
are of width ﬁve in Fig. 8.5 where they were only of width one before.) As
the ﬁgure shows, when viewed in this way, the degree distribution follows,
roughly speaking, a straight line. In mathematical terms, the logarithm of the
degree distribution pk is a linear function of degree k thus:
ln pk = −α ln k + c,

(8.2)

where α and c are constants. The minus sign here is optional—we could have
omitted it—but it is convenient, since the slope of the line in Fig. 8.5 is clearly
negative, making α a positive constant equal to minus the slope in the ﬁgure.
In this case, the slope gives us a value for α of about 2.1.
Taking the exponential of both sizes of Eq. (8.2), we can also write this logarithmic relation as
(8.3)
pk = Ck−α ,
where C = ec is another constant. Distributions of this form, varying as a
power of k, are called power laws. Based on the evidence of Fig. 8.5 we can say
247

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Fraction pk of vertices with degree k

10

10

10

-1

-2

10

10

0

-3

-4

1

10

100

Degree k

Figure 8.5: The power-law degree distribution of the Internet. Another histogram of
the degree distribution of the Internet graph, plotted this time on logarithmic scales.
The approximate straight-line form of the histogram indicates that the degree distribution roughly follows a power law of the form (8.3).

that, roughly speaking, the degree distribution of the Internet follows a power
law.
This is, in fact, a common pattern seen in quite a few different networks.
For instance, as shown in Fig. 8.8 on page 253, both the in- and out-degrees
of the World Wide Web roughly follow power-law distributions, as do the indegrees in many citation networks (but not the out-degrees).
The constant α is known as the exponent of the power law. Values in the
range 2 ≤ α ≤ 3 are typical, although values slightly outside this range are
possible and are observed occasionally. Table 8.1 gives the measured values
of the exponents for a number of networks that have power-law or approximately power-law degree distributions, and we see that most of them fall in
this range. The constant C in Eq. (8.3) is mostly uninteresting, being ﬁxed by
the requirement of normalization, as described in Section 8.4.2.
Degree distributions do not usually follow Eq. (8.3) over their entire range.
Looking at Fig. 8.3, for example, we can see that the degree distribution is not
monotonic for small k, even allowing for statistical ﬂuctuations in the histo-

248

8.4

|

P OWER LAWS AND SCALE - FREE NETWORKS

gram. A true power-law distribution is monotonically decreasing over its entire range and hence the degree distribution must in this case deviate from the
true power law in the small-k regime. This is typical. A common situation
is that the power law is obeyed in the tail of the distribution, for large values
of k, but not in the small-k regime. When one says that a particular network
has a power-law degree distribution one normally means only that the tail of
the distribution has this form. In some cases, the distribution may also deviate from the power-law form for high k as well. For instance, there is often a
cut-off of some type that limits the maximum degree of vertices in the tail.
Networks with power-law degree distributions are sometimes called scalefree networks, and we will use this terminology occasionally. Of course, there
are also many networks that are not scale-free, that have degree distributions
with non-power-law forms, but the scale-free ones will be of particular interest
to us because they have a number of intriguing properties. Telling the scalefree ones from the non-scale-free is not always easy however. The simplest
strategy is to look at a histogram of the degree distribution on a log–log plot,
as we did in Fig. 8.5, to see if we have a straight line. There are, however, a
number of problems with this approach and where possible we recommend
you use other methods, as we now explain.
8.4.1

D ETECTING AND VISUALIZING POWER LAWS

As a tool for visualizing or detecting power-law behavior, a simple histogram
like Fig. 8.5 presents some problems. One problem obvious from the ﬁgure is
that the statistics of the histogram are poor in the tail of the distribution, the
large-k region, which is precisely the region in which the power law is normally followed most closely. Each bin of the histogram in this region contains
only a few samples, which means that statistical ﬂuctuations in the number of
samples from bin to bin are large. This is visible as a “noisy signal” at the righthand end of Fig. 8.5 that makes it difﬁcult to determine whether the histogram
really follows a straight line or not, and what the slope of that line is.
There are a number of solutions to this problem. The simplest is to use a
histogram with larger bins, so that more samples fall into each bin. In fact, we
already did this in going from Fig. 8.3 to Fig. 8.5—we increased the bin width
from one to ﬁve between the two ﬁgures. Larger bins contain more samples
and hence give less noise in the tail of the histogram, but at the expense of
less detail overall, since the number of bins is correspondingly reduced. Bin
width in this situation is always something of a compromise: we would like
to use very wide bins in the tail of the distribution where noise is a problem,
but narrower ones at the left-hand end of the histogram where there are many
249

T HE LARGE - SCALE STRUCTURE OF NETWORKS

samples and we would prefer to have more bins if possible.
Alternatively, we could try to get the best of both worlds by using bins of
different sizes in different parts of the histogram. For example, we could use
bins of width one for low degrees and switch to width ﬁve for higher degrees.
In doing this we must be careful to normalize the bins correctly: a bin of width
ﬁve will on average accrue ﬁve times as many samples as a similarly placed bin
of width one, so if we wish to compare counts in the two we should divide the
number of samples in the larger bin by ﬁve. More generally, we should divide
sample counts by the width of their bins to make counts in bins of different
widths comparable.
We need not restrict ourselves to only two different sizes of bin. We could
use larger and larger bins as we go further out in the tail. We can even make
every bin a different size, each one a little larger than the one before it. One
commonly used version of this idea is called logarithmic binning. In this scheme,
each bin is made wider than its predecessor by a constant factor a. For instance,
if the ﬁrst bin in a histogram covers the interval 1 ≤ k < 2 (meaning that all
vertices of degree 1 fall in this bin) and a = 2, then the second would cover the
interval 2 ≤ k < 4 (vertices of degrees 2 and 3), the third the interval 4 ≤ k < 8,
and so forth. In general the nth bin would cover the interval an−1 ≤ k < an and
have width an − an−1 = ( a − 1) an−1 . The most common choice for a is a = 2,
since larger values tend to give bins that are too coarse while smaller ones give
bins with non-integer limits.
Figure 8.6 shows the degree distribution of the Internet binned logarithmically in this way. We have been careful to normalize each bin by dividing by
its width, as described above. As we can see, the histogram is now much less
noisy in the tail and it is considerably easier to see the straight-line behavior
of the degree distribution. The ﬁgure also reveals a nice property of logarithmically binned histograms, namely that when plotted on logarithmic scales as
here, the bins in such a histogram appear to have equal width. This is, in fact,
the principal reason for this particular choice of bins and also the origin of the
name “logarithmic binning.”
Note that on a logarithmically binned histogram there is never any bin that
contains vertices of degree zero. Since there is no zero on logarithmic scales
like those of Fig. 8.6, this doesn’t usually make much difference, but if we do
want to know how many vertices there are of degree zero we will have to
measure this number separately.
A different solution to the problem of visualizing a power-law distribution

250

8.4

Fraction pk of vertices having degree k

10

P OWER LAWS AND SCALE - FREE NETWORKS

0

10

-2

10

-4

10

-6

10

|

-8

1

10

100

1000

Degree k

Figure 8.6: Histogram of the degree distribution if the Internet, created using logarithmic binning. In this histogram the widths of the bins are constant on a logarithmic
scale, meaning that on a linear scale each bin is wider by a constant factor than the one
to its left. The counts in the bins are normalized by dividing by bin width to make
counts in different bins comparable.

is to construct the cumulative distribution function, which is deﬁned by
∞

Pk = ∑ pk .

(8.4)

k =k

In other words, Pk is the fraction of vertices that have degree k or greater. (Alternatively, it is the probability at a randomly chosen vertex has degree k or
greater.)
Suppose the degree distribution pk follows a power law in its tail. To be
precise, let us say that pk = Ck−α for k ≥ kmin for some kmin . Then for k ≥ kmin
we have
∞

Pk = C ∑ k
k =k

=

−α

≃C

C −(α−1)
k
,
α−1

 ∞
k

k

−α

dk
(8.5)

where we have approximated the sum by an integral, which is reasonable since
251

Fraction of vertices Pk having degree k or greater

T HE LARGE - SCALE STRUCTURE OF NETWORKS

1

0.1

0.01

0.001

0.0001
1

10

100

1000

Degree k

Figure 8.7: Cumulative distribution function for the degrees of vertices on the Internet. For a distribution with a power-law tail, as is approximately the case for the degree
distribution of the Internet, the cumulative distribution function, Eq. (8.4), also follows
a power law, but with a slope 1 less than that of the original distribution.

the power law is a slowly varying function for large k. (We are also assuming
that α > 1 so that the integral converges.) Thus we see that if the distribution
pk follows a power law, then so does the cumulative distribution function Pk ,
but with an exponent α − 1 that is 1 less than the original exponent.
This gives us another way of visualizing a power-law distribution: we plot
the cumulative distribution function on log–log scales, as we did for the original histogram, and again look for straight-line behavior. We have done this in
Fig. 8.7 for the case of the Internet, and the (approximate) straight-line form is
clearly visible. Three more examples are shown in Fig. 8.8, for the in- and outdegree distributions of the World Wide Web and for the in-degree distribution
of a citation network.
This approach has some advantages. In particular, the calculation of Pk
does not require us to bin the values of k as we do with a normal histogram.
Pk is perfectly well deﬁned for any value of k and can be plotted just as a normal function. When bins in a histogram contain more than one value of k—
i.e., when their width is greater than 1—the binning of data necessarily throws
away quite a lot of the information contained in the data, eliminating, as it
252

8.4

0

Cumulative distribution function

10

|

P OWER LAWS AND SCALE - FREE NETWORKS

0

10

0

10

-2

10

-4

10

-2

10

-2

10

-4

10

-4

10
-6

10

0

10

2

10

In-degree
(a) World Wide Web

4

10

0

10

2

10

4

10

Out-degree
(b) World Wide Web

0

10

1

10

2

10

3

10

In-degree
(c) Citation

Figure 8.8: Cumulative distribution functions for in- and out-degrees in three directed networks. (a) The in-degree
distribution of the World Wide Web, from the data of Broder et al. [56]. (b) The out-degree distribution for the same Web
data set. (c) The in-degree distribution of a citation network, from the data of Redner [280]. The distributions follow
approximate power-law forms in each case.

does, the distinction between any two values that fall into the same bin. The
cumulative distribution function on the other hand preserves all of the information contained in the data, because no bins are involved. The most obvious manifestation of this difference is that the number of points in a plot like
Fig. 8.5 or Fig. 8.6 is relatively small, whereas in a cumulative distribution plot
like Fig. 8.7 there are as many points along the k (horizontal) axis as there are
distinct values of k.
The cumulative distribution function is also easy to calculate. The number
of vertices with degree greater than or equal to that of the rth-highest-degree
vertex in a network is, by deﬁnition, r. Thus the fraction with degree greater
than or equal to that of the rth-highest-degree vertex in a network is Pk = r/n.
So a simple way of ﬁnding Pk is to sort the degrees of the vertices in descending
order and then number them from 1 to n in that order. These numbers are the
so-called ranks ri of the vertices. A plot of ri /n as a function of degree k i , with
the vertices in rank order, then gives us our cumulative distribution plot.3
3

Such plots are also sometimes called rank/frequency plots because one of their earliest uses
was to detect power-law behavior in the frequency of occurrence of words in natural languages.
If the data you are measuring are frequencies, then the cumulative distribution graph is a plot of
rank against frequency. Since then such plots have been used to detect power-law behavior in

253

T HE LARGE - SCALE STRUCTURE OF NETWORKS

For instance, consider again the small example network we looked at at the
beginning of Section 8.3, on page 244. The degrees of the vertices in that case
were {0, 1, 1, 2, 2, 2, 2, 3, 3, 4}. Listing these in decreasing order and numbering
them, we can easily calculate Pk as follows:
Degree k
4
3
3
2
2
2
2
1
1
0

Rank r
1
2
3
4
5
6
7
8
9
10

Pk = r/n
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0

Then a plot of the last column as a function of the ﬁrst gives us our cumulative
distribution function.
Cumulative distributions do have some disadvantages. One is that they are
less easy to interpret than ordinary histograms, since they are only indirectly
related to the actual distribution of vertex degrees. A more serious disadvantage is that the successive points on a cumulative plot are correlated—the cumulative distribution function in general only changes a little from one point
to the next, so adjacent values are not at all independent. This means that it
is not valid for instance to extract the exponent of a power-law distribution by
ﬁtting the slope of the straight-line portion of a plot like Fig. 8.7 and equating
the result with α − 1, at least if the ﬁtting is done using standard methods such
as least squares that assume independence between the data points.
In fact, it is in general not good practice to evaluate exponents by performing straight-line ﬁts to either cumulative distribution functions or ordinary histograms. Both are known to give biased answers, although for different reasons [72, 141]. Instead, it is usually better to calculate α directly from the data,
many quantities other than frequencies, but the name “rank/frequency plot” is still often used.

254

|

8.4

using the formula4



ki
α = 1 + N ∑ ln
1
k
min − 2
i

P OWER LAWS AND SCALE - FREE NETWORKS

 −1
.

(8.6)

Here, kmin is the minimum degree for which the power law holds, as before,
and N is the number of vertices with degree greater than or equal to kmin . The
sum is performed over only those vertices with k ≥ kmin , and not over all
vertices.
We can also calculate the statistical error on α from the formula:
 −1

√
ki
α−1
= √ .
(8.7)
σ = N ∑ ln
1
k
−
N
min
i
2
For example, applying Eqs. (8.6) and (8.7) to the degree sequence of the Internet
from Fig. 8.3 gives an exponent value of α = 2.11 ± 0.01.
The derivation of these formulas, which makes use of maximum likelihood
techniques, would take us some way from our primary topic of networks,
so we will not go into it here. The interested reader can ﬁnd a discussion in
Ref. [72], along with many other details such as methods for determining the
value of kmin and methods for telling whether a particular distribution follows
a power law at all.
8.4.2

P ROPERTIES OF POWER - LAW DISTRIBUTIONS

Quantities with power-law distributions behave in some surprising ways. We
take a few pages here to look at some of the properties of power-law distributions, since the results will be of use to us later on.
Power laws turn up in a wide variety of places, not just in networks. They
are found in the sizes of city populations [24, 336], earthquakes [153], moon
craters [230], solar ﬂares [203], computer ﬁles [84], and wars [283]; in the frequency of use of words in human languages [109, 336], the frequency of occurrence of personal names in most cultures [335], the numbers of papers scientists write [201], and the number of hits on web pages [5]; in the sales of books,
music recordings, and almost every other branded commodity [83, 185]; and
in the numbers of species in biological taxa [58, 330]. A review of the data and
some mathematical properties of power laws can be found in Ref. [244]. Here
we highlight just a few issues that will be relevant for our study of networks.
4

In fact, this formula is only an approximation to the full formula for the exponent. The full
formula, unfortunately, does not give a closed-form solution for α and is therefore hard to use.
Equation (8.6) works well provided kmin is greater than about 6, which is true for many networks.
In cases where it is not, however, the full formula must be used—see Ref. [72].

255

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Normalization: The constant C appearing in Eq. (8.3) is ﬁxed by the requirement that the degree distribution be normalized. That is, when we add up the
total fraction of vertices having all possible degrees k = 0 . . . ∞, we must get 1:
∞

∑ pk = 1.

(8.8)

k =0

If our degree distribution truly follows a pure power law, obeying Eq. (8.3) for
all k, then no vertices of degree zero are allowed, because p0 would then be inﬁnite, which is impossible since it is a probability and must lie between 0 and 1.
Let us suppose therefore that the distribution starts at k = 1. Substituting from
Eq. (8.3) we then ﬁnd that C ∑k k−α = 1, or
C=

1

1

=
,
∞
ζ (α)
∑ k =1 k − α

(8.9)

where ζ (α) is the Riemann zeta function. Thus the correctly normalized powerlaw distribution is
k −α
,
(8.10)
pk =
ζ (α)
for k > 0 with p0 = 0.
This is a reasonable starting point for mathematical models of scale-free
networks—we will use it in Chapter 13—but it’s not a very good representation of most real-world networks, which deviate from pure power-law behavior for small k as described above and seen in Fig. 8.3. In that case, the
normalization constant will take some other value dependent on the particular shape of the distribution, but nonetheless it is still ﬁxed by the requirement
of normalization and we must make sure we get it right in our calculations.
For some of our calculations we will be interested only in the tail of the
distribution where the power-law behavior holds and can discard the rest of
the data. In such cases, we normalize over only the tail, starting from the
minimum value kmin for which the power law holds, as above. This gives
pk =

k −α

k −α

=
,
∞
ζ (α, kmin )
∑k=kmin k−α

(8.11)

where ζ (α, kmin ) is the so-called generalized or incomplete zeta function.
Alternatively, we could observe, as we did for Eq. (8.5), that in the tail of
the distribution the sum over k is well approximated by an integral, so that the
normalization constant can written
1
−1
= (α − 1)kαmin
,
−α dk
k
kmin

C ≃ ∞
256

(8.12)

8.4

or
pk ≃

α−1
kmin

|

P OWER LAWS AND SCALE - FREE NETWORKS

−α

k

.

kmin

(8.13)

In the same approximation the cumulative distribution function, Eq. (8.5), is
given by
−(α−1)
k
.
(8.14)
Pk =
kmin
Moments: Of great interest to us will be the moments of the degree distribution. The ﬁrst moment of a distribution is its mean:
∞

k = ∑ kpk .

(8.15)

k =0

The second moment is the mean square:
∞

k2 = ∑ k2 pk .

(8.16)

k =0

And the mth moment is

∞

km = ∑ km pk .

(8.17)

k =0

Suppose we have a degree distribution pk that has a power-law tail for
k ≥ kmin , in the manner of the Internet or the World Wide Web. Then
km =

kmin −1

∑

k =0

km pk + C

∞

∑ k m−α .

(8.18)

k =kmin

Since the power law is a slowly varying function of k for large k, we can again
approximate the second sum by an integral thus:
km ≃

=

kmin −1

∑

k =0
kmin −1

∑

k =0

km pk + C
km pk +

 ∞
kmin

km−α dk


∞
C
k m − α +1
.
m−α+1
kmin

(8.19)

The ﬁrst term here is some ﬁnite number whose value depends on the particular (non-power-law) form of the degree distribution for small k. The second
term however depends on the values of m and α. If m − α + 1 < 0, then the
bracket has a ﬁnite value, and km is well-deﬁned. But if m − α + 1 ≥ 0 then
the bracket diverges and with it the value of km . Thus, the mth moment of
the degree distribution is ﬁnite if and only if α > m + 1. Put another way, for a
given value of α all moments will diverge for which m ≥ α − 1.
257

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Of particular interest to us will be the second moment k2 , which arises
in many calculations to do with networks (such as mean degree of neighbors,
Section 13.3, robustness calculations, Section 16.2.1, epidemiological processes,
Section 17.8.1, and many others). The second moment is ﬁnite if and only if
α > 3. As discussed above, however, most real-world networks with powerlaw degree distributions have values of α in the range 2 ≤ α ≤ 3, which means
that the second moment should diverge, an observation that has a number
of remarkable implications for the properties of scale-free networks, some of
which we will explore in coming chapters. Notice that this applies even for
networks where the power law only holds in the tail of the distribution—the
distribution does not have to follow a power law everywhere for the second
moment to diverge.
These conclusions, however, are slightly misleading. In any real network
all the moments of the degree distribution will actually be ﬁnite. We can always calculate the mth moment directly from the degree sequence thus:
km =

1 n m
ki ,
n i∑
=1

(8.20)

and since all the k i are ﬁnite, so must the sum be. When we say that the mth
moment is inﬁnite, what we mean is that if we were to calculate it for an arbitrarily large network with the same power-law degree distribution the value
would be inﬁnite. But for any ﬁnite network Eq. (8.20) applies and all moments
are ﬁnite.
There is however another factor that limits the values of the higher moments of the degree distribution, namely that most real-world networks are
simple graphs. That is, they have no multiedges and no self-loops, which
means that a vertex can have, at most, one edge to every other vertex in the
network, giving it a maximum degree of n − 1, where n is the total number of
vertices. In practice, the power-law behavior of the degree distribution may
be cut off for other reasons before we reach this limit, but in the worst case, an
integral such as that of Eq. (8.19) will be cut off in a simple graph at k = n so
that

n
k m ∼ k m − α +1
∼ n m − α +1 ,
(8.21)
kmin

as n → ∞ for m > α − 1. This again gives moments that are ﬁnite on ﬁnite
networks but become inﬁnite as the size of the network becomes inﬁnite. For
instance, the second moment goes as
k 2 ∼ n 3− α .

(8.22)

In a network with α = 52 , this diverges as n1/2 as the network becomes large.
258

8.4

|

P OWER LAWS AND SCALE - FREE NETWORKS

We will throughout this book derive results that depend on moments of the
degree distributions of networks. Some of those results will show unusual behavior in power-law networks because of the divergence of the moments. On
practical, ﬁnite networks that divergence is replaced by large ﬁnite values of
the moments. In many cases, however, this produces similar results to a true
divergence. On the Internet, for instance, with its power-law degree distribution and a total of about n ≃ 20 000 autonomous systems as vertices, we can
expect the second (and all higher moments) to take not inﬁnite but very large
values. For the Internet data we used in Figs. 8.3 and 8.5 the second moment
has the value k2 = 1159, which can in practice be treated as inﬁnite for many
purposes.
Top-heavy distributions: Another interesting quantity is the fraction of edges
in a network that connect to the vertices with the highest degrees. For a pure
power-law degree distribution, it can be shown [244] that a fraction W of ends
of edges attach to a fraction P of the highest-degree vertices in the network,
where
(8.23)
W = P ( α −2) / ( α −1) ,
A set of curves of W against P is shown in Fig. 8.9 for various values of α.
Curves of this kind are called Lorenz curves, after Max Lorenz, who ﬁrst studied
them around the turn of the twentieth century [200]. As the ﬁgure shows, the
curves are concave downward for all values of α, and for values only a little
above 2 they have a very fast initial increase, meaning that a large fraction of
the edges are connected to a small fraction of the highest degree nodes.
Thus, for example, the in-degree distribution of the World Wide Web follows a power law above about kmin = 20 with exponent around α = 2.2. Equation (8.23) with P = 12 then tells us that we would expect that about W = 0.89
or 89% of all hyperlinks link to pages in the top half of the degree distribution, while the bottom half gets a mere 11%. Conversely, if we set W = 12 in
Eq. (8.23) we get P = 0.015, implying that 50% of all the links go to less than
2% of the “richest” vertices. Thus the degree distribution is in a sense “topheavy,” a large fraction of the “wealth”—meaning incoming hyperlinks in this
case—falling to a small fraction of the vertices.
This calculation assumes a degree distribution that follows a perfect power
law, whereas in reality, as we have seen, degree distributions usually only follow a power law in their high-degree tail. The basic principle still holds, however, and even if we cannot write an exact formula like Eq. (8.23) for a particular network we can easily evaluate W as a function of P directly from degree

259

T HE LARGE - SCALE STRUCTURE OF NETWORKS

Fraction of ends of edges W

1

0.8

0.6

= 2.1
= 2.2
= 2.4
= 2.7

0.4

= 3.5

0.2

0
0

0.2

0.4

0.6

0.8

1

Fraction of vertices P

Figure 8.9: Lorenz curves for scale-free networks. The curves show the fraction W
of the total number of ends of edges in a scale-free network that are attached to the
fraction P of vertices with the highest degrees, for various values of the power-law
exponent α.

data. For the real degree distribution of the Web5 we ﬁnd that 50% of the incoming hyperlinks point to just 1.1% of the richest vertices (so Eq. (8.23) was
not too bad in this case).
Similarly, for paper citations 8.3% of the highest cited papers get 50% of all
the citations6 and on the Internet just 3.3% of the most highly connected nodes
have 50% of the connections.7
In the remaining chapters of this book we will see many examples of networks with power-law degree distributions, and we will make use of the results of this section to develop an understanding of their behavior.

260

5

Using the data of Broder et al. [56].

6

Using the data of Redner [280].

7

For the AS-level data of Fig. 8.3.

8.5

8.5

|

D ISTRIBUTIONS OF OTHER CENTRALITY MEASURES

D ISTRIBUTIONS OF OTHER CENTRALITY MEASURES

Vertex degree is just one of a variety of centrality measures for vertices in networks, as discussed in Chapter 7. Other centrality measures include eigenvector centrality and its variations (Sections 7.2 to 7.5), closeness centrality
(Section 7.6), and betweenness centrality (Section 7.7). The distributions of
these other measures, while of lesser importance in the study of networks than
the degree distribution, are nonetheless of some interest.
Eigenvector centrality can be thought of as an extended form of degree centrality, in which we take into account not only how many neighbors a vertex
has but also how central those neighbors themselves are (Section 7.2). Given its
similarity to degree centrality, it is perhaps not surprising to learn that eigenvector centrality often has a highly right-skewed distribution. The left panel
of Fig. 8.10 shows the cumulative distribution of eigenvector centralities for
the vertices of the Internet, using again the autonomous-system-level data that
we used in Section 8.3. As the ﬁgure shows, the tail of the distribution approximately follows a power law but the distribution rolls off for vertices with
low centrality. Similar roughly power-law behavior is also seen in eigenvector
centralities for other scale-free networks, such as the World Wide Web and citation networks, while other networks show right-skewed but non-power-law
distributions.
Betweenness centrality (Section 7.7) also tends to have right-skewed distributions on most networks. The right panel of Fig. 8.10 shows the cumulative
distribution of betweenness for the vertices of the Internet and, as we can see,
this distribution is again roughly power-law in form. Again there are some
other networks that also have power-law betweenness distributions and others
still that have skewed but non-power-law distributions.
An exception to this pattern is the closeness centrality (Section 7.6), which
is the mean geodesic distance from a vertex to all other reachable vertices. As
discussed in Section 7.6 the values of the closeness centrality are typically limited to a rather small range from a lower bound of 1 to an upper bound of
order log n, and this means that their distribution cannot have a long tail. In
Fig. 8.11, for instance, we show the distributions of closeness centralities for
our snapshot of the Internet, and the distribution spans well under an order of
magnitude from a minimum of 2.30 to a maximum of 7.32. There is no long
tail to the distribution, and the distribution is not even roughly monotonically
decreasing (as our others have been) but shows clear peaks and dips.

261

Fraction of vertices having centrality x or greater

T HE LARGE - SCALE STRUCTURE OF NETWORKS

1

1

0.1

0.1

0.01

0.01

0.001

0.001

10

-5

10

-4

10

-3

Eigenvector centrality x

10

-4

10

-3

10

-2

10

-1

Betweenness centrality x

Figure 8.10: Cumulative distribution functions for centralities of vertices on the Internet. Left panel: eigenvector centrality. Right panel: betweenness centrality.

8.6
See Section 7.9 for a discussion of clustering coefﬁcients.

C LUSTERING COEFFICIENTS

The clustering coefﬁcient measures the average probability that two neighbors
of a vertex are themselves neighbors. In effect it measures the density of triangles in the networks and it is of interest because in many cases it is found
to have values sharply different from what one would expect on the basis of
chance. To see what we mean by this, look again at Table 8.1 on page 237,
which gives measured values of the clustering coefﬁcient for a variety of networks. (Look at the column denoted C, which gives values for the coefﬁcient
deﬁned by Eq. (7.41).) Most of the values are of the order of tens of percent—
there is typically a probability between about 10% and maybe 60% that two
neighbors of a vertex will be neighbors themselves. However, as we will see
in Section 13.4, if we consider a network with a given degree distribution in
which connections between vertices are made at random, the clustering coefﬁcient takes the value
2
1 k2 − k
.
(8.24)
C=
n
k 3
In networks where k2 and k have ﬁxed ﬁnite values, this quantity becomes
small as n → ∞ and hence we expect the clustering coefﬁcient to be very small
on large networks. This makes the values in Table 8.1, which are of order 1,

262

8.6

|

C LUSTERING COEFFICIENTS

0.25

Fraction of vertices

0.2

0.15

0.1

0.05

0
2

3

4

5

6

7

Closeness centrality

Figure 8.11: Histogram of closeness centralities of vertices on the Internet. Unlike
Fig. 8.10 this is a normal non-cumulative histogram showing the actual distribution of
closeness centralities. This distribution does not follow a power law.

quite surprising, and indeed many of them turn out to be much larger than the
estimate given by Eq. (8.24). For instance, the collaboration network of physicists is measured to have a clustering coefﬁcient of 0.45. Plugging the appropriate values for n, k , and k2 into Eq. (8.24) on the other hand gives C = 0.0023.
Thus the measured value is more than a hundred times greater than the value
we would expect if physicists chose their collaborators at random.
Presumably this large difference is indicative of real social effects at work.
There are a number of reasons why a real collaboration network might contain
more triangles than one would expect by chance, but for example it might be
that people introduce pairs of their collaborators to one another and those pairs
then go on to collaborate themselves. This is an example of the process that
social network analysts call triadic closure: an “open” triad of vertices (i.e., a
triad in which one vertex is linked to the other two, but the third possible edge
is absent) is “closed” by the addition of the last edge, forming a triangle.
One can study triadic closure processes directly if one has time-resolved
data on the formation of a network. The network of physics collaborators discussed here was studied in this way in Ref. [233], where it was shown that
pairs of individuals who have not previously collaborated, but who have an263

T HE LARGE - SCALE STRUCTURE OF NETWORKS

other mutual collaborator, are enormously more likely to collaborate in future
than pairs who do not—a factor of 45 times as likely in that particular study.
Furthermore, the probability of future collaboration also goes up sharply as
the number of mutual collaborators increases, with pairs having two mutual
collaborators being more than twice as likely to collaborate in future as those
having just one.
However, it is not always the case that the measured clustering coefﬁcient
greatly exceeds the expected value given by Eq. (8.24). Take the example of
the Internet again. For the data set we examined earlier the measured clustering coefﬁcient is just 0.012. The expected value, if connections were made at
random, is 0.84. (The large value arises because, as discussed in Section 8.4,
the Internet has a highly right-skewed degree distribution, which makes k2
large.) Clearly in this case the clustering is far less than one would expect on
the basis of chance, suggesting that in the Internet there are forces at work that
shy away from the creation of triangles.8
In some other networks, such as food webs or the World Wide Web, clustering is neither higher nor lower than expected, taking values roughly comparable with those given by Eq. (8.24). It is not yet well understood why clustering
coefﬁcients take such different values in different types of network, although
one theory is that it may be connected with the formation of groups or communities in networks [252].
The clustering coefﬁcient measures the density of triangles in a network.
There is no reason, however, for us to limit ourselves to studying only triangles. We can also look at the densities of other small groups of vertices, or
motifs, as they are often called. One can deﬁne coefﬁcients similar to the clustering coefﬁcient to measure the densities of different motifs, although more often
one simply counts the numbers of the motifs of interest in a network. And, as
with triangles, one can compare the results with the values one would expect
to ﬁnd if connections in the network are made at random. In general, one can
8

It is sometimes claimed that essentially all networks show clustering higher than expected [12, 323], which is at odds with the results given here. There seem to be two reasons for
the disagreement. First, the claims are based primarily on comparisons of measured clustering
coefﬁcients against values calculated on the Poisson random graph, a simple model network with
a Poisson degree distribution, which we study in Chapter 12.1. Many networks, however, have
right-skewed degree distributions which are very far from Poissonian, and hence the random
graph is a poor model against which to compare measurements and probably gives misleading results. Second, the clustering coefﬁcients in these comparisons are mostly calculated as an average
of the local clustering, following Eq. (7.44). On networks with highly skewed degree distributions
this deﬁnition can give very different results from the deﬁnition, Eq. (7.41), used in our calculations. Usually Eq. (7.44) gives much larger numbers than Eq. (7.41), which could explain the
discrepancies in the ﬁndings.

264

|

8.6

C LUSTERING COEFFICIENTS

ﬁnd counts that are higher, lower, or about the same as the expected values, all
of which can have implications for the understanding of the networks in question. For example, Milo et al. [221] looked at motif counts in genetic regulatory
networks and neural networks and found certain small motifs that occurred
far more often than was expected on the basis of chance. They conjectured that
these motifs were playing the role of functional “circuit elements,” such as ﬁlters or pulse generators, and that their frequent occurrence in these networks
might be an evolutionary result of their usefulness to the organisms involved.
8.6.1

L OCAL CLUSTERING COEFFICIENT

In Section 7.9.1 we introduced the local clustering coefﬁcient for a vertex:
Ci =

(number of pairs of neighbors of i that are connected)
,
(number of pairs of neighbors of i)

(8.25)

which is the fraction of pairs of neighbors of vertex i that are themselves neighbors. If we calculate the local clustering coefﬁcient for all vertices in a network,
an interesting pattern emerges in many cases: we ﬁnd that on average vertices
of higher degree tend to have lower local clustering [278, 318]. Figure 8.12, for
example, shows the average value of the local clustering coefﬁcient for vertices
of degree k on the Internet as a function of k. The decrease of the average Ci
with k is clear. It has been conjectured that plots of this type take either the
form Ci ∼ k−0.75 [318] or the form Ci ∼ k−1 [278]. In this particular case neither
of these conjectures matches the data very well, but for some other networks
they appear reasonable.
On possible explanation for the decrease in Ci with increasing degree is that
vertices group together into tightly knit groups or communities, with vertices
being connected mostly to others within their own group. In a network showing this kind of behavior vertices that belong to small groups are constrained
to have low degree, because they have relatively few fellow group members to
connect to, while those in larger groups can have higher degree. (They don’t
have to have higher degree, but they can.) At the same time, the local clustering coefﬁcient of vertices in small groups will tend to be larger. This occurs
because each group, being mostly detached from the rest of the network, functions roughly as its own small network and, as discussed in Section 8.6, smaller
networks are expected to have higher clustering. When averaged over many
groups of different sizes, therefore, we would expect vertices of lower degree
to have higher clustering on average, as in Fig. 8.12.9
9

Community structure in
networks is discussed at
some length in Chapter 11.

An alternative and more complex proposal is that the behavior of the local clustering co-

265

Average local clustering coefficient Ci

T HE LARGE - SCALE STRUCTURE OF NETWORKS

0.1

0.01

0.001

1

10

100

1000

Degree k

Figure 8.12: Local clustering as a function of degree on the Internet. A plot of the
measured mean local clustering coefﬁcient of vertices on the Internet (at the level of
autonomous systems) averaged over all vertices with the given degree.

8.7

A SSORTATIVE MIXING

Assortative mixing or homophily is the tendency of vertices to connect to
others that are like them in some way. We discussed assortative mixing in
Section 7.13, where we gave some examples from social networks, such as the
high school friendships depicted in Figs. 7.10 and 7.11 in which school students
tend to associate more with others of the same ethnicity or age as themselves.
Of particular interest is assortative mixing by degree, the tendency of vertices to connect others with degrees that are similar to their own. We can
also have disassortative mixing by degree, in which vertices connect to others
with very different degrees. As we saw in Section 7.13.3, assortative mixing
can have substantial effects on the structure of a network (see particularly
Fig. 7.12).
Assortative mixing by degree can be quantiﬁed in a number of different
efﬁcient arises through hierarchical structure in a network—that not only are there groups, but
that the groups are divided into smaller groups, and those into still smaller ones, and so on. See
Refs. [95, 278, 309].

266

8.7

|

A SSORTATIVE MIXING

ways. One of them is to use the correlation coefﬁcient deﬁned in Eq. (7.82):
r=

∑ij ( Aij − k i k j /2m)k i k j
∑ij (k i δij − k i k j /2m)k i k j

.

(8.26)

If we were going to calculate the value of this coefﬁcient, however, we should
not do it directly from this equation, because the double sum over vertices i
and j has a lot of terms (n2 of them) and is slow to evaluate on a computer.
Instead we write
S1 Se − S22
r=
,
(8.27)
S1 S3 − S22
with

Se = ∑ Aij k i k j = 2

∑ ki k j ,

(8.28)

edges (i,j)

ij

where the second sum is over all distinct (unordered) pairs of vertices (i, j)
connected by an edge, and
S1 = ∑ k i ,
i

S2 = ∑ k2i ,
i

S3 = ∑ k3i .

(8.29)

i

The sum in (8.28) has m terms, where m is the number of edges in the network
and the sums in (8.29) have n terms each, so Eq. (8.27) is usually a lot faster to
evaluate than Eq. (8.26).
In Table 8.1 we show the values of r for a range of networks and the results reveal an interesting pattern. While none of the values are of very large
magnitude—the correlations between degrees are not especially strong—there
is a clear tendency for the social networks to have positive r, indicating assortative mixing by degree, while the rest of the networks—technological, information, biological—have negative r, indicating disassortative mixing.
The reasons for this pattern are not known for certain, but it appears that
many networks have a tendency to negative values of r because they are simple graphs. As shown by Maslov et al. [211], graphs that have only single edges
between vertices tend in the absence of other biases to show disassortative mixing by degree because the number of edges that can fall between high-degree
vertex pairs is limited. Since most networks are represented as simple graphs
this implies that most should be disassortative, as indeed Table 8.1 indicates
they are.
And what about the social networks? One suggestion is that social networks are assortatively mixed because they tend to be divided into groups, as
discussed in Section 8.6.1. If a network is divided up into tightly knit groups
of vertices that are mostly disconnected from the rest of the network, then, as

The computer time needed
to calculate network quantities is an important topic
in its own right. We discuss
the main issues in Chapter 9.

267

T HE LARGE - SCALE STRUCTURE OF NETWORKS

we have said, vertices in small groups tend to have lower degree than vertices
in larger groups. But since the members of small groups are in groups with
other members of the same small groups, it follows that the low-degree vertices will tend to be connected to other low-degree vertices, and similarly for
high-degree ones. This simple idea can be turned into a quantitative calculation [252] and indeed it appears that, at least under some circumstances, this
mechanism does produce positive values of r.
Thus a possible explanation of the pattern of r-values seen in Table 8.1 is
that most networks are naturally disassortative by degree because they are
simple graphs while social networks (and perhaps a few others) override this
natural bias and become assortative by virtue of their group structure.

P ROBLEMS
8.1

One can calculate the diameter of certain types of network exactly.
a) What is the diameter of a clique?
b) What is the diameter of a square portion of square lattice, with L edges (or equivalently L + 1 vertices) along each side, like this:

L

L

What is the diameter of the corresponding hypercubic lattice in d dimensions with
L edges along each side? Hence what is the diameter of such a lattice as a function
of the number n of vertices?
c) A Cayley tree is a symmetric regular tree in which each vertex is connected to the
same number k of others, until we get out to the leaves, like this:

268

P ROBLEMS

(We have k = 3 in this picture.)
Show that the number of vertices reachable in d steps from the central vertex
is k(k − 1)d−1 for d ≥ 1. Hence ﬁnd an expression for the diameter of the network
in terms of k and the number of vertices n.
d) Which of the networks in parts (i), (ii), and (iii) displays the small-world effect,
deﬁned as having a diameter that increases as log n or slower?
8.2 Suppose that a network has a degree distribution that follows the exponential
form pk = Ce−λk , where C and λ are constants.
a) Find C as a function of λ.
b) Calculate the fraction P of vertices that have degree k or greater.
c) Calculate the fraction W of ends of edges that are attached to vertices of degree k
or greater.
d) Hence show that for the exponential degree distribution with exponential parameter λ, the Lorenz curve—the equivalent of Eq. (8.23)—is given by
W = P−

1 − eλ
P ln P.
λ

e) Show that the value of W is greater than one for some values of P in the range
0 ≤ P ≤ 1. What is the meaning of these “unphysical” values?
8.3 A particular network is believed to have a degree distribution that follows a power
law. Among a random sample of vertices in the network, the degrees of the ﬁrst 20
vertices with degree 10 or greater are:
16
14
12
36

17
28
10
12

10
45
136
14

26
10
16
22

13
12
25
10

Estimate the exponent α of the power law and the error on that estimate using Eqs. (8.6)
and (8.7).

269

T HE LARGE - SCALE STRUCTURE OF NETWORKS

8.4 Consider the following simple and rather unrealistic mathematical model of a network. Each of n vertices belongs to one of several groups. The mth group has nm vertices and each vertex in that group is connected to others in the group with independent
probability pm = A(nm − 1)− β , where A and β are constants, but not to any vertices in
other groups. Thus this network takes the form of a set of disjoint clusters or communities.
a) Calculate the expected degree k of a vertex in group m.
b) Calculate the expected value C m of the local clustering coefﬁcient for vertices in
group m.
c) Hence show that C m ∝ k − β/(1− β) .
d) What value would β have to have for the expected value of the local clustering to
fall off with increasing degree as k −3/4 ?

270

This page intentionally left blank

This page intentionally left blank

PART III
C OMPUTER ALGORITHMS

273

This page intentionally left blank

C HAPTER 9

B ASIC CONCEPTS OF ALGORITHMS
An introduction to some of the basic concepts of
computer algorithms for network calculations,
particularly data structures for storing networks and
methods for estimating the time computations will take

I

N THE preceding chapters of this book we have introduced various types of

networks encountered in scientiﬁc study, methods for collecting data about
those networks, and some of the basic theoretical tools used to describe and
quantify networks. Then in the last chapter we combined these ideas in an
analysis of the structural features of a variety of real-world networks, revealing
in the process a number of interesting patterns that will be important to our
further studies in the remainder of the book.
Analysis of this kind, and most analysis involved in the contemporary
study of networks, is primarily performed using computers. In the early days
of network analysis in the ﬁrst part of the twentieth century, calculations were
mostly performed by hand, partly out of necessity, since computers were slow,
expensive, and rare, but also because the networks studied were typically quite
small, consisting of perhaps just a few dozen vertices or even less. These days
we are concerned with networks that have thousands or even millions of vertices. Gathering and analyzing the data for networks like these is only possible
because of the advent of fast cheap computing.
Some networks calculations are simple enough that it is obvious how one
would get a computer to carry them out, but many are not and performing
them efﬁciently requires careful consideration and thoughtful programming.
Even merely storing a network in a computer requires some thought, since
there are many methods for doing it and the choice of method can make a
substantial difference to the performance of subsequent calculations.
In this chapter and the following two we discuss some of the techniques
275

B ASIC CONCEPTS OF ALGORITHMS

and algorithms used for network calculations on computers. A good understanding of the material discussed here will form a solid foundation for writing
software to perform a wide variety of calculations with network data.
In this chapter we describe some simple but important ideas about the running time of algorithms and data structures for the storage of networks. We
will not describe any actual algorithms in this chapter, but the ideas introduced
form a foundation for understanding the algorithms that appear in the following chapters.
In Chapter 10 we describe a selection of basic network algorithms, including many of the classics of the ﬁeld, such as algorithms for calculating centrality indices, ﬁnding components, and calculating shortest paths and maximum
ﬂows. We continue our study of algorithms in Chapter 11, where we look at
matrix-based algorithms and particularly at methods for network “partitioning.”
Understanding the content of these chapters does not require that you know
how to program a computer. We will not, for instance, discuss particular programming languages. However, some experience with programming will certainly help enormously in understanding the material, and the reader who has
none will in any case probably not have very much use for the methods we
describe.
Conversely, readers who already have a thorough knowledge of computer
algorithms may well ﬁnd some of the material here too basic for them, particularly the material on run times and data structures in the present chapter.
Such readers should feel free to skip material as appropriate and move quickly
on to the possibly less familiar subject matter of Chapters 10 and 11. For very
advanced readers for whom all the material covered here is already familiar,
or readers who simply wish to go into the subject in greater detail, we recommend the books by Cormen et al. [81], which is a general computer science
text on algorithms, and by Ahuja et al. [8], which is speciﬁcally on network
algorithms.
Before we leap into the study of algorithms, one further word of advice is
worthwhile. Many of the standard algorithms for the study of networks are
already available, ready-made, in the form of professional network analysis
software packages. Many of these packages are of very high quality, produced
by excellent and knowledgeable programmers, and if they are adequate for
your needs then there is no reason not to use them. Writing and debugging
your own software for the analysis of network data can take hours or days,
and there is little reason to expend that time when someone else has already
done it for you. Table 9.1 lists some of the most widely used current software
packages for the analysis of network data along with a brief description of
276

B ASIC CONCEPTS OF ALGORITHMS

Name
Pajek
Net Workbench
Netminer
InFlow
UCINET
yEd
Visone
Graphviz
NetworkX
JUNG
igraph
GTL
LEDA/AGD

Availability
Free
Free
Commercial
Commercial
Commercial
Free
Free
Free
Free
Free
Free
Free
Commercial

Platform
W
WML
W
W
W
WML
WL
L
WML
WML
WML
WML
WL

Description
Interactive social network analysis and visualization
Interactive network analysis and visualization
Interactive social network analysis and visualization
Interactive social network analysis and visualization
Interactive social network analysis
Interactive visualization
Interactive visualization
Visualization
Interactive network analysis and Python library
JAVA library for network analysis and visualization
C/R/Python libraries for network analysis
C++ library for network analysis
C++ library for network analysis

Table 9.1: A selection of software implementing common network algorithms. Platforms are Microsoft Windows (W),
Apple Macintosh (M), and Linux (L). Most Linux programs also run under Unix and Unix-like systems such as BSD,
and many Windows programs can run on Macs and Linux systems using emulation software.

what they do. The present author, for instance, has made considerable use of
Graphviz, Pajek, and yEd, all of which provide useful features that could save
you a lot of time in your work. Some other network calculations, especially
the matrix-based methods of Chapter 11 and calculations using the models of
Chapters 12 to 15, can be performed using standard mathematical software
such as Matlab, Mathematica, or Maple, and again there is no reason not to
make use of these resources if they are adequate for the particular task before
you.
That said there are still some excellent reasons for studying network algorithms and computer methods. First of all, even when you are making use of
pre-packaged software to do your calculations, it helps greatly if you understand how the algorithms work and what the software is doing. Much time
can be wasted when people fail to understand how a program works or misunderstand the kinds of answers the program can give them. Furthermore, if
you are going to undertake a substantial amount of work using network data,
you will sooner or later ﬁnd that you need to do something that cannot be done
with standard software and you’ll have to write some programs of your own.
Second, there is a marked tendency in the current networks literature for
some researchers to restrict their calculations to those that can be carried out
using the standard software. By relying on pre-packaged programs to do their

277

B ASIC CONCEPTS OF ALGORITHMS

calculations for them, researchers have become limited in what types of analysis they can perform. In this way, the standard packages have, in effect, shaped
the research agenda of the empirical side of the ﬁeld, which is completely the
reverse of what it should be. Good research decides the interesting questions
ﬁrst and then goes in search of answers. Research that restricts itself only to
the questions it already knows how to answer will be narrowly focused indeed.
By following the developments in this and the following chapters, and, if you
wish, reading further in the algorithms literature, you give yourself the opportunity to pursue whatever network questions are of interest to you, without
having to rely on others to produce software to tackle those questions.

9.1

R UNNING TIME AND COMPUTATIONAL COMPLEXITY

Before we can look at exactly how network algorithms work, there is an important issue we need to tackle, that of computational complexity. If you have
programmed computers before, you may well have had the experience of writing a program to perform a particular calculation and setting it running, only
to ﬁnd that it is still running an hour or even a day later. Performing a quick
back-of-the-envelope calculation, you discover to your dismay that the calculation you have started will take a thousand years to ﬁnish, and hence that the
program you wrote is basically useless.
The concept of computational complexity (or just “complexity” for short) is
essentially a more formal version of back-of-the-envelope calculations like this
one, and is useful precisely because it helps us to avoid wasting our energies
on programs that will not ﬁnish running in any reasonable amount time. By
considering the complexity of an algorithm before we even start to write a
computer program, we can be sure we are writing one that will actually ﬁnish.
Computational complexity is a measure of the running time of a computer
algorithm. Consider a simple example: how long does it take to ﬁnd the largest
number in a list of n numbers? Assuming the numbers are not given to us in
some special order (such as largest ﬁrst), then there is no quicker way to ﬁnd
the largest than simply to go through the whole list, item by item, keeping a
running record of the largest number we have seen, until we get to the end.
This is a very simple example of a computer algorithm. We could use it,
for instance, to ﬁnd the vertex in a network that has the highest degree. The
algorithm consists of a number of steps, one for each number in the list. On
each step, we examine the next number in the list and ask whether it is larger
than the largest we have seen so far. If it is, it becomes the new largest-numberseen-so-far, otherwise nothing happens and we move on to the next step.
Now here is the crucial point: in the worst possible case the most work we
278

9.1

|

R UNNING TIME AND COMPUTATIONAL COMPLEXITY

will have to do for this algorithm is on each step to (1) examine the next number, (2) compare it with our previous record holder, and (3) replace the previous
record holder with the new number. That is, the largest amount of work we
have to do happens when every number is bigger than all the ones before it.
In this case the amount of work we do is the same on every step and hence
the total time taken to complete the algorithm, its running time, is just nτ,
where τ is the time taken on each individual step. If we are lucky, the actual
time taken may be less than this, but it will never be more. Thus we say that
the running time or time complexity of this algorithm is order n, or just O(n)
for short. Technically the notation O(n) means that the running time varies as
a constant times n or less, to leading order in n.1 We say “to leading-order”
because it is possible that there may be contributions to the running time that
increase with system size more slowly than this leading-order term. For instance, there might be some initial start-up time for the algorithm, such as time
taken initializing variables, that is a constant independent of n. We would denote this time as being O(1), i.e., a constant times 1. By convention, however,
one drops such sub-leading terms when citing the complexity of an algorithm,
because if n is large enough that the running time of the program becomes a
serious issue then the sub-leading terms will usually be small enough by comparison with the leading ones that they can be safely neglected.2 Thus the time
complexity of our simple largest-number algorithm is just O(n).
Technically, the computational complexity of an algorithm is an indication
of how the algorithm’s running time scales with the size of its input. In our
example, the input to the algorithm is the list of numbers and the size of that
input is the length n of the list. If this algorithm were used to ﬁnd the highest
degree node in a network, then the size of the input would be the number of
vertices in the network. In many of the network algorithms we will look at
this will be the case—the number of vertices n will be the important parameter
we consider. In other cases, the important parameter will be the number of
edges m in the network, while in others still we will need both m and n to fully
specify the size of the input—there could be different parts to an algorithm, for
instance, that operate separately on the vertices and the edges, so that the total
running time depends on both. Thus, for example, we will see in Section 10.3
that the algorithm known as “breadth-ﬁrst search,” which is used for ﬁnding
geodesic paths in networks, has a computational complexity O(m) + O(n) for
1
If we wish to say that the running time is exactly proportional to n, we can use the notation Θ(n).
2
There are occasional instances where this is not true, so it is worth just bearing in mind the
possibility of sub-leading terms.

279

B ASIC CONCEPTS OF ALGORITHMS

a network with m edges and n vertices, meaning that it runs in time am + bn
where a and b are constants, or quicker. Very often one writes this, in shorthand
and slightly sloppy form, as O(m + n). This latter notation is not meant to
imply that the constants in front of m and n are the same.
In a lot of networks research we are concerned with sparse graphs (see
Section 6.9) and particularly with graphs for which m increases in proportion to
n as n becomes large. To put that another way, the mean degree of the network
c = 2m/n remains constant (see Eq. (6.23)). In such networks, O(m + n) ≡
O(n) and we can drop the m from our notation.
The importance of the computational complexity lies in its use for estimating the actual running time of real algorithms. If a particular algorithm is going
to take a month to solve a problem of interest, or a year or a century, we’d like
to know that in advance. We want to estimate how long the calculation is going to take before we start it, so we can make a decision about whether the wait
is justiﬁed. A knowledge of the computational complexity allows us to do that
by measuring run-time on a small problem and then scaling up appropriately
to the size of the real problem.
For example, suppose we wish to run the breadth-ﬁrst search algorithm
mentioned above on a network with a million vertices and ten million edges.
Knowing that the algorithm has time complexity O(m + n), we could start out
with a small test-run of the program on a network with n = 1000 vertices, say,
and m = 10 000 edges. Often we artiﬁcially create small networks just for the
purposes of such tests. Perhaps we ﬁnd that the program ﬁnishes in a second
on the test network. We then scale up this result knowing that the running time
varies as am + bn. On the full network with n = 1 000 000 and m = 10 000 000
both n and m are a thousand times larger than on the test network, so the
program should take about a thousand times longer to ﬁnish, i.e., a thousand
seconds or about a quarter of an hour. Armed with this information we can
safely start our program working on the larger problem and step out for a cup
of tea or a phone call while we wait for it ﬁnish.
Conversely, suppose we had an algorithm with computational complexity O(n4 ). That means that if we increase the number of vertices n in our network by a factor of a thousand the running time will increase by a trillion.
In such a case it almost does not matter what the run time of the algorithm
is on our small test network; the run time on the full network is going to be
prohibitively long. For instance, if the test network takes a second again, then
the full network would take a trillion seconds, which is around 30 000 years.
In this case, we would certainly abandon the calculation, or at least look for a
faster algorithm that can complete it in reasonable time.
Finding the computational complexity of an algorithm, generating test net280

9.1

|

R UNNING TIME AND COMPUTATIONAL COMPLEXITY

works, performing small runs, and doing scaling calculations of this type all
require some work—additional work on top of the work of developing and
programming the computer algorithm in the ﬁrst place. Nonetheless, this extra work is well worth the effort involved and one should always perform this
type of analysis, at least in some rough manner, before embarking on any major numerical calculations. Computational complexity will be one of our major
concerns throughout of the discussions of algorithms in this chapter and the
following two. An algorithm is next to useless if its running time scales poorly
with the size of a network. In practice, any algorithm that scales with system
size as O(n3 ) or greater is useless for large networks, although such algorithms
still ﬁnd some use for the smaller cases. In the world of computer science,
where many researchers have devoted their entire careers to the invention of
new algorithms for solving particular problems, the calculation of the computational complexity of an algorithm is a primary goal—often the primary
goal—of research. Plenty of papers are published whose sole contribution is to
provide a calculation of the complexity of some algorithm.
It is worth mentioning that calculations of the run time of algorithms based
on their complexity, as above, do not always give very accurate answers. We
have mentioned already that standard measures of time complexity neglect
sub-leading contributions to the run time, which may introduce inaccuracies
in practical situations. But in addition there are, for technical reasons, many
cases where the behavior of the run time is considerably poorer than a simple
scaling argument would suggest. For instance, in calculations on networks
it is important that the entire network ﬁt in the main memory (RAM) of our
computer if the algorithm is to run quickly. If the network is so large that at
least part of it must be stored on a disk or some other slow form of storage,
then the performance of the algorithm may be substantially hindered.3 Even
if the entire network ﬁts in the main memory, there may be additional space
required for the operation of the algorithm, and that must ﬁt in the memory
too. Also, not all kinds of memory are equally fast. Modern computers have
a small amount of extra-fast “cache” memory that the computer can use for
storing small quantities of frequently used data. If all or most of the data for a
calculation ﬁt in the cache, then the program will run far faster than if it does
not.
There are also cases in which a program will perform better than the es3
There are whole subﬁelds in computer science devoted to the development of algorithms that
run quickly even when part of the data is stored on a slow disk. Usually such algorithms work by
reordering operations so that many operations can be performed on the same data, stored in the
main memory, before swapping those data for others on the disk.

281

B ASIC CONCEPTS OF ALGORITHMS

timate based on its complexity would indicate. In particular, the complexity
is usually calculated by considering the behavior of the program in the worst
case. But for some programs the worst-case behavior is relatively rare, occurring only for certain special values of the program inputs or particularly unlucky parameter choices, and the typical behavior is signiﬁcantly better than
the worst case. For such programs the complexity can give an unreasonably
pessimistic estimate of running time.
For all of these reasons, and some others as well, programs can show unexpected behaviors as the size of their input increases, sometimes slowing down
substantially more than we would expect given their theoretical time complexity and sometimes running faster. Nonetheless, computational complexity is
still a useful general guide to program performance and an indispensable tool
in the computer analysis of large networks.

9.2

S TORING NETWORK DATA

The ﬁrst task of most programs that work with network data is to read the
data, usually from a computer ﬁle, and store it in some form in the memory of
the computer. Network data stored in ﬁles can be in any of a large number of
different formats, some standard, some not, but typically the ﬁle contains an
entry containing information for each vertex or for each edge, or sometimes
both. The way the data are stored in the computer memory after they are read
from the ﬁle can, as we will see, make a substantial difference to both the speed
of a program and the amount of memory it uses. Here we discuss some of the
commonest ways to store network data.
The ﬁrst step in representing a network in a computer is to label the vertices
so that each can be uniquely identiﬁed. The most common way of doing this is
to give each a numeric label, usually an integer, just as we have been doing in
our mathematical treatment of networks in Chapters 6 and 7. In the simplest
case, we can number the n vertices of a network by the consecutive integers
i = 1 . . . n, although in some cases we might wish to use non-consecutive integers for some reason or to start the numbering from a different point. (For
instance, in the C programming language it is conventional for numbering to
start at zero and run through i = 0 . . . n − 1.) Most, though not all, ﬁle formats for storing networks already specify integer labels for vertices, which
may simplify things. For those that don’t, one typically just labels vertices
consecutively in the order they are read from the ﬁle. In what follows, we will
assume that vertices are numbered 1 . . . n.
Often the vertices in a network have other notations or values attached
to them in addition to their integer labels. The vertices in a social network,
282

9.3

|

T HE ADJACENCY MATRIX

for instance, might have names; vertices in the World Wide Web might have
URLs; vertices on the Internet might have IP addresses or AS numbers. Vertices could also have properties like age, capacity, or weight represented by
other numbers, integer or not. All of these other notations and values can be
stored straightforwardly in the memory of the computer by deﬁning an array
of a suitable type with n elements, one for each vertex, and ﬁlling it with the
appropriate values in order. For example, we might have an array of n text
strings to store the names of the individuals in a social network, and another
array of integers to store their ages in years.
Having devised a suitable scheme for storing the properties of vertices, we
then need a way to represent the edges in the network. This is where things
get more complicated.

9.3

T HE ADJACENCY MATRIX

In most of the mathematical developments of previous chapters we have represented networks by their adjacency matrix Aij —see Section 6.2. The adjacency matrix also provides one of the simplest ways to represent a network on
a computer. Most computer languages provide two-dimensional arrays that
can be used to store an adjacency matrix directly in memory. An array of integers can be used if the adjacency matrix consists only of integers, as it does for
unweighted simple graphs or multigraphs. An array of ﬂoating-point numbers is needed for an adjacency matrix that may have reals (non-integers) as
its elements, as does the adjacency matrix of some weighted networks—see
Section 6.3.
Storing a network in the form of an adjacency matrix is convenient in many
ways. Most of the formulas and calculations described in this book are written
out in terms of adjacency matrices. So if we have that matrix stored in our
computer it is usually a trivial matter to turn those formulas into computer
code to calculate the corresponding quantities.
The adjacency matrix can be highly advantageous for other reasons too.
For instance, if one wishes to add or remove an edge between a given pair
of vertices, this can be achieved very quickly with an adjacency matrix. To
add an edge between vertices i and j one simply increases the ijth element of
the adjacency matrix by one. To remove an edge between the same vertices
one decreases the element by one. These operations take a constant amount of
time regardless of the size of the network, so their computational complexity
is O(1). Similarly if we want to test whether there is an edge between a given
pair of vertices i and j we need only inspect the value of the appropriate matrix
element, which can also be done in O(1) time.
283

B ASIC CONCEPTS OF ALGORITHMS

Undirected networks give a slight twist to the issue since they are represented by symmetric matrices. If we want to add an undirected edge between
vertices i and j, then in principle we should increase both the ijth and jith elements of the adjacency matrix by one, but in practice this is a waste of time.
A better approach is to update only elements in the upper triangle of the matrix and leave the lower one empty, knowing that its correct value is just the
mirror image of the upper triangle.4 To put this another way, we only update
elements (i, j) of the matrix for which i < j. (For networks in which self-edges
are allowed, we would use the diagonal elements as well, so we would update
elements with i ≤ j—see Section 6.2.) For instance, if we wish to create an edge
between vertex 2 and vertex 1, this means in principle that we want to increase
both the (2, 1) element and the (1, 2) element of the adjacency matrix by one.
But, since we are only updating elements with i < j, we would increase only
the (1, 2) element and leave the other alone.5
Taking this idea one step further, we could not bother to store the lower triangle of the adjacency matrix in memory at all. If we are not going to update
it, why waste memory storing it? Unfortunately, dropping the lower triangle
of the matrix makes our remaining matrix triangular itself, and most computer
languages don’t contain arrays designed to hold triangular sets of quantities.
One can, by dint of a certain amount of work, arrange to store triangular matrices using, for example, the dynamic memory allocation facilities provided by
languages like C and JAVA, but this is only worth the effort if memory space is
the limiting factor in performing your calculation.
The adjacency matrix is not always a convenient representation, however.
It is cumbersome if, for instance, we want to run quickly through the neighbors
of a particular vertex, at least on a sparse graph. The neighbors of vertex i are
denoted by non-zero elements in the ith row of the adjacency matrix and to
ﬁnd them all we would have to go through all the elements of the row one by
one looking for those that are non-zero. This takes time O(n) (since that is the
length of the row), which could be a lot of time in a large network, and yet on
a sparse graph most of that time is wasted because each vertex is connected to
only a small fraction of the others and most of the elements in the adjacency
matrix are zero. As we will see in this chapter, many network algorithms do
indeed require us to ﬁnd all neighbors of a vertex, often repeatedly, and for
4
For directed networks, which are represented by asymmetric adjacency matrices, this issue
does not arise—the full matrix, both the upper and lower triangles, is used to store the structure
of the network.
5
Of course we could equally well store the edges in the lower triangle of the matrix and neglect
the upper triangle. Either choice works ﬁne.

284

9.3

Operation
Insert
Delete
Find
Enumerate

Adjacency matrix
O(1)
O(1)
O(1)
O( n )

Adjacency list
O(1)
O(m/n)
O(m/n)
O(m/n)

|

T HE ADJACENCY MATRIX

Adjacency tree
O(log(m/n))
O(log(m/n))
O(log(m/n))
O(m/n)

Table 9.2: The leading-order time complexity of four operations for various representations of a network of n vertices and m edges. The operations are adding an edge
to the network (insert), removing an edge from the network (delete), testing whether
a given pair of vertices are connected by an edge (ﬁnd), and listing the neighbors of a
given vertex (enumerate).

such algorithms the adjacency matrix is not an ideal tool.
The computational complexity of the network operations discussed here
for an adjacency matrix is summarized in Table 9.2.
Another disadvantage of the adjacency matrix representation is that for
sparse graphs it makes inefﬁcient use of computer memory. In a network in
which most elements of the adjacency matrix are zero, most of the memory
occupied by the matrix is used for storing those zeros. As we will see, other
representations exist, such as the “adjacency list,” that avoid storing the zeros
and thereby take up much less space.6
It is a simple matter to work out how much memory is consumed in storing
the adjacency matrix of a network. The matrix has n2 elements. If each of them
is an integer (which requires 4 bytes for its storage on most modern computers)
then the entire matrix will take 4n2 bytes. At the time of writing, a typical
computer has about 1010 bytes of RAM (10 GB), and hence the largest network
that can be stored in adjacency matrix format satisﬁes 4n2 = 1010 , or n =
50 000. This is not nearly large enough to store the largest networks of interest
today, such as large subsets of the Web graph or large social networks, and is
not even big enough for some of the medium-sized ones.
The disadvantages of the adjacency matrix representation described here
6
One advantage of the adjacency matrix is that the amount of space it consumes is independent of the number of edges in the network. (It still depends on the number of vertices, of course.)
As we will see in Section 9.4, other data formats such as the adjacency list use varying amounts
of memory, even for networks with the same number of vertices, depending on how many edges
there are. In calculations where edges are frequently added or removed it may be convenient—
and increase the speed of our algorithms—to have the size of our data structures remain constant,
although this advantage must be weighed against the substantial space savings of using the adjacency list or other memory-efﬁcient formats.

285

B ASIC CONCEPTS OF ALGORITHMS

apply primarily to sparse networks. If one is interested in dense networks—
those in which a signiﬁcant fraction of all possible edges are present—then the
adjacency matrix format may be appropriate. It will still use a lot of memory
in such cases, but so will any data format, since there is simply a lot of information that needs to be stored, so the advantages of other formats are less
signiﬁcant. The adjacency matrix may also be a good choice if you are only
interested in relatively small networks. For instance, the social network analysis package UCINET, which is targeted primarily at sociological practitioners
working with smaller networks, uses the adjacency matrix format exclusively.
Most current research on networks however is focused on larger data sets, and
for these another representation is needed.

9.4

T HE ADJACENCY LIST

The simplest alternative to storing the complete adjacency matrix of a network
is to use an adjacency list. The adjacency list is, in fact, probably the most widely
used network representation for computer algorithms.
An adjacency list is actually not just a single list but a set of lists, one for
each vertex i. Each list contains the labels of the other vertices to which i is
connected by an edge. Thus, for example, this small network:

1

2
5

3

4

would be represented by this adjacency list:
Vertex
1
2
3
4
5

Neighbors
3, 4
4, 1
5, 1, 3
4

An adjacency list can be stored in a series of integer arrays, one for each vertex,
or as a two-dimensional array with one row for each vertex.7 It is common to
also store somewhere the degree of each vertex, so that we know how many
7

286

Note that the number of entries in the list of neighbors for a vertex varies from one vertex

9.4

|

T HE ADJACENCY LIST

entries there are in the list of neighbors for each vertex; this can be done using
a separate array of n integers. Note also that there is usually no requirement
that the neighbors of a vertex in the adjacency list appear in numerical order.
Normally they are allowed to appear in any order.
In the example adjacency list above, each edge appears twice. For instance,
the existence of an edge between vertices 1 and 3 means that vertex 3 is listed
as a neighbor of vertex 1 and vertex 1 is also listed as a neighbor of vertex 3. To
represent m edges, therefore, we need to store 2m integers. This is much better
than the n2 integers used to store the full adjacency matrix.8 For instance, on
a computer where each integer occupies 4 bytes of memory, a network with
n = 10 000 vertices and m = 100 000 edges would occupy 800 kB in adjacency
list form, as opposed to 400 MB in matrix format. The double storage of the
edges is slightly wasteful—we could save an additional factor of two if we only
stored each edge once. However, the double storage turns out to have other
advantages, making our algorithms substantially faster and easier to program
in many cases, and these beneﬁts are normally worth the extra cost in terms of
space. In these days of cheap memory, not many networks are large enough
that space to store an adjacency list is a serious consideration.
An adjacency list can store networks with multiedges or self-edges. A
multiedge is represented by multiple identical entries in the list of neighbors
of a vertex, all pointing to the same adjacent vertex. A self-edge is represented
by an entry identifying a vertex as its own neighbor. In fact, a self-edge is most
correctly represented by two such entries in the list, so that the total number of
entries in the list is still equal to the degree of the vertex. (Recall that a self-edge
adds 2 to the degree of the vertex it is connected to.)
The example adjacency list above is for an undirected network, but adjacency lists can be used with directed networks as well. For instance, this
network:
to another, and may even be zero, being equal to the degree of the corresponding vertex. Most
modern computer languages, including C and its derivatives and JAVA, allow the creation of twodimensional matrices with rows having varying numbers of elements in this fashion. Some older
languages, like FORTRAN 77, do not allow this, making it more difﬁcult to store adjacency lists in
a memory-efﬁcient way.
8
Note that the amount of memory used is now a function of m rather than than n. For algorithms in which edges are added or removed from a network during the course of a calculation
this means that the size of the adjacency list can change, which can complicate the programming
and potentially slow down the calculation. Normally, however, this added complication is not
enough to outweigh the considerable beneﬁts of the adjacency list format.

287

B ASIC CONCEPTS OF ALGORITHMS

1

2
5

3

4

could be represented by this adjacency list:9
Vertex
1
2
3
4
5

Outgoing edges
3, 4
4
5, 1
4

Here we have listed the outgoing edges for each vertex. Since each edge is
outgoing from some vertex, this approach is guaranteed to capture every edge
in the network, but each edge now appears only once in the adjacency list, not
twice as in the undirected case.
Alternatively, we could represent the same network by listing the ingoing
edges for each vertex thus:
Vertex
1
2
3
4
5

Incoming edges
4
1
3, 1, 5
4

In principle these two representations are equivalent. Both include all the
edges and either of them can be constructed from a knowledge of the other.
When creating computer programs, however, the crucial point is to have the
information you need for your calculations easily available, so that the program runs fast. Different calculations require different information and some
might need ingoing edges while others need outgoing ones. The choice of
which adjacency list to use thus depends on the particular calculations being
9
Indeed, the adjacency list for an undirected network such as that given above could be
viewed as a special case of the directed adjacency list for a network in which each undirected
edge is replaced by two directed ones, one in each direction. It takes only a moment to convince
oneself that this results precisely in the sort of double representation of each edge that we saw in
the undirected case.

288

9.4

|

T HE ADJACENCY LIST

performed. Some calculations even require both ingoing and outgoing edges,
in which case we could create a double adjacency list like this:
Vertex
1
2
3
4
5

Incoming edges
4

Outgoing edges
3, 4

1
3, 1, 5
4

4
5, 1
4

Note that, as in the undirected case considered above, this double adjacency
list stores each edge twice, once as an incoming edge and once as an outgoing
one, and is thus in some respects wasteful of space, although not to an extent
that is normally a problem.
As with the adjacency matrix it is important also to ask how fast our calculations will run if we use an adjacency list. Will they still run at a reasonable
pace? If the answer is no, then the adjacency list is not a useful representation,
no matter what its other advantages may be.
Consider the undirected case10 and the four basic network operations that
we considered previously for the adjacency matrix, addition and removal of
edges, ﬁnding whether an edge is present, and enumeration of all edges connected to a vertex—see Table 9.2.
We can add an edge to our network very quickly: to add an edge (i, j) we
need only add one new entry each to the ends of the neighbor lists for vertices
i and j, which takes time O(1).
Finding or removing an edge is a little harder. To ﬁnd whether an edge
exists between vertices i and j we need to go through the list of neighbors of i
to see whether j appears in that list, or vice versa. Since the list of neighbors
is in no particular order, there is no quicker way of doing this than simply
going through the entire list step by step from the beginning. In the worst
case, we will have check all elements to ﬁnd our edge or to conﬁrm that it does
not exist, and on average11 this will take time of order the mean number c of
elements in the list, which is given by the mean degree c = 2m/n (Eq. 6.23).
10
The answers are essentially the same in the directed case. The demonstration is left as an
exercise.
11
We are thus calculating a sort of “average worst-case” behavior, allowing for the worst case
in which we have to look through the entire list, but then averaging that worst case over many
different lists. This is a reasonable (and standard) approach because almost all of the algorithms
we will be considering do many successive “ﬁnd” operations during a single run, but it does mean
that we are technically not computing the complexity of the absolute worst case situation.

289

B ASIC CONCEPTS OF ALGORITHMS

4 1 3 2

4 2 3
The element “1” is deleted
from a list by moving the
last element “2” to overwrite it.

Thus the “ﬁnd” operation takes time O(m/n) for a network in adjacency list
form. This is a bit slower than the same operation using an adjacency matrix,
which takes time O(1) (Section 9.3). On a sparse graph with constant mean
degree, so that m ∝ n (see Sections 6.9 and 9.1), O(m/n) ≡ O(1), so technically
the complexity of the adjacency list is as good as that of the adjacency matrix,
but in practice the former will be slower than the latter by a constant factor
which could become large if the average degree is large.
Removing an edge involves ﬁrst ﬁnding it, which takes time O(m/n), and
then deleting it. The deletion operation can be achieved in O(1) time by simply
moving the last entry in the list of neighbors to overwrite the entry for the
deleted edge and decreasing the degree of the vertex by one (see ﬁgure). (If
there is no last element, then we need do nothing other than decreasing the
degree by one.) Thus the leading-order running time for the edge removal
operation is O(m/n).
However, the adjacency list really comes into its own when we need to
run quickly through the neighbors of a vertex, a common operation in many
network calculations, as discussed in Section 9.3. We can do this very easily by
simply running through the stored list of neighbors for the vertex in question,
which takes time proportional to the number of neighbors, which on average is
c = 2m/n. The leading-order time complexity of the operation is thus O(m/n),
much better than the O(n) of the adjacency matrix for the same operation.
The computational complexity of operations on the adjacency list is summarized in Table 9.2.

9.5

T REES

The adjacency list is, as we have said, probably the most commonly used format for the storage of networks. Its main disadvantage is the comparatively
long time it takes to ﬁnd or remove edges—O(m/n) time, compared with the
O(1) of the adjacency matrix. In many of the most common network algorithms, such as the breadth-ﬁrst search of Section 10.3 or the augmenting path
algorithm of Section 10.5, this is not a problem, since one never needs to perform these operations. Some algorithms, however, such as the algorithm for
calculating the clustering coefﬁcient given in Section 10.2, do require these operations and can be slowed by the use of an adjacency list. On a network with
mean degree 100, for instance, the edge-ﬁnding operations in the clustering
coefﬁcient algorithm can be expected to slow the calculation down by about a
factor of 100, which could make the difference between a calculation that takes
an hour to ﬁnish and one that takes a week.
A data structure that has most of the advantages of the adjacency list, while
290

9.5

|

T REES

being considerably faster in many situations, is the adjacency tree.12 An adjacency tree is identical to an adjacency list except that each “row”—the set of
neighbors of each vertex—is stored in a tree rather than a simple array. If you
already know what a tree is then you probably don’t need to read the rest of
this section—you’ll have got the idea already. If you don’t know what a tree is,
read on.13
A tree is a data structure for storing values of some kind, such as integers
or real numbers, in a way that allows them to be added, removed, and located
quickly. Trees come in a number of types. We consider the case where the values stored are all distinct, which is the relevant case for our purposes, although
it is only slightly more complicated to allow for identical values.
Figure 9.1a shows an example of a tree that is being used to store the integers {1, 3, 4, 6, 7, 10, 12, 14}. The basic structure is one of a set of nodes (not to be
confused with the nodes of the network that we are storing), which correspond
to memory locations in the computer, each containing one of the integers. The
tree nodes are arranged in a top-down fashion with a root node at the top.14
Each node can have zero, one, or two child nodes that are drawn immediately
below it and connected to it by lines to indicate the child relationship. One can
create trees with nodes that have more than two children, but for our purposes
it works better to limit the number to two. A tree with at most two children
per node is called a binary tree.
Each node in the tree, except for the root, has exactly one parent node. The
root has no parent. Nodes with no children are called leaves. On a computer a
tree is typically implemented with dynamically allocated memory locations to
store the numbers, and pointers from one node to another to indicate the child
and parent relationships.15
12

This is not a standard name. As far as the present author is aware, this data structure doesn’t
have a standard name, since it is not used very often. Moreover, the name isn’t even entirely accurate. The structure is technically not a tree but a forest, i.e., a collection of many trees. Still,
“adjacency tree” is simple and descriptive, and analogous to “adjacency list,” which is also, technically, not a single list but a collection of lists.
13
The word “tree” has a different meaning here from the one it had in Section 6.7, although the
two are related. There a tree meant a network with no loops in it. Here it refers to a data structure,
although as we will see, the tree data structure can also be regarded as a network with no loops. In
effect we are using a network to store information about another network, which is a nice touch.
14
As pointed out in a previous footnote on page 127, it is slightly odd to put the “root” the top
of the tree. Most of us are more familiar with trees that have their roots at the bottom. We could
of course draw the tree the other way up—it would have the same meaning—but it has become
conventional to draw the root at the top of the picture, and we bow to that convention here.
15

A “pointer” in computer programming is a special variable that holds the address in memory
of another variable.

291

B ASIC CONCEPTS OF ALGORITHMS

(a)

(b)
4

3

3

12

1

7
6

1

4
14

10

6
7
10
12
14

Figure 9.1: Two trees containing the same set of numbers. The two trees depicted here
both store the numbers {1, 3, 4, 6, 7, 10, 12, 14}. (a) A balanced tree in which the depths
of the subtrees below each node differ by no more than 1. (b) An unbalanced tree.

A deﬁning property of our binary tree will be that the values stored in the
left child of node i (if there is one) and in all other nodes descended from that
child, are less than the value stored in i itself. Conversely, the values stored in
the right child of i (if there is one) and all nodes descended from it are greater
than the value stored in i. The reader might like to conﬁrm that the values in
Fig. 9.1a satisfy these requirements at every node in the tree.
Our goal is to use trees to store the lists of neighbors of each vertex in a
network. We will show that if we do so we can perform our four basic network
operations—addition, removal, and ﬁnding of edges, and enumeration of the
complete set of a vertex’s neighbors—very quickly on average. Below we ﬁrst
explain in the general language of the binary tree how these operations are
achieved. At the end of the section we discuss how they are used in the speciﬁc
context of the adjacency tree format for networks.
The ﬁnd operation: The ﬁrst tree operation we consider is the “ﬁnd” operation, which is the operation of determining whether a particular value is
present in our tree. We accomplish this operation as follows. Starting at the
root node:
1. Examine the value x in the current node. If it is the value we are looking
for, stop—our task is done.
2. If not and the value we are looking for is less than x, then by the prop292

9.5

erties described above, the value we are looking for must be in the left
child of the current node or one of its descendants. So we now move to
the left child, if there is one, which becomes our new current node. If
there is no left child, then the value we are looking for does not exist in
the tree and our task is done.
3. Conversely if the value we are looking for is greater than x, we move to
the right child, if there is one, which becomes our new current node. If
there is no right child, the value we are looking for does not exist in the
tree and our task is done.
4. Repeat from step 1.
Taking the example of the tree in Fig. 9.1a, suppose that we are trying to determine whether the number 7 appears in the tree. Starting at the root note we
ﬁnd a 4, which is not the number 7 that we are looking for. Since 7 is greater
than 4, we move to the right child of the root and there ﬁnd a 12. Since 7 is
less than 12 we move to the left child and there we ﬁnd our number 7, and our
search is over.
On the other hand, suppose we wish to determine whether the number 9
appears in the tree. Again we would start at the root and move right, then
left, then right as we went down the tree, arriving after three steps at the node
containing the number 10. This number is not equal to the number 9 and since
9 is less than 10 we would normally now move to the left child down the tree.
In this case, however, there is no left child, and hence we conclude that the
number we are looking for does not exist in the tree.
How long does the “ﬁnd” operation take? That depends on how many
steps we have to take through the tree: we have to perform the same operations
on each step, so the time taken is simply proportional to the number of steps.
The maximum number of steps to reach any node from the root is called the
depth of the tree. Unfortunately, the depth doesn’t have a simple ﬁxed value.
There are many possible ways to store the same numbers in a tree while still
obeying the conditions on child and parent nodes. For instance, both of the
trees in Fig. 9.1 are valid ways to store the same set of numbers. The one in
panel (a) has depth 4, while the one in panel (b) has depth 8. In general the
maximum possible depth is given by an arrangement like (b) and is equal to
the number k of values stored in the tree. For such a tree the ﬁnd operation
would, in the worst case, take O(k ) time, which is no better than what we get
if we store the values in a simple array—in either case we just end up going
through the values one by one until we ﬁnd the one we want.
On the other hand, if we can make the tree reasonably balanced, like the
one in Fig. 9.1a, then the depth can be a lot less than k. Let us calculate the
minimum depth required to store k values. If we start at the top of the tree and

|

T REES

4
3

12

1

7
6

14
10

The path taken through our
binary tree to locate the
number 7.

293

B ASIC CONCEPTS OF ALGORITHMS

ﬁll in the levels one by one, we can put one value at the root, two values in the
second level, four in the third, and so forth, each level holding twice as many
values as the previous one. In general, level l can hold 2l −1 values and the total
number of values in L levels is
L

∑ 2l−1 = 2L − 1.

(9.1)

l =1

Setting this equal to k and rearranging, we ﬁnd that L = log2 (k + 1). However,
L must be an integer, so, rounding up, we conclude that a minimum of
!
(9.2)
L = log2 (k + 1)
levels are needed to store k numbers, where  x  denotes the smallest integer
not less than x. If we can pack the values into the tree like this, ﬁlling each
level completely, then our ﬁnd operation will only take O(log2 (k + 1)) to
complete. In fact, since log2 (k + 1) ≤ log2 (k + 1) + 1 we could also say that
it will take O(log2 (k + 1)) time, where as usual we have kept only the leadingorder term and dropped the sub-leading +1 term. We can also neglect the
base of the logarithm, since all logs are proportional to one another, regardless
of their base, and we can replace log(k + 1) by log k since again we are only
interested in the leading-order scaling.
Thus, we conventionally say that the ﬁnd operation in a balanced tree containing k values can be completed in time O(log k ). This is much better than
the O(k ) of the simple list or the unbalanced tree. For a tree with k = 100
values stored in it we have log2 k ≃ 7, so the ﬁnd operation should be about
100/7 ≃ 14 times faster than for the simple list, and the speed advantage increases further the larger the value of k.
The addition operation: And how do we add a new value to a tree? The
crucial point to notice is that in adding a new value we must preserve the
relations between parent and child nodes, that lower values are stored in the
left child of a node and its descendants and higher ones in the right child and
descendants. These relations were crucial to the speedy performance of the
ﬁnd operation above, so we must make sure they are maintained when new
items are added to the tree.
This, however, turns out not to be difﬁcult. To add an item to the tree we
ﬁrst perform a “ﬁnd” operation as above, to check if the value in question
already exists in the tree. If the value already exists, then we don’t need to add
it. (Imagine for example that we are adding an edge to a network. If that edge
already exists then we don’t need to add it.)
On the other hand, if the value does not exist in the tree then the ﬁnd operation will work its way down the tree until it gets to the leaf node that would
294

|

9.5

(a)

4

4

4

T REES

4

4

4
2
4

2

6

2

6

2

6

2

6

6
1

1

3

1

3

5

1

3

5

7

2

(b)

1

1

1
2

1
2

1
2

3

1
2

3

2
3

4

1
2
3

4

3
4

5

4
5

5
6

6
7

Figure 9.2: The structure of a tree depends on the order in which elements are added to it. Here the values 1 to 7
are added to a tree in two different orders. In (a) they are added in the order 4, 2, 6, 1, 3, 5, 7, resulting in a perfectly
balanced tree with the minimum possible depth of three. In (b) they are added in the order 1, 2, 3, 4, 5, 6, 7, resulting in
an unbalanced tree with the maximum possible depth of seven.

have been the parent of our value, but which does not have an appropriate
child node. Then we simply add the appropriate child of that leaf node and
store our value in it, thereby increasing the number of nodes in the tree by one.
Since the ﬁnd operation takes O(log k ) time and the creation of the new node
takes constant time, the leading-order complexity of the addition operation is
O(log k ).
Balancing the tree: This is satisfying and simple, but it immediately raises
another problem. The position a newly added value occupies in the tree depends on the values that are already in the tree, and hence the shape of the
tree depends, in general, on the values we add to it and the order in which we
add them. Indeed, it turns out a tree can take quite different shapes even for
the same values, just as a result of adding those values in different orders. In
particular a tree can end up balanced or not as a result of different orders of
addition—see Fig. 9.2—and if we are unlucky and get an unbalanced tree then
the speed of our tree operations can be severely affected. Obviously we would
like to avoid this if possible.

4
3

12

1

7
6

14
10

9
Addition of the number 9
to the tree.

295

B ASIC CONCEPTS OF ALGORITHMS

For algorithms in which elements are added to the tree only at the beginning of the program and no elements are added or removed thereafter (the
clustering coefﬁcient algorithm of Section 10.2 is an example), a simple solution to the problem is just to randomize the order in which the elements are
added. Although the resulting tree is not completely packed full, as in the case
considered above, it will still have depth O(log k ) on average.16
If our algorithm requires us to add or remove values as we go along, then
this approach will not work and we must explicitly balance the tree by performing rebalancing operations whenever the tree becomes unbalanced. We
typically don’t attempt to keep the elements packed as tightly in the tree as
possible, but we can still achieve O(log k ) run times by adopting a looser definition of balance. One practical and simple deﬁnition (though not the only
one) is that a tree is balanced if the depth of the two subtrees below any node
differ by no more than 1. The tree in Fig. 9.1a satisﬁes this criterion. For instance, the depths of the subtrees of the node containing the value 12 are 2 on
the left and 1 on the right.
It is straightforward to prove that a tree satisfying this criterion, which is
16
The proof is as follows.
Consider the set of “empty nodes,” meaning the missing children immediately below current
nodes in the tree (gray boxes in the ﬁgure on the right). Suppose that when
there are k nodes in total in the tree there are ck such empty nodes and that
their average depth, measured from the root, is dk . When we add one new
value to the tree at random it will occupy one of these empty nodes thereby
decreasing their number by one. At the same time two new empty nodes
will appear, the children of the newly added node. Overall therefore ck+1 =
ck + 1. Noting that c1 = 2, this immediately implies that ck = k + 1.
At the same time the sum of the lengths of all paths from the root to an empty node, which by
deﬁnition is equal to ck dk , decreases (on average) by dk when a new random node is added and
increases by 2(dk + 1) for the two new ones, so that ck+1 dk+1 = ck dk + dk + 2. Eliminating ck , we
then ﬁnd that dk+1 = dk + 2/(k + 2). Noting that d1 = 2, this implies
k −1

k +1
2
1
= −1 + 2 ∑
= 2γ − 1 + 2 ln k + O(1/k),
m
m =0 m + 2
m =1

dk = 1 + ∑

where γ = 0.5772 . . . is Euler’s constant.
Thus the average depth of the empty nodes is O(log k). Since the ﬁnd and addition operations
on the tree both involve searching the tree until an empty node is encountered, it immediately
follows that both operations have average complexity O(log k) on our randomized tree, just as
they do on the optimally packed tree.
Note that this is only a statement about the average behavior of the tree and not about the worstcase behavior. If we are unlucky the depth of the tree could be much larger than the average, up to
the maximum depth k. The randomized tree only provides a guarantee of average performance,
meaning performance averaged over many possible runs of an algorithm. Individual runs will
vary around the mean.

296

9.5

|

T REES

called an AVL tree, has depth O(log k ). What’s more it is possible to maintain
this level of balance with fairly simple rebalancing operations called “pivots”
that themselves take only O(log k ) time to perform. As a result, we can both
ﬁnd elements in and add elements to an AVL tree in time O(log k ), even if we
have to rebalance the tree after every single addition (although usually we will
not have to do this).
Details of the workings of the AVL tree can be found in most books on
computer algorithms, such as Cormen et al. [81]. However, if you need to use
such a tree in your own work it’s probably not worth programming it yourself.
There are many readily available standard implementations of AVL trees or
other balanced trees that will do the job just ﬁne and save you a lot of effort.
A suitable one appears, for instance, in the standard C++ library STL, which is
available with every installation of C++.
The deletion operation: The process of deleting a value from a tree is rather
involved, but none of the algorithms described in this book require it, so we
will not go into it in detail here. The basic idea is that you ﬁrst ﬁnd the value
you want to delete in the normal way, which takes time O(log k ), then delete
it and perform a “pivot” operation of the type mentioned above to remove the
hole left by the deletion. Each of these operations takes at most time O(log k )
and hence the entire deletion can be complete in O(log k ) time. The interested
reader can ﬁnd the details in Ref. [81].
Enumerating the items in a tree: We can also quickly run through the items
stored in a tree, an operation that takes O(k ) time, just as it does for a simple
list stored in an array. To do this we use an Euler tour, which is a circuit of the
tree that visits each node at most twice and each edge exactly twice. An Euler
tour starts at the root of the tree and circumnavigates the tree by following its
outside edge all the way round (see ﬁgure). More precisely, starting from the
root we move to the left child of the current node if we haven’t already visited
it and failing that we move to the right child. If we have already visited both
children we move upward to the parent. We repeat these steps until we reach
the root again, at which point the tour is complete. Since each edge is traversed
twice and there are k − 1 edges in a tree with k nodes (see Section 6.7), this
immediately tells us we can run through all elements in the tree in O(k ) time.

An Euler tour.

Given the above properties of trees, the adjacency tree for a network is now
simple to deﬁne: we store the list of neighbors of each vertex as values in a
binary tree. There is one tree for each vertex, or two for a directed network if
we want to store both the incoming edges and the outgoing ones. Edges can
be found, added, or deleted from the tree for a given vertex in time O(log k ),
where k is the degree of the vertex, or O( log k ) when averaged over all ver297

B ASIC CONCEPTS OF ALGORITHMS

tices. However, the average of the logs of a set of positive numbers is always
less than the log of their average, so a running time of O( log k ) also implies
a running time of O(log k ) ≡ O(log(m/n)).
The computational complexity of operations on the adjacency tree is summarized in Table 9.2. Comparing our three storage formats for networks, the
adjacency matrix, list, and tree, we see that there is no overall winner; the
choice of format is going to depend on what we want to do with it. For use in
algorithms where we are only going to add and remove edges and check for
their existence, the adjacency matrix is the fastest option. On the other hand,
in algorithms where we are only adding edges or enumerating the neighbors
of vertices, which includes most of the algorithms in this chapter, the adjacency list is the clear winner. The adjacency tree is the fastest format if we
need to ﬁnd or delete edges as well as create them. (Note that log(m/n) is
usually much better than a mere m/n, particularly in the case where the mean
degree c  1.) In algorithms that only need to enumerate edges and not ﬁnd,
add, or delete them, the adjacency list and adjacency tree are equally good
in principle. In practice, however, the additional complexity of the adjacency
tree usually makes it somewhat slower and the adjacency list is the format of
choice.
It’s worth bearing in mind that speed isn’t everything, and in particular that
the adjacency matrix format uses a prohibitive amount of memory space for
networks with large numbers of vertices (see Section 9.3). Overall, as we have
said, the adjacency list is the format used most often, but the others certainly
have their place and each will be useful to us more than once in the remainder
of this book.

9.6

O THER NETWORK REPRESENTATIONS

We have discussed three ways of representing network data in the memory of
a computer. These are probably the most useful simple representations and
the ones that you are most likely to need if you write your own programs to
analyze networks, but there are a few other representations that it is worth
knowing about.
Hybrid matrix/list representations: The representations of Table 9.2 all have
their advantages and disadvantages, but none is optimal. In the best of all
possible worlds, we would like a data structure that can insert, delete, and
ﬁnd edges in O(1) time and enumerate the O(m/n) neighbors (on average) of
a given vertex in O(m/n) time, but none of our representations can do this.
It is possible to create a representation that can do this, however, if we are

298

9.6

|

O THER NETWORK REPRESENTATIONS

willing to sacriﬁce memory space: we can make a hybrid representation that
consists of an adjacency matrix and an adjacency list. Non-zero elements in the
adjacency matrix, those corresponding to edges, are accompanied by pointers
that point to the corresponding elements in the adjacency list. Then we can
ﬁnd whether an edge exists between a speciﬁed pair of vertices in O(1) time
using the adjacency matrix as usual. And we can enumerate the neighbors of
a vertex in O(m/n) time using the adjacency list. We can add an edge in O(1)
time since both matrix and list allow this anyway (Table 9.2). And ﬁnally, we
can delete an edge in O(1) time by ﬁrst locating it in the adjacency matrix and
setting the corresponding element to zero, then following the pointers to the
relevant elements of the adjacency list and deleting those too by moving the
last element of the list to ﬁll their place.
In terms of time complexity, i.e., scaling of run time with network size,
this hybrid data structure is optimal.17 Its main disadvantage is that it uses
even more memory than the ordinary adjacency matrix, and hence is suitable
only for relatively small networks, up to a few tens of thousands of vertices
on a typical computer at the time of writing. If this is not an issue in your
case, however, and speed is, then this hybrid representation may be worth
considering.
Representations with variables on edges: In some networks the edges have
values, weights, or labels on them. One can store additional properties like
these using simple variants of the adjacency matrix or adjacency list representations. For instance, if edges come in several types we could deﬁne an additional n × n matrix to go with the adjacency matrix that has elements indicating
the type of each extant edge. (For edges that do not exist the elements of such a
matrix would have no meaning.) Or one could combine the two matrices into
a single one that has a non-zero element for every extant edge whose value
indicates the edge type. If there are many different variables associated with
each edge, as there are for instance in some social network studies, then one
could use many different matrices, one for each variable, or a matrix whose
elements are themselves arrays of values or more complicated programming
objects like structures. Similarly, with an adjacency list one could replace the
elements of the list with arrays or structures that contain all the details of the
edges they correspond to.
17
It does place some overhead on the edge addition and deletion operations, meaning the complexity is still O(1) but the operations take a constant factor longer to complete, since we have to
update both adjacency matrix and list, where normally we would only have to update one or the
other. Whether this makes an signiﬁcant difference to the running of a program will depend on
the particular algorithm under consideration.

299

B ASIC CONCEPTS OF ALGORITHMS

However, these representations can be wasteful or clumsy. The matrix
method can waste huge amounts of memory storing meaningless matrix elements in all the positions corresponding to edges that don’t exist. The adjacency list (for an undirected network) contains two entries for each edge, both
of which would have to be updated every time we modify the properties of
that edge. If each edge has many properties this means a lot of extra work and
wasted space.
In some cases, therefore, it is worthwhile to create an additional data structure that stores the properties of the edges separately. For instance, one might
use a suitable array of m elements, one for each edge. This array can be linked
to the main representation of the network structure: with an adjacency list we
could store a pointer from each entry in the list to the corresponding element
in the array of edge data. Then we can immediately ﬁnd the properties of any
edge we encounter in the main adjacency list. Similarly, each entry in the array
of edge data could include pointers to the elements in the adjacency list that
correspond to the edge in question. This would allow us to go through the
array of edge data looking for edges with some particular property and, for
example, delete them.
Edge lists: One very simple representation of a network that we have not yet
mentioned is the edge list. This is simply a list of the labels of pairs of vertices
that are connected by edges. Going back to this network, which we saw in
Section 9.4:

1

2
5

3

4

the edge list representation would be (1, 3), (4, 1), (4, 3), (4, 5). The order of the
edges is usually not important in an edge list, nor is the order of the vertices in
the vertex pairs.
The edge list is a convenient and space-efﬁcient way to store the structure
of a network, and furthermore allows us easily to associate properties with
the edges—we can simply store those properties along with the corresponding
pairs of labels. It is not such a good representation if we wish to store properties of vertices. Indeed, the representation doesn’t explicitly list vertices at all,
so there is no way to tell that a vertex even exists if it is not connected to any
edges. Vertex 2 in the network above is an example of this problem: it doesn’t
appear in the edge list because it has no edges. On the other hand, this problem
300

9.7

|

H EAPS

and the problem of storing vertex properties can be remedied easily enough by
creating a separate list of vertices and the data associated with them.
However, the edge list is a poor format for storing network data in computer memory for most of the algorithms we will be considering in this book.
It does not, for instance, allow us to determine quickly whether a particular
edge exists—we would have to go through the entire list to answer that question. And, crucially, it does not allow us easily to enumerate the neighbors of
a given vertex, an operation that is central to many algorithms. For these reasons, the edge list is hardly ever used as a format for the representation of a
network in memory.
Where it does ﬁnd use is in ﬁle formats for networks. Being a fairly compact representation, edge lists are often used as a way to store network structure in computer ﬁles on a disk or other storage medium. When we wish to
perform calculations on these networks we must read the ﬁle and convert its
contents into a more suitable form for calculation, such as an adjacency matrix
or adjacency list. This, however, is simple: we create an empty network in the
memory of our computer, one with no edges initially, then run through the
edges stored in the edge list and add them one by one to the network in the
memory. Since the operation of adding an edge can be accomplished quickly
in all of the formats we have considered (Table 9.2), this normally does not take
a signiﬁcant amount of time. When it is ﬁnished, we have a complete copy of
the network in the format of our choice stored in the memory of the computer,
and we are ready to continue with our computations.

9.7

H EAPS

The last data structure we describe in this chapter is a specialized structure
called a binary heap. Unlike the structures introduced in the last few sections,
heaps are not normally used for storing networks themselves, but are used for
storing values on networks, usually values associated with a network’s vertices. The deﬁnitive property of a heap is that it allows us to quickly ﬁnd the
entry in the heap with the minimum (or maximum) value.
We will make use of the binary heap in Section 10.4 when we study one
of the most famous of network algorithms, Dijkstra’s algorithm, which is an
algorithm for ﬁnding shortest paths on weighted networks. This is the main
place the heap will come up in this book, so if you are not interested in, or do
not need to know, the detailed workings of Dijkstra’s algorithm, you can safely
skip the remainder of this chapter. Otherwise, read on.
Suppose, then, that we have some numerical value associated with every
vertex in a network. That value might be, for instance, the distance from an301

B ASIC CONCEPTS OF ALGORITHMS

other vertex in the network, or a time until something happens. To give a
concrete example, consider a disease spreading across a social network, as discussed in Chapters 1 and 3, and suppose we want to make a computer model
of the spread. One simple and efﬁcient way to do this is to associate with each
vertex of the network a number representing our current estimate of the time
at which that vertex will be infected by the disease (if it ever is). Initially each
of these times is set to ∞, except for a single vertex representing the initial
carrier of the disease, for which the time is set to zero. Then a simple algorithm for simulating the disease involves at each step ﬁnding the next vertex
to be infected, i.e., the one with the earliest infection time, infecting it, and then
calculating the time until it subsequently infects each of its neighbors. If any
of those infection times is earlier than the current recorded time for the same
neighbor, the new time supersedes the old one. Then we ﬁnd the vertex in the
network with the next earliest infection time and the process proceeds.
The crucial requirements for this algorithm to run efﬁciently are that we
should be able to quickly ﬁnd the smallest value of the infection time anywhere
on the network and that we should be able to quickly decrease the value at
any other given vertex. The binary heap is a data structure that allows us to do
these things.
The binary heap is built upon a binary tree structure similar to the trees
in Section 9.5, although the tree in a binary heap is arranged and used in a
different fashion. Each of the items stored in a heap (items that will represent vertices in the network context) consists of two parts, an integer label that
identiﬁes the item and a numerical value. In the disease example above, for
instance, the labels are the vertex indices i = 1 . . . n for vertices not yet infected
and the values are the times at which the vertices are infected with the disease.
The items in the heap are stored at the nodes of a binary tree as depicted in
Fig. 9.3. There are two important features to notice about this structure. First,
the tree is always completely packed. We ﬁll the tree row by row starting with
the root node at the top and ﬁlling each row from left to right. Thus the tree is
denser than the typical binary tree of Section 9.5 and always has a depth that
is logarithmic in the number of items in the tree—see Eq. (9.2).
Second, the values associated with the items in the heap (the lower number
at each node in Fig. 9.3) are partially ordered. This means that each value is
greater than or equal to the one above it in the tree and less than or equal to
both of the two below it. If we follow any branch down the tree—any path
from top to bottom—the values grow larger along the branch or stay the same,
but never decrease. The values are said to be “partially” ordered because the
ordering only applies along branches and not between different branches. That
is, there is no special relation between values on different branches of the tree;
302

9.7

Index

Value

7
0.4
3
1.1

4
4.7

10
2.0
2
1.6

11
3.3

La

Label

12
3.3
1
3.8

8
4.1
9
5.4

H EAPS

be
l
Ro
w
Po
sit
io
n

Tree

|

5
2.9

6
4.3

1
2
3
4
5
6
7
8
9
10
11
12

4
3
2
4
3
4
1
3
4
2
4
3

3
2
1
1
4
5
1
3
4
2
2
1

Next
available space

Figure 9.3: The structure of a binary heap. A binary heap consists of two parts, a tree
and an index. The nodes of the tree each contain a label and a numerical value, and
the tree is partially ordered so that the numerical value at each node is greater than or
equal to the value above it in the tree and less than or equal to both of the values below
it. The index is a separate array that lists by label the positions of each of the items in
the tree, so that we can ﬁnd a given item quickly. New items are added to the tree in
the next available space at the bottom, starting a new row if necessary.

they may be larger or smaller than one another, whether they are on the same
level in the tree or on different levels.
The property of partial ordering has the important result that the value
stored at the root node of the tree is always the smallest value anywhere. Since
values are non-decreasing along all branches of the tree starting from the root,
it follows that no value can be smaller than the root value.
The binary heap also has another component to it, the index, which tells
us the location of each item in the tree. The index is an array containing the
coordinates in the tree of all the items, listed in order of their labels. It might,
for instance, contain the row in the tree and position along that row of each
item, starting with the item with label 1 and proceeding through each in turn—
see Fig. 9.3 again.
A heap allows us to perform three operations on its contents: (1) adding
303

B ASIC CONCEPTS OF ALGORITHMS

7
0.4

7
0.4

7
0.4

7
0.4

10
2.0

10
2.0

10
2.0

13
1.7

8
4.1

8
4.1

13
1.7

10
2.0

13
1.7

8
4.1

8
4.1

Figure 9.4: Sifting a value up the heap. A branch in the tree initially contains three
items as shown. A new item with value 1.7 is added at the bottom. The upward sift
repeatedly compares and swaps this value with the value above it until it reaches its
correct place in the partial ordering. In this case the added value 1.7 gets swapped
twice, ending up (correctly) between the values 0.4 and 2.0.

an item to the heap, (2) reducing the numerical value stored in the item with
a speciﬁed label, and (3) ﬁnding and removing the item with the smallest numerical value from the heap. Let us look at how each of these operations is
carried out.
Adding an item: To add an item to the heap we place it in the ﬁrst available
free space at the bottom of the tree as indicated in Fig. 9.3. If the bottom row
of the tree is full, we start a new row. It is important in adding an item to the
tree that we preserve the partially ordered structure, but a new item added at
the bottom may well violate that structure by having a numerical value smaller
than the item above it. We can ﬁx this by sifting the tree as illustrated in Fig. 9.4.
The newly added item is “sifted up” its branch of the tree by comparing its
value with that of the item above it. If its value is smaller, the two are swapped,
the new item moving up one row. We repeat this process until the new item
either reaches a point where it is not smaller than the item above it, or it has
risen to the root of the tree. If it rises to the root of the tree, then by deﬁnition it
is has the smallest value in the tree because it is smaller than the value for the
previous root item.
When we add a new item we also have to update the index of the heap.
The coordinates of the new item are recorded at the position in the index corresponding to the item’s label and then during the sifting operation, we simply

304

9.7

|

H EAPS

swap the index entries for every two items that are swapped in the tree.
Since the tree is completely packed it has depth given by Eq. (9.2), which
is O(log k ), where k is the number of items in the tree. Thus the maximum
number of swaps we have to do during the sifting process is O(log k ) and
the total time to add an item to the heap, ignoring sub-leading terms, is also
O(log k ).
Reducing a value in the heap: Reducing the numerical value associated with
a given labeled item is similar to the addition operation. We ﬁrst use the index to locate the given item in the tree and we reduce its numerical value as
desired. Since this may mean that the item is now smaller than one or more of
those above it, violating the partial ordering, we sift up as before until the item
reaches its correct place in the ordering, updating the index as we go. This
operation, like the addition operation, takes time O(log k ).
Finding and removing the smallest value: The item in the heap with the
smallest numerical value is easily found since, as we have said, it is always
located at the root of the tree. In Fig. 9.3, for example, the smallest value is 0.4
for the item with label 7.
We remove the smallest item by ﬁrst deleting it from the tree and deleting
its entry in the index. This leaves a hole in the tree which violates the condition that the tree be completely packed, but we can ﬁx this problem by taking
the last item from the bottom row of the tree and moving it up to the root, at
the same time updating the relevant entry in the index. This, however, creates
its own problem because in moving the item we will likely once again create
a violation of the partial ordering of the tree. The item at the root of the tree
is supposed to have the smallest numerical value and it’s rather unlikely that
the item we have moved satisﬁes this condition. This problem we can ﬁx by
“sifting down.” Sifting down involves comparing the numerical value stored
in the root item with both of those below it. If it is larger than either of them,
we swap it with the smaller of the two and at the same time swap the corresponding entries in the index. We repeatedly perform such comparisons and
swaps, moving our item down the tree until either it reaches a point at which
it is smaller than both of the items below it, or it reaches the bottom of the tree.
Again the sifting process, and hence the entire process of removing the root
item from the tree, takes time O(log k ).
Thus the binary heap allows us to do all three of our operations—adding
an item, reducing a value, or ﬁnding and removing the item with the smallest
value—in time O(log k ).

305

B ASIC CONCEPTS OF ALGORITHMS

P ROBLEMS
9.1

What (roughly) is the time complexity of:
a) Vacuuming a carpet if the size of the input to the operation is the number n of
square feet of carpet?
b) Finding a word in a (paper) dictionary if the size of the input is the number n of
words in the dictionary?

9.2

Suppose you have a sparse network with m ∝ n. What is the time complexity of:
a) Multiplying an arbitrary n-element vector by the adjacency matrix, if the network
is stored in the adjacency matrix format.
b) Performing the same multiplication if the network is in adjacency list format.
c) The “modularity matrix” B of a network is the matrix with elements
Bij = Aij −

ki k j
.
2m

(See Eq. (7.70) on page 224.) What is the time complexity of multiplying an arbitrary vector by the modularity matrix of our sparse network if the network is in
adjacency list format?
d) In fact, if we are clever about it, this last operation can be performed in time O(n)
for the sparse network with m ∝ n. Describe an algorithm that achieves this.
9.3 An interesting question, which is discussed in some detail in Chapter 16, concerns
what happens to a network if you disable or remove its vertices one by one. The question is of relevance, for instance, to the vaccination of populations against the spread of
disease. One typical approach is to remove vertices in order of their degrees, starting
with the highest degrees ﬁrst. Note that once you remove one vertex (along with its
associated edges) the degrees of some of the other vertices may change.
In most cases it is not possible to do the experiment of removing vertices from a real
network to see what effect it has, but we can simulate the process on a computer by taking a network stored in computer memory, removing its vertices, and then measuring
various properties of the remaining network.
a) What is the time complexity of ﬁnding the highest-degree vertex in a network,
assuming the vertices are given to you in no particular order?
b) If we perform the repeated vertex removal in a dumb way, searching exhaustively
for the highest-degree vertex, removing it, then searching for the next highest, and
so forth, what is the time complexity of the entire operation?
c) Describe how the same operation could be performed with the degrees of the
vertices stored instead in a heap. You will need to modify the heap structure of
Section 9.7 in a couple of ways to make the algorithm work. One modiﬁcation
is trivial: the heap needs to be sorted in the opposite order so that the largest
element is at the root. What other modiﬁcation is needed, and how would you do
it? What now is the time complexity of the entire calculation?

306

P ROBLEMS

d) Taking the same approach, describe in a sentence or two a method for taking n
numbers in random order and sorting them into decreasing order using a heap.
Show that the time complexity of this sorting algorithm is O(n log n).
e) The degrees of the vertices in a simple graph are integers between zero and n. It
is possible to sort such a set of integers into numerical order, either increasing or
decreasing, in time O(n). Describe brieﬂy an algorithm that achieves this feat.

307

C HAPTER 10

F UNDAMENTAL NETWORK ALGORITHMS
A discussion of some of the most important and
fundamental algorithms for performing network
calculations on a computer

RMED WITH the tools and data structures of Chapter 9, we look in this

A

chapter at the algorithms that are used to perform network calculations.
We start with some simple algorithms for calculating quantities such as degrees, degree distributions, and clustering. In the later sections of the chapter we look at more sophisticated algorithms for shortest paths, betweenness,
maximum ﬂows, and other non-local quantities.
In the following chapter we extend our examination of network algorithms
to algorithms based on matrix calculations and linear algebra, including algorithms for matrix-based centralities like eigenvector centrality and algorithms
for graph partitioning and community discovery in networks.

10.1

A LGORITHMS FOR DEGREES AND DEGREE DISTRIBUTIONS

Many network quantities are easy to calculate and require only the simplest
of algorithms, algorithms that are little more than translations into computer
code of the deﬁnitions of the quantities in question. Nonetheless, it is worth
looking at these algorithms at least brieﬂy, for two reasons. First, there is in
some cases more than one simple algorithm for calculating a quantity, and one
algorithm may be much faster than another. It pays to evaluate one’s algorithm at least momentarily before writing a computer program, to make sure
one is going about the calculation in the most sensible manner. Second, it is
worthwhile to calculate the computational complexity of even the simplest algorithm, so that one can make an estimate of how long a computation will take
to ﬁnish—see Section 9.1. Even simple algorithms can take a long time to run.
308

10.1

|

A LGORITHMS FOR DEGREES AND DEGREE DISTRIBUTIONS

One of the most fundamental and important of network quantities is the
degree of a vertex. Normally degrees are very simple to calculate. In fact, if
a network is stored in the form of an adjacency list1 then, as described in Section 9.4, we normally maintain an array containing the degree of each vertex
so that we know how many entries there are in the list of neighbors for each
vertex. That means that ﬁnding the degree of any particular vertex is a simple
matter of looking it up in this array, which takes O(1) time.
If the network is stored in an adjacency matrix, then the calculation takes
longer. Calculating the degree of a vertex i in this case involves going through
all elements of the ith row of the adjacency matrix and counting the number
that are non-zero. Since there are n elements in each row of the matrix, where
n is the number of vertices in the network, the calculation takes time O(n),
making the calculation far slower than for the adjacency list. If one needed to
ﬁnd the degrees of vertices frequently during the course of a larger calculation
using an adjacency matrix, it might make good sense to calculate the degree
of each vertex once and for all and store the results for later easy retrieval in a
separate array.
In Section 8.3 we discussed degree distributions, which are of considerable
interest in the study of networks for the effect they have on network structure and processes on networks (see Chapters 13 and 14). Calculating a degree
distribution pk is also very straightforward: once we have the degrees of all
vertices, we make a histogram of them by creating an array to store the number of vertices of each degree up to the network maximum, setting all the array
elements initially to zero, and then running through the vertices in turn, ﬁnding the degree k of each and incrementing by one the kth element of the array.
This process trivially takes time O(n) to complete. Once it is done the fraction
pk of vertices of degree k is given by the count in the kth array element divided
by n.
The cumulative distribution function Pk of Section 8.4.1 requires a little
more work. There are two common ways to calculate it. One is ﬁrst to form a
histogram of the degrees as described above and then to calculate the cumulative distribution directly from it using
∞

Pk = ∑ pk = − pk−1 +
k =k

∞

∑ pk = Pk−1 − pk−1 .


(10.1)

k  = k −1

Noting that P0 = ∑∞
k =0 p k = 1, we can then start from P0 and use Eq. (10.1)
to calculate successive Pk up to any desired value of k. This process trivially
1

Or an adjacency tree—see Section 9.5.

309

F UNDAMENTAL NETWORK ALGORITHMS

takes O(n) time and, since the calculation of pk also takes O(n) time, the whole
process is O(n).
In fact, however, as described in Section 8.4.1, this is not usually how one
calculates the cumulative distribution function. Although the method is fast,
it’s also moderately complicated and there is a simpler way of doing the calculation that involves taking the degrees of all the vertices, sorting them in
descending order, and ranking them from 1 to n. A plot of the rank divided
by n as a function of degree then gives the cumulative distribution. The most
time-consuming part of this calculation is the sorting of the degrees. Sorting is a well-studied problem and the fastest general algorithms2 run in time
O(n log n). Thus the leading order scaling of this algorithm to calculate the
cumulative distribution is O(n log n). This is slower than the ﬁrst method described above, which was O(n), but not much slower and the second method
has the considerable advantage that almost all computers provide standard
software for sorting numbers, which means that in most cases one doesn’t have
to write a program at all to calculate the cumulative distribution. All spreadsheet programs, for instance, include facilities for sorting numbers, so one can
calculate cumulative distributions directly in a spreadsheet.
Another quantity of interest is the correlation coefﬁcient r for vertex degrees, Eq. (8.26), which measures assortative mixing by degree. This too is
straightforward to calculate—one uses Eq. (8.27) and the sums deﬁned in Eqs.
(8.28) and (8.29). Given the degrees of all vertices, the sum in Eq. (8.28) takes
time O(m) to evaluate, where m is the number of edges in the network, and
the sums in Eq. (8.29) each take time O(n), so the total time required to calculate r is O(m + n). As mentioned in Section 9.1, we are often concerned with
sparse networks in which the mean degree remains constant as the network
gets larger, i.e., networks in which m ∝ n. In such networks O(m + n) ≡ O(n)
and the time to calculate r taken just scales as the number of vertices. On the
other hand, if the network is dense, meaning that m ∝ n2 , then O(m) ≡ O(n2 ),
which is considerably worse.

10.2

C LUSTERING COEFFICIENTS

The calculation of clustering coefﬁcients is only slightly more complicated than
the calculation of degrees. To see how it works, we start by calculating the
local clustering coefﬁcient Ci for a single vertex i on an undirected network,
2
For integers, such as vertex degrees, it is under certain conditions possible to sort faster, in
time O(n), using the so-called radix sort algorithm. See, for example, Cormen et al. [81].

310

10.2

|

C LUSTERING COEFFICIENTS

Eq. (7.42):3
Ci =

(number of pairs of neighbors of i that are connected)
.
(number of pairs of neighbors of i)

(10.2)

Calculating the numerator involves going through every pair of distinct neighbors of vertex i and counting how many are connected. We need only consider
each pair once, which we can do conveniently by restricting ourselves to pairs
( j, l ) for which j < l. For each pair we determine whether an edge exists between them, which is done in various ways depending on the representation
used for the network as described in Sections 9.3–9.5, and count up the number of such edges. Then we divide the result by the number of pairs, which is
just 12 k i (k i − 1), where k i is the degree of the vertex.
To calculate the overall clustering coefﬁcient for the entire network, which
is given by
(number of triangles) × 3
.
(10.3)
C=
(number of connected triples)
(see Eq. (7.41)), we extend the same calculation to the whole network. That is
we consider for every vertex each pair of neighbors ( j, l ) with j < l and ﬁnd
whether they are connected by an edge.4 We add up the total number of such
edges over all vertices and then divide by the number of connected triples,
which is ∑i 12 k i (k i − 1).
This last algorithm is simple and straightforward, a direct implementation
of the formula (10.3) deﬁning the clustering coefﬁcient, but some interesting
issues nonetheless come up when we consider its running time. Even without
performing a full calculation of the complexity of the algorithm we can see
that something unusual is going to happen because a vertex i with degree k i
has 12 k i (k i − 1) pairs of neighbors. We have to check for the presence of an edge
between each such pair on the entire network and hence the total number of
checks we have to perform is


(10.4)
∑ 12 ki (ki − 1) = 12 n k2 − k ,
i

where
k =

1
ki ,
n∑
i

k2 =

1
k2i ,
n∑
i

(10.5)

3

An equivalent to the clustering coefﬁcient can be deﬁned for a directed network (see Section 7.9) but we limit ourselves here to the much commoner undirected case.
4
Note that this calculation automatically accounts for the factor of three appearing in the numerator of Eq. (10.3), since each triangle is counted three times, once each from the point of view
of the three vertices it connects.

311

F UNDAMENTAL NETWORK ALGORITHMS

See Section 8.3 for a discussion of degree distributions.

are the mean and mean square degree for the network. (We previously denoted
the mean degree by c, but we use the alternate notation k here for clarity, and
to highlight the distinction between the mean and the mean square.)
The interesting point here is that Eq. (10.4) depends in a non-trivial way on
the degree distribution of our network. The running times of other algorithms
we have seen so far have depended on the number of vertices n and the number of edges m, and hence, indirectly, on the mean degree k = 2m/n. For
the clustering coefﬁcient, however, we see that the amount of work we have
to do, and hence also the running time, depends not only on n and k , but on
the second moment k2 , which is an additional independent parameter. Even
if we suppose that the degree distribution remains the same with increasing n
so that the quantities k and k2 can be considered constant, strange things
can happen. Consider the case of a network whose degree distribution follows
a power law pk ∼ k−α , as described in Section 8.4. For such networks, the
ﬁrst moment is well behaved but the second moment k2 formally diverges if
α < 3 (see Section 8.4.2) which implies that it will take an inﬁnite amount of
time to evaluate the clustering coefﬁcient!
To understand better what is going on let us perform a more careful calculation of the time complexity of our clustering coefﬁcient algorithm. We start
by considering again a single vertex i. And let us assume that we have our
network stored in adjacency list form. In that case, we can, as we have seen,
easily enumerate all of the neighbors of our vertex in time that goes like k i . For
each neighbor j we run through each other neighbor l > j that could be paired
with it, for a total of 12 k i (k i − 1) pairs and determine for each pair whether an
edge exists between them. This latter operation takes a time proportional, to
leading order, to either k j or to k l (see Table 9.2), depending on whether we
ﬁnd the edge by looking at the adjacency list for vertex j or for vertex l. Let us
for the moment assume a simple algorithm that chooses at random between
the two vertices, in which case the typical time taken will go as the average of
the two degrees, i.e., it will be proportional to k j + k l .
Let Γi denote the set of neighbors of vertex i. Then the total time taken to
check for edges between all pairs of neighboring vertices is proportional to

∑ (k j + kl ) = 12 ∑ (k j + kl ) = ∑ k j

j,l ∈Γi : j<l

j,l ∈Γi : j=l

j,l ∈Γi : j=l

= ( k i − 1) ∑ k j .

(10.6)

j ∈ Γi

The total time needed to calculate the numerator of Eq. (10.3) is then pro-

312

10.2

|

C LUSTERING COEFFICIENTS

portional to the sum of this quantity over all vertices i:

∑(ki − 1) ∑ k j = ∑ Aij (ki − 1)k j = ∑ Aij ki k j − ∑ k2j
j ∈ Γi

i

ij

ij

(10.7)

j

where Aij is an element of the adjacency matrix and we have made use of the
result ∑i Aij = k j (Eq. (6.19)).
Compare this equation with our earlier expression for the correlation coefﬁcient r between degrees in a network, Eq. (7.82), which quantiﬁes assortativity
by degree in networks:
r=

∑ij ( Aij − k i k j /2m)k i k j
∑ij (k i δij − k i k j /2m)k i k j

.

(10.8)

As we can see, the ﬁrst term in Eq. (10.7) is the same as the ﬁrst term in the
numerator of the correlation coefﬁcient. As a result, our estimate of the time to
calculate the clustering coefﬁcient depends on whether the degrees of vertices
are correlated or not. This can lead to some interesting behaviors for speciﬁc
networks, but for simplicity let us assume here that there is no correlation between degrees, that the network we are considering has no assortativity. In
that case r = 0 in Eq. (10.8), which can only occur if the numerator is itself
zero, or equivalently if

∑ Aij ki k j =
ij

2
1
1 
2 2
2
k
k
=
k
.
i j
i
2m ∑
2m ∑
ij
i

(10.9)

Combining this result with Eq. (10.7), the running time for our calculation of
the clustering coefﬁcient on an uncorrelated network is proportional to
 2

2
1 
k
2
2
2
−1 ,
ki − ∑ k j = n k
(10.10)
2m ∑
k
i
j
where we have made use of the fact that 2m = ∑i k i = n k (see Eq. (6.20)).
This is a measure of the time taken to evaluate the numerator of Eq. (10.3).
The denominator is simply equal to ∑i k i (k i − 1) and so just takes O(n) time
to evaluate, given that, for a network stored in adjacency list format, we already have the degrees of all vertices available. This will never be longer than
the time represented in Eq. (10.10), so Eq. (10.10) gives the leading-order time
complexity of the calculation of the clustering coefﬁcient.
So we see that the calculation of the clustering coefﬁcient indeed takes a
time that depends not only on n and m but also on the second moment k2 of
the degree distribution. In many cases this does not matter, since the second
313

F UNDAMENTAL NETWORK ALGORITHMS

moment often tends to a modest constant value as the network becomes large.
But for networks with highly skewed degree distributions k2 can become
very large and in the case of a power-law degree distribution with exponent
α < 3 it formally diverges (see Section 8.4.2) and with it so does the expected
running time of our algorithm.
More realistically, if the network is a simple graph with no multiedges, then
the maximum allowed degree is k = n and the degree distribution is cut off,
which means that the second moment scales at worst as n3−α (Eq. (8.22)) while
the ﬁrst moment remains constant. This in turn implies that the running time
of our clustering coefﬁcient algorithm on a scale-free network would go as
n × n3−α × n3−α = n7−2α . For values of α in the typical range of 2 ≤ α ≤ 3
(Table 8.1), this gives running times that vary from a minimum of O(n) for
α = 3 to a maximum of O(n3 ) for α = 2. For the lower values of α this makes
the calculation of the clustering coefﬁcient quite arduous, taking a time that
increases sharply as the network gets larger.
So can we improve on this algorithm? There are various possibilities. Most
of the work of the algorithm is in the “ﬁnd” operation to determine whether
there is an edge between a given pair of vertices, and the algorithm will be considerably faster if we can perform this operation more efﬁciently. One simple
(though memory-inefﬁcient) method is to make use of the hybrid matrix/list
data structure of Section 9.6, which can perform the ﬁnd operation in constant
time.5 Even in this case, however, the number of ﬁnd operations that must
be performed is still equal to the number of connected triples in the network,
which means the running time is given by Eq. (10.4), and hence still formally
diverges on a network with a power-law degree distribution. On a simple
graph for which the power law is cut off at k = n, it will go as n4−α , which
ranges from O(n) to O(n2 ) for values of α in the interesting range 2 ≤ α ≤ 3.
This is better than our earlier algorithm, but still relatively poor for the lower
values of α.
These difﬁculties are speciﬁc to the case of scale-free networks. In other
cases there is usually no problem calculating the clustering coefﬁcient quickly.
Some alternative algorithms have been proposed for calculating approximate
values of the clustering coefﬁcient rapidly, such as the algorithm of Schank
and Wagner [292], and these may be worth considering if you need to perform
calculations on very large networks.
5
Other possible ways to improve the algorithm are to use the adjacency tree structure of Section 9.5, or to use the adjacency list but always test for the presence of an edge between two vertices
by searching the neighbors of the lower-degree vertex to see if the higher is among them (rather
than the algorithm described above, which chooses which one to search at random).

314

10.3

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

S HORTEST PATHS AND BREADTH - FIRST SEARCH

We now move on to some more complex algorithms, algorithms for calculating mostly non-local quantities on the networks, such as shortest paths between vertices. The study of each of these algorithms has three parts. Two
are, as before, the description of the algorithm and the analysis of its running
time. But now we also include a proof that the algorithm described performs
the calculation it claims to. For the previous algorithms in this chapter such
proofs were unnecessary; the algorithms were direct implementations of the
equations deﬁning the quantities calculated. As we move onto more complex
algorithms, however, it will become much less obvious why those algorithms
give the results they do, and to gain a full understanding we will need to examine their working in some detail.
The ﬁrst algorithm we look at is the standard algorithm for ﬁnding shortest
distances in a network, which is called breadth-ﬁrst search.6 A single run of the
breadth-ﬁrst search algorithm ﬁnds the shortest (geodesic) distance from a single source vertex s to every other vertex in the same component of the network
as s. In some cases we want to know only the shortest distance between a single pair of vertices s, t, but there is no procedure known for calculating such
a distance that is faster in the worst case than calculating the distances from s
to every other vertex using breadth-ﬁrst search and then throwing away all of
the results except for the one we want.7
With only minor modiﬁcations, as we will describe, breadth-ﬁrst search can
also ﬁnd the geodesic path one must take to realize each shortest distance and
if there is more than one geodesic path, it can ﬁnd all such paths. It works also
on both directed and undirected networks, although our description will focus
on the undirected case.
10.3.1

D ESCRIPTION OF THE ALGORITHM

Breadth-ﬁrst search ﬁnds the shortest distance from a given starting vertex s to
every other vertex in the same component as s. The basic principle behind the
algorithm is illustrated in Fig. 10.1. Initially we know only that s has distance 0
from itself and the distances to all other vertices are unknown. Now we ﬁnd all
the neighbors of s, which by deﬁnition have distance 1 from s. Then we ﬁnd all
the neighbors of those vertices. Excluding those we have already visited, these
6

In physics, breadth-ﬁrst search is sometimes called the “burning algorithm.”

7

In many cases we may ﬁnd the result we want before calculating all distances, in which
case we can save ourselves the effort of calculating the rest, but in the worst case we will have to
calculate them all. See Section 10.3.4 for more discussion.

315

F UNDAMENTAL NETWORK ALGORITHMS

0

1

2

3

Figure 10.1: Breadth-ﬁrst search. A breadth-ﬁrst
search starts at a given vertex, which by deﬁnition
has distance 0 from itself, and grows outward in
layers or waves. The vertices in the ﬁrst wave,
which are the immediate neighbors of the starting vertex, have distance 1. The neighbors of those
neighbors have distance 2, and so forth.

vertices must have distance 2. And their neighbors, excluding those we have
already visited have distance 3, and so on. On every iteration, we grow the set
of vertices visited by one step.
This is the basic idea of breadth-ﬁrst search. Now let us go over it more
carefully to see how it works in practice and show that it really does ﬁnd correct geodesic distances. We begin by noting the following fact:

s

Every vertex whose shortest distance from s is d has a network neighbor whose shortest distance from s is d − 1.

t
A network path from s to
t of length d (where d = 3
in this case) necessarily includes a path of length d −
1 (i.e., 2) from s to an immediate neighbor of t.

316

This follows since if the shortest path from s to a vertex t is of length d then the
penultimate vertex along that path, which is a neighbor of t, can, by deﬁnition,
be reached in d − 1 steps and hence cannot have shortest distance greater than
d − 1. It also cannot have shortest distance less than d − 1 because it if did there
would be a path to t of length less than d.
Now suppose that we already know the distance to every vertex on the
network that is d steps or less from our source vertex s. For example, we might
know all the distances to vertices at distance 2 or less from the central vertex
in Fig. 10.1. For every neighbor of one of the vertices at distance d there exists
a path of length d + 1 to that neighbor: we can get to the vertex at distance d
along a path of length d and then we take one more step to its neighbor. Thus
every such neighbor is at most d + 1 steps from s, but it could be less than
d + 1 from s if there is another shorter path through the network. However, we
already know whether there is a shorter path to any particular vertex, since by

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

hypothesis we know the distance to every vertex d steps or less from s.
Consider the set of all vertices that are neighbors of vertices at distance d
but that are not already known to have distance d or less from s. We can say
immediately that (1) all neighbors in this set have distance d + 1 from s, and
(2) that there are no other vertices at distance d + 1. The latter follows from
the property cited above: all vertices at distance d + 1 must be neighbors of
vertices at distance d. Thus we have found the set of vertices at distance d + 1,
and hence we now know the distances to all vertices that are d + 1 or less
from s.
Now we just repeat the process. On each round of the algorithm we ﬁnd all
the vertices one step further out from s than on the last round. The algorithm
continues until we reach a point at all the neighbors of vertices at distance d
are found already to have known distances of d or less. This implies that there
are no vertices of distance d + 1 and hence, by the property above, no vertices
of any greater distance either, and so we must have found every vertex in the
component containing s.
As a corollary of the process of ﬁnding distance, breadth-ﬁrst search thus
also ﬁnds the component to which vertex s belongs, and indeed breadth-ﬁrst
search is the algorithm of choice for ﬁnding components in networks.
10.3.2

A NAIVE IMPLEMENTATION

Let us now consider how we would implement breadth-ﬁrst search on our
computer. The simplest approach (but not, as we will see, the best) would go
something like this. We create an array of n elements to store the distance of
each vertex from the source vertex s, and initially set the distance of vertex s
from itself to be zero while all other vertices have unknown distance from s.
Unknown distances could be indicated, for instance, by setting the corresponding element of the array to −1, or some similar value that could never occur in
reality.
We also create a distance variable d to keep track of where we are in the
breadth-ﬁrst search process and set its value initially to zero. Then we do the
following:
1. Find all vertices that are distance d from s, by going through the distance
array, element by element.
2. Find all the neighbors of those vertices and check each one to see if its
distance from s is unknown (denoted, for example, by an entry −1 in the
distance array).
3. If the number of neighbors with unknown distances is zero, the algorithm is over. Otherwise, if the number of neighbors with unknown dis317

F UNDAMENTAL NETWORK ALGORITHMS

tances is non-zero, set the distance of each of those neighbors to d + 1.
4. Increase the value of d by 1.
5. Repeat from step 1.
When the algorithm is ﬁnished we are left with an array that contains the distances to every vertex in the component of the network that contains s (and
every vertex in every other component has unknown distance).
How long does this algorithm take? First of all we have to set up the
distance array, which has one element for each vertex. We spend a constant
amount of time setting up each element, so overall we spend O(n) time setting
up the distance array.
For the algorithm proper, on each iteration we go through all n vertices
looking for those with distance d. Most will not have distance d in which case
we pass over them, spending only O(1) time on each. Thus there is a basic
cost of O(n) time for each iteration. The total number of iterations we will for
the moment call r, and overall we thus spend O(rn) time on this part of the
algorithm, in the worst case.
However, when we do come across a vertex with distance d, we must pause
at that vertex and spend an additional amount of time checking each of its
neighbors to see if their distances are unknown and assigning them distance d +
1 if they are. If we assume that the network is stored in adjacency list format
(see Section 9.4) then we can go through the neighbors of a vertex in O(m/n)
on average, and during the whole course of the algorithm we pause like this
at each vertex exactly once so that the total extra time we spend on checking
neighbors of vertices is n × O(m/n) = O(m).
Thus the total running time of the algorithm, including set-up, is O(n +
rn + m).
And what is the value of the parameter r? The value of r is the maximum
distance from our source vertex s to any other vertex. In the worst case, this
distance is equal to the diameter of the network (Section 6.10.1) and the worstcase diameter is simply n, which is realized when the network is just a chain
of n vertices strung one after another in a line. Thus in the worst case our
algorithm will have running time O(m + n2 ) (where we have dropped the ﬁrst
n because we are keeping only the leading-order terms).
This is very pessimistic, however. As discussed in Sections 8.2 and 12.7 the
diameter of most networks increases only as log n, in which case our algorithm
would run in time O(m + n log n) to leading order. This may be a moot point,
however, since we can do signiﬁcantly better than this if we use a little cunning
in the implementation of our algorithm.

318

10.3

10.3.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

A BETTER IMPLEMENTATION

The time-consuming part of the implementation described in the previous section is step 1, in which we go through the list of distances to ﬁnd vertices that
are distance d from the starting vertex s. Since this operation involves checking the distances of all n vertices, only a small fraction of which will be at
distance d, it wastes a lot of time. Observe, however, that in each wave of
the breadth-ﬁrst search process we ﬁnd and label all vertices with a given distance d + 1. If we could store a list of these vertices, then on the next wave
we wouldn’t have to search through the whole network for vertices at distance d + 1; we could just use our list.
The most common implementation of this idea makes use of a ﬁrst-in/ﬁrstout buffer or queue, which is nothing more than an array of (in this case) n elements that store a list of labels of vertices. On each sweep of the algorithm,
we read the vertices with distance d from the list, we use these to ﬁnd the vertices with distance d + 1, add those vertices with distance d + 1 to the list, and
repeat.
To do this in practice, we ﬁll up the queue array starting from the beginning. We keep a pointer, called the write pointer, which is a simple integer
variable whose value indicates the next empty location at the end of the queue
that has not been used yet. When we want to add an item to the queue, we
store it in the element of the array pointed to by the write pointer and then
increase the pointer by one to point to the next empty location.
At the same time we also keep another pointer, the read pointer, which
points to the next item in the list that is to be read by our algorithm. Each item
is read only once and once it is read the read pointer is increased by one to
point to the next unread item.
Here is a sketch of the organization of the queue:

Read pointer Write pointer
(next item
(next empty
to read)
space to fill)

5 2 6 4 1 9 3




n elements



Our breadth-ﬁrst search algorithm now uses two arrays of n elements, one for
the queue and one for the distances from s to each other vertex. The algorithm
is as follows.

319

F UNDAMENTAL NETWORK ALGORITHMS

1. Place the label of the source vertex s in the ﬁrst element of the queue,
set the read pointer to point to it, and set the write pointer to point to the
second element, which is the ﬁrst empty one. In the distance array, record
the distance of vertex s from itself as being zero and the distances to all
other vertices as “unknown” (for instance, by setting the corresponding
elements of the distance array to −1, or some similar impossible value).
2. If the read and write pointers are pointing to the same element of the
queue array then the algorithm is ﬁnished. Otherwise, read a vertex label
from the element pointed to by the read pointer and increase that pointer
by one.
3. Find the distance d for that vertex by looking in the distance array.
4. Go through each neighboring vertex in turn and look up its distance in
the distance array as well. If it has a known distance, leave it alone. If
it has an unknown distance, assign it distance d + 1, store its label in the
queue array in the element pointed to by the write pointer, and increase
the write pointer by one.
5. Repeat from step 2.
Note the test applied in step 2: if the read pointer points to the same element
as the write pointer, then there is no vertex to be read from the queue (since the
write pointer always points to an empty element). Thus this test tells us when
there are no further vertices waiting to have their neighbors investigated.
Note also that this algorithm reads all the vertices with distance d from the
queue array one after another and uses them to ﬁnd all the vertices with distance d + 1. Thus all vertices with the same distance appear one after another
in the queue array, with the vertices of distance d + 1 immediately after those of
distance d. Furthermore, each vertex appears in the queue array at most once.
A vertex may of course be a neighbor of more than one other, but a vertex is
assigned a distance and put in the queue only on the ﬁrst occasion on which it
is encountered. If it is encountered again, its distance is known rather than unknown, and hence it is not again added to the queue. Of course, a vertex may
not appear in the queue array at all if it is never reached by the breadth-ﬁrst
search process, i.e., if it belongs to a different component from s.
Thus the queue does exactly what we wanted it to: it stores all vertices with
a speciﬁed distance for us so that we have the list handy on the next sweep of
the algorithm. This spares us from having to search through the network for
them and so saves us a lot of time. In all other respects the algorithm works
exactly as in the simple implementation of Section 10.3.2 and gives the same
answers.
How long does this implementation of the algorithm take to run? Again
there is an initial time of O(n) to set up the distance array (see Section 10.3.2).
320

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

Then, for each element in the queue, which means for each of the vertices in
the same component as s, we do the following operations: we run through its
neighbors, of which there are O(m/n) on average, and either calculate their
distance and add them to the queue, or do nothing if their distance is already
known. Either way the operations take O(1) time. Thus for each vertex in the
component, of which there are in the worst case n, we spend time O(m/n) and
hence we require overall at most a time n × O(m/n) = O(m) to complete the
algorithm for all n vertices.
Thus, including the time to set up the distance array, the whole algorithm
takes time O(m + n), which is better than the O(m + n log n) of the naive implementation (Section 10.3.2). For the common case of a sparse network with
m ∝ n, O(m + n) is equivalent to O(n) and our algorithm runs in time proportional to the number of vertices.8 This seems just about optimal, since the
algorithm is calculating the distance of all n vertices from the source vertex s.
Thus it is assigning n numbers to the n elements of the distance array, which
in the best possible case must take O(n) time.
On a sparse network, therefore, the breadth-ﬁrst search algorithm does as
well as we can hope for in ﬁnding the distances from a single vertex to all
others, and indeed it is the fastest known algorithm for performing this operation.
10.3.4

VARIANTS OF BREADTH - FIRST SEARCH

There are a number of minor variants of breadth-ﬁrst search that merit a mention. First, one might wish to calculate the shortest distance between only a single pair of vertices s and t, rather than between s and all others. As mentioned
in Section 10.3 there is no known way to do this faster than using breadth-ﬁrst
search. We can, however, improve the running time slightly by the obvious
tactic of stopping the algorithm as soon as the distance to the target vertex t
has been found. There is no point in continuing to calculate distances to the
remaining vertices once we have the answer we want. In the worst case, the
calculation still takes O(m + n) time since, after all, our particular target vertex t might turn out to be the last one the algorithm ﬁnds. If we are lucky,
however, and encounter the target early then the running time might be considerably shorter.
Conversely, we sometimes want to calculate the shortest distance between
every pair of vertices in an entire network, which we can do by performing
a breadth-ﬁrst search starting at each vertex in the network in turn. The total
8

On the other hand, for a dense network where m ∝ n2 , we have a running time of O(n2 ).

321

F UNDAMENTAL NETWORK ALGORITHMS

running time for this “all-pairs shortest path” calculation is n × O(m + n) =
O(n(m + n)), or O(n2 ) on a sparse graph. As with the standard breadth-ﬁrst
search, this is optimal in the sense that we are calculating O(n2 ) quantities in
O(n2 ) time, which is the best we can hope for.
As mentioned in the previous section, breadth-ﬁrst search can also be used
to identify the members of the component to which a vertex s belongs. At the
end of the algorithm the distance array contains the distance from s to every
vertex in its component, while distances to all other vertices are recorded as
unknown. Thus we can ﬁnd the size of the component just by counting the
number of vertices with known distances. It takes time O(n) to perform the
count, so the operation of ﬁnding the component still takes O(m + n) time in
total.
The closeness centrality of Section 7.6 can also be calculated simply using
breadth-ﬁrst search. Recall that closeness is deﬁned as the inverse of the mean
distance from a vertex to all others in the same component. Since our breadthﬁrst search calculates distances to all others in a component we need then only
go through the distance array, calculate the sum of all known distances, divide
by the size of the component, and take the inverse. Again the running time
is O(n + m). The variant closeness deﬁned in terms of the harmonic mean in
Eq. (7.30) can also be calculated, in the same running time, by a similar method.
10.3.5

F INDING SHORTEST PATHS

The breadth-ﬁrst search algorithm as we have described it so far ﬁnds the
shortest distance from a vertex s to all others in the same component of the
network. It does not tell us the particular path or paths by which that shortest
distance is achieved. With only a relatively small modiﬁcation of the algorithm, however, we can calculate the paths as well. The trick is to construct
another network on top of our original network, this one directed, that represents the shortest paths. This other network is often called the shortest path tree,
although in the most general case it is a directed acyclic graph, not a tree.
The idea is as follows. At the start of our algorithm we create an extra
network, which will become our shortest path tree, with the same number n
of vertices as our original network and the same vertex labels, but with no
edges at all. Then we start our breadth-ﬁrst search algorithm from the speciﬁed source vertex s as before. The algorithm repeatedly pulls a vertex out of
the queue and examines its neighbors, as described in Section 10.3.3, but now
every time the neighbor j of some vertex i turns out to be a previously unseen
vertex, one whose distance is recorded as “unknown,” we not only assign j a
distance and store it in the queue, we also add a directed edge to our shortest
322

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

(a)

(b)

Figure 10.2: Shortest path trees. (a) A simple shortest path tree for the network of Fig. 10.1. Each vertex has a directed
edge pointing to the vertex by which it was reached during the breadth-ﬁrst search process. By following directed
edges from any vertex we can ﬁnd a shortest path to the starting vertex in the center. (b) The full shortest path tree
(which is actually not a tree at all but a directed acyclic graph) contains extra directed edges that allow us to reconstruct
all possible shortest paths.

path tree from vertex j to vertex i. This directed edge tells us that we found j
by following a path from its neighbor i. However, vertex i will also have a directed edge leading from it to one of its neighbors, telling us that we found i by
following that path, and so forth. Thus, by following a succession of these directed edges we eventually get all the way back to s, and so we can reconstruct
the entire shortest path between j and s.
So, when our breadth-ﬁrst search is ﬁnished, the shortest path tree contains
the information we need to ﬁnd the actual shortest path from every vertex in
the component containing s to s itself. An example of a shortest path tree is
shown in Fig. 10.2a for the same network as in Fig. 10.1.
This algorithm works well and the extra step of adding an edge to the shortest path tree can be accompanied quickly—in O(1) time if we store the network
in adjacency list format (see Table 9.2). Thus the overall running time of the algorithm is still O(m + n) to ﬁnd all distances from s and the corresponding
shortest paths.
The algorithm does have one shortcoming, however, which is that it only
323

F UNDAMENTAL NETWORK ALGORITHMS

ﬁnds one shortest path to each vertex. As pointed out in Section 6.10.1, a pair
of vertices may have more than one shortest path between them (see Fig. 6.10).
Another slight modiﬁcation of the algorithm allows us to deal with this case.
Multiple shortest paths exist between any vertex and the source vertex s if
the path to s splits in two or more directions at some point along its length. This
occurs if there is a vertex j somewhere along that path, say at distance d + 1
from s, that has more than one neighbor at distance d—see Fig. 10.2b. We can
record this circumstance in our shortest-path tree by adding more than one
directed edge from j to each of the relevant neighbors. These directed edges
tell us that we can ﬁnd a shortest path to vertex s by taking a step to any of
those neighboring vertices.
To do this we modify our algorithm as follows. We perform the breadthﬁrst search starting from s as before, and add directed edges from newly found
vertices to their neighbor as before. But we also add an extra step. If, in the
process of examining the neighbors of a vertex i that has distance d from the
source vertex, we discover a neighbor j that already has an assigned distance,
and that distance is d + 1, then we know that a path of length d + 1 has already
been found to j, but we also know that another path of length d + 1 must exist
via the current vertex i. So we add an extra directed edge to the shortest path
tree from j to i. This makes the shortest path tree no longer a tree but, as we
have said, it’s usually called a tree anyway. In any case, the algorithm gives
exactly what we want. When it is ﬁnished running the shortest path “tree”
allows us to reconstruct all shortest paths from every vertex in the component
to the source vertex s. See Fig. 10.2b.
10.3.6

B ETWEENNESS CENTRALITY

In Section 7.7 we described betweenness centrality, a widely used centrality
index that measures the extent to which a vertex in a network lies on the paths
between other vertices. The betweenness centrality of vertex v is the number
of geodesic paths between pairs of vertices s, t that pass through v. (Sometimes
it is normalized to be the fraction of such paths, rather than the total number.
The difference is only a multiplicative constant—see Section 7.7.) Given that
we have a method for ﬁnding the shortest path (or paths) between any two
vertices (Section 10.3.5), we can with only a little more work now create an
algorithm for calculating betweenness.
The simplest way to calculate betweenness would be to implement the deﬁnition of the measure directly: use breadth-ﬁrst search to ﬁnd the shortest path
between s and t, as described in Section 10.3.5 (assuming such a path exists),
and then work our way along that path checking the vertices it passes though
324

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

to see if the vertex v we are interested in lies among them. Repeating this process for every distinct pair s, t, we can then count the total number of paths that
pass through v. (Things are slightly more complicated for the case in which a
pair of vertices are connected by more than one shortest path, but let us ignore
this complication for the moment—we will come to it soon.)
This algorithm is certainly a correct algorithm and it would work, but it
is also inefﬁcient. As we have seen, breadth-ﬁrst search takes time O(m + n)
to ﬁnd a shortest path between two vertices, and there are 21 n(n − 1) distinct
pairs of vertices s, t. Thus the work of calculating betweenness for a single
vertex would take O(n2 (m + n)) time, or O(n3 ) in the common case of a sparse
graph for which m ∝ n. (The operation of checking the vertices along each
shortest path will take time of the order of the length of the path, which is
typically O(log n) (Section 8.2), making it negligible compared with the time
taken to ﬁnd the path.) This is prohibitively slow: while one might be able
to calculate the betweenness of a vertex on a given network in, say, an hour’s
work, the same calculation on a graph ten times larger would take 103 = 1000
hours, or more than a month of computer time.
But we can do a lot better if we make use of some of our results about
breadth-ﬁrst search from previous sections. First, the standard breadth-ﬁrst
search can ﬁnd paths between a source s and all other vertices (in the same
component) in time O(m + n), which means, as noted in Section 10.3.4, we can
ﬁnd paths between all pairs in the network in time O(n(m + n)), or O(n2 ) on
a sparse network.
An improved algorithm for calculating the betweenness of a vertex v might
work as follows. For each s we use breadth-ﬁrst search to ﬁnd shortest paths
between s and all other vertices, constructing a shortest path tree as described
in Section 10.3.5. Then we use that tree to trace the paths from each vertex
back to s, counting in the process the number of paths that go through v. We
repeat this calculation for all s and so end up with a count of the total number
of shortest paths that pass through v.
Indeed, we can trivially extend this algorithm to calculate betweenness for
all vertices at the same time—we simply maintain a count of the number of
paths that go through every vertex, for example in an array.9
9

Note that this actually counts each path twice (since the path between i and j is counted once
when i is considered the source vertex and once when j is), except for the path from each vertex
to itself, which is counted only once (when that vertex is the source). This, however, is correct:
the betweenness centrality, as deﬁned in Eq. (7.36), indeed counts each path twice, except for the
path from a vertex to itself. As discussed in Section 7.7, some researchers deﬁne betweenness
differently, counting paths only once, but that merely reduces all values by a factor of two.

325

F UNDAMENTAL NETWORK ALGORITHMS

s
(a)

7

2
1

(b)
4

1

1

2
1

s

7

1

11
6

1

25
6

2

5
3

1

7
3

3

1

1

1

Leaves
Figure 10.3: Calculation of betweenness centrality. (a) When there is only a single
shortest path from a source vertex s (top) to all other reachable vertices, those paths
necessarily form a tree, which makes the calculation of the contribution to betweenness
from this set of paths particularly simple, as described in the text. (b) For cases in
which there is more than one shortest path to some vertices, the calculation is more
complex. First we must calculate the number of paths from the source s to each other
vertex (numbers to the left of vertices), and then use these to weight the path counts
appropriately and derive the betweenness scores (numbers to the right of vertices).

For any given s, this algorithm will take time O(m + n) to ﬁnd the shortest
paths. Paths have length that by deﬁnition is less than or equal to the diameter
of the network, which is typically of order log n, and hence traversing the n
paths from each vertex to s will take time O(n log n), for a running time of
O(m + n log n) for each value of s. Repeating for all s, the whole algorithm
will then take total time O(n(m + n log n)) or O(n2 log n) on a sparse network.
This is much better than our earlier O(n3 ) algorithm, but we can do better
still. It is in fact possible to cut the running time down to just O(n(m + n)) by
exploiting the fact that many of the shortest paths in the shortest path tree share
many of the same edges. To understand this development, consider Fig. 10.3a,
which shows a shortest path tree from a vertex s to all other vertices on a graph.
In this case the shortest path tree really is a tree, meaning there is only one
shortest path from s to any other vertex. This case is a good ﬁrst example to
study because of its simplicity, but we will consider the more general case in
just a moment.
We use the tree to calculate a score for each vertex representing the number
of shortest paths passing through that vertex. We ﬁnd ﬁrst the “leaves” of the
tree, i.e., those vertices such that no shortest paths from other vertices to s pass
326

10.3

|

S HORTEST PATHS AND BREADTH - FIRST SEARCH

through them. (In Fig. 10.3a the leaves are drawn at the bottom of the tree.)
We assign a score of 1 to each of these leaves—the only path to s that passes
through these vertices is the one that starts there.10 Then, starting at the bottom
of the tree we work upward, assigning to each vertex a score that is 1 plus the
sum of the scores on the neighboring vertices immediately below it. That is,
the number of paths through a vertex v is 1 for the path that starts at v plus the
count of all paths that start below v in the tree and hence have to pass through
it.
When we have worked all the way up the tree in this manner and reached
vertex s, the scores at each vertex are equal to the betweenness counts for paths
that end at vertex s. Repeating the process for all s and summing the scores,
we arrive at the full betweenness scores for all paths.
In practice, the process of working up the tree can be accomplished by running through the vertices in order of decreasing distance from s. Conveniently,
we already have a list of vertices in order of their distances, namely the entries in the queue array created by the breadth-ﬁrst search process. Thus the
betweenness algorithm in practice involves running backwards through the
list of vertices in this array and calculating the number of paths through each
vertex as above until the beginning of the array is reached.
In the worst case, this process involves going through all n vertices and
checking every neighbor of every vertex, of which there are a total of 2m, so
that the overall running time is O(m + n). The breadth-ﬁrst search itself also
takes time O(m + n) (as usual) and hence the total time to count paths for each
source vertex s is O(m + n), which means the complete betweenness calculation takes time O(n(m + n)), as promised.
In general, however, we cannot assume that the shortest paths to a given
vertex form a tree. As we saw in Section 10.3.5, often they do not. Consider, for
instance, the “tree” shown in Fig. 10.3b. Following the deﬁnition of betweenness in Section 7.7, multiple shortest paths between the same pair of vertices
are given equal weights summing to 1, so that for a vertex pair connected by
three shortest paths, for example, we give each path weight 13 . Note that some
of the paths may share vertices for part of their length, resulting in vertices
with greater weight.
10

In this case we are considering the ﬁrst and last vertices on a path to be members of that path.
As discussed in Section 7.7, the ﬁrst and last vertices are sometimes excluded from the calculation,
which means that the betweenness score of each vertex is smaller by an additive constant equal to
twice the number of vertices in the component. If we wish to calculate betweenness according to
this alternative deﬁnition, the simplest approach is to use the algorithm described here and then
subtract the additive constant from each vertex’s score at the end.

327

F UNDAMENTAL NETWORK ALGORITHMS

To calculate correctly the weights of the paths ﬂowing through each vertex
in a network, we need ﬁrst to calculate the total number of shortest paths from
each vertex to s. This is actually quite straightforward to do: the shortest paths
from s to a vertex i must pass through one or more neighbors of i and the total
number of shortest paths to i is simply the sum of the numbers of shortest
paths to each of those neighbors. We can calculate these sums as part of a
modiﬁed breadth-ﬁrst search process as follows.
Consider Fig. 10.3b and suppose we are starting at vertex s. We carry out
the following steps:
1. Assign vertex s distance zero, to indicate that it is zero steps from itself,
and set d = 0. Also assign s a weight ws = 1 (whose purpose will become
clear shortly).
2. For each vertex i whose assigned distance is d, follow each attached edge
to the vertex j at its other end and then do one of the following three
things:
a) If j has not yet been assigned a distance, assign it distance d + 1 and
weight w j = wi .
b) If j has already been assigned a distance and that distance is equal
to d + 1, then the vertex’s weight is increased by wi , that is w j ←
w j + wi .
c) If j has already been assigned a distance less than d + 1, do nothing.
3. Increase d by 1.
4. Repeat from step 2 until there are no vertices that have distance d.
The resulting weights for the example of Fig. 10.3b are shown to the left of each
vertex in the ﬁgure. Each weight is the sum of the ones above it in the “tree.”
(It may be helpful to work through this example yourself by hand to see how
the algorithm arrives at these values for the weights.) Physically, the weight on
a vertex i represents the number of distinct geodesic paths between the source
vertex s and i.
Now if two vertices i and j are connected by a directed edge in the shortest
path “tree” pointing from j to i, then the fraction of the paths to s that pass
through (or starting at) j and that also pass through i is given by wi /w j .
Thus, and ﬁnally, to calculate the contribution to the betweenness from
shortest paths starting at all vertices and ending at s, we need only carry out
the following steps:
1. Find every “leaf” vertex t, i.e., a vertex such that no paths from s to other
vertices go though t, and assign it a score of xt = 1.
2. Now, starting at the bottom of the tree, work up towards s and assign
to each vertex i a score xi = 1 + ∑ j x j wi /w j , where the sum is over the
neighbors j immediately below vertex i.
328

10.4

|

S HORTEST PATHS IN NETWORKS WITH VARYING EDGE LENGTHS

3. Repeat from step 2 until vertex s is reached.
The resulting scores are shown to the right of each vertex in Fig. 10.3b. Now
repeating this process for all n source vertices s and summing the resulting
scores on the vertices gives us the total betweenness scores for all vertices in
time O(n(m + n)).11
This algorithm again takes time O(n(m + n)) in general or O(n2 ) on a
sparse network, which is the best known running time for any betweenness
algorithm at the time of writing, and moreover seems unlikely to be beaten by
any future algorithm given that the calculation of the betweenness necessarily
requires us to ﬁnd shortest paths between all pairs of vertices, which operation
also has time complexity O(n(m + n)). Indeed, even if we want to calculate the
betweenness of only a single vertex it seems unlikely we can do better given
that such a calculation still requires us to ﬁnd all shortest paths.

10.4

S HORTEST PATHS IN NETWORKS WITH VARYING EDGE LENGTHS

In Section 6.3 we discussed weighted networks, networks in which the edges
have values or strengths representing, for instance, the trafﬁc capacities of connections on the Internet or the frequencies of contacts between acquaintances
in a social network. In some cases the values on edges can be interpreted as
lengths for the edges. The lengths could be real lengths, such as distances
along roads in a road network, or they could represent quantities that act like
lengths, such as transmission delays for packets traveling along Internet connections. In other cases they might just be approximately length-like measures:
one might say, for instance, that a pair of acquaintances in a social network are
twice as far apart as another pair if they see one another half as often.
Sometimes with networks such as these we would like to calculate the
shortest path between two vertices taking the lengths of the edges into account.
For instance, we might want to calculate the shortest driving route from A to B
via a road network or we might want to calculate the route across the Internet
that gets a data packet to its destination in the shortest time. (In fact, this is
exactly what many Internet routers do when routing data packets.)
But now we notice a crucial—and annoying—fact. The shortest path across
a network when we take edge lengths into account may not the be same as
the shortest path in terms of number of edges. Consider Fig. 10.4. The shortest path between s and t in this small network traverses four edges, but is
11
As discussed in footnote 9, these scores give the betweenness as deﬁned in Eq. (7.36). To get
true path counts one would have to divide by two and add a half (or equivalently add one then
divide by two) to correct for the double counting of paths between distinct vertices.

329

F UNDAMENTAL NETWORK ALGORITHMS

still shorter, in terms of total edge length, than the competing path with just
two edges. Thus we cannot ﬁnd the shortest path in such a network using
standard breadth-ﬁrst search, which ﬁnds paths with the minimum number of
edges. For problems like this we need a different algorithm. We need Dijkstra’s
algorithm.
Dijkstra’s algorithm, like breadth-ﬁrst search, ﬁnds the shortest
1
1
distance from a given source vertex s to every other vertex in the
same component of a network, but does so taking the lengths of
1
1
edges into account.12 It works by keeping a record of the shortest
s
t
distance it has found so far to each vertex and updating that record
whenever a shorter one is found. It can be shown that, at the end
of the algorithm, the shortest distance found to each vertex is in fact
3
3
the shortest distance possible by any route. In detail the algorithm
is as follows.
We start by creating an array of n elements to hold our current
estimates of the distances from s to every vertex. At all times during
Figure 10.4: The shortest path in a netthe running of the algorithm these estimates are upper bounds on
work with varying edge lengths. The
the true shortest distances. Initially we set our estimate of the disnumbers on the edges in this network
tance from s to itself to be zero, which is trivially correct, and from
represent their lengths. The shorts to every other vertex to be ∞, which is clearly a safe upper bound.
est path between s and t, taking the
lengths into account, is the upper path
We also create another array of n elements in which we record
marked with the arrow (which has towhether we are certain that the distance we have to a given vertex is
tal length 4), even though it traverses
the smallest possible distance. For instance, we might use an integer
more edges than the alternative, lower
array with 1s to indicate the distances we are sure about and 0s for
path (which has length 6).
the distances that are just our best current estimate. Initially, we put
a 0 in every element of this array. (You might argue that we know
for certain that the distance from s to itself is zero and hence that we should
put a 1 in the element corresponding to vertex s. Let us, however, pretend that
we don’t know this to begin with, as it makes the algorithm work out more
neatly.)
Now we do the following.
1. We ﬁnd the vertex v in the network that has the smallest estimated distance from s, i.e., the smallest distance about which we are not yet certain.
12

We assume that the lengths are all non-negative. If lengths can be negative, which happens in
some cases, then the problem is much harder, falling in the class of “NP-complete” computational
problems, for which even the best known algorithms take an amount of time exponential in n to
ﬁnish, in the worst case [8]. Indeed, if edges are allowed to have negative lengths, there may not
be any shortest path between a pair of vertices, since one can have a loop in the network that has
negative length, so that one can reduce the length of a path arbitrarily by going around the loop
repeatedly.

330

10.4

|

S HORTEST PATHS IN NETWORKS WITH VARYING EDGE LENGTHS

Hyp

y

rp

ath

x

othetical shorte

s
Known distances

v

Estimated distances
Figure 10.5: Paths in Dijkstra’s algorithm. If v is the vertex with the smallest estimated
(i.e., not certain) distance from s then that estimated distance must in fact be the true
shortest distance to v. If it were not and there were a shorter path s, . . . , x, y, . . . , v then
all points along that path must have shorter distances from s than v’s estimated distance, which means that y has a smaller estimated distance than v, which is impossible.

2. We mark this distance as being certain.
3. We calculate the distances from s via v to each of the neighbors of v by
adding to v’s distance the lengths of the edges connecting v to each neighbor. If any of the resulting distances is smaller than the current estimated
distance to the same neighbor, the new distance replaces the older one.
4. We repeat from step 1 until the distances to all vertices are ﬂagged as
being certain.
Simple though it is to describe, it’s not immediately obvious that this algorithm
does what it is supposed to do and ﬁnds true shortest paths. The crucial step
is step 2 where we declare the current smallest estimated distance in fact to be
certain. That is, we claim that among vertices for which we don’t yet deﬁnitely
know the distance, the smallest distance recorded to any vertex is in fact the
smallest possible distance to that vertex.
To see why this is true consider such a vertex, which we’ll again call v,
and consider a hypothetical path from s to v that has a shorter length than
the current estimated distance recorded for v. The situation is illustrated in
Fig. 10.5. Since this hypothetical path is shorter than the estimated distance
to v, the distance along the path to each vertex in the path must also be less
than that estimated distance.
Furthermore, there must exist somewhere along the path a pair of adjacent
vertices x, y such that x’s distance is known for certain and y’s is not. Vertex x
need not necessarily be distinct from vertex s (although we have drawn it that
331

F UNDAMENTAL NETWORK ALGORITHMS

way in the ﬁgure), but vertex y must be distinct from v: if y and v were the
same vertex, so that v was a neighbor of x, then we would already have found
the shorter path to v when we explored the neighbors of x in step 3 above and
we would accordingly have revised our estimate of v’s distance downward.
Since this hasn’t happened, y and v must be distinct vertices.
But notice now that y’s current estimated distance will be at most equal to
its distance from s along the path because that distance is calculated in step 3
above when we explore x’s neighbors. And since, as we have said, all distances along the path are necessarily less than the current estimated distance
to v, it follows that y’s estimated distance must be less than v’s and we have a
contradiction, because v is by hypothesis the vertex with the shortest estimated
distance. Hence there is no path to vertex v with length less than v’s current
estimated distance, so we can safely mark that distance as being certain, as in
step 2 above.
Thus on each step the algorithm correctly ﬂags one additional distance as
being known exactly and when all distances have been so ﬂagged the algorithm has done its job.
As with breadth-ﬁrst search, the running time of Dijkstra’s algorithm depends on how it is implemented. The simplest implementation is one that
searches through all vertices on each round of the algorithm to ﬁnd the one
that has the smallest estimated distance. This search takes time O(n). Then we
must calculate a new estimated distance to each of the neighbors of the vertex
we ﬁnd, of which there are O(m/n) on average. To leading order, one round
thus takes time O(m/n + n) and the whole algorithm, which runs (in the worst
case of a network with a single component) for n rounds, takes time O(m + n2 )
to ﬁnd the distance from s to every other vertex.
But we can do better than this. If we store the estimated distances in a
binary heap (see Section 9.7) then we can ﬁnd the smallest one and remove
it from the heap in time O(log n). The operation of replacing an estimated
distance with a new and better estimate (which in the worst case we have to
do an average of O(m/n) times per round) also takes O(log n) time, and hence
a complete round of the algorithm takes time O((m/n) log n + log n) and all
n rounds then take O((m + n) log n), or O(n log n) on a sparse network with
m ∝ n. This is very nearly the best running time known for this problem,13 and
close to, though not quite as good as, the O(m + n) for the equivalent problem
on an unweighted network (factors of log n being close to constant given that
In theory one can achieve a slightly better running time of O(m + n log n) using a data structure known as a Fibonacci heap [81], but in practice the operation of the Fibonacci heap is so
complicated that the calculation usually ends up running slower.
13

332

10.5

|

M AXIMUM FLOWS AND MINIMUM CUTS

the logarithm is a very slowly growing function of its argument).
As we have described it, Dijkstra’s algorithm ﬁnds the shortest distance
from a vertex s to every other in the same component but, like breadth-ﬁrst
search, it can be modiﬁed also to ﬁnd the actual paths that realize those distances. The modiﬁcation is very similar to the one for breadth-ﬁrst search. We
maintain a shortest path tree, which is initially empty and to which we add
directed edges pointing from the vertices along the ﬁrst step of their shortest
path to s. We create such a directed edge when we ﬁrst assign a vertex an estimated distance less than ∞ and move the edge to point to a new vertex every
time we ﬁnd a new estimated distance that is less than the current one. The
last position in which an edge comes to rest indicates the true ﬁrst step in the
shortest path. If a new estimate of the distance to a vertex is ever exactly the
same as the current estimate then we put two directed edges in the shortest
path tree indicating the two alternative paths that give the shortest distance.
When the algorithm is ﬁnished the shortest path tree, like those in Fig. 10.2,
can be used to reconstruct the shortest paths themselves, or to calculate other
quantities such as a weighted version of betweenness centrality (which could
be used for instance as a measure of trafﬁc ﬂow in a network where trafﬁc
always takes the shortest weighted path).

10.5

M AXIMUM FLOWS AND MINIMUM CUTS

In Section 6.12 we discussed the ideas of connectivity, independent paths, cut
sets, and maximum ﬂows in networks. In particular, we deﬁned two paths
that connect the same vertices s and t to be edge-independent if they share
none of the same edges and vertex-independent if they share none of the same
vertices except for s and t themselves. And the edge or vertex connectivity of
the vertices is the number of edge- or vertex-independent paths between them.
We also showed that the edge or vertex connectivity is equal to the size of the
minimum edge or vertex cut set—the minimum number of edges or vertices
that need to be removed from the network to disconnect s from t. Connectivity
is thus a simple measure of the robustness of the connection between a pair
of vertices. Finally, we showed that the edge-connectivity is also equal to the
maximum ﬂow that can pass from s to t if we think of the network as a network
of pipes, each of which can carry one unit of ﬂow.
In this section we look at algorithms for calculating maximum ﬂows between vertices on networks. As we will see, there is a simple algorithm, the
Ford–Fulkerson or augmenting path algorithm, that calculates the maximum
ﬂow between two vertices in average time O((m + n)m/n). Once we have
this maximum ﬂow, then we also immediately know the number of edge333

F UNDAMENTAL NETWORK ALGORITHMS

independent paths and the size of the minimum edge cut set between the
same vertices. With a small extension, the algorithm can also ﬁnd the particular edges that constitute the minimum edge cut set. A simple modiﬁcation of
the augmenting path algorithm allows us also to calculate vertex-independent
paths and vertex cuts sets.
All the developments of this section are described for undirected networks,
but in fact the algorithms work perfectly well, without modiﬁcation, for directed networks as well. Readers who want to know more about maximum
ﬂow algorithms are recommended to look at the book by Ahuja et al. [8], which
contains several hundred pages on the topic and covers almost every conceivable detail.

s

s

t

t

A simple breadth-ﬁrst
search ﬁnds a path from
source s to target t (top)
in this network. A second
search using only the edges
not used in the ﬁrst ﬁnds a
second path (bottom).

10.5.1

T HE AUGMENTING PATH ALGORITHM

In this section we describe the augmenting path algorithm of Ford and Fulkerson for calculating maximum ﬂows between vertices in a network.14 The case
of primary interest to us is the one where each edge in the network can carry
the same single unit of ﬂow. The algorithm can be used in the more general
case where the edges have varying capacities, but we will not discuss that case
here.15
The basic idea behind the augmenting path algorithm is a simple one. We
ﬁrst ﬁnd a path from source s to target t using the breadth-ﬁrst search algorithm of Section 10.3.16 This “uses up” some of the edges in the network, ﬁlling them to capacity so that they can carry no more ﬂow. Then we ﬁnd another
path from s to t among the remaining edges and we repeat this procedure until
no more paths can be found.
Unfortunately, this does not yet give us a working algorithm, because as
we have described it the procedure will not always ﬁnd the maximum ﬂow.
Consider Fig. 10.6a. If we apply breadth-ﬁrst search between s and t we ﬁnd
14
The augmenting path algorithm is not the only algorithm for calculating maximum ﬂows. It
is, however, the simplest and its average performance is about as good as any other, so it is a good
choice for everyday calculations. It’s worth noting, however, that the worst-case performance of
the algorithm is quite poor: for pathological networks, the algorithm can take a very long time
to run. Another algorithm, the preﬂow-push algorithm [8], has much better worst-case performance
and comparable average-case performance, but is considerably more complicated to implement.
15
16

See Ahuja et al. [8] or Cormen et al. [81] for details of the general case.

Technically, the augmenting path algorithm doesn’t specify how paths are to be found. Here
we study the particular version in which paths are found using breadth-ﬁrst search, which is
known to be one of the better-performing variants. Sometimes this variant is called the shortest
augmenting path algorithm or the Edmonds–Karp algorithm.

334

10.5

(a)

s

M AXIMUM FLOWS AND MINIMUM CUTS

(b)

t

(c)

s

|

s

t

(d)

t

s

t

Figure 10.6: The augmenting path algorithm. (a) We ﬁnd a ﬁrst path from source s to
target t using breadth-ﬁrst search. This leaves no more independent paths from s to t
among the remaining edges. (b) However, if we allow ﬂows in both directions along an
edge (such as the central edge in this network), then we can ﬁnd another path. Panels
(c) and (d) show the residual graphs corresponding to panels (a) and (b).

the path marked in bold. Unfortunately, once we have ﬁlled all the edges along
this path to capacity there are no more paths from s to t that can be constructed
with the remaining edges, so the algorithm stops after ﬁnding just one path.
It is clear, however, that there are in fact two edge-independent paths from s
to t—along the top and bottom of the network—and a maximum ﬂow of two,
so the algorithm has given the wrong answer.
There is however, a simple ﬁx for this problem, which is to allow ﬂuid
to ﬂow simultaneously both ways down an edge in our network. That is, we
allow a state in which there is one unit of ﬂow in each direction along any
given edge. If the edges were real pipes, then this would not be possible: if a
pipe is full of ﬂuid ﬂowing one way, then there is no room for ﬂuid ﬂowing the
other way too. However, if ﬂuid were ﬂowing both ways down an edge, the
net ﬂow in and out of either end of that edge would be zero—the two ﬂows
would effectively cancel out giving zero net ﬂow. And zero ﬂow down an edge
certainly is possible.
So we use a trick and allow our algorithm to place a unit of ﬂow both ways
down any edge, but declare this to mean in practice that there is no ﬂow at all
on that edge. This means that the paths we will ﬁnd will no longer necessarily

335

F UNDAMENTAL NETWORK ALGORITHMS

be independent paths, since two of them can share an edge so long as they pass
along it in opposite directions. But this doesn’t matter: the ﬂows the paths
represent are still allowed ﬂows, since no pipe is ever required to carry more
than one unit of ﬂow, and we know that in the end our ﬁnal, maximum ﬂow
will be numerically equal to the actual number of independent paths, even
though those independent paths may be different from the paths picked out
by the algorithm. Thus we create an algorithm that counts independent paths
by counting a special class of non-independent paths: strange as this sounds,
the max-ﬂow/min-cut theorem tells us that it must work, and indeed it does.
More generally, since the maximum allowed ﬂow down an edge is one unit
in either direction, we can have any number of units ﬂowing either way down
an edge provided they cancel out so that net ﬂow is no more than one unit.
Thus, two units of ﬂow in either direction would be allowed, or three units
one way and four the other, and so forth. Three units one way and ﬁve the
other would not be allowed, however.17
To see how this works in practice, consider Fig. 10.6 again. We begin by
performing a breadth-ﬁrst search that ﬁnds the path shown in panel (a). Now,
however, there is a second path to be found, as shown in panel (b), making use
of the fact that we are still allowed to send one unit of ﬂow backwards along
the edge in the center of the network. After this, however, there are no more
paths left from s to t and so the algorithm stops and tells us that the maximum
possible ﬂow is two units, which is the correct answer.
This is merely one example of the algorithm: we still have to prove that it
gives the correct answer in all cases, which we do in Section 10.5.3. To understand the proof, however, we ﬁrst need to understand how the algorithm is
implemented.
10.5.2

I MPLEMENTATION AND RUNNING TIME

Implementation of the augmenting path algorithm makes use of a residual
graph, which is a directed network in which the edges connect the pairs of vertices on the original network between which we still have capacity available to
carry one or more units of ﬂow in the given direction. For instance, Figs. 10.6c
and 10.6d show the residual graphs corresponding to the ﬂow states in 10.6a
and 10.6b.
The residual graph is constructed by ﬁrst taking the initial network and
17
On networks with directed edges, we allow either the same ﬂow in both directions along an
edge (i.e., zero net ﬂow) or one more unit in the forward direction than in the backward direction,
but not vice versa.

336

10.5

|

M AXIMUM FLOWS AND MINIMUM CUTS

replacing each undirected edge with two directed ones, one in each direction.
We now perform our breadth-ﬁrst searches on this residual graph, rather than
on the original network, respecting the directions of the edges. Every time
our algorithm ﬁnds a new path through the network, we update the residual
graph by adding a directed edge in the opposite direction to the path between
every pair of vertices along the path, provided no such edge already exists.
If a vertex pair already has such a backward-pointing edge, we instead take
away a forward-pointing one. (There will always be such a forward-pointing
edge, otherwise the path would not exist in the ﬁrst place.) The largest number
of edges we update during this process is m, the total number of edges in the
original network, so the process takes time O(m) and thus makes no difference
to the O(m + n) time complexity of the breadth-ﬁrst search.
Now we ﬁnd the next path by performing another breadth-ﬁrst search on
the updated residual graph. By always working on the residual graph in this
way, we insure that we ﬁnd only paths along edges that have not yet reached
their maximum ﬂow. Such paths are called augmenting paths. The process is
repeated until our breadth-ﬁrst search fails to ﬁnd any augmenting path from s
to t, at which point we have found all the paths there are and the number of
paths found is equal to the number of units in the maximum ﬂow from s to t.
Each breadth-ﬁrst search, along with the corresponding updates to the residual graph, takes time O(m + n) for a network stored in adjacency list format
(see Sections 9.4 and 10.3). Moreover, the number of independent paths from
s to t can be no greater than the smaller of the two degrees k s and k t of the
source and target vertices (since each path must leave or enter one of those
vertices along some edge, and that edge can carry at most one path). Thus the


running time of the algorithm is O min(k s , k t )(m + n) . If we are interested in
the average running time over many pairs of vertices, then we can make use of
the fact that min(k s , k t ) ≤ k (where the averages are over all vertices), and
recalling that k = 2m/n (Eq. (6.23)), this implies that the average running


time of the algorithm is O (m + n)m/n , which is O(n) on a sparse network
with m ∝ n. (On the other hand, on a dense graph where m ∝ n2 , we would
have O(n3 ), which is much worse.)
10.5.3

W HY THE ALGORITHM GIVES CORRECT ANSWERS

It is plausible but not immediately obvious that the augmenting path algorithm correctly ﬁnds maximum ﬂows. We can prove that it does as follows.
Suppose at some point during the operation of the algorithm (including
the very beginning) we have found some (or no) paths for ﬂow from s to t, but
any paths we have found do not yet constitute the maximum possible ﬂow.
337

F UNDAMENTAL NETWORK ALGORITHMS

That is, there is still room in the network for more ﬂow from s to t. If this is
the case then, as we will now show, there must exist at least one augmenting
path from s to t, which by deﬁnition carries one unit of ﬂow. And if there
exists an augmenting path, our breadth-ﬁrst search will always ﬁnd it, and so
the algorithm will go on ﬁnding augmenting paths until there is no room in
the network for more ﬂow, i.e., we have reached the maximum ﬂow, which is
equal to the number of paths found.
Thus the proof that the algorithm is correct requires only that we prove the
following theorem:
If at some point in our algorithm the ﬂow from s to t is less than the
maximum possible ﬂow, then there must exist at least one augmenting path on the current residual graph.
Consider such a point in the operation of the algorithm and consider the ﬂows
on the network as represented by f , the set of all individual net ﬂows along
the edges of the network. And consider also the maximum possible ﬂow from
s to t, represented by f max , the corresponding set of individual net ﬂows. By
hypothesis, the total ﬂow out of s and into t is greater in f max than in f . Let us
calculate the difference ﬂow Δ f = f max − f , by which we mean we subtract the
net ﬂow along each edge in f from the net ﬂow along the corresponding edge
in f max , respecting ﬂow direction—see Fig. 10.7. (For instance, the difference of
two unit ﬂows in the same direction would be zero while the difference of two
in opposite directions would be two in one direction or the other.)
Since the total ﬂow is greater in f max than in f , the difference ﬂow Δ f must
have a net ﬂow out of s and net ﬂow into t. What’s more, because the “ﬂuid”
composing the ﬂow is conserved at vertices, every vertex except s and t must
have zero net ﬂow in or out of it in both f max and f and hence also in Δ f . But if
each vertex other than s and t has zero net ﬂow, then the ﬂow from s to t must
form at least one path across the network—it must leave every vertex it enters,
except the last one, vertex t. Let us choose any one of these paths formed by
the ﬂow from s to t in Δ f and let us call this path p.
Since there is a positive ﬂow in Δ f in the forward direction along each
edge in p, there must have been no such ﬂow in f along any of the same edges.
If there were such a ﬂow in f then when we performed the subtraction Δ f =
f max − f the ﬂow in Δ f would be either zero or negative on the edge in question
(depending on the ﬂow in f max ), but could not be positive. Thus we can always
safely add to f a unit of ﬂow forward along each edge in p without overloading
any of the edges. But this immediately implies that p is an augmenting path
for f .
Thus, for any ﬂow that is not maximal, at least one augmenting path always
338

10.5

|

M AXIMUM FLOWS AND MINIMUM CUTS

Maximum flow

s

t

s

s

t

t

Difference flow

Submaximal flow
Figure 10.7: Correctness of the augmenting path algorithm. If we subtract from the
maximum ﬂow f max (upper left) any submaximal ﬂow f (lower left), the resulting difference ﬂow (right) necessarily contains at least one path from s to t, and that path is
necessarily an augmenting path for f .

exists, and hence it follows that the augmenting path algorithm as described
above is correct and will always ﬁnd the maximum ﬂow.
10.5.4

F INDING INDEPENDENT PATHS AND MINIMUM CUT SETS

Once we have found the maximum possible ﬂow between a given pair of vertices, we also automatically have the size of the minimum edge cut set and the
number of edge-independent paths, which are both numerically equal to the
number of units in the maximum ﬂow (see Section 6.12).
We might also wish to know exactly where the independent paths run. The
augmenting path algorithm does not give us this directly since, as we have
seen, the augmenting paths it ﬁnds are not necessarily the same as the independent paths, but only a very small extension of the algorithm is necessary to
ﬁnd the independent paths: we take the ﬁnal residual graph produced at the
end of the algorithm and remove from it every pair of directed edges that joins
the same two vertices in opposite directions—see Fig. 10.8. In other words we
are removing all network edges that carry no net ﬂow. The edges remaining

339

F UNDAMENTAL NETWORK ALGORITHMS

s

t

s

t

Figure 10.8: Reconstructing the independent paths from the residual graph. Deleting
every pair of edges on the residual graph that join the same two vertices in opposite directions leaves a graph consisting of the independent paths only, spelled out in directed
edges that point backwards along those paths from target to source.

after we have done this are necessarily those that actually carry the maximum
ﬂow and it is a straightforward matter to trace these edges from s to t to reconstruct the paths themselves.18 (In fact, as Fig. 10.8 shows, the remaining
directed edges in the residual graph point backwards from t to s, so it is often
easier to reconstruct the paths backwards.)
Another thing we might want is the set of edges that constitutes the minimum cut set for the vertices s and t. In fact in most cases there is more than
one cut set of the minimum size, so more generally we would like to ﬁnd one
of the minimum cut sets. Again we can do this by a small extension of the
augmenting path algorithm. The procedure is illustrated in Fig. 10.9. We again
consider the ﬁnal residual graph generated at the end of the algorithm. By
deﬁnition this graph has no directed path in it from s to t (since if it did the
algorithm would not have stopped yet). Thus we can reach some subset of
vertices by starting at vertex s, but we cannot reach all of them. (For example, we cannot reach t.) Let Vs be the subset of vertices reachable from s by
some path on the residual graph and let Vt be the set of all the other vertices
in the graph that are not in Vs . Then the set of edges on the original graph that
connect vertices in Vs to vertices in Vt constitutes a minimum cut set for s and t.
Why does this work? Clearly if we removed all edges that connect vertices
in Vs to those in Vt we disconnect s and t, since then there is no path at all
between s and t. Thus the edges between Vs and Vt constitute a cut set. That it
18

Note, however, that the independent paths are not necessarily unique: there can be more than
one choice of paths and some of them may not be found by this algorithm. Furthermore, there can
be points in the network where paths come together at a vertex and then part ways again. If such
points exist, you will have to make a choice about which way to go at the parting point. It doesn’t
matter what choice you make in the sense that all choices lead to a correct set of paths, but different
choices will give different sets of paths.

340

10.5

s

t

s

Vt
Vs

|

M AXIMUM FLOWS AND MINIMUM CUTS

t

Figure 10.9: Finding a minimum cut set. Once we have found a set of maximum ﬂows
for a given s and t (left) we can ﬁnd a corresponding minimum cut set by considering
the residual graph (right). The set Vs is the set of vertices reachable from s by following
directed edges on the residual graph and Vt is the rest of the vertices. The minimum
cut set is the set of edges (two of them in this case) that connect Vs to Vt on the original
network.

is a minimum cut set we can see by the following argument. Every edge from
a vertex in Vs to a vertex in Vt must be carrying a unit of ﬂow from Vs to Vt . If
it were not, then it would have available capacity away from Vs , meaning that
there would be a corresponding directed edge away from Vs in the residual
graph. In that case, however, the vertex at the far end of that edge would be
reachable from Vs on the residual graph and therefore would be a part of Vs .
Since the vertex in question is, by hypothesis, in Vt and not in Vs , it follows that
it must be carrying a unit of the maximum ﬂow from s to t.
Now, since every edge in the cut set between Vs and Vt is carrying a unit of
ﬂow, the size of that cut set is numerically equal to the size of the ﬂow from
Vs to Vt , which is also the ﬂow from s to t. And, by the max-ﬂow/min-cut
theorem, a cut set between s and t that is equal in size to the maximum ﬂow
between s and t is a minimum cut set, and hence our result is proved.
10.5.5

F INDING VERTEX - INDEPENDENT PATHS

Once we know how to ﬁnd edge-independent paths it is straightforward to
ﬁnd vertex-independent paths as well. First, note that any set of vertex-independent paths between two vertices s and t is necessarily also a set of edgeindependent paths: if two paths share none of the same vertices, then they also
share none of the same edges. Thus, we can ﬁnd vertex-independent paths
using the same algorithm that we used to ﬁnd edge-independent paths, but
adding the restriction that no two paths may pass through the same vertex.
One way to impose this restriction is the following. First, we replace our undirected network with a directed one, as shown in Fig. 10.10, with a directed
341

F UNDAMENTAL NETWORK ALGORITHMS

(a)

(b)

s

t

s

t

(c)

s

t

Figure 10.10: Mapping from the vertex-independent path problem to the edgeindependent path problem. Starting with an undirected network (a), we (b) replace
each edge by two directed edges, then (c) replace each vertex, except for s and t, with
a pair of vertices with a directed edge between them (shaded) following the prescription in Fig. 10.11. Edge-independent paths on the ﬁnal network then correspond to
vertex-independent paths on the initial network.

edge in either direction between every connected pair of vertices. This does
not change the maximum ﬂow possible in the network and hence does not
change the number of independent paths either.
Second, we replace each of the vertices in the network, except s and t, with
a construct like that shown in Fig. 10.11. Each vertex is replaced with two
vertices separated by a directed edge. All original incoming edges connect
to the ﬁrst of these two (on the left in Fig. 10.11) and all outgoing edges to
the second. This new construct functions as the original vertex did, allowing
ﬂows to pass in along ingoing edges and out along outgoing ones, but with one
important difference: assuming that the new edge joining the two vertices has
unit capacity like all others, we are now limited to just one unit of ﬂow through
the entire construct, since every path through the construct must traverse this
central edge. Thus every allowed ﬂow on this network corresponds to a ﬂow
342

P ROBLEMS

Figure 10.11: Vertex transformation for the vertex-independent path algorithm. Each
vertex in the network is replaced by a pair of vertices joined by a single directed edge.
All incoming edges are connected to one of the pair and all outgoing edges to the other
as shown.

on the original network with at most a single unit passing though each vertex.
Transforming the entire network of Fig. 10.10a using this method gives
us a network that looks like Fig. 10.10c. Now we simply apply the normal
augmenting path algorithm to this directed network, and the number of edgeindependent paths we ﬁnd is equal to the number of vertex-independent paths
on the original network.

P ROBLEMS
10.1 What is the time complexity, as a function of the number n of vertices and m
of edges, of the following network operations if the network in question is stored in
adjacency list format?
a) Calculating the mean degree.
b) Calculating the median degree.
c) Calculating the air-travel route between two airports that has the shortest total
ﬂying time, assuming the ﬂying time of each individual ﬂight is known.
d) Calculating the minimum number of routers that would have to fail to disconnect
two given routers on the Internet.
10.2

For an undirected network of n vertices stored in adjacency list format show that:

a) It takes time O(n(n + m)) to ﬁnd the diameter of the network.
b) It takes time O( k ) on average to list the neighbors of a vertex, where k is the
average degree in the network, but time O( k2 ) to list the second neighbors.
10.3 For a directed network in which in- and out-degrees are uncorrelated, show that
it takes time O(m2 /n) to calculate the reciprocity of the network. Why is the restriction
to uncorrelated degrees necessary? What could happen if they were correlated?

343

F UNDAMENTAL NETWORK ALGORITHMS

10.4 Suppose that we deﬁne a new centrality measure xi for vertex i in a network to
be a sum of contributions as follows: 1 for vertex i itself, α for each vertex at (geodesic)
distance 1 from i, α2 for each vertex at distance 2, and so forth, where α < 1 is a given
constant.
a) Write an expression for xi in terms of α and the geodesic distances dij between
vertex pairs.
b) Describe brieﬂy an algorithm for calculating this centrality measure. What is the
time complexity of calculating xi for all i?

344

C HAPTER 11

M ATRIX ALGORITHMS AND GRAPH
PARTITIONING
A discussion of network algorithms that use matrix and
linear algebra methods, including algorithms for
partitioning network nodes into groups

I

N THE preceding chapter we discussed a variety of computer algorithms for

calculating quantities of interest on networks, including degrees, centralities, shortest paths, and connectivity. We continue our study of network algorithms in this chapter with algorithms based on matrix calculations and methods of linear algebra applied to the adjacency matrix or other network matrices
such as the graph Laplacian. We begin with a simple example, the calculation
of eigenvector centrality, which involves ﬁnding the leading eigenvector of the
adjacency matrix, and then we move on to some more advanced examples,
including Fiedler’s spectral partitioning method and algorithms for network
community detection.

11.1

L EADING EIGENVECTORS AND EIGENVECTOR CENTRALITY

As discussed in Section 7.2, the eigenvector centrality of a vertex i in a network
is deﬁned to be the ith element of the leading eigenvector of the adjacency
matrix, meaning the eigenvector corresponding to the largest (most positive)
eigenvalue. Eigenvector centrality is an example of a quantity that can be calculated by a computer in a number of different ways, but not all of them are
equally efﬁcient. One way to calculate it would be to use a standard linear
algebra method to calculate the complete set of eigenvectors of the adjacency
matrix, and then discard all of them except the one corresponding to the largest
eigenvalue. This, however, would be a wasteful approach, since it involves cal345

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

culating a lot of things that we don’t need. A simpler and faster method for
calculating the eigenvector centrality is the power method.
If we start with essentially any initial vector x(0) and multiply it repeatedly
by the adjacency matrix A, we get
x ( t ) = A t x (0),

(11.1)

and, as shown in Section 7.2, x(t) will converge1 to the required leading eigenvector of A as t → ∞. This is the power method, and, simple though it is,
there is no faster method known for calculating the eigenvector centrality (or
the leading eigenvector of any matrix). There are a few caveats, however:
1. The method will not work if the initial vector x(0) happens to be orthogonal to the leading eigenvector. One simple way to avoid this problem
is to choose the initial vector to have all elements positive. This works
because all elements of the leading eigenvector of a real matrix with nonnegative elements have the same sign,2 which means that any vector or1

Technically the power method ﬁnds the eigenvector corresponding to the eigenvalue of
largest absolute magnitude and hence the method would fail to ﬁnd the eigenvector we want
if the largest absolute magnitude belongs to a negative eigenvalue. For a matrix with all elements
non-negative, however, such as the adjacency matrix, it turns out this can never happen. Here is a
proof of this result for an undirected network where A is symmetric; the general case is covered,
for example, in Ref. [217]. Let μ be the most negative eigenvalue of a real symmetric matrix A and
let w be the corresponding eigenvector, with elements wi . Then, given that w T w = ∑i w2i > 0,
"
"
"
"
|μ|wT w = |μwT w| = |wT Aw| = ""∑ Aij wi w j "" ≤ ∑ | Aij wi w j | = ∑ Aij |wi ||w j | = xT Ax,
ij

ij

ij

where x is the vector with components |wi |. The inequality here follows from the so-called triangle
inequality | a + b| ≤ | a| + |b|, which is true for all real numbers a, b. Rearranging, we now ﬁnd that

|μ| ≤

x T Ax
x T Ax
= T ,
T
w w
x x

where we have made use of x T x = ∑i |wi |2 = w T w. Now we write x as a linear combination of the
normalized eigenvectors vi of A thus: x = ∑i ci vi , where the ci are real coefﬁcients whose exact
values are not important for this proof. Then, if κi is the eigenvalue corresponding to vi and κ1 is
the most positive eigenvalue, we have
∑ j c j v Tj A ∑i ci vi
∑ j c j v Tj ∑i ci κi vi
x T Ax
∑ c2 κ i
∑ c2 κ 1
=
=
= i i 2 ≤ i i 2 = κ1 ,
T
T
xT x
c
c
v
c
v
c
v
c
v
∑i i
∑i ci
∑ j j j ∑i i i
∑ j j j ∑i i i
where we have made use of the orthogonality property v Tj vi = δij . (The inequality is an exact
equality if and only if x is an eigenvector with eigenvalue κ1 .) Putting these results together, we
ﬁnd that |μ| ≤ κ1 and hence the most negative eigenvalue never has a magnitude greater than that
of the most positive eigenvalue (although if we are unlucky the two magnitudes could be equal).
The result proved here is one part of the Perron–Frobenius theorem. The other part, that the leading
eigenvector has all elements non-negative, is proved in the following footnote.
2

346

This result, like that in footnote 1, is a part of the Perron–Frobenius theorem. To prove it—

11.1

|

L EADING EIGENVECTORS AND EIGENVECTOR CENTRALITY

thogonal to the leading eigenvector must contain both positive and negative elements. Hence, if we choose all elements of our initial vector to
be positive, we are guaranteed that the vector cannot be orthogonal to
the leading eigenvector.
2. The elements of the vector have a tendency to grow on each iteration—
they get multiplied by approximately a factor of the leading eigenvalue
at least for the case of symmetric A—let κ1 be the most positive eigenvalue of A and let v be a
corresponding eigenvector. (We will allow, for the moment, the possibility that there is more than
one eigenvector with eigenvalue κ1 , though we show below that in fact this cannot happen in a
connected network.) Note that κ1 ≥ 0 since the sum of the eigenvalues of A is given by Tr A ≥ 0,
and hence at least one eigenvalue must be non-negative. Then, given that v T v = ∑i v2i > 0 and all
elements of A are non-negative, we have
"
"
"
"
κ1 v T v = |κ1 v T v| = |v T Av| = ""∑ Aij vi v j "" ≤ ∑ | Aij vi v j | = ∑ Aij |vi ||v j | = x T Ax,
ij

ij

ij

where x is the vector with elements |vi |. Rearranging this result, we ﬁnd
κ1 ≤

x T Ax
x T Ax
= T ,
vT v
x x

where we have made use of x T x = ∑i |vi |2 = vT v. As demonstrated in footnote 1 on page 346, for
any vector x we have
x T Ax
≤ κ1 ,
xT x
with the equality being achieved only when x is an eigenvector corresponding to eigenvalue κ1 .
The only way to reconcile the two inequalities above is if they are in fact equalities in this case,
implying that x must indeed be an eigenvector with eigenvalue κ1 . But x has all elements nonnegative, and hence there exists an eigenvector with eigenvalue κ1 and all elements non-negative.
It is still possible that there might be more than one eigenvector with eigenvalue κ1 , and that one
of the others might have negative elements. This, however, we can rule out as follows. Recall that
eigenvectors with same eigenvalue can always be chosen orthogonal, and any eigenvector v that
is orthogonal to the eigenvector with all elements non-negative would have to have both positive
and negative elements in order that the product of the two vectors equal zero. Thus there is only
one eigenvector with all elements non-negative.
Then, for eigenvector v, by the results above, the vector x with elements |vi | is necessarily equal
to the unique eigenvector with all elements non-negative. Thus if vi is one of the positive elements
of v then vi = xi and
∑ Aij |v j | = ∑ Aij x j = κ1 xi = κ1 vi = ∑ Aij v j ,
j

j

j

or, equivalently, ∑ j Aij (|v j | − v j ) = 0. But |v j | − v j ≥ 0 so this last result can only be true if for all j
we have either Aij = 0 or v j − |v j | = 0, meaning that v j = |v j | ≥ 0. Thus if vi > 0 then v j > 0
whenever Aij = 0. In network terms, if vi > 0 then v j > 0 for every neighbor of i. But then we can
start at i and work outwards, moving from neighbor to neighbor and so demonstrate that v j > 0
for every vertex and hence v = x and the leading eigenvector is unique.
The only exception to this last result is when the network has more than component, so that
some vertices are not reachable from an initial vertex i. In that case, it is possible for the elements
of the leading eigenvector corresponding to vertices in different components to have different
signs. This, however, causes no problems for any of the results presented here.

347

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

each time, which is usually greater than 1. Computers however cannot
handle arbitrarily large numbers. Eventually the variables storing the elements of the vector will overﬂow their allowed range. To obviate this
problem, we must periodically renormalize the vector by dividing all the
elements by the same value, which we are allowed to do since an eigenvector divided throughout by a constant is still an eigenvector. Any suitable divisor will do, but we might, for instance, divide by the magnitude
of the vector, thereby normalizing it so that its new magnitude is 1.
3. How long do we need to go on multiplying by the adjacency matrix before the result converges to the leading eigenvalue? This will depend on
how accurate an answer we require, but one simple way to gauge convergence is to perform the calculation in parallel for two different initial
vectors and watch to see when they reach the same value, within some
prescribed tolerance. This scheme works best if, for the particular initial
vectors chosen, at least some elements of the vector converge to the ﬁnal
answer from opposite directions for the two vectors, one from above and
one from below. (We must make the comparisons immediately after the
renormalization of the vector described in (2) above—if we compare unnormalized vectors, then most likely all elements will increase on every
iteration and no convergence will be visible.) If we can ﬁnd some elements that do this (and we usually can), then it is a fairly safe bet that
the difference between the two values for such an element is greater than
the difference of either from the true value of the same element in the
leading eigenvector.
The power method can also be used to calculate the leading eigenvalue κ1 of
the adjacency matrix. Once the algorithm has converged to the leading eigenvector, one more multiplication by the adjacency matrix will multiply that vector by exactly a factor of κ1 . Thus, we can take the ratio of the values of any
element of the vector at two successive iterations of the algorithm after convergence and that ratio should equal κ1 . Or we could take the average of the
ratios for several different elements to reduce numerical errors. (We should
however avoid elements whose values are very small, since a small error in
such an element could lead to a large fractional error in the ratio; our accuracy
will be better if we take the average of some of the larger elements.)
11.1.1

C OMPUTATIONAL COMPLEXITY

How long does the power method take to run? The answer comes in two parts.
First, we need to know how long each multiplication by the adjacency matrix
takes, and second we need to know how many multiplications are needed to
348

11.1

|

L EADING EIGENVECTORS AND EIGENVECTOR CENTRALITY

get a required degree of accuracy in our answer.
If our network is stored in adjacency matrix form, then multiplying that
matrix into a given vector is straightforward. Exactly n2 multiplications are
needed for one matrix multiplication—one for each element of the adjacency
matrix. We can do better, however, if our network is in adjacency list form.
Elements of the adjacency matrix that are zero contribute nothing to the matrix
multiplication and so can be neglected. The adjacency list allows us to skip the
zero terms automatically, since it stores only the non-zero ones anyway.
In an ordinary unweighted network each non-zero element of the adjacency matrix is equal to 1. Let {u j }, j = 1 . . . k i be the set of neighbors of vertex i (where k i is the degree of i). Then the ith element of Ax, which we denote
[Ax]i , is given by [Ax]i = ∑kj=i 1 xu j . The evaluation of this sum involves only
k i operations, so one element of the matrix multiplication can be completed in
time proportional to k i and all elements can be completed in time proportional
to ∑i k i = 2m, where m is the total number of edges in the network, or in other
words in O(m) time.
And how many such multiplications must we perform? Equation (7.4) tells
us that after t iterations our vector is equal to
 t
n
κi
t
vi ,
(11.2)
x ( t ) = κ1 ∑ ci
κ
1
i =1
where vi is the normalized ith eigenvector, κi is the corresponding eigenvalue,
and the ci are constants whose values depend on the choice of initial vector.
Rearranging slightly, we can write this as
c2
x(t)
= v1 +
c1
c1 κ1t

κ2
κ1

t

v2 + . . . ,

(11.3)

which gives us our estimate of the leading eigenvector v1 plus the dominant
contribution to the error. Neglecting the smaller terms, the root-mean-square
error on the eigenvector is then
#"
"2
t
" x(t)
"
"
" = c2 κ 2 ,
−
v
(11.4)
1
t
" c1 κ
"
c1 κ 1
1
and if we want this error to be at most  then we require
t≥

ln(1/) + ln(c1 /c2 )
.
ln(κ1 /κ2 )

(11.5)

Neither  nor the constants c1 and c2 depend on the network size. All the variation in the run time comes from the eigenvalues κ1 and κ2 . The eigenvalues
349

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

range in value from a maximum of κ1 to a minimum of κn ≥ −|κ1 | and hence
have a mean spacing of at most 2κ1 /(n − 1). Thus an order-of-magnitude estimate for the second eigenvalue is κ2 ≃ κ1 − aκ1 /n, where a is a constant of
order unity, and hence
ln

a
κ1
≃ − ln 1 −
κ2
n

=

a
+ O ( n −2 ).
n

(11.6)

Combining Eqs. (11.5) and (11.6), we ﬁnd that the number of steps required for
convergence of the power method is t = O(n) to leading order.3
Overall therefore, the complete calculation of the eigenvector centralities of
all n vertices of the network takes O(n) multiplications which take O(m) time
each, or O(mn) time overall, for a network stored in adjacency list format. If
our network is sparse with m ∝ n, a running time of O(mn) is equivalent to
O(n2 ). On the other hand, if the network is dense, with m ∝ n2 , then O(mn) is
equivalent to O(n3 ).
Conversely, if our network is stored in adjacency matrix format the multiplications take O(n2 ) time, as noted above, so the complete calculation takes
O(n3 ), regardless of whether the network is sparse or dense. Thus for the common case of a sparse matrix the adjacency list is the representation of choice
for this calculation.
11.1.2

C ALCULATING OTHER EIGENVALUES AND EIGENVECTORS

The power method of the previous section calculates the largest eigenvalue of
a matrix and the corresponding eigenvector. This is probably the most common type of eigenvector calculation encountered in the study of networks, but
there are cases where we wish to know other eigenvectors or eigenvalues as
well. One example is the calculation of the so-called algebraic connectivity,
which is the second smallest (or second most negative) eigenvalue of the graph
Laplacian. As we saw in Section 6.13.3, the algebraic connectivity is non-zero
if and only if a network is connected (i.e., has just a single component). The
algebraic connectivity also appears in Section 11.5 as a measure of how easily
a network can be bisected into two sets of vertices such that only a small number of edges run between the sets. Moreover, as we will see the elements of the
corresponding eigenvector of the Laplacian tell us exactly how that bisection
3

In fact, this estimate usually errs on the pessimistic side, since the spacing of the highest
eigenvalues tends to be wider than the mean spacing, so that in practice the algorithm may be
faster than the estimate would suggest.

350

11.1

|

L EADING EIGENVECTORS AND EIGENVECTOR CENTRALITY

should be performed. Thus it will be useful to us to have a method for calculating eigenvalues beyond the largest one and their accompanying eigenvectors.
There are a number of techniques that can be used to ﬁnd non-leading
eigenvalues and eigenvectors of matrices. For instance, we can calculate the
eigenvector corresponding to the most negative eigenvalue by shifting all the
eigenvalues by a constant amount so that the most negative one becomes the
eigenvalue of largest magnitude. The eigenvalues of the graph Laplacian L,
for instance, are all non-negative. If we number them in ascending order as
in Section 6.13.2, so that λ1 ≤ λ2 . . . ≤ λn , with v1 , v2 , . . . , vn being the corresponding eigenvectors, then

( λ n I − L ) vi = ( λ n − λi ) vi ,

(11.7)

and hence vi is an eigenvector of λn I − L with eigenvalue λn − λi . These eigenvalues are still all non-negative, but their order is reversed from those of the
original Laplacian, so that the former smallest has become the new largest.
Now we can calculate the eigenvector corresponding to the smallest eigenvalue of the Laplacian by ﬁnding the leading eigenvector of λn I − L using the
technique described in Section 11.1. We can also ﬁnd the eigenvalue λ1 by
taking the measured value of λn − λ1 , subtracting λn , and reversing the sign.
(Performing these calculations does require that we know the value of λn , so
the complete calculation would be a two-stage process consisting of ﬁrst ﬁnding the largest eigenvalue of L, then using that to ﬁnd the smallest.4 )
In this particular case, it would not in fact be very useful to calculate the
smallest eigenvalue or its associated eigenvector since, as we saw in Section
6.13.2, the smallest eigenvalue of the Laplacian is always zero and the eigenvector is (1, 1, 1, . . .). However, if we can ﬁnd the second-largest eigenvalue
of a matrix we can use the same subtraction method also to ﬁnd the secondsmallest. And the second-smallest eigenvalue of the Laplacian is, as we have
said, deﬁnitely of interest.
We can ﬁnd the second-largest eigenvalue (and the corresponding eigenvector) using the following trick. Let v1 be the normalized eigenvector corresponding to the largest eigenvalue of a matrix A, as found, for instance, by the
power method of Section 11.1. Then we choose any starting vector x as before
4
If we wish to be more sophisticated, we can note that it is sufﬁcient to shift the eigenvalues by
any amount greater than or equal to λn . Anderson and Morley [18] have shown that λn ≤ 2kmax
where kmax is the largest degree in the network, which we can ﬁnd in time O(n), considerably
faster than we can ﬁnd λn itself. Thus a quicker way to ﬁnd the smallest eigenvalue would be to
ﬁnd the largest eigenvalue of 2kmax I − L.

351

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

and deﬁne
y = x − (v1T x)v1 .

(11.8)

This vector has the property that
viT y = viT x − (v1T x)(viT v1 ) = viT x − v1T x δi1

0
if i = 1,
=
T
vi x otherwise,

(11.9)

where vi is again the ith eigenvector of A and δij is the Kronecker delta. In other
words it is equal to x along the direction of every eigenvector of A except the
leading eigenvector, in whose direction it has no component at all. This means
that the expansion of y in terms of the eigenvectors of A, which is given by
y = ∑in=1 ci vi with ci = viT y, has no term in v1 , since c1 = v1T y = 0. Thus
n

y = ∑ ci vi ,

(11.10)

i =2

with the sum starting at i = 2.
Now we use this vector y as the starting vector for repeated multiplication
by A, as before. After multiplying y by A a total of t times, we have
n

y(t) = At y(0) = κ2t ∑ ci
i =2



κi
κ2

t
vi .

(11.11)

The ratio κi /κ2 is less than 1 for all i > 2 (assuming only a single eigenvalue
of value κ2 ) and hence in the limit of large t all terms in the sum disappear
except the ﬁrst so that y(t) tends to a multiple of v2 as t → ∞. Normalizing
this vector, we then have our result for v2 .
This method has the same caveats as the original power method for the
leading eigenvector, as well as one additional one: it is in practice possible
for the vector y, Eq. (11.8), to have a very small component in the direction of
v1 . This can happen as a result of numerical error in the subtraction, or because our value for v1 is not exactly correct. If y does have a component in
the direction of v1 , then although it may start out small it will get magniﬁed
relative to the others when we multiply repeatedly by A and eventually it may
come to dominate y(t), Eq. (11.11), or at least to contribute a sufﬁciently large
term as to make the calculation of v2 inaccurate. To prevent this happening,
we periodically perform a subtraction similar to that of Eq. (11.8), removing
any component in the direction of v1 from y(t), while leaving the components
in all other directions untouched. (The subtraction process is sometimes referred to as Gram–Schmidt orthogonalization—a rather grand name for a simple
352

11.1

|

L EADING EIGENVECTORS AND EIGENVECTOR CENTRALITY

procedure. The repeated application of the process to prevent the growth of
unwanted terms is called reorthogonalization.)
We could in theory extend this method to ﬁnd further eigenvectors and
eigenvalues of our matrix, but in practice the approach does not work well beyond the ﬁrst couple of eigenvectors because of cumulative numerical errors.
Moreover it is also slow because for each additional eigenvector we calculate
we must carry out the entire repeated multiplication process again. In practice,
therefore, if we wish to calculate anything beyond the ﬁrst eigenvector or two,
other methods are used.
11.1.3

E FFICIENT ALGORITHMS FOR COMPUTING ALL EIGENVALUES AND
EIGENVECTORS OF MATRICES

If we wish to calculate all or many of the eigenvalues or eigenvectors of a
matrix A then specialized techniques are needed. The most widely used such
techniques involve ﬁnding an orthogonal matrix Q such that the similarity
transform T = Q T AQ gives either a tridiagonal matrix (if A is symmetric) or a
Hessenberg matrix (if A is asymmetric). If we can ﬁnd such a transformation
and if vi is an eigenvector of A with eigenvalue κi , then, bearing in mind that
for an orthogonal matrix Q−1 = Q T , we have
κi Q T vi = Q T Avi = TQ T vi .

(11.12)

In other words, the vector wi = Q T vi is an eigenvector of T with eigenvalue κi .
Thus if we can ﬁnd the eigenvalues of T and the corresponding eigenvectors,
we automatically have the eigenvalues of A as well, and the eigenvectors of A
are simply vi = Qwi . Luckily there exist efﬁcient numerical methods for ﬁnding the eigenvalues and eigenvectors of tridiagonal and Hessenberg matrices,
such as the QL algorithm [273]. The QL algorithm takes time O(n) to reach an
answer for an n × n tridiagonal matrix and O(n2 ) for a Hessenberg one.
The matrix Q can be found in various ways. For a general symmetric matrix
the Householder algorithm [273] can ﬁnd Q in time O(n3 ). More often, however,
we are concerned with sparse matrices, in which case there are faster methods.
For a symmetric matrix, the Lanczos algorithm [217] can ﬁnd Q in time O(mn),
where m is the number of network edges in an adjacency matrix, or more generally the number of non-zero elements in the matrix. For sparse matrices with
m ∝ n this gives a running time of O(n2 ), considerably better than the Householder method. A similar method, the Arnoldi algorithm [217], can ﬁnd Q for
an asymmetric matrix.
Thus, combining the Lanczos and QL algorithms, we expect to be able to
ﬁnd all eigenvalues and eigenvectors of a sparse symmetric matrix in time
353

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

O(mn), which is as good as the worst-case run time of our direct multiplication method for ﬁnding just the leading eigenvector. (To be fair, the direct
multiplication is much simpler, so its overall run time will typically be better
than that of the combined Lanczos/QL algorithm, although the scaling with
system size is the same.)
While there is certainly much to be gained by learning about the details of
these algorithms, one rarely implements them in practice. Their implementation is tricky (particularly in the asymmetric case), and has besides already
been done in a careful and professional fashion by many software developers.
In practice, therefore, if one wishes to solve eigensystem problems for large
networks, one typically turns to commercial or freely available implementations in professionally written software packages. Examples of such packages
include Matlab, LAPACK, and Mathematica. We will not go into more detail
here about the operation of these algorithms.

11.2

D IVIDING NETWORKS INTO CLUSTERS

We now turn to the topics that will occupy us for much of the rest of the chapter, graph partitioning and community detection.5 Both of these terms refer to the
division of the vertices of a network into groups, clusters, or communities according to the pattern of edges in the network. Most commonly one divides
the vertices so that the groups formed are tightly knit with many edges inside
groups and only a few edges between groups.
Consider Fig. 11.1, for instance, which shows patterns of collaborations between scientists in a university department. Each vertex in this network represents a scientist and links between vertices indicate pairs of scientists who
have coauthored one or more papers together. As we can see from the ﬁgure,
this network contains a number of densely connected clusters of vertices, corresponding to groups of scientists who have worked closely together. Readers
familiar with the organization of university departments will not be surprised
to learn that in general these clusters correspond, at least approximately, to
formal research groups within the department.
But suppose one did not know how university departments operate and
wished to study them. By constructing a network like that in Fig. 11.1 and then
observing its clustered structure, one would be able to deduce the existence of
groups within the larger department and by further investigation could prob5
Community detection is sometimes also called “clustering,” although we largely avoid this
term to prevent confusion with the other, and quite different, use of the word clustering introduced
in Section 7.9.

354

11.2

|

D IVIDING NETWORKS INTO CLUSTERS

Figure 11.1: Network of coauthorships in a university department. The vertices in this
network represent scientists in a university department, and edges links pairs of scientists who have coauthored scientiﬁc papers. The network has clear clusters or “community structure,” presumably reﬂecting divisions of interests and research groups within
the department.

ably quickly work out how the department was organized. Thus the ability
to discover groups or clusters in a network can be a useful tool for revealing structure and organization within networks at a scale larger than that of a
single vertex. In this particular case the network is small enough and sparse
enough that the groups are easily visible by eye. Many of the networks that
have engaged our interest in this book, however, are much larger or denser
networks for which visual inspection is not a useful tool. Finding clusters in
such networks is a task for computers and the algorithms that run on them.

355

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

11.2.1

Partition of a network into
two groups of equal sizes.

356

PARTITIONING AND COMMUNITY DETECTION

There are a number of reasons why one might want to divide a network into
groups or clusters, but they separate into two general classes that lead in turn
to two corresponding types of computer algorithm. We will refer to these two
types as graph partitioning and community detection algorithms. They are distinguished from one another by whether the number and size of the groups is
ﬁxed by the experimenter or whether it is unspeciﬁed.
Graph partitioning is a classic problem in computer science, studied since
the 1960s. It is the problem of dividing the vertices of a network into a given
number of non-overlapping groups of given sizes such that the number of
edges between groups is minimized. The important point here is that the
number and sizes of the groups are ﬁxed. Sometimes the sizes are only ﬁxed
roughly—within a certain range, for instance—but they are ﬁxed nonetheless.
For instance, a simple and prototypical example of a graph partitioning problem is the problem of dividing a network into two groups of equal size, such
that the number of edges between them is minimized.
Graph partitioning problems arise in a variety of circumstances, particularly in computer science, but also in pure and applied mathematics, physics,
and of course in the study of networks themselves. A typical example is the
numerical solution of network processes on a parallel computer.
In the last part of this book (Chapters 16 to 19) we will study processes that
take place on networks, such as diffusion processes or the spread of diseases.
These processes can be modeled mathematically by placing variables on the
vertices of a network and evolving them according to equations that typically
depend on the variables’ current values and the values on neighboring vertices. The solution of such equations is often a laborious computational task,
but it can be sped up by using a parallel computer, a computer with more than
one processor or CPU. Many modern personal computers have two or more
processors and large research organizations sometimes use parallel computers with very many processors. Solutions of network equations can be spread
across several processors by assigning to each processor the task of solving the
equations on a subset of the vertices. For instance, on a two-processor desktop
computer we might give a half of the vertices to each processor.
The catch is that, unless the network consists of totally unconnected components, some vertices on one processor are always going to have neighbors that
are on the other processor and hence the solution of their equations involves
variables whose value is known only to the other processor. To complete the
solution, therefore, those values have to be transmitted from the one processor
to the other at regular intervals throughout the calculation and this is typically

11.2

|

D IVIDING NETWORKS INTO CLUSTERS

a slow process (or at least it’s slow compared to the dazzling speed of most
other computer operations). The time spent sending messages between processors can, in fact, be the primary factor limiting the speed of calculations
on parallel computers, so it is important to minimize interprocessor communication as much as possible. One way that we do this is by minimizing the
number of pairs of neighboring vertices assigned to different processors.
Thus we want to divide up the vertices of the network into different groups,
one for each processor, such that the number of edges between groups is minimized. Most often we want to assign an equal or roughly equal number of
vertices to each processor so as to balance the workload among them. This is
precisely a graph partitioning problem of the type described above.
The other type of cluster ﬁnding problem in networks is the problem we
call community detection. Community detection problems differ from graph
partitioning in that the number and size of the groups into which the network
is divided are not speciﬁed by the experimenter. Instead they are determined
by the network itself: the goal of community detection is to ﬁnd the natural
fault lines along which a network separates. The sizes of the groups are not
merely unspeciﬁed but might in principle vary widely from one group to another. A given network might divide into a few large groups, many small ones,
or a mixture of all different sizes.
The most common use for community detection is as a tool for the analysis
and understanding of network data. We saw in Fig. 11.1 an example of a network for which a knowledge of the group structure might help us understand
the organization of the underlying system. Figure 7.10 on page 221 shows another example of clusters of vertices, in a network of friendships between US
high-school students. In this case the network splits into two clear groups,
which, as described in Section 7.13, are primarily dictated by students’ ethnicity, and this structure and others like it can give us clues about the nature of
the social interactions within the community represented.
Community detection has uses in other types of networks as well. Clusters
of nodes in a web graph for instance might indicate groups of related web
pages. Clusters of nodes in a metabolic network might indicate functional
units within the network.
Community detection is a less well-posed problem than graph partitioning.
Loosely stated, it is the problem of ﬁnding the natural divisions of a network
into groups of vertices such that there are many edges within groups and few
edges between groups. What exactly we mean by “many” or “few,” however,
is debatable, and a wide variety of different deﬁnitions have been proposed,
leading to a correspondingly wide variety of different algorithms for community detection. In this chapter we will focus mainly on the most widely used
357

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

formulation of the problem, the formulation in terms of modularity optimization, but we will mention brieﬂy a number of other approaches at the end of
the chapter.
In summary, the fundamental difference between graph partitioning and
community detection is that the number and size of the groups into which a
network is divided is speciﬁed in graph partitioning but unspeciﬁed in community detection. However, there is also a difference between the goals of the
two types of calculations. Graph partitioning is typically performed as a way
of dividing up a network into smaller more manageable pieces, for example to
perform numerical calculations. Community detection is more often used as a
tool for understanding the structure of a network, for shedding light on largescale patterns of connection that may not be easily visible in the raw network
topology.
Notice also that in graph partitioning calculations the goal is usually to
ﬁnd the best division of a network, subject to certain conditions, regardless
of whether any good division exists. If the performance of a calculation on
a parallel computer, for example, requires us to divide a network into pieces,
then we had better divide it up. If there are no good divisions, then we must
make do with the least bad one. With community detection, on the other hand,
where the goal is normally to understand the structure of the network, there is
no need to divide the network if no good division exists. Indeed if a network
has no good divisions then that in itself may be a useful piece of information,
and it would be perfectly reasonable for a community detection algorithm only
to divide up networks when good divisions exist and to leave them undivided
the rest of the time.

11.3

G RAPH PARTITIONING

In the next few sections we consider the graph partitioning problem and look
at two well-known methods for graph partitioning. The ﬁrst, the Kernighan–
Lin algorithm, is not based on matrix methods (and therefore doesn’t strictly
belong in this chapter) but it provides a simple introduction to the partitioning
problem and is worth spending a little time on. In Section 11.5 we look at
a more sophisticated partitioning method based on the spectral properties of
the graph Laplacian. This spectral partitioning method both is important in
its own right and will also provide a basis for our discussion of community
detection later in the chapter.
First, however, we address an important preliminary question: why does
one need fancy partitioning algorithms at all? Partitioning is an easy problem
to state, so is it not just as easy to solve?
358

11.3

11.3.1

|

G RAPH PARTITIONING

W HY PARTITIONING IS HARD

The simplest graph partitioning problem is the division of a network into just
two parts. Division into two parts is sometimes called graph bisection. Most of
the algorithms we consider in this chapter are in fact algorithms for bisecting
networks rather than for dividing them into arbitrary numbers of parts. This
may at ﬁrst appear to be a drawback, but in practice it is not, since if we can
divide a network into two parts, then we can divide it into more than two
by further dividing one or both of those parts. This repeated bisection is the
commonest approach to the partitioning of networks into arbitrary numbers
of parts.
Formally the graph bisection problem is the problem of dividing the vertices of a network into two non-overlapping groups of given sizes such that the
number of edges running between vertices in different groups is minimized.
The number of edges between groups is called the cut size.6
Simple though it is to describe, this problem is not easy to solve. One might
imagine that one could bisect a network simply by looking through all possible
divisions of the network into two parts of the required sizes and choosing the
one with the smallest cut size. For all but the smallest of networks, however,
this so-called exhaustive search turns out to be prohibitively costly in terms of
computer time.
The number of ways of dividing a network of n vertices into two groups
of n1 and n2 vertices respectively
√ is n!/(n1 ! n2 !). Approximating the factorials
using Stirling’s formula n! ≃ 2πn(n/e)n and making use of the fact that
n1 + n2 = n, we get
√
nn+1/2
2πn(n/e)n
n!
√
≃ √
=
.
(11.13)
n1 ! n2 !
2πn1 (n1 /e)n1 2πn2 (n2 /e)n2
n1n1 +1/2 n2n2 +1/2
Thus, for instance, if we want to divide a network into two parts of equal
size 12 n the number of different ways to do it is roughly
nn+1/2
2n +1
√ .
=
(n/2)n+1
n

(11.14)

So the amount of time required to look through all of these divisions will go
up roughly exponentially with the size of the network. Unfortunately, the exponential is a very rapidly growing function of its argument, which means the
6
The problem is somewhat similar to the minimum cut problem of Section 6.12, but we are
now searching for the minimum cut over all possible bisections of a network, rather than just
between a given pair of vertices.

359

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

partitioning task quickly leaves the realm of the possible at quite moderate values of n. Values up to about n = 30 are feasible with current computers, but
go much beyond that and the calculation becomes intractable.
One might wonder whether it is possible to ﬁnd a way around this problem. After all, brute-force enumeration of all possible divisions of a network
is not a very imaginative way to solve the partitioning problem. Perhaps one
could ﬁnd a way to limit one’s search to only those divisions of the network
that have a chance of being the best one? Unfortunately, there are some fundamental results in computer science that tell us that no such algorithm will ever
be able to ﬁnd the best division of the network in all cases. Either an algorithm
can be clever and run quickly, but will fail to ﬁnd the optimal answer in some
(and perhaps most) cases, or it always ﬁnds the optimal answer but takes an
impractical length of time to do it. These are the only options.7
This is not to say, however, that clever algorithms for partitioning networks
do not exist or that they don’t give useful answers. Even algorithms that fail
to ﬁnd the very best division of a network may still ﬁnd a pretty good one,
and for many practical purposes pretty good is good enough. The goal of
essentially all practical partitioning algorithms is just to ﬁnd a “pretty good”
division in this sense. Algorithms that ﬁnd approximate, but acceptable, solutions to problems in this way are called heuristic algorithms or just heuristics.
All the algorithms for graph partitioning discussed in this chapter are heuristic
algorithms.

11.4

T HE K ERNIGHAN –L IN ALGORITHM

The Kernighan–Lin algorithm, proposed by Brian Kernighan8 and Shen Lin in
1970 [171], is one of the simplest and best known heuristic algorithms for the
graph bisection problem. The algorithm is illustrated in Fig. 11.2.
We start by dividing the vertices of our network into two groups of the required sizes in any way we like. For instance, we could divide the vertices randomly. Then, for each pair (i, j) of vertices such that i lies in one of the groups
7
Technically, this statement has not actually been proved. Its truth hinges on the assumption
that two fundamental classes of computational problem, called P and NP, are not the same. Although this assumption is universally believed to be true—the world would pretty much fall apart
if it weren’t—no one has yet proved it, nor even has any idea about where to start. Readers interested in the fascinating branch of theoretical computer science that deals with problems of this
kind are encouraged to look, for example, at the book by Moore and Mertens [227].
8

Some readers may be familiar with Kernighan’s name. He was one of the authors of
the original book describing the C programming language [172]. “Kernighan” is pronounced
“Kernihan”—the “g” is silent.

360

11.4

|

T HE K ERNIGHAN –L IN ALGORITHM

(a)

(b)

Figure 11.2: The Kernighan–Lin algorithm. (a) The Kernighan–Lin algorithm starts with any division of the vertices
of a network into two groups (shaded) and then searches for pairs of vertices, such as the pair highlighted here, whose
interchange would reduce the cut size between the groups. (b) The same network after interchange of the two vertices.

and j in the other, we calculate how much the cut size between the groups
would change if we were to interchange i and j, so that each was placed in the
other group. Among all pairs (i, j) we ﬁnd the pair that reduces the cut size by
the largest amount or, if no pair reduces it, we ﬁnd the pair that increases it by
the smallest amount. Then we swap that pair of vertices. Clearly this process
preserves the sizes of the two groups of vertices, since one vertex leaves each
group and another joins. Thus the algorithm respects the requirement that the
groups take speciﬁed sizes.
The process is then repeated, but with the important restriction that each
vertex in the network can only be moved once. Once a vertex has been swapped
with another it is not swapped again (at least not in the current round of the
algorithm—see below). Thus, on the second step of the algorithm we consider
all pairs of vertices excluding the two vertices swapped on the ﬁrst step.
And so the algorithm proceeds, swapping on each step that pair that most
decreases, or least increases, the number of edges between our two groups,
until eventually there are no pairs left to be swapped, at which point we stop.
(If the sizes of the groups are unequal then there will be vertices in the larger
group that never get swapped, equal in number to the difference between the
sizes of the groups.)
When all swaps have been completed, we go back through every state
that the network passed through during the swapping procedure and choose
among them the state in which the cut size takes its smallest value.9
9

One might imagine that an equivalent procedure would be to go on swapping vertex pairs

361

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

Finally, this entire process is performed repeatedly, starting each time with
the best division of the network found on the last time around and continuing
until no improvement in the cut size occurs. The division with the best cut size
on the last round is the ﬁnal division returned by the algorithm.
Once we can divide a network into two pieces of given size then, as we
have said, we can divide into more than two simply by repeating the process.
For instance, if we want to divide a network into three pieces of equal size,
we would ﬁrst divide into two pieces, one twice the size of the other, and then
further divide the larger one into two equally sized halves. (Note, however,
that even if the algorithm were able to ﬁnd the optimal division of the network
in each of these two steps, there would be no guarantee that we would end up
with the optimal division of the network into three equal parts. Nonetheless,
we do typically ﬁnd a reasonably good division, which, as we have said, is
often good enough. This point is discussed further in Section 11.9.)
Note that if we choose the initial assignment of vertices to groups randomly, then the Kernighan–Lin algorithm may not give the same answer if it
is run twice on the same network. Two different random starting states could
(though needn’t necessarily) result in different divisions of the network. For
this reason, people sometimes run the algorithm more than once to see if the
results vary. If they do vary then among the divisions of the network returned
on the different runs it makes sense to take the one with the smallest cut size.
As an example of the use of the Kernighan–Lin algorithm, consider Fig. 11.3,
which shows an application of the algorithm to a mesh, a two-dimensional network of the type often used in parallel ﬁnite-element computations. Suppose
we want to divide this network into two parts of equal size. Looking at the
complete network in Fig. 11.3a there is no obvious division—there is no easy
cut or bottleneck where the network separates naturally—but we must do the
best we can. Figure 11.3b shows the best division found by the Kernighan–Lin
algorithm, which involves cutting 40 edges in the network. Though it might
not be the best possible division of the network, this is certainly good enough
for many practical purposes.
The primary disadvantage of the Kernighan–Lin algorithm is that it is quite
slow. The number of swaps performed during one round of the algorithm is
until no swap can be found that decreases the cut size. This, however, turns out to be wrong. It is
perfectly possible for the cut size to decrease for a few steps of the algorithm, then increase, then
decrease again. If we halt the algorithm the ﬁrst time we see the cut size increasing, we run the risk
of missing a later state with smaller cut size. Thus the correct algorithm is the one described here,
with two separate processes, one of vertex swapping, and one of checking the states so generated
to see which is optimal.

362

11.4

(a)

|

T HE K ERNIGHAN –L IN ALGORITHM

(b)

(c)

Figure 11.3: Graph partitioning applied to a small mesh network. (a) A mesh network of 547 vertices of the kind
commonly used in ﬁnite element analysis. (b) The edges removed indicate the best division of the network into parts of
273 and 274 vertices found by the Kernighan–Lin algorithm. (c) The best division found by spectral partitioning. The
network is from Bern et al. [35].

equal to the smaller of the sizes of the two groups, which lies between zero
and 12 n in a network of n vertices. Thus there are O(n) swaps in the worst case.
For each swap we have to examine all pairs of vertices in different groups, of
which there are, in the worst case, 12 n × 12 n = 14 n2 = O(n2 ). And for each of
these we need to determine the change in the cut size if the pair is swapped.
When a vertex i moves from one group to the other any edges connecting it
to vertices in its current group become edges between groups after the swap.
such edges. Similarly, any edges that i has
Let us suppose that there are ksame
i
, become withinto vertices in the other group, of which there are say kother
i
group edges after the swap, but with one exception. If i is being swapped
with vertex j and there is an edge between i and j, then that edge lies between
groups before the swap and still lies between groups after the swap. Thus the
− ksame
− Aij . A similar
change in the cut size due to the movement of i is kother
i
i
expression applies for vertex j also and the total change in cut size as a result
of the swap is
− ksame
+ kother
− ksame
− 2Aij .
(11.15)
Δ = kother
i
i
j
j
For a network stored in adjacency list form, the evaluation of this expression
363

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

involves running through all the neighbors of i and j in turn, and hence takes
time of order the average degree in the network, or O(m/n), where m is, as
usual, the total number of edges in the network.
Thus the total time for one round of the algorithm is O(n × n2 × m/n) =
O(mn2 ), which is O(n3 ) on a sparse network in which m ∝ n or O(n4 ) on
a dense network. This in itself would already be quite bad, but we are not
yet done. This time must be multiplied by the number of rounds the algorithm performs before the cut size stops decreasing. It is not well understood
how the number of rounds required varies with network size. In typical applications the number is small, maybe ﬁve or ten for networks of up to a few
thousand vertices, and larger networks are currently not possible because of
the demands of the algorithm, so in practice the number of rounds is always
small. Still, it seems quite unlikely that the number of rounds would actually increase as network size grows, and even if it remains constant the time
complexity of the algorithm will still be O(mn2 ), which is relatively slow.
We can improve the running time of the algorithm a little by a couple of
and
tricks. If we initially calculate and store the number of neighbors, ksame
i
,
that
each
vertex
has
within
and
between
groups
and
update
it
every
kother
i
time a vertex is moved, then we save ourselves the time taken to recalculate
these quantities on each step of the algorithm. And if we store our network
in adjacency matrix form then we can tell whether two vertices are connected
(and hence evaluate Aij ) in time O(1). Together these two changes allow us to
calculate Δ above in time O(1) and improve the overall running time to O(n3 ).
For a sparse graph this is the same as O(mn2 ), but for a dense one it gives us
an extra factor of n.
Overall, however, the algorithm is quite slow. Even with O(n3 ) performance the algorithm is suitable only for networks up to a few hundreds or
thousands of vertices, but not more.

11.5

S PECTRAL PARTITIONING

So are there faster methods for partitioning networks? There are indeed, although they are typically more complex than the simple Kernighan–Lin algorithm, and may be correspondingly more laborious to implement. In this
section we discuss one of the most widely used methods, the spectral partitioning method of Fiedler [118, 271], which makes use of the matrix properties of
the graph Laplacian. We describe the spectral partitioning method as applied
to the graph bisection problem, the problem of dividing a graph into two parts
of speciﬁed sizes. As discussed in the previous section, division into more than
two groups is typically achieved by repeated bisection, dividing and subdivid364

11.5

|

S PECTRAL PARTITIONING

ing the network to give groups of the desired number and size.
Consider a network of n vertices and m edges and a division of that network into two groups, which we will call group 1 and group 2. We can write
the cut size for the division, i.e., the number of edges running between the two
groups, as
(11.16)
R = 12 ∑ Aij ,
i, j in
different
groups

where the factor of 12 compensates for our counting each edge twice in the sum.
Let us deﬁne a set of quantities si , one for each vertex i, which represent the
division of the network thus:

+1
if vertex i belongs to group 1,
(11.17)
si =
−1
if vertex i belongs to group 2.
Then


1
2 (1 − s i s j ) =

1
0

if i and j are in different groups,
if i and j are in the same group,

(11.18)

which allows us to rewrite Eq. (11.16) as
R = 14 ∑ Aij (1 − si s j ),

(11.19)

ij

with the sum now over all values of i and j. The ﬁrst term in the sum is

∑ Aij = ∑ ki = ∑ ki s2i = ∑ ki δij si s j ,
ij

i

i

(11.20)

ij

where k i is the degree of vertex i as usual, δij is the Kronecker delta, and we
have made use of the fact that ∑ j Aij = k i (see Eq. (6.19)) and s2i = 1 (since
si = ±1). Substituting back into Eq. (11.19) we then ﬁnd that
R = 14 ∑(k i δij − Aij )si s j = 14 ∑ Lij si s j ,
ij

(11.21)

ij

where Lij = k i δij − Aij is the ijth element of the graph Laplacian matrix—see
Eq. (6.44).
Equation (11.21) can be written in matrix form as
R = 14 s T Ls,

(11.22)

where s is the vector with elements si . This expression gives us a matrix formulation of the graph partitioning problem. The matrix L speciﬁes the structure
365

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

of our network, the vector s deﬁnes a division of that network into groups, and
our goal is to ﬁnd the vector s that minimizes the cut size (11.22) for given L.
You will probably not be surprised to learn that, in general, this minimization problem is not an easy one. If it were easy then we would have a corresponding easy way to solve the partitioning problem and, as discussed in
Section 11.3.1, there are good reasons to believe that partitioning has no easy
solutions.
What makes our matrix version of the problem hard in practice is that the
si cannot take just any values. They are restricted to the special values ±1. If
they were allowed to take any real values the problem would be much easier;
we could just differentiate to the ﬁnd the optimum.
This suggests a possible approximate approach to the minimization problem. Suppose we indeed allow the si to take any values (subject to a couple of
basic constraints discussed below) and then ﬁnd the values that minimize R.
These values will only be approximately the correct ones, since they probably
won’t be ±1, but they may nonetheless be good enough to give us a handle on
the optimal partitioning. This idea leads us to the so-called relaxation method,
which is one of the standard methods for the approximate solution of vector
optimization problems such as this one. In the present context it works as follows.
The allowed values of the si are actually subject to two constraints. First, as
we have said, each individual one is allowed to take only the values ±1. If we
regard s as a vector in a Euclidean space then this constraint means that the
vector always points to one of the 2n corners of an n-dimensional hypercube
√
centered on the origin, and always has the same length, which is n. Let
us relax the constraint on the vector’s direction, so that it can point in any
direction in its n-dimensional space. We will however still keep its length the
same. (It would not make sense to allow the length to vary. If we did that then
the minimization of R would have the obvious trivial solution s = 0, which
would tell us nothing.) So s will be allowed to take any value, but subject to
√
the constraint that |s| = n, or equivalently
The relaxation of the constraint allows s to point to
any position on a hypersphere circumscribing the
original hypercube, rather
than just the corners of the
hypercube.

366

∑ s2i = n.

(11.23)

i

Another way of putting this is that s can now point to any location on the sur√
face of a hypersphere of radius n in our n-dimensional Euclidean space. The
hypersphere includes the original allowed values at the corners of the hypercube, but also includes other points in between.
The second constraint on the si is that the numbers of them that are equal
to +1 and −1 respectively must equal the desired sizes of the two groups. If

11.5

|

S PECTRAL PARTITIONING

those two sizes are n1 and n2 , this second constraint can be written as

∑ s i = n1 − n2 .

(11.24)

1 T s = n1 − n2 ,

(11.25)

i

or in vector notation
where 1 is the vector (1, 1, 1, . . .) whose elements are all 1. We keep this second
constraint unchanged in our relaxed calculations, so that our partitioning problem, in its relaxed form, is a problem of minimizing the cut size, Eq. (11.22),
subject to the two constraints (11.23) and (11.24).
This problem is now just a standard piece of algebra. We differentiate with
respect to the elements si , enforcing the constraints using two Lagrange multipliers, which we denote λ and 2μ (the extra 2 being merely for notational
convenience):

%
%
$
$
∂
2
L jk s j sk + λ n − ∑ s j + 2μ (n1 − n2 ) − ∑ s j
= 0.
(11.26)
∂si ∑
j
j
jk
Performing the derivatives, we then ﬁnd that

∑ Lij s j = λsi + μ,

(11.27)

Ls = λs + μ1.

(11.28)

j

or, in matrix notation
We can calculate the value of μ by recalling that 1 is an eigenvector of the
Laplacian with eigenvalue zero so that L · 1 = 0 (see Section 6.13.2). Multiplying (11.28) on the left by 1 T and making use of Eq. (11.25), we then ﬁnd that
λ(n1 − n2 ) + μn = 0, or
n1 − n2
μ=−
λ.
(11.29)
n
If we deﬁne the new vector
x = s+

μ
n1 − n2
1 = s−
1,
λ
n

then Eq. (11.28) tells us that
$
μ %
Lx = L s + 1 = Ls = λs + μ1 = λx,
λ

(11.30)

(11.31)

where we have used L · 1 = 0 again.
In other words, x is an eigenvector of the Laplacian with eigenvalue λ.
We are still free to choose which eigenvector it is—any eigenvector will satisfy
367

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

Eq. (11.31)—and clearly we should choose the one that gives the smallest value
of the cut size R. Notice, however, that
1T x = 1T s −

μ T
n1 − n2
1 1 = ( n1 − n2 ) −
n = 0,
λ
n

(11.32)

where we have used Eq. (11.25). Thus x is orthogonal to 1, which means that,
while it should be an eigenvector of L, it cannot be the eigenvector (1, 1, 1, . . .)
that has eigenvalue zero.
So which eigenvector should we choose? To answer this question we note
that
(11.33)
R = 14 s T Ls = 14 x T Lx = 14 λxT x.
But from Eq. (11.30) we have
 μ2
μ T
s 1 + 1T s + 2 1T 1
λ
λ
n1 − n2
( n1 − n2 )2
n
= n−2
( n1 − n2 ) +
n
n
n1 n2
,
=4
n

xT x = sT s +

(11.34)

and hence

n1 n2
λ.
(11.35)
n
Thus the cut size is proportional to the eigenvalue λ. Given that our goal is to
minimize R, this means we should choose x to be the eigenvector corresponding to the smallest allowed eigenvalue of the Laplacian. All the eigenvalues
of the Laplacian are non-negative (see Section 6.13.2). The smallest one is the
zero eigenvalue that corresponds to the eigenvector (1, 1, 1, . . .) but we have
already ruled this one out—x has to be orthogonal to this lowest eigenvector.
Thus the best thing we can do is choose x proportional to the eigenvector v2
corresponding to the second lowest eigenvalue λ2 , with its normalization ﬁxed
by Eq. (11.34).
Finally, we recover the corresponding value of s from Eq. (11.30) thus:
R=

s = x+

n1 − n2
1,
n

or equivalently

(11.36)

n1 − n2
.
(11.37)
n
This gives us the optimal relaxed value of s.
As we have said, however, the real vector s is subject to the additional constraints that its elements take the values ±1 and moreover that exactly n1 of
si = xi +

368

11.5

|

S PECTRAL PARTITIONING

them are +1 and the other n2 are −1. Typically these constraints will prevent s
from taking exactly the value given by Eq. (11.37). Let us, however, do the best
we can and choose s to be as close as possible to our ideal value subject to its
constraints, which we do by making the product
$
$
n1 − n2 %
n1 − n2 %
1 = ∑ si xi +
(11.38)
sT x +
n
n
i
as large as possible. The maximum of this expression is achieved by assigning
si = +1 for the vertices with the largest (i.e., most positive) values of xi + (n1 −
n2 )/n and si = −1 for the remainder.
Note however that the most positive values of xi + (n1 − n2 )/n are also the
most positive values of xi , which are in turn also the most positive elements
of the eigenvector v2 (to which, as we have said, x is proportional). So after
this moderately lengthy derivation we actually arrive at a very simple ﬁnal
prescription for dividing our network. We calculate the eigenvector v2 , which
has n elements, one for each vertex in the network, and place the n1 vertices
with the most positive elements in group 1 and the rest in group 2.
There is one further small subtlety. It is arbitrary which group we call
group 1 and which we call group 2, and hence which one we assign to the more
positive elements of the eigenvector and which to the more negative. Thus, if
the sizes of the two groups are different there are two different ways of making
the split—either the larger or the smaller group could correspond to the more
positive values. (In the geometrical language of our vectors, this is equivalent
to saying our eigenvector calculation might ﬁnd the vector x that we actually
want, or minus that vector—both are good eigenvectors of the Laplacian.) To
get around this problem, we simply compute the cut size for both splits of the
network and choose the one with the smaller value.
Thus our ﬁnal algorithm is as follows:
1. Calculate the eigenvector v2 corresponding to the second smallest eigenvalue λ2 of the graph Laplacian.
2. Sort the elements of the eigenvector in order from largest to smallest.
3. Put the vertices corresponding to the n1 largest elements in group 1, the
rest in group 2, and calculate the cut size.
4. Then put the vertices corresponding to the n1 smallest elements in group
1, the rest in group 2, and recalculate the cut size.
5. Between these two divisions of the network, choose the one that gives
the smaller cut size.
In Fig. 11.3c we show the result of the application of this method to the
same mesh network that we studied in conjunction with the Kernighan–Lin
algorithm. In this case the spectral method ﬁnds a division of the network
369

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

very similar to that given by the Kernighan–Lin algorithm, although the cut
size is slightly worse—the spectral method cuts 46 edges in this case, where the
Kernighan–Lin algorithm cut only 40. This is typical of the spectral method. It
tends to ﬁnd divisions of a network that have the right general shape, but are
not perhaps quite as good as those returned by other methods.
An advantage of the spectral approach, however, is its speed. The timeconsuming part of the algorithm is the calculation of the eigenvector v2 , which
takes time O(mn) using either the orthogonalization method or the Lanczos
method (see Section 11.1.2), or O(n2 ) on a sparse network having m ∝ n. This
is one factor of n better than the O(n3 ) of the Kernighan–Lin algorithm, which
makes the algorithm feasible for much larger networks. Spectral partitioning
can be extended to networks of hundreds of thousands of vertices, where the
Kernighan–Lin algorithm is restricted to networks of a few thousand vertices
at most.
The second eigenvalue of the Laplacian has come up previously in this
book in Section 6.13.3, where we saw that it is non-zero if and only if a network
is connected. The second eigenvalue is for this reason sometimes called the algebraic connectivity of a network. In this section we have seen it again in another
context, that of partitioning. What happens if a network is not connected and
the second eigenvalue is zero? In that case, the two lowest eigenvalues are the
same, and the corresponding eigenvectors are indeterminate—any mixture of
two eigenvectors with the same eigenvalue is also an eigenvector. This is not
however a serious problem. If the network is not connected, having more than
one component, then usually we are interested either in partitioning one particular component, such as the largest component, or in partitioning all components individually, and so we just treat the components separately as connected networks according to the algorithm above.
The algebraic connectivity itself appears in our expression for the cut size,
Eq. (11.35), and indeed is a direct measure of the cut size, being directly proportional to it, at least within the “relaxed” approximation used to derive the
equation. Thus the algebraic connectivity is a measure of how easily a network
can be divided. It is small for networks that have good cuts and large for those
that do not. This in a sense is a generalization of our earlier result that the
algebraic connectivity is non-zero for connected networks and zero for unconnected ones—we now see that how non-zero it is is a measure of how connected
the network is.

370

11.6

11.6

|

C OMMUNITY DETECTION

C OMMUNITY DETECTION

In the last few sections we looked at the problem of graph partitioning, the division of network vertices into groups of given number and size, so as to minimize the number of edges running between groups. A complementary problem, introduced in Section 11.2.1, is that of community detection, the search
for the naturally occurring groups in a network regardless of their number or
size, which is used primarily as a tool for discovering and understanding the
large-scale structure of networks.
The basic goal of community detection is similar to that of graph partitioning: we want to separate the network into groups of vertices that have few connections between them. The important difference is that the number or size of
the groups is not ﬁxed. Let us focus to begin with on a very simple example of
a community detection problem, probably the simplest, which is analogous to
the graph bisection problems we examined in previous sections. We will consider the problem of dividing a network into just two non-overlapping groups
or communities, as previously, but now without any constraint on the sizes of
the groups, other than that the sum of the sizes should equal the size n of the
whole network. Thus, in this simple version of the problem, the number of
groups is still speciﬁed but their sizes are not, and we wish to ﬁnd the “natural” division of the network into two groups, the fault line (if any) along which
the network inherently divides, although we haven’t yet said precisely what
we mean by that, so that the question we’re asking is not yet well deﬁned.
Our ﬁrst guess at how to tackle this problem might be simply to ﬁnd the
division with minimum cut size, as in the corresponding graph partitioning
problem, but without any constraint on the sizes of our groups. However, a
moment’s reﬂection reveals that this will not work. If we divide a network
into two groups with any number of vertices allowed in the groups then the
optimum division is simply to put all the vertices in one of the groups and none
of them in the other. This trivial division insures that the cut size between the
two groups will be zero—there will be no edges between groups because one
of the groups contains no vertices! As an answer to our community detection
problem, however, it is clearly not useful.
One way to do better would be to impose loose constraints of some kind
on the sizes of the groups. That is, we could allow the sizes of the groups
to vary, but not too much. An example of this type of approach is ratio cut
partitioning in which, instead of minimizing the standard cut size R, we instead
minimize the ratio R/(n1 n2 ), where n1 and n2 are the sizes of the two groups.
The denominator n1 n2 has its largest value, and hence reduces the ratio by the
largest amount, when n1 and n2 are equal n1 = n2 = 12 n. For unequal group
371

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

sizes the denominator becomes smaller the greater the inequality, and diverges
when either group size becomes zero. This effectively eliminates solutions in
which all vertices are placed in the same group, since such solutions never
give the minimum value of the ratio, and biases the division towards those
solutions in which the groups are of roughly equal size.
As a tool for discovering the natural divisions in a network, however, the
ratio cut is not ideal. In particular, although it allows group sizes to vary it
is still biased towards a particular choice, that of equally sized groups. More
importantly, there is no principled rationale behind its deﬁnition. It works
reasonably well in some circumstances, but there’s no fundamental reason to
believe it will give sensible answers or that some other approach will not give
better ones.
An alternative strategy is to focus on a different measure of the quality of a
division other than the simple cut size or its variants. It has been argued that
the cut size is not itself a good measure because a good division of a network
into communities is not merely one in which there are few edges between communities. On the contrary, the argument goes, a good division is one where
there are fewer than expected such edges. If we ﬁnd a division of a network that
has few edges between its groups, but nonetheless the number of such edges
is about what we would have expected were edges simply placed at random
in the network, then most people would say we haven’t found anything signiﬁcant. It is not the total cut size that matters, but how that cut size compares
with what we expect to see.
In fact, in the conventional development of this idea one considers not the
number of edges between groups but the number within groups. The two
approaches are equivalent, however, since every edge that lies within a group
necessarily does not lie between groups, so one can calculate one number from
the other given the total number of edges in the network as whole. We will
follow convention here and base our calculations on the numbers of withingroup edges.
Our goal therefore will be to ﬁnd a measure that quantiﬁes how many
edges lie within groups in our network relative to the number of such edges
expected on the basis of chance. This, however, is an idea we have encountered before. In Section 7.13.1 we considered the phenomenon of assortative
mixing in networks, in which vertices with similar characteristics tend to be
connected by edges. There we introduced the measure of assortative mixing
known as modularity, which has a high value when many more edges in a network fall between vertices of the same type than one would expect by chance.
This is precisely the type of measure we need to solve our current community
detection problem. If we consider the vertices in our two groups to be vertices
372

11.7

|

S IMPLE MODULARITY MAXIMIZATION

of two types then good divisions of the network into communities are precisely
those that have high values of the corresponding modularity.
Thus one way to detect communities in networks is to look for the divisions
that have the highest modularity scores and in fact this is the most commonly
used method for community detection. Like graph partitioning, modularity
maximization is a hard problem (see Section 11.3.1). It is believed that, as with
partitioning, the only algorithms capable of always ﬁnding the division with
maximum modularity take exponentially long to run and hence are useless
for all but the smallest of networks [54]. Instead, therefore, we turn again to
heuristic algorithms, algorithms that attempt to maximize the modularity in
an intelligent way that gives reasonably good results most of the time.

11.7

S IMPLE MODULARITY MAXIMIZATION

One straightforward algorithm for maximizing modularity is the analog of
the Kernighan–Lin algorithm [245]. This algorithm divides networks into two
communities starting from some initial division, such as a random division
into equally sized groups. The algorithm then considers each vertex in the network in turn and calculates how much the modularity would change if that
vertex were moved to the other group. It then chooses among the vertices the
one whose movement would most increase, or least decrease, the modularity
and moves it. Then it repeats the process, but with the important constraint
that a vertex once moved cannot be moved again, at least on this round of the
algorithm.
And so the algorithm proceeds, repeatedly moving the vertices that most
increase or least decrease the modularity. Notice that in this algorithm we
are not swapping pairs as we did in the Kernighan–Lin algorithm. In that
algorithm we were required to keep the sizes of the groups constant, so for
every vertex removed from a group we also had to add one. Now we no longer
have such a constraint and so we can move single vertices on each step.
When all vertices have been moved exactly once, we go back over the states
through which the network has passed and select the one with the highest
modularity. We then use that state as the starting condition for another round
of the same algorithm, and we keep repeating the whole process until the modularity no longer improves.
Figure 11.4 shows an example application of this algorithm to the “karate
club” network of Zachary, which we encountered previously in Chapter 1 (see
Fig. 1.2 on page 6). This network represents the pattern of friendships between
members of a karate club at a North American university, as determined by
direct observation of the club’s members by the experimenter over a period
373

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

Figure 11.4: Modularity maximization applied to the karate club network. When
we apply our vertex-moving modularity maximization algorithm to the karate club
network, the best division found is the one indicated here by the two shaded regions,
which split the network into two groups of 17 vertices each. This division is very nearly
the same as the actual split of the network in real life (open and solid circles), following
the dispute among the club’s members. Just one vertex is classiﬁed incorrectly.

of about two years. The network is interesting because during the period of
observation a dispute arose among the members of the club over whether to
raise the club’s fees and as a result the club eventually split into two parts, of
18 and 16 members respectively, the latter departing to form their own club.
The colors of the vertices in Fig. 11.4 denote the members of the two factions,
while the shaded regions show the communities identiﬁed in the network by
our vertex-moving algorithm. As we can see from the ﬁgure, the communities
identiﬁed correspond almost perfectly to the known groups in the network.
Just one vertex on the border between the groups is incorrectly assigned. Thus
in this case our algorithm appears to have picked out structure of genuine
sociological interest from an analysis of network data alone. It is precisely for
results of this kind, that shed light on potentially important structural features
of networks, that community detection methods are of interest.
The vertex moving algorithm is also quite efﬁcient. At each step of the algorithm we have to evaluate the modularity change due to the movement of
each of O(n) vertices, and each such evaluation, like the corresponding ones
for the Kernighan–Lin algorithm, can be achieved in time O(m/n) if the network is stored as an adjacency list. Thus each step takes time O(m) and there
are n steps in one complete round of the algorithm for a total time of O(mn).
This is considerably better than the O(mn2 ) of the Kernighan–Lin algorithm,
374

11.8

|

S PECTRAL MODULARITY MAXIMIZATION

and the algorithm is in fact one of the better of the many proposed algorithms
for modularity maximization.10 The fundamental reason for the algorithm’s
speed is that when moving single vertices we only have to consider O(n) possible moves at each step, by contrast with the O(n2 ) possible swaps of vertex
pairs that must be consider in a step of the Kernighan–Lin algorithm.

11.8

S PECTRAL MODULARITY MAXIMIZATION

Having seen in the previous section an algorithm for modularity maximization analogous to the Kernighan–Lin algorithm, it is natural to ask whether
there also exists an analog for community detection of the spectral graph partitioning algorithm of Section 11.5. The answer is yes, there is indeed such an
algorithm, as we now describe.
In Section 7.13.1 we wrote an expression for the modularity of a division of
a network as follows (Eq. (7.69)):
Q=

ki k j
1
Aij −
∑
2m ij
2m

δ ( ci , c j ) =

1
Bij δ(ci , c j ),
2m ∑
ij

(11.39)

where ci is the group or community to which vertex i belongs, δ(m, n) is the
Kronecker delta, and
ki k j
.
(11.40)
Bij = Aij −
2m
Note that Bij has the property
ki

ki

∑ Bij = ∑ Aij − 2m ∑ k j = ki − 2m 2m = 0,
j

j

(11.41)

j

and similarly for sums over i. (We have made use of Eq. (6.20) in the second
equality.) This property will be important shortly.
Let us again consider the division of a network into just two parts (we will
consider the more general case later) and again represent such a division by
the quantities

si =

+1
−1

if vertex i belongs to group 1,
if vertex i belongs to group 2.

(11.42)

10
If the network is stored in adjacency matrix form then the total run time can be improved
further to O(n2 ), although for the common case of a sparse network this makes relatively little
difference, and the adjacency matrix is costly in terms of memory space.

375

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

We note that the quantity 12 (si s j + 1) is 1 if i and j are in the same group and
zero otherwise, so that
(11.43)
δ(ci , c j ) = 12 (si s j + 1).
Substituting this expression into Eq. (11.39), we ﬁnd
Q=

1
1
Bij (si s j + 1) =
Bij si s j ,
∑
4m ij
4m ∑
ij

(11.44)

where we have used Eq. (11.41). In matrix terms we can write this as
1 T
s Bs,
(11.45)
4m
where s is, as before, the vector with elements si , and B is the n × n matrix with
elements Bij , also called the modularity matrix.
Equation (11.45) is similar in form to our expression, Eq. (11.22), for the cut
size of a network in terms of the graph Laplacian. By exploiting this similarity we can derive a spectral algorithm for community detection that is closely
analogous to the spectral partitioning method of Section 11.5.
We wish to ﬁnd the division of a given network that maximizes the modularity Q. That is, we wish to ﬁnd the value of s that maximizes Eq. (11.45)
for a given modularity matrix B. The elements of s are constrained to take
values ±1, so that the vector always points to one of the corners of an ndimensional hypercube, but otherwise there are no constraints on the problem. In particular, the number of elements with value +1 or −1 is not ﬁxed
as it was in the corresponding graph partitioning problem—the sizes of our
communities are unconstrained.
As before, this optimization problem is a hard one, but it can be tackled
approximately—and effectively—by a relaxation method. We relax the constraint that s must point to a corner of the hypercube and allow it to point in
any direction, though keeping its length the same, meaning that it can take any
real value subject only to the constraint that
Q=

s T s = ∑ s2i = n.

(11.46)

i

The maximization is now a straightforward problem. We maximize Eq. (11.44)
by differentiating, imposing the constraint with a single Lagrange multiplier β:

%
$
∂
2
B
s
s
+
β
n
−
s
(11.47)
jk j k
∑ j = 0.
∂si ∑
j
jk
When we perform the derivatives, this gives us

∑ Bij s j = βsi ,
j

376

(11.48)

11.8

|

S PECTRAL MODULARITY MAXIMIZATION

or in matrix notation
Bs = βs.

(11.49)

In other words, s is one of the eigenvectors of the modularity matrix. Substituting (11.49) back into Eq. (11.45), we ﬁnd that the modularity itself is given
by
1
n
β,
(11.50)
βs T s =
Q=
4m
4m
where we have used Eq. (11.46). For maximum modularity, therefore, we
should choose s to be the eigenvector u1 corresponding to the largest eigenvalue of the modularity matrix.
As before, we typically cannot in fact choose s = u1 , since the elements of
s are subject to the constraint si = ±1. But we do the best we can and choose it
as close to u1 as possible, which means maximizing the product
s T u1 = ∑ s i u1 i ,

(11.51)

i

where [u1 ]i is the ith element of u1 . The maximum is achieved when each term
in the sum is non-negative, i.e., when

+1
if [u1 ]i > 0,
(11.52)
si =
−1
if [u1 ]i < 0.
In the unlikely event that a vector element is exactly zero, either value of si is
equally good and we can choose whichever we prefer.
And so we are led the following very simple algorithm. We calculate the
eigenvector of the modularity matrix corresponding to the largest (most positive) eigenvalue and then assign vertices to communities according to the signs
of the vector elements, positive signs in one group and negative signs in the
other.
In practice this method works very well. For example, when applied to the
karate club network of Fig. 11.4 it works perfectly, classifying every one of the
34 vertices into the correct group.
One potential problem with the algorithm is that the matrix B is, unlike the
Laplacian, not sparse, and indeed usually has all elements non-zero. At ﬁrst
sight, this appears to make the algorithm’s complexity signiﬁcantly worse than
that of the normal spectral bisection algorithm; as discussed in Section 11.1.1,
ﬁnding the leading eigenvector of a matrix takes time O(mn), which is equivalent to O(n3 ) in a dense matrix, as opposed to O(n2 ) in a sparse one. In fact,
however, by exploiting special properties of the modularity matrix it is still
possible to ﬁnd the eigenvector in time O(n2 ) on a sparse network. The details
can be found in [246].
377

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

Overall, this means that the spectral method is about as fast as, but not
signiﬁcantly faster than, the vertex-moving algorithm of Section 11.7. Both
have time complexity O(n2 ) on sparse networks.11 There is, however, merit
to having both algorithms. Given that all practical modularity maximizing
algorithms are merely heuristics—clever perhaps, but not by any means guaranteed to perform well in all cases—having more than one fast algorithm in
our toolkit is always a good thing.

11.9

D IVISION INTO MORE THAN TWO GROUPS

The community detection algorithms of the previous two sections both perform a limited form of community detection, the division of a network into
exactly two communities, albeit of unspeciﬁed sizes. But “communities” are
deﬁned to be the natural groupings of vertices in networks and there is no
reason to suppose that networks will in general have just two of them. They
might have two, but they might have more than two, and we would like to be
able to ﬁnd them whatever their number. Moreover we don’t, in general, want
to have to specify the number of communities; that number should be ﬁxed by
the structure of the network and not by the experimenter.
In principle, the modularity maximization method can handle this problem
perfectly well. Instead of maximizing modularity over divisions of a network
into two groups, we should just maximize it over divisions into any number
of groups. Modularity is supposed to be largest for the best division of the
network, no matter how many groups that division possesses.
There are a number of community detection algorithms that take this “free
maximization” approach to determining community number, and we discuss
some of them in the following section. First, however, we discuss a simpler
approach which is a natural extension of the methods of previous sections and
of our graph partitioning algorithms, namely repeated bisection of a network.
We start by dividing the network ﬁrst into two parts and then we further subdivide those parts in to smaller ones, and so on.
One must be careful about how one does this, however. We cannot proceed as one can in the graph partitioning case and simply treat the communities found in the initial bisection of a network as smaller networks in their
Note, however, that the vertex moving algorithm takes time O(n2 ) for each round of the
algorithm, but we have not calculated, and do not in fact know, how many rounds are needed
in general. As with the Kernighan–Lin algorithm, it is reasonable to suppose that the number of
rounds needed might increase, at least slowly, with network size, which would make the time
complexity of the vertex moving algorithm poorer than that of the spectral algorithm.
11

378

11.9

|

D IVISION INTO MORE THAN TWO GROUPS

own right, applying our bisection algorithm to those smaller networks. The
modularity of the complete network does not break up (as cut size does) into
independent contributions from the separate communities and the individual
maximization of the modularities of those communities treated as separate networks will not, in general, produce the maximum modularity for the network
as a whole.
Instead, we must consider explicitly the change ΔQ in the modularity of the
entire network upon further bisecting a community c of size nc . That change is
given by


1 1
Bij (si s j + 1) − ∑ Bij
ΔQ =
2m 2 i,j∑
∈c
i,j∈c




1
1
Bij − δij ∑ Bik si s j
=
Bij si s j − ∑ Bij =
∑
∑
4m i,j∈c
4m i,j∈c
i,j∈c
k∈c

=

1 T (c)
s B s,
4m

(11.53)

where we have made use of s2i = 1, and B(c) is the nc × nc matrix with elements
(c)

Bij = Bij − δij ∑ Bik .

(11.54)

k∈c

Since Eq. (11.53) has the same general form as Eq. (11.45) we can now apply
our spectral approach to this generalized modularity matrix, just as before,
to maximize ΔQ, ﬁnding the leading eigenvector and dividing the network
according to the signs of its elements.
In repeatedly subdividing a network in this way, an important question we
need to address is at what point to halt the subdivision process. The answer is
quite simple. Given that our goal is to maximize the modularity for the entire
network, we should only go on subdividing groups so long as doing so results
in an increase in the overall modularity. If we are unable to ﬁnd any division
of a community that results in a positive change ΔQ in the modularity, then we
should simply leave that community undivided. The practical indicator of this
situation is that our bisection algorithm will put all vertices in one of its two
groups and none in the other, effectively refusing to subdivide the community
rather than choose a division that actually decreases the modularity. When we
have subdivided our network to the point where all communities are in this
indivisible state, the algorithm is ﬁnished and we stop.
This repeated bisection method works well in many situations, but it is by
no means perfect. A particular problem is that, as in the equivalent approach
to graph partitioning, there is no guarantee that the best division of a network
379

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

(a)

(b)

Figure 11.5: Division of a simple network by repeated maximization of the modularity. (a) The optimal bisection of this network of eight vertices and seven edges is
straight down the middle. (b) The optimal division into an arbitrary number of groups
is this division into three.

into, say, three parts, can be found by ﬁrst ﬁnding the best division into two
parts and then subdividing one of the two. Consider for instance the simple
network shown in Fig. 11.5, which consists of eight vertices joined together in a
line. The bisection of this network with highest modularity is the one shown in
Fig. 11.5a, down the middle of the network, splitting it into two equally sized
groups of four vertices each. The best modularity if the number of groups is
unconstrained, however, is that shown in Fig. 11.5b, with three groups of sizes
3, 2, and 3, respectively. A repeated optimal bisection algorithm would never
ﬁnd the division in 11.5b because, having ﬁrst made the bisection in 11.5a,
there is no further bisection that will get us to 11.5b.
As mentioned above, an alternative method for dividing networks into
more than two communities is to attempt to ﬁnd directly the maximum modularity over divisions into any number of groups. This approach can, in principle, ﬁnd better divisions than repeated bisection, but in practice is more complicated to implement and often runs slower. A number of promising methods
have been developed, however, some of which are discussed in the next section.

11.10

O THER MODULARITY MAXIMIZATION METHODS

There are a great variety of general algorithms for maximizing (or minimizing)
functions over sets of states, and in theory any one of them could be brought
to bear on the modularity maximization problem, thereby creating a new community detection algorithm. We describe brieﬂy here three approaches that
have met with some success. Each of these approaches attempts to maximize
modularity over divisions into any number of communities of any sizes and
380

11.10

|

O THER MODULARITY MAXIMIZATION METHODS

thus to determine both the number and size of communities in the process.
One of the most widely used general optimization strategies is simulated
annealing, which proceeds by analogy with the physics of slow cooling or “annealing” of solids. It is known that a hot system, such as a molten metal, will,
if cooled sufﬁciently slowly to a low enough temperature, eventually ﬁnd its
ground state, that state of the system that has the lowest possible energy. Simulated annealing works by treating the quantity of interest—modularity in this
case—as an energy and then simulating the cooling process until the system
ﬁnds the state with the lowest energy. Since we are interested in ﬁnding the
highest modularity, not the lowest, we equate energy in our case with minus
the modularity, rather than with the modularity itself.
The details of the simulated annealing method are beyond the scope of
this book, but the application to modularity maximization is a straightforward
one and it appears to work very well [85, 150, 151, 215, 281]. For example,
Danon et al. [85] performed an extensive test in which they compared the performance of a large number of different community detection algorithms on
standardized tasks and found that the simulated annealing method gave the
best results of any method tested. The main disadvantage of the approach
is that it is slow, typically taking several times as long to reach an answer as
competing methods do.
Another general optimization method is the genetic algorithm, a method
inspired by the workings of biological evolution. Just as ﬁtter biological species
reproduce more and so pass on the genes that confer that ﬁtness to future generations, so one can consider a population of different divisions of the same
network and assign to each a “ﬁtness” proportional to its modularity. Over
a series of generations one simulates the preferential “reproduction” of highmodularity divisions, while those of low modularity die out. Small changes
or mutations are introduced into the offspring divisions, allowing their modularity values either to improve or get worse and those that improve are more
likely to survive in the next generation while those that get worse are more
likely to be killed off. After many generations one has a population of divisions with good modularity and the best of these is the ﬁnal division returned
by the algorithm. Like simulated annealing the method appears to give results
of high quality, but is slow, which restricts its use to networks of a few hundred
vertices or fewer [295].
A third method makes use of a so-called greedy algorithm. In this very simple approach we start out with each vertex in our network in a one-vertex
group of its own, and then successively amalgamate groups in pairs, choosing at each step the pair whose amalgamation gives the biggest increase in
modularity, or the smallest decrease if no choice gives an increase. Eventually
381

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

all vertices are amalgamated into a single large community and the algorithm
ends. Then we go back over the states through which the network passed
during the course of the algorithm and select the one with the highest value
of the modularity. A naive implementation of this idea runs in time O(n2 ),
but by making use of suitable data structures the run time can be improved
to O(n log2 n) on a sparse graph [71, 319]. Overall the algorithm works only
moderately well: it gives reasonable divisions of networks, but the modularity
values achieved are in general somewhat lower than those found by the other
methods described here. On the other hand, the running time of the method
may be the best of any current algorithm, and this is one of the few algorithms
fast enough to work on the very largest networks now being explored. Wakita
and Tsurumi [319] have given one example of an application to a network of
more than ﬁve million vertices, something of a record for studies of this kind.

11.11

O THER ALGORITHMS FOR COMMUNITY DETECTION

As we have seen, the problem of detecting communities in networks is a less
well-posed one than the problem of graph partitioning. In graph partitioning
the goal is clear: to ﬁnd the division of a network with the smallest possible
cut size. There is, by contrast, no universally agreed upon deﬁnition of what
constitutes a good division of a network into communities. In the previous
sections we have looked at algorithms based one particular deﬁnition in terms
of the modularity function, but there are a number of other deﬁnitions in common use that lead to different algorithms. In the following sections we look
brieﬂy at a few of these other algorithms.
11.11.1

B ETWEENNESS - BASED METHODS

One alternative way of ﬁnding communities of vertices in a network is to look
for the edges that lie between communities. If we can ﬁnd and remove these
edges, we will be left with just the isolated communities.
There is more than one way to quantify what we mean when we say an
edge lies “between communities,” but one common approach is to use betweenness centrality. As described in Section 7.7, the betweenness centrality
of a vertex in a network is the number of geodesic (i.e., shortest) paths in the
network that pass through that vertex. Similarly, we can deﬁne an edge betweenness that counts the number of geodesic paths that run along edges and,
as shown in Fig. 11.6, edges that lie between communities can be expected to
have high values of the edge betweenness.

382

11.11

|

O THER ALGORITHMS FOR COMMUNITY DETECTION

v
u

Figure 11.6: Identiﬁcation of between-group edges. This simple example network is
divided into two groups of vertices (denoted by the dotted lines), with only two edges
connecting the groups. Any path joining vertices in different groups (such as vertices u
and v) must necessarily pass along one of these two edges. Thus if we consider a set of
paths between all pairs of vertices (such as geodesic paths, for instance), we expect the
between-group edges to carry more paths than most. By counting the number of paths
that pass along each edge we can in this way identify the between-group edges.

The calculation of edge betweenness is precisely analogous to the vertex
case: we consider the geodesic path or paths between every pair of vertices
in the network (except vertices in different components, for which no such
path exists), and count how many such paths go along each edge. Edge betweenness can be calculated for all edges in time O(n(m + n)) using a slightly
modiﬁed version of the algorithm described in Section 10.3.6 [250].
Our algorithm for detecting communities is then as follows. We calculate
the betweenness scores of all edges in our network and then search through
them for the edge with the highest score and remove it. In removing the edge
we will change the betweenness scores of some edges, because any shortest
paths that previously traversed the removed edge will now have to be rerouted
another way. So we must recalculate the betweenness scores following the
removal. Then we search again for the edge with the highest score and remove
it, and so forth. As we remove one edge after another an initially connected
network will eventually split into two pieces, and then into three, and so on.
The progress of the algorithm can be represented using a tree or dendrogram
like that depicted in Fig. 11.7. At the bottom of the ﬁgure we have the “leaves”
of the tree, which each represent one of the vertices of the network, and as
we move up the tree, the leaves join together ﬁrst in pairs and then in larger
groups, until at the top of the tree all are joined together to form a single whole.
Our algorithm in fact generates the dendrogram from the top, rather than the
bottom, starting with a single connected network and splitting it repeatedly

383

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

5

6

2 10 9 7 12 1 4

3

8 11

Vertices

Figure 11.7: A dendrogram. The results of the edge betweenness algorithm can be represented as a tree or “dendrogram” in which the vertices are depicted (conventionally)
at the bottom of the tree and the “root” at the top represent the whole network. The progressive fragmentation of the network as edges are removed one by one is represented
by the successive branching of the tree as we move down the ﬁgure and the identities
of the vertices in a connected subset at any point in the procedure can be found by
following the lines of the tree down to the bottom of the picture. Each intermediate division of the network through which the algorithm passes corresponds to a horizontal
cut through the dendrogram. For instance, the cut denoted by the dotted line in this
dendrogram splits the network into four groups of 6, 1, 2, and 3 vertices respectively.

until we get to the level of single vertices. Individual intermediate conﬁgurations of the network during the run of the algorithm correspond to horizontal
cuts through the dendrogram, as indicated by the dotted line in the ﬁgure.
Each branch of the tree that intersects this dotted line represents one group of
vertices, whose membership we can determine by following the branch down
to its leaves at the bottom of the ﬁgure. Thus the dendrogram captures in a
single diagram the conﬁguration of groups in the network at every stage from
start to ﬁnish of the algorithm.
This algorithm is somewhat different from previous ones, therefore, in that
it doesn’t give a single decomposition of a network into communities, but a
selection of different possibilities, ranging from coarse divisions into just a few
large communities (at the top of the dendrogram) to ﬁne divisions into many
small communities (at the bottom). It is up to the user to decide which of
the many divisions represented is most useful for their purposes. One could
in principle use a measure such as modularity to quantify the quality of the
different divisions and select the one with the highest quality in this sense.
This, however, somewhat misses the point. If high modularity is what you
384

11.11

|

O THER ALGORITHMS FOR COMMUNITY DETECTION

care about, then you are better off simply using a modularity maximization
algorithm in the ﬁrst place. It is more appropriate simply to think of this
betweenness-based algorithm as producing a different kind of output, one that
has its own advantages and disadvantages but that can undoubtedly tell us interesting things about network structure.
The betweenness-based algorithm is, unfortunately, quite slow. As we have
said the calculation of betweenness for all edges takes time of order O(n(m +
n)) and we have to perform this calculation before the removal of each of the m
edges, so the entire algorithm takes time O(mn(m + n)), or O(n3 ) on a sparse
graph with m ∝ n. This makes this algorithm one of the slower algorithms
considered in this chapter. The algorithm gives quite good results in practice [138, 250], but has mostly been superseded by the faster modularity maximization methods of previous sections.
Nonetheless, the ability of the algorithm to return an entire dendrogram,
rather than just a single division of a network, could be useful in some cases.
The divisions represented in the dendrogram form a hierarchical decomposition
in which the communities at one level are completely contained within the
larger communities at all higher levels. There has been some interest in hierarchical structure in networks and hierarchical decompositions that might
capture it. We look at another algorithm for hierarchical decomposition in Section 11.11.2.
An interesting variation on the betweenness algorithm has been proposed
by Radicchi et al. [276]. Their idea revolves around the same basic principle of
identifying the edges between communities and removing them, but the measure used to perform the identiﬁcation is different. Radicchi et al. observe that
the edges that fall between otherwise poorly connected communities are unlikely to belong to short loops of edges, since doing so would require that there
be two nearby edges joining the same groups—see Fig. 11.8. Thus one way to
identify the edges between communities would be to look for edges that belong to an unusually small number of short loops. Radicchi et al. found that
loops of length three and four gave the best results. By repeatedly removing
edges that belong to small numbers of such loops they were able to accurately
uncover communities in a number of example networks.
An attractive feature of this method is its speed. The calculation of the
number of short loops to which an edge belongs is a local calculation and
can be performed for all edges in time that goes like the total size of the network. Thus, in the worst case, the running time of the algorithm will only
go as O(n2 ) on a sparse graph, which is one order of system size faster than
the betweenness-based algorithm and as fast as the earlier methods based on
modularity maximization.
385

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

3
1

2

Figure 11.8: The algorithm of Radicchi et al. The algorithm of Radicchi et al. uses a
different measure to identify between-group edges, looking for the edges that belong
to the fewest short loops. In many networks, edges within groups typically belong to
many short loops, such as the loops of length three and four labeled “1” and “2.” But
edges between groups, such as the edge labeled “3” here, often do not belong to such
loops, because to do so would require there to be a return path along another betweengroup edge, of which there are, by deﬁnition, few.

On the other hand, the algorithm of Radicchi et al. has the disadvantage
that it only works on networks that have a signiﬁcant number of short loops
in the ﬁrst place. This restricts the method primarily to social networks, which
indeed have large numbers of short loops (see Section 7.9). Other types of
network, such as technological and biological networks, tend to have smaller
numbers of short loops, and hence there is little to distinguish between-group
edges from within-group ones.
11.11.2

H IERARCHICAL CLUSTERING

The algorithms of the previous section differ somewhat from the other community detection algorithms in this chapter in that they produce a hierarchical
decomposition of a network into a set of nested communities, visualized in the
form of a dendrogram as in Fig. 11.7, rather than just a single division into a
unique set of communities. In this section we look at another algorithm that
also produces a hierarchical decomposition, one of the oldest of community
detection methods, the method of hierarchical clustering.12
Hierarchical clustering is not so much a single algorithm as an entire class
12

The word “clustering” as used here just refers to community detection. We have mostly
stayed away from using this word in this chapter, to avoid confusion with the other use of the
word clustering introduced in Section 7.9 (see footnote 5 on page 354), but the name “hierarchical
clustering” is a well established and traditional one, and we use it here in deference to convention.

386

O THER ALGORITHMS FOR COMMUNITY DETECTION

g

B
on

Str

A

g

of algorithms, with many variations and alternatives. Hierarchical clustering
is an agglomerative technique in which we start with the individual vertices of
a network and join them together to form groups. This contrasts with most
of the other methods we have looked at for community detection and graph
partitioning, which were divisive methods that took a complete network and
split it apart. (One earlier algorithm, the greedy modularity maximization algorithm of Section 11.10, was an agglomerative method.)
The basic idea behind hierarchical clustering is to deﬁne a measure of similarity or connection strength between vertices, based on the network structure,
and then join together the closest or most similar vertices to form groups. We
discussed measures of vertex similarity in networks at some length in Section 7.12. Any of the measures of structural equivalence introduced there
would be suitable as a starting point for hierarchical clustering, including cosine similarity (Section 7.12.1), correlation coefﬁcients between rows of the
adjacency matrix (Section 7.12.2), or the so-called Euclidean distance (Section
7.12.3). The regular equivalence measures of Section 7.12.4 might also be good
choices, although the author is not aware of them having been used in this
context.
That there are many choices for similarity measures is both a strength and a
weakness of the hierarchical clustering method. It gives the method ﬂexibility
and allows it to be tailored to speciﬁc problems, but it also means that the
method gives different answers depending on which measure we choose, and
in many cases there is no way to know if one measure is more correct or will
yield more useful information than another. Most often the choice of measure
is determined more by experience or experiment than by argument from ﬁrst
principles.
Once a similarity measure is chosen we calculate it for all pairs of vertices
in the network. Then we want to group together those vertices having the
highest similarities. This, however, leads to a further problem: the similarities
can give conﬂicting messages about which vertices should be grouped. Suppose vertices A and B have high similarity, as do vertices B and C. One might
therefore argue that A, B, and C should all be in a group together. But suppose
that A and C have low similarity. Now we are left with a dilemma. Should A
and C be in the same group or not?
The basic strategy adopted by the hierarchical clustering method is to start
by joining together those pairs of vertices with the highest similarities, forming
a group or groups of size two. For these there is no ambiguity, since each pair
only has one similarity value. Then we further join together the groups that are
most similar to form larger groups, and so on. When viewed in terms of agglomeration of groups like this, the problem above can be stated in a new and

on

|

Str

11.11

Weak

C

If the connections (A,B)
and (B,C) are strong but
(A,C) is weak, should A
and C be in the same group
or not?

387

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

useful way. Our process requires for its operation a measure of the similarity
between groups, so that we can join the most similar ones together. But what
we actually have is a measure of similarity between individual vertices, so we
need to combine these vertex similarities somehow to create similarities for the
groups. If we can do this, then the rest of the algorithm is straightforward and
the ambiguity is resolved.
There are three common ways of combining vertex similarities to give similarity scores for groups. They are called single-, complete-, and average-linkage
clustering. Consider two groups of vertices, group 1 and group 2, containing
n1 and n2 vertices respectively. There are then n1 n2 pairs of vertices such that
one vertex is in group 1 and the other in group 2. In the single-linkage clustering
method, the similarity between the two groups is deﬁned to be the similarity of
the most similar of these n1 n2 pairs of vertices. Thus if the values of the similarities of the vertex pairs range from 1 to 100, the similarity of the two groups
is 100. This is a very lenient deﬁnition of similarity: only a single vertex pair
need have high similarity for the groups themselves to be considered similar.
(This is the origin of the name “single-linkage clustering”—similarity between
groups is a function of the similarity between only the single most similar pair
of vertices.)
At the other extreme, complete-linkage clustering deﬁnes the similarity between two groups to be the similarity of the least similar pair of vertices. If the
similarities range from 1 to 100 then the similarity of the groups is 1. By contrast with single-linkage clustering this is a very stringent deﬁnition of group
similarity: every single vertex pair must have high similarity for the groups to
have high similarity (hence the name “complete-linkage clustering”).
In between these two extremes lies average-linkage clustering, in which the
similarity of two groups is deﬁned to be the mean similarity of all pairs of vertices. Average-linkage clustering is probably the most satisfactory choice of the
three, being a moderate one—not extreme in either direction—and depending
on the similarity of all vertex pairs and not just of the most or least similar pair.
It is, however, relatively rarely used, for reasons that are not entirely clear.
The full hierarchical clustering method is as follows:
1. Choose a similarity measure and evaluate it for all vertex pairs.
2. Assign each vertex to a group of its own, consisting of just that one vertex. The initial similarities of the groups are simply the similarities of the
vertices.
3. Find the pair of groups with the highest similarity and join them together
into a single group.
4. Calculate the similarity between the new composite group and all others
using one of the three methods above (single-, complete-, or average388

11.11

|

O THER ALGORITHMS FOR COMMUNITY DETECTION

linkage clustering).
5. Repeat from step 3 until all vertices have been joined into a single group.
In practice, the calculation of the new similarities is relatively straightforward. Let us consider the three cases separately. For single-linkage clustering
the similarity of two groups is equal to the similarity of their most similar pair
of vertices. In this case, when we join groups 1 and 2 together, the similarity
of the composite group to another group 3, is the greater of the similarities of
1 with 3 and 2 with 3, which can be found in O(1) time.
For complete-linkage clustering the similarity of the composite group is the
smaller of the similarities of 1 with 3 and 2 with 3, which can also be found in
O(1) time.
The average-linkage case is only slightly more complicated. Suppose as
before that the groups 1 and 2 that are to be joined have n1 and n2 vertices
respectively. Then if the similarities of 1 with 3 and 2 with 3 were previously
σ13 and σ23 , the similarity of the composite group with another group 3 is given
by the weighted average
σ12,3 =

n1 σ13 + n2 σ23
.
n1 + n2

(11.55)

Again this can be calculated in O(1) time.
On each step of the algorithm we have to calculate similarities in this way
for the composite group with every other group, of which there are O(n).
Hence the recalculation of similarities will take O(n) time on each step. A naive
search through the similarities to ﬁnd the greatest one, on the other hand, takes
time O(n2 ), since there are O(n2 ) pairs of groups to check, so this will be the
most time-consuming step in the algorithm. We can speed things up, however,
by storing the similarities in a binary heap (see Section 9.713 ), which allows us
to add and remove entries in time O(log n) and ﬁnd the greatest one in time
O(1). This slows the recalculation of the similarities to O(n log n) but speeds
the search for the largest to O(1).
Then the whole process of joining groups has to be repeated n − 1 times
until all vertices have been joined into a single group. (To see this, simply
consider that the number of groups goes down by one every time two groups
are joined, so it takes n − 1 joins to go from n initial groups to just a single one
13

The heap must be modiﬁed slightly from the one described in Section 9.7. First, the partial
ordering must be inverted so that the largest, not the smallest, element of the heap is at its root.
Second, we need to be able to remove arbitrary items from the heap, not just the root item, which
we do by deleting the relevant item and then moving the last item in the heap to ﬁll the vacated
space. Then we have to sift the moved item both up and down the heap, since it might be either
too large or too small for the position in which it ﬁnds itself.

389

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

Figure 11.9: Partitioning of the karate club network by average linkage hierarchical clustering. This dendrogram is the result of applying the hierarchical clustering
method described in the text to the karate club network of Fig. 11.4, using cosine similarity as our measure of vertex similarity. The shapes of the nodes represent the two
known factions in the network, as in the two previous ﬁgures.

at the end.) Thus the total running time of the algorithm is O(n3 ) in the naive
implementation or O(n2 log n) if we use a heap.14
And how well does it work in practice? The answer depends on which
similarity measure one chooses and which linkage method, but a typical application, again to the karate club network, is shown in Fig. 11.9. This ﬁgure
shows what happens when we apply average-linkage clustering to the karate
network using cosine similarity as our similarity measure. The ﬁgure shows
the dendrogram that results from such a calculation and we see that there is a
clear division of the dendrogram into two communities that correspond perfectly to the two known groups in the network.
Hierarchical clustering does not always work as well as this, however. In
particular, though it is often good at picking out the cores of groups, where
the vertices are strongly similar to one another, it tends to be less good at assigning peripheral vertices to appropriate groups. Such vertices may not be
strongly similar to any others and so tend to get left out of the agglomerative
14
For the special case of single-linkage clustering, there is a slightly faster way to implement the
algorithm that makes use of a so-called union/ﬁnd technique and runs in time O(n2 ). In practice
the performance difference is not very large but the union/ﬁnd method is considerably simpler
to program. It is perhaps for this reason that single-linkage is more often used than complete- or
average-linkage clustering.

390

P ROBLEMS

clustering process until the very end. A common result of hierarchical clustering is therefore a set of tightly knit cores surrounded by a loose collection of
single vertices or smaller groups. Such a result may nonetheless contain a lot
of valuable information about the underlying network structure.
Many other methods have been proposed for community detection and there
is not room in this book to describe them all. For the reader interested in pursuing the topic further the review articles by Fortunato [124] and Schaeffer [291]
provide useful overviews.

P ROBLEMS
11.1 Show that the inverse of a symmetric matrix M is given by M−1 = UDU T where
U is the orthogonal matrix whose columns are the normalized eigenvectors of M and
D is the diagonal matrix whose elements are the reciprocals of the eigenvalues of M.
Hence argue that the time complexity of the best algorithm for inverting a symmetric
matrix can be no worse than the time complexity of ﬁnding all of its eigenvalues and
eigenvectors. (In fact they are the same—both are O(n) for an n × n matrix.)
11.2

Consider a general n × n matrix M with eigenvalues μi where i = 1 . . . n.

a) Show that the matrix M − aI has the same eigenvectors as M and eigenvalues
μi − a.
b) Suppose that the matrix’s two eigenvalues of largest magnitude are both positive.
Show that the time taken to ﬁnd the leading eigenvector of the matrix using the
power method of Section 11.1 can be improved by performing the calculation
instead for the matrix M − aI, where a is positive.
c) What stops us from increasing the constant a arbitrarily until the calculation takes
no time at all?
11.3

Consider a “line graph” consisting of n vertices in a line like this:

a) Show that if we divide the network into two parts by cutting any single edge, such
that one part has r vertices and the other has n − r, the modularity, Eq. (7.76), takes
the value
3 − 4n + 4rn − 4r2
Q=
.
2( n − 1)2

391

M ATRIX ALGORITHMS AND GRAPH PARTITIONING

b) Hence show that when n is even the optimal such division, in terms of modularity,
is the division that splits the network exactly down the middle.
11.4 Using your favorite numerical software for ﬁnding eigenvectors of matrices, construct the Laplacian and the modularity matrix for this small network:

a) Find the eigenvector of the Laplacian corresponding to the second smallest eigenvalue and hence perform a spectral bisection of the network into two equally sized
parts.
b) Find the eigenvector of the modularity matrix corresponding to the largest eigenvalue and hence divide the network into two communities.
You should ﬁnd that the division of the network generated by the two methods is, in
this case, the same.
11.5

Consider this small network with ﬁve vertices:

a) Calculate the cosine similarity for each of the (52) = 10 pairs of vertices.
b) Using the values of the ten similarities construct the dendrogram for the singlelinkage hierarchical clustering of the network according to cosine similarity.

392

This page intentionally left blank

This page intentionally left blank

PART IV
N ETWORK MODELS

395

This page intentionally left blank

C HAPTER 12

R ANDOM GRAPHS
An introduction to the most basic of network models, the
random graph

S

O FAR in this book we have looked at how we measure the structure of

networks and at mathematical, statistical, and computational methods for
making sense of the network data we get from our measurements. We have
seen for instance how to measure the structure of the Internet, and once we
have measured it how to determine its degree distribution, or the centrality of
its vertices, or the best division of the network into groups or communities.
An obvious next question to ask is, “If I know a network has some particular
property, such as a particular degree distribution, what effect will that have
on the wider behavior of the system?” It turns out that properties like degree
distributions can in fact have huge effects on networked systems, which is one
of the main reasons we are interested in them. And one of the best ways to
understand and get a feel for these effects is to build mathematical models.
The remainder of this book is devoted to the examination of some of the many
network models in common use.
In Chapters 12 to 15 we consider models of the structure of networks, models that mimic the patterns of connections in real networks in an effort to understand the implications of those patterns. In Chapters 16 to 19 we consider
models of processes taking place on networks, such as epidemics on social networks or search engines on the Web. In many cases these models of network
processes are themselves built on top of our models of network structure, combining the two to shed light on the interplay between structure and dynamics
in networked systems.
In Section 8.4, for instance, we noted that many networks have degree distributions that roughly follow a power law—the so-called scale-free networks.

397

R ANDOM GRAPHS

A reasonable question would be to ask how the structure and behavior of such
scale-free networks differs from that of their non-scale-free counterparts. A
good way to address this question would be to create, on a computer for example, two artiﬁcial networks, one with a power-law degree distribution and
one without, and explore their differences empirically. Better still, one could
create a large number of networks in each of the two classes, to see what statistically signiﬁcant features appear in one class and not in the other. This is
precisely the rationale behind random graph models, which are the topic of
this chapter and the following one. In random graph models, one creates networks that possess particular properties of interest, such as speciﬁed degree
distributions, but which are otherwise random. Random graphs are interesting in their own right for the light they shed on the structural properties of
networks, but have also been widely used as a substrate for models of dynamical processes on networks. In Chapter 17, for instance, we examine their use
in epidemic modeling.
We also look at a number of other types of network model in succeeding chapters. In Chapter 14 we look at generative models of networks, models in which the network is “grown” according to a speciﬁed set of growth
rules. Generative models are particularly useful for understanding how network structure arises in the ﬁrst place. By growing networks according to a
variety of different rules and comparing the results with real networks, we can
get a feel for which growth processes are plausible and which can be ruled
out. In Chapter 15 we look at “small-world models,” which model the phenomenon of network transitivity or clustering (see Section 7.9), and at “exponential random graphs,” which are particularly useful when we want to create
model networks that match the properties of observed networks as closely as
possible.

12.1

R ANDOM GRAPHS

In general, a random graph is a model network in which some speciﬁc set of
parameters take ﬁxed values, but the network is random in other respects. One
of the simplest examples of a random graph is the network in which we ﬁx only
the number of vertices n and the number of edges m. That is, we take n vertices
and place m edges among them at random. More precisely, we choose m pairs
of vertices uniformly at random from all possible pairs and connect them with
an edge. Typically one stipulates that the network should be a simple graph,
i.e., that it should have no multiedges or self-edges (see Section 6.1), in which
case the position of each edge should be chosen among only those pairs that

398

12.1

|

R ANDOM GRAPHS

are distinct and not already connected.1 This model is often referred to by its
mathematical name G (n, m).
Another entirely equivalent deﬁnition of the model is to say that the network is created by choosing uniformly at random among the set of all simple
graphs with exactly n vertices and m edges.
Strictly, in fact, the random graph model is not deﬁned in terms of a single randomly generated network, but as an ensemble of networks, i.e., a probability distribution over possible networks. Thus the model G (n, m) is correctly deﬁned as a probability distribution P( G ) over all graphs G in which
P( G ) = 1/Ω for simple graphs with n vertices and m edges and zero otherwise, where Ω is the total number of such simple graphs. We will see more
complicated examples of random graph ensembles shortly.
When one talks about the properties of random graphs one typically means
the average properties of the ensemble. For instance, the “diameter” of G (n, m)
would mean the diameter ( G ) of a graph G, averaged over the ensemble thus

 = ∑ P( G )( G ) =
G

1
( G ).
Ω∑
G

(12.1)

This is a useful deﬁnition for a several of reasons. First, it turns out to lend
itself well to analytic calculations; many such average properties of random
graphs can be calculated exactly, at least in the limit of large graph size. Second, it often reﬂects exactly the thing we want to get at in making our model
network in the ﬁrst place. Very often we are interested in the typical properties
of networks. We might want to know, for instance, what the typical diameter is
of a network with a given number of edges. Certainly there are special cases of
such networks that have particularly large or small diameters, but these don’t
reﬂect the typical behavior. If it’s typical behavior we are after, then the ensemble average of a property is often a good guide. Third, it can be shown that
the distribution of values for many network measures is sharply peaked, becoming concentrated more and more narrowly around the ensemble average
as the size of the network becomes large, so that in the large n limit essentially
all values one is likely to encounter are very close to the mean.
Some properties of the random graph G (n, m) are straightforward to calculate: obviously the average number of edges is m, for instance, and the average
degree is k = 2m/n. Unfortunately, other properties are not so easy to calculate, and most mathematical work has actually been conducted on a slightly
different model that is considerably easier to handle. This model is called
1
It would in theory be perfectly possible, however, to create a variant of the model with multiedges or self-edges, or both.

399

R ANDOM GRAPHS

G (n, p). In G (n, p) we ﬁx not the number but the probability of edges between
vertices. Again we have n vertices, but now we place an edge between each
distinct pair with independent probability p. In this network the number of
edges is not ﬁxed. Indeed it is possible that the network could have no edges
at all, or could have edges between every distinct pair of vertices. (For most
values of p these are not likely outcomes, but they could happen.)
Again, the technical deﬁnition of the random graph is not in terms of a
single network, but in terms of an ensemble, a probability distribution over all
possible networks. To be speciﬁc, G (n, p) is the ensemble of networks with n
vertices in which each simple graph G appears with probability
P( G ) = pm (1 − p)(2)−m ,
n

(12.2)

where m is the number of edges in the graph, and non-simple graphs have
probability zero.
G (n, p) was ﬁrst studied, to this author’s knowledge, by Solomonoff and
Rapoport [303], but it is most closely associated with the names of Paul Erdős
and Alfréd Rényi, who published a celebrated series of papers about the model
in the late 1950s and early 1960s [105–107]. If you read scientiﬁc papers on this
subject, you will sometimes ﬁnd the model referred to as the “Erdős–Rényi
model” or the “Erdős–Rényi random graph” in honor of their contribution. It
is also sometimes called the “Poisson random graph” or the “Bernoulli random
graph,” names that refer to the distributions of degrees and edges in the model.
And sometimes the model is referred to simply as “the” random graph—there
are many random graph models, but G (n, p) is the most fundamental and
widely studied of them, so if someone is talking about a random graph but
doesn’t bother to mention which one, they are probably thinking of this one.
In this chapter we describe the basic mathematics of the random graph
G (n, p), focusing particularly on the degree distribution and component sizes,
which are two of the model’s most illuminating characteristics. The techniques
we develop in this chapter will also prove useful for some of the more complex
models examined later in the book.

12.2

M EAN NUMBER OF EDGES AND MEAN DEGREE

Let us start our study of the random graph G (n, p) with a very simple calculation, the calculation of the expected number of edges in our model network.
We have said that the number of edges in the model is not ﬁxed, but we can
calculate its mean or expectation value as follows. The number of graphs with
exactly n vertices and m edges is equal to the number of ways of picking the
positions of the edges from the (n2 ) distinct vertex pairs. Each of these graphs
400

12.3

|

D EGREE DISTRIBUTION

appears with the same probability P( G ), given by Eq. (12.2), and hence the
total probability of drawing a graph with m edges from our ensemble is
n
(n2 ) m
p (1 − p)(2)−m ,
m

P(m) =

(12.3)

which is just the standard binomial distribution. Then the mean value of m is
(n2 )

m = ∑ mP(m) =
m =0

n
p.
2

(12.4)

This result comes as no surprise. The expected number of edges between any
individual pair of vertices is just equal to the probability p of an edge between
the same vertices, and Eq. (12.4) thus says merely that the expected total number of edges in the network is equal to the expected number p between any
pair of vertices, multiplied by the number of pairs.
We can use this result to calculate the mean degree of a vertex in the random
graph. As pointed out in the previous section, the mean degree in a graph with
exactly m edges is k = 2m/n, and hence the mean degree in G (n, p) is
(n2 )

2m
2 n
p = (n − 1) p,
P(m) =
2
n
n
m =0

k = ∑

(12.5)

where we have used Eq. (12.4) and the fact that n is constant. The mean degree
of a random graph is often denoted c in the literature, and we will adopt this
convention here also, writing
c = (n − 1) p.

(12.6)

This result is also unsurprising. It says that the expected number of edges
connected to a vertex is equal to the expected number p between the vertex
and any other vertex, multiplied by the number n − 1 of other vertices.

12.3

D EGREE DISTRIBUTION

Only slightly more taxing is the calculation of the degree distribution of G (n, p).
A given vertex in the graph is connected with independent probability p to
each of the n − 1 other vertices. Thus the probability of being connected to a
particular k other vertices and not to any of the others is pk (1 − p)n−1−k . There
are (n−k 1) ways to choose those k other vertices, and hence the total probability
of being connected to exactly k others is
pk =

n−1 k
p (1 − p ) n −1− k ,
k

(12.7)
401

R ANDOM GRAPHS

which is a binomial distribution again. In other words, G (n, p) has a binomial
degree distribution.
In many cases we are interested in the properties of large networks, so that
n can be assumed to be large. Furthermore, as discussed in Section 6.9, many
networks have a mean degree that is approximately constant as the network
size becomes large. (For instance, the typical number of friends a person has
does not depend strongly on the total number of people in the world.) In such
a case Eq. (12.7) simpliﬁes as follows.
Equation (12.6) tells us that p = c/(n − 1) will become vanishingly small
as n → ∞, which allows us to write
ln (1 − p)n−1−k = (n − 1 − k ) ln 1 −

≃ −(n − 1 − k)

c
n−1

c
≃ −c,
n−1

(12.8)

where we have expanded the logarithm as a Taylor series, and the equalities
become exact as n → ∞. Taking exponentials of both sizes, we thus ﬁnd that
(1 − p)n−1−k = e−c in the large-n limit. Also for large n we have
n−1
k

=

( n − 1) !
( n − 1) k
,
≃
(n − 1 − k)! k!
k!

(12.9)

and thus Eq. (12.7) becomes
pk =

( n − 1) k k − c
( n − 1) k
pe =
k!
k!

c
n−1

k

e− c = e− c

ck
,
k!

(12.10)

in the limit of large n.
Equation (12.10) is the Poisson distribution: in the limit of large n, G (n, p)
has a Poisson degree distribution. This is the origin of the name Poisson random
graph, which we will use occasionally to distinguish this model from some of
the more sophisticated random graphs in the following chapter that don’t in
general have Poisson degree distributions.

12.4

C LUSTERING COEFFICIENT

A very simple quantity to calculate for the Poisson random graph is the clustering coefﬁcient. Recall that the clustering coefﬁcient C is a measure of the
transitivity in a network (Section 7.9) and is deﬁned as the probability that two
network neighbors of a vertex are also neighbors of each other. In a random

402

12.5

|

G IANT COMPONENT

graph the probability that any two vertices are neighbors is exactly the same—
all such probabilities are equal to p = c/(n − 1). Hence
C=

c
.
n−1

(12.11)

This is one of several respects in which the random graph differs sharply from
most from real-world networks, many of which have quite high clustering
coefﬁcients—see Table 8.1—while Eq. (12.11) tends to zero in the limit n → ∞
if the mean degree c stays ﬁxed. This discrepancy is discussed further in Section 12.8.

12.5

G IANT COMPONENT

Consider the Poisson random graph G (n, p) for p = 0. In this case there are
no edges in the network at all and it is completely disconnected. Each vertex
is an island on its own; the network has n separate components of exactly one
vertex each.
In the opposite limit, when p = 1, every possible edge in the network is
present and the network is an n-vertex clique in the technical sense of the word
(see Section 7.8.1) meaning that every vertex is connected directly to every
other. In this case, all the vertices are connected together in a single component
that spans the entire network.
Now let us focus on the size of the largest component in the network in
each of these cases. In the ﬁrst case (p = 0) the largest component has size 1.
In the second (p = 1) the largest component has size n. Apart from the second
being much larger than the ﬁrst, there is an important qualitative difference
between these two cases: in the ﬁrst case the size of the largest component is
independent of the number of vertices n in the network; in the second it is
proportional to n, or extensive in the jargon of theoretical physics. In the ﬁrst
case, the largest component will stay the same size if we make the network
larger, but in the second it will grow with the network.
The distinction between these two cases is an important one. In many applications of networks it is crucial that there be a component that ﬁlls most
of the network. For instance, in the Internet it is important that there be a
path through the network from most computers to most others. If there were
not, the network wouldn’t be able to perform its intended role of providing
computer-to-computer communications for its users. Moreover, as discussed
in Section 8.1, most networks do in fact have a large component that ﬁlls most
of the network. We can gain some useful insights about what is happening
in such networks by considering how the components in our random graph
403

R ANDOM GRAPHS

behave. Although the random graph is a very simple network model and
doesn’t provide an accurate representation of the Internet or other real-world
networks, we will see that when trying to understand the world it can be very
helpful to study such simpliﬁed models.
So let us consider the largest component of our random graph, which, as we
have said, has constant size 1 when p = 0 and extensive size n when p = 1. An
interesting question to ask is how the transition between these two extremes
occurs if we construct random graphs with gradually increasing values of p,
starting at 0 and ending up at 1. We might guess, for instance, that the size
of the largest component somehow increases gradually with p, becoming extensive only in the limit where p = 1. In reality, however, something much
more interesting happens. As we will see, the size of the largest component
undergoes a sudden change, or phase transition, from constant size to extensive
size at one particular special value of p. Let us take a look at this transition.
A network component whose size grows in proportion to n we call a giant
component. We can calculate the size of the giant component in the Poisson
random graph exactly in the limit of large network size n → ∞ as follows.
We denote by u the average fraction of vertices in the random graph that do
not belong to the giant component. Thus if there is no giant component in
our graph, we will have u = 1, and if there is a giant component we will have
u < 1. Alternatively, we can regard u as the probability that a randomly chosen
vertex in the graph does not belong to the giant component.
For a vertex i not to belong to the giant component it must not be connected
to the giant component via any other vertex. That means that for every other
vertex j in the graph either (a) i is not connected to j by an edge, or (b) i is
connected to j but j is itself not a member of the giant component. The probability of outcome (a) is simply 1 − p, the probability of not having an edge
between i and j, and the probability of outcome (b) is pu, where the factor of p
is the probability of having an edge and the factor of u is the probability that
vertex j doesn’t belong to the giant component.2 Thus the total probability of
not being connected to the giant component via vertex j is 1 − p + pu.
Then the total probability of not being connected to the giant component
2
We need to be a little careful here: u here should really be the probability that j is not connected to the giant component via any of its connections other than the connection to i. However,
it turns out that in the limit of large system size this probability is just equal to u. For large n the
probability of not being connected to the giant component via any of the n − 2 vertices other than i
is not signiﬁcantly smaller than the probability for all n − 1 vertices.

404

12.5

|

G IANT COMPONENT

via any of the n − 1 other vertices in the network is

u = (1 − p + pu)n−1 = 1 −

c
(1 − u )
n−1

 n −1
,

where we have used Eq. (12.6). Now we take logs of both sides thus:


c
(1 − u )
ln u = (n − 1) ln 1 −
n−1
c
≃ −(n − 1)
(1 − u ) = − c (1 − u ),
n−1

(12.12)

(12.13)

where the approximate equality becomes exact in the limit of large n. Taking
exponentials of both sides, we then ﬁnd that
u = e− c (1− u ) .

(12.14)

But if u is the fraction of vertices not in the giant component, then the fraction
of vertices that are in the giant component is S = 1 − u. Eliminating u in favor
of S then gives us
(12.15)
S = 1 − e−cS .
This equation, which was ﬁrst given by Erdős and Rényi in 1959 [105], tells
us the size of the giant component as a fraction of the size of the network in the
limit of large network size, for any given value of the mean degree c. Unfortunately, though the equation is very simple it doesn’t have a simple solution
for S in closed form.3 We can however get a good feeling for its behavior from
a graphical solution. Consider Fig. 12.1. The three curves show the function
y = 1 − e−cS for different values of c. Note that S can take only values from
zero to one, so only this part of the curve is shown. The dashed line in the
3

One can write a closed-form solution in terms of the Lambert W-function, which is deﬁned
as the solution to the equation W (z)eW (z) = z. In terms of this function the size of the giant
component is
W (−ce−c )
S = 1+
,
c
where we take the principal branch of the W-function. This expression may have some utility for
numerical calculations and series expansions, but it is not widely used. Alternatively, although we
cannot write a simple solution for S as a function of c, we can write a solution for c as a function
of S. Rearranging Eq. (12.15) for c gives
c=−

ln(1 − S)
,
S

which can be useful, for instance, for plotting purposes. (We can make a plot of S as a function of c
by ﬁrst making a plot of c as a function of S and then swapping the axes.)

405

R ANDOM GRAPHS

1

(a)

0.8

(b)

0.6

y

c = 1.5

c=1

0.4

0.5

c = 0.5

0.2

0

0

0.2

0.4

0.6

S

0.8

1

0

1

2

3

Size of giant component S

1

0

Average degree c

Figure 12.1: Graphical solution for the size of the giant component. (a) The three curves in the left panel show
y = 1 − e−cS for values of c as marked, the diagonal dashed line shows y = S, and the intersection gives the solution to
Eq. (12.15), S = 1 − e−cS . For the bottom curve there is only one intersection, at S = 0, so there is no giant component,
while for the top curve there is a solution at S = 0.583 . . . (vertical dashed line). The middle curve is precisely at the
threshold between the regime where a non-trivial solution for S exists and the regime where there is only the trivial
solution S = 0. (b) The resulting solution for the size of the giant component as a function of c.

ﬁgure is the function y = S. Where line and curve cross we have S = 1 − e−cS
and the corresponding value of S is a solution to Eq. (12.15).
As the ﬁgure shows, depending on the value of c there may be either one
solution for S or two. For small c (bottom curve in the ﬁgure) there is just
one solution at S = 0, which implies that there is no giant component in the
network. (You can conﬁrm for yourself that S = 0 is a solution directly from
Eq. (12.15).) On the other hand, if c is large enough (top curve) then there are
two solutions, one at S = 0 and one at S > 0. Only in this regime can there be
a giant component.
The transition between the two regimes corresponds to the middle curve
in the ﬁgure and falls at the point where the gradient of the curve and the
gradient of the dashed line match at S = 0. That is, the transition takes place
when

d 
1 − e−cS = 1,
(12.16)
dS

406

12.5

(a)

|

G IANT COMPONENT

(b)

Figure 12.2: Growth of a vertex set in a random graph. (a) A set of vertices (inside the gray circles) consists of a core
(dark gray) and a periphery (lighter). (b) If we grow the set by adding to it those vertices immediately adjacent to the
periphery, then the periphery vertices become a part of the new core and a new periphery is added.

or

ce−cS = 1.

(12.17)

Setting S = 0 we then deduce that the transition takes place at c = 1.
In other words, the random graph can have a giant component only if c > 1.
At c = 1 and below we have S = 0 and there is no giant component.
This does not entirely solve the problem, however. Technically we have
proved that there can be no giant component for c ≤ 1, but not that there has
to be a giant component at c > 1—in the latter regime there are two solutions
for S, one of which is the solution S = 0 in which there is no giant component.
So which of these solutions is the correct one that describes the true size of the
giant component?
In answering this question, we will see another way to think about the
formation of the giant component. Consider the following process. Let us ﬁnd
a small set of connected vertices somewhere in our network—say a dozen or
so, as shown in Fig. 12.2a. In the limit of large n → ∞ such a set is bound to
exist somewhere in the network, so long as c > 0. We will divide the set into
its core and its periphery. The core is the vertices that have connections only to
other vertices in the set—the darker gray region in the ﬁgure. The periphery is
407

R ANDOM GRAPHS

the vertices that have at least one neighbor outside the set—the lighter gray.
Now imagine enlarging our set by adding to it all those vertices that are immediate neighbors, connected by at least one edge to the set—Fig. 12.2b. Now
the old periphery is part of the core and there is a new periphery consisting
of the vertices just added. How big is this new periphery? We don’t know for
certain, but we know that each vertex in the old periphery is connected with
independent probability p to every other vertex. If there are s vertices in our
set, then there are n − s vertices outside the set, and the average number of
connections a vertex in the periphery has to outside vertices is
p(n − s) = c

n−s
≃ c,
n−1

(12.18)

where the equality becomes exact in the limit n → ∞. This means that the
average number of immediate neighbors of the set—the size of the new periphery when we grow the set—is c times the size of the old periphery.
We can repeat this argument, growing the set again and again, and each
time the average size of the periphery will increase by another factor of c.
Thus if c > 1 the average size of the periphery will grow exponentially. On
the other hand, if c < 1 it will shrink exponentially and eventually dwindle to
zero. Furthermore, if it grows exponentially our connected set of vertices will
eventually form a component comparable in size to the whole network—a giant component—while if it dwindles the set will only ever have ﬁnite size and
no giant component will form.
So we see that indeed we expect a giant component if (and only if) c > 1.
And when there is a giant component the size of that giant component will be
given by the larger solution to Eq. (12.15). This now allows us to calculate the
size of the giant component for all values of c. (For c > 1 we have to solve for
the larger solution of Eq. (12.15) numerically, since there is no exact solution,
but this is easy enough to do.) The results are shown in Fig. 12.1. As the ﬁgure
shows, the size of the giant component grows rapidly from zero as the value
of c passes 1, and tends towards S = 1 as c becomes large.

12.6

S MALL COMPONENTS

In this section we look at the properties of random graphs from a different
point of view, the point of view of the non-giant components. We have seen
that in a random graph with c > 1 there exists a giant component that ﬁlls
an extensive fraction of the network. That fraction is typically less than 100%,
however. What is the structure of the remainder of the network? The answer

408

12.6

|

S MALL COMPONENTS

is that it is made up of many small components whose average size is constant
and doesn’t increase with the size of the network.
The ﬁrst step in demonstrating this result and shedding light on the structure of the small components is to show that there is only one giant component
in a random graph, and hence that all other components are “non-giant” components. This is fairly easy to establish. Suppose that there were two or more
giant components in a random graph. Take any two giant components, which
have size S1 n and S2 n, where S1 and S2 are the fractions of the network ﬁlled
by each. The number of distinct pairs of vertices (i, j), where i is in the ﬁrst
giant component and j is in the second, is just S1 n × S2 n = S1 S2 n2 . Each of
these pairs is connected by an edge with probability p, or not with probability
1 − p. For the two giant components to be separate components we require
that there be zero edges connecting them together, which happens with probability q given by
q = (1 − p )

S1 S2 n 2

=

c
1−
n−1

S1 S2 n 2

,

(12.19)

where we have made use of Eq. (12.6).
Taking logs of both sides and going to the limit n → ∞, we then ﬁnd


c
2
= S1 S2 −c(n + 1) + 12 c2
ln q = S1 S2 lim n ln 1 −
n→∞
n−1


= cS1 S2 −n + 12 c − 1 ,
(12.20)
where we have dropped terms of order 1/n. Taking the exponential again, we
get
(12.21)
q = q0 e−cS1 S2 n ,
where q0 = ec(c/2−1)S1 S2 , which is independent of n if c is constant. Thus,
for constant c, the probability that the two giant components are really separate components dwindles exponentially with increasing n, and in the limit
of large n will vanish altogether. In a large random graph, therefore, there is
only the very tiniest of probabilities that we will have two giant components,
and for inﬁnite n the probability is formally zero and it will never happen.
Given then that there is only one giant component in our random graph
and that in most situations it does not ﬁll the entire network, it follows that
there must also be some non-giant components, i.e., components whose size
does not increase in proportion to the size of the network. These are the small
components.

409

R ANDOM GRAPHS

12.6.1

S IZES OF THE SMALL COMPONENTS

The small components can, in general, come in various different sizes. We can
calculate the distribution of these sizes as follows.
The basic quantity we focus on is the probability πs that a randomly chosen
vertex belongs to a small component of size exactly s vertices total. Note that
if there is a giant component in our network then some vertices do not belong
to a small component of any size and hence πs is not normalized to unity. The
sum of πs over all sizes s is equal to the fraction of vertices that are not in the
giant component. That is,
∞

∑ πs = 1 − S,

(12.22)

s =0

Recall that a tree is a graph
or subgraph that has no
loops—see Section 6.7.

If we add an edge (dashed)
to a tree we create a loop.

410

where S is, as before, the fraction of vertices in the giant component.
The crucial insight that allows us to calculate πs is that the small components are trees, as we can see by the following argument. Consider a small
component of s vertices that takes the form of a tree. A tree of s vertices contains s − 1 edges, as shown in Section 6.7, and this is the smallest number of
edges that is needed to connect this many vertices together. If we add another
edge to our component then we will create a loop, since we will be adding a
new path between two vertices that are already connected (see ﬁgure). In a
Poisson random graph the probability of such edge being present is the same
as for any other edge, p = c/(n − 1). The total number of places where we
could add such an extra edge to the component is given by the number of distinct pairs of vertices minus the number that are already connected by an edge,
or
s
− (s − 1) = 12 (s − 1)(s − 2),
(12.23)
2
and the total number of extra edges in the component is 12 (s − 1)(s − 2)c/(n −
√
1). Assuming that s increases more slowly than n (and we will shortly see
that it does), this probability tends to zero in the limit n → ∞, and hence there
are no loops in the component and the component is a tree.
We can use this observation to calculate the probability πs as follows. Consider a vertex i in a small component of a random graph, as depicted in Fig. 12.3.
Each of i’s edges leads to a separate subgraph—the shaded regions in the
ﬁgure—and because the whole component is a tree we know that these subgraphs are not connected to one another, other than via vertex i, since if they
were there would be a loop in the component and it would not be a tree. Thus
the size of the component to which i belongs is the sum of the sizes of the
subgraphs reachable along each of its edges, plus 1 for vertex i itself. To put

|

12.6

n1

S MALL COMPONENTS

n1
i

n2

n3

n3
n2

(a)

(b)

Figure 12.3: The size of one of the small components in a random graph. (a) The size of the component to which a
vertex i belongs is the sum of the number of vertices in each of the subcomponents (shaded regions) reachable via i’s
neighbors n1 , n2 , n3 , plus one for i itself. (b) If vertex i is removed the subcomponents become components in their own
right.

that another way, vertex i belongs to a component of size s if the sizes of the
subgraphs to which its neighbors n1 , n2 , . . . belong sum to s − 1.
Bearing this in mind, consider now a slightly modiﬁed network, the network in which vertex i is completely removed, along with all its edges.4 This
network is still a random graph with the same value of p—each possible edge
is still present with independent probability p—but the number of vertices has
decreased by one, from n to n − 1. In the limit of large n, however, this decrease
is negligible. The average properties, such as size of the giant component and
size of the small components will be indistinguishable for random graphs with
sizes n and n − 1, but the same p.
In this modiﬁed network, what were previously the subgraphs of our small
component are now separate small components in their own right. And since
the network has the same average properties as the original network for large n,
that means that the probability that neighbor n1 belongs to a small component of size s1 (or a subgraph of size s1 in the original network) is itself given
by πs1 . We can use this observation to develop a self-consistent expression for
4

In the statistical physics literature, this trick of removing a vertex is called a cavity method.
Cavity methods are used widely in the solution of all kinds of physics problems and are a powerful method for many calculations on lattices and in low-dimensional spaces as well as on networks [218].

411

R ANDOM GRAPHS

the probability πs .
Suppose that vertex i has degree k. As we have said, the probability that
neighbor n1 belongs to a small component of size s1 when i is removed from the
network is πs1 . So the probability P(s|k ) that vertex i belongs to a small component of size s, given that its degree is k, is the probability that its k neighbors
belong to small components of sizes s1 , . . . , sk —which is ∏kj=1 πs j —and that
those sizes add up to s − 1:


∞
∞
k


(12.24)
P(s|k ) = ∑ . . . ∑ ∏ πs j δ s − 1, ∑ j s j ,
s1 =1

s k =1 j =1

where δ(m, n) is the Kronecker delta.
To get πs , we now just average P(s|k ) over the distribution pk of the degree
thus:


∞
∞
∞
k
∞


πs = ∑ pk P(s|k ) = ∑ pk ∑ . . . ∑ ∏ πs j δ s − 1, ∑ j s j
k =0

k =0

s1 =1



s k =1 j =1



∞
k


ck ∞
. . . ∑ ∏ πs j δ s − 1, ∑ j s j ,
∑
k! s1 =1
s k =1 j =1
k =0
∞

= e− c ∑

(12.25)

where we have made use of Eq. (12.10) for the degree distribution of the random graph.
This expression would be easy to evaluate if it were not for the delta function: one could separate the terms in the product, distribute them among the
individual summations, and complete the sums in closed form. With the delta
function, however, it is difﬁcult to see how the sum can be completed.
Luckily there is a trick for problems like these, a trick that we will use many
times in the rest of this book. We introduce a generating function or z-transform,
deﬁned by
∞

h ( z ) = π1 z + π2 z2 + π3 z3 + . . . = ∑ π s z s .

(12.26)

s =1

This generating function is a polynomial or series in z whose coefﬁcients are
the probabilities πs . It encapsulates all of the information about the probability
distribution in a single function. Given h(z) we can recover the probabilities
by differentiating:
"
1 ds h ""
πs =
.
(12.27)
s! dzs "z=0

Thus h(z) is a complete representation of our probability distribution and if
we can calculate it, then we can calculate πs . We will look at generating functions in more detail in the next section, but for now let us complete the present
calculation.
412

12.6

|

S MALL COMPONENTS

We can calculate h(z) by substituting Eq. (12.25) into Eq. (12.26), which
gives


∞
∞
k
∞
k ∞


c
h ( z ) = ∑ z s e− c ∑
∑ . . . ∑ ∏ πsj δ s − 1, ∑ j s j
k!
s =1
s1 =1
s k =1 j =1
k =0


∞
k
∞
k ∞
c
= e− c ∑
. . . ∑ ∏ π s j z 1+ ∑ j s j
k! s∑
s k =1 j =1
k =0
1 =1


∞
k
∞
ck ∞
−c
sj
= ze ∑
. . . ∑ ∏ πs j z
k! s∑
s k =1 j =1
k =0
1 =1

k
∞
∞
ck ∞
ck
k
−c
s
h(z)
= ze ∑
πs z
= ze−c ∑
∑
k! s=1
k!
k =0
k =0


= z exp c h(z) − 1 .
(12.28)
Thus we have a simple, self-consistent equation for h(z) that eliminates the
awkward delta function of (12.25).
Unfortunately, like the somewhat similar Eq. (12.15), this equation doesn’t
have a known closed-form solution for h(z), but that doesn’t mean the expression is useless. In fact we can calculate many useful things from it without
solving for h(z) explicitly. For example, we can calculate the mean size of the
component to which a randomly chosen vertex belongs, which is given by
s =

h  (1)
∑s sπs
,
=
1−S
∑s πs

(12.29)

where h (z) denotes the ﬁrst derivative of h(z) with respect to its argument
and we have made use of Eqs. (12.22) and (12.26). (The denominator in this
expression is necessary because πs is not normalized to 1.)
From Eq. (12.28) we have




h (z) = exp c h(z) − 1 + czh (z) exp c h(z) − 1

=

h(z)
+ ch(z)h (z),
z

or, rearranging,
h (z) =

(12.30)

h(z)
,
z[1 − ch(z)]

(12.31)

h (1)
.
1 − ch(1)

(12.32)

and thus
h  (1) =

413

R ANDOM GRAPHS

But h(1) = ∑s πs = 1 − S, from Eqs. (12.22) and (12.26), so that
h  (1) =

1−S
.
1 − c + cS

(12.33)

And so the average size s of Eq. (12.29) becomes
s =

1
.
1 − c + cS

(12.34)

When c < 1 and there is no giant component, this gives simply s =
1/(1 − c). When there is a giant component, the behavior is more complicated,
because we have to solve for S ﬁrst before ﬁnding the value of s , but the calculation can still be done. We ﬁrst solve Eq. (12.15) for S and then substitute
into Eq. (12.34).
It’s interesting to note that Eq. (12.34) diverges when c = 1. (At this point
S = 0, so the denominator vanishes.) Thus, if we slowly increase the mean degree c of our network from some small initial value less than 1, the average size
of the component to which a vertex belongs gets bigger and bigger and ﬁnally
becomes inﬁnite exactly at the point where the giant component appears. For
c > 1 Eq. (12.34) measures only the sizes of the non-giant components and the
equation tells us that these get smaller again above c = 1. Thus the general picture we have is in one in which the small components get larger up to c = 1,
where they diverge and the giant component appears, then smaller again as
the giant component grows larger. Figure 12.4 shows a plot of s as a function
of c with the divergence clearly visible.
Although the random graph is certainly not a realistic model of most networks, this general picture of the component structure of the network turns out
to be a good guide to the behavior of networks in the real world. If a network
has a low density of edges then typically it consists only of small components,
but if the density is becomes enough then a single large component forms,
usually accompanied by many separate small ones. Moreover, the small components tend on average to be smaller if the largest component is very large.
This is a good example of the way in which simple models of networks can
give us a feel for how more complicated real-world systems should behave in
general.
12.6.2

AVERAGE SIZE OF A SMALL COMPONENT

A further important point to notice about Eq. (12.34) is that the average size
of the small components does not grow with the number of vertices n. The
typical size of the small components in a random graph remains constant as
414

12.6

|

S MALL COMPONENTS

8

Size

6

4

2

0

0

1

2

3

Mean degree c

Figure 12.4: Average size of the small components in a random graph. The upper
curve shows the average size s of the component to which a randomly chosen vertex
belongs, calculated from Eq. (12.34). The lower curve shows the overall average size R
of a component, calculated from Eq. (12.40). The dotted vertical line marks the point
c = 1 at which the giant component appears. Note that, as discussed in the text, the
upper curve diverges at this point but the lower one does not.

the graph gets larger. We must, however, be a little careful with these statements. Recall that πs is the probability that a randomly chosen vertex belongs
to a component of size s, and hence s as calculated here is not strictly the
average size of a component, but the average size of the component to which a
randomly chosen vertex belongs. Because larger components have more vertices in them, the chances of landing on them when we choose a random vertex
is larger, in proportion to their size, and hence s is a biased estimate of the
actual average component size. To get a correct ﬁgure for the average size of a
component we need to make a slightly different calculation.
Let ns be the actual number of components of size s in our random graph.
Then the number of vertices that belong to components of size s is sns and
hence the probability of a randomly chosen vertex belonging to such a component is
sns
.
(12.35)
πs =
n
415

R ANDOM GRAPHS

The average size of a component, which we will denote R, is
R=

1−S
n ∑s πs
∑s sns
=
=
,
n ∑s πs /s
∑s ns
∑s πs /s

(12.36)

where we have made use of Eq. (12.22). The remaining sum we can again
evaluate using our generating function by noting that
 1
0

∞
h(z)
dz = ∑ πs
z
s =1

 1
0

∞

πs
.
s =1 s

zs−1 dz = ∑

(12.37)

A useful expression for h(z)/z can be obtained by rearranging Eq. (12.31) to
yield
dh
h(z)
,
(12.38)
= 1 − ch(z)
z
dz
and hence we ﬁnd that
∞

πs
∑ s =
s =1

 1
0

dh
1 − ch(z)
dz =
dz

 1− S
0

(1 − ch) dh

= 1 − S − 12 c(1 − S)2 ,

(12.39)

where we have used h(1) = ∑s πs = 1 − S for the upper integration limit.
Substituting this result into Eq. (12.36), we ﬁnd that the average component
size is
2
.
(12.40)
R=
2 − c + cS
As with Eq. (12.34), this expression is independent of n, so the average size of
a small component indeed does not grow as the graph becomes large.
On the other hand, R does not diverge at c = 1 as s does. At c = 1,
with S = 0, Eq. (12.40) gives just R = 2. The reason for this is that, while the
largest component in the network for c = 1 does become inﬁnite in the limit of
large n, so also does the total number of components. So the average size of a
component is the ratio of two diverging quantities. Depending on the nature
of the divergences, such a ratio could be inﬁnite itself, or zero, or ﬁnite but nonzero in the special case where the two divergences have the same asymptotic
form. In this instance the latter situation holds—both quantities are diverging
linearly with n—and the average component size remains ﬁnite. A plot of R is
included in Fig. 12.4 for comparison with s .
12.6.3

T HE COMPLETE DISTRIBUTION OF COMPONENT SIZES

So far we have calculated the average size of a small component in the random
graph, but not the individual probabilities πs that specify the complete distribution of sizes. In principle, we should be able to calculate the πs by solving
416

12.6

|

S MALL COMPONENTS

Eq. (12.28) for the generating function h(z) and then differentiating according
to Eq. (12.27) to get πs . Unfortunately we cannot follow this formula in practice
because, as mentioned above, Eq. (12.28) does not have a known solution.
Remarkably, however, it turns out that we can still calculate the values of
the individual πs , by an alternative route. The calculations involve some more
advanced mathematical techniques and if you are not particularly interested
in the details it will do no harm to skip this section. If you’re interested in this
rather elegant development, however, read on.
To calculate an explicit expression for the probabilities πs of the component
sizes we make use of a beautiful result from the theory of complex variables,
the Lagrange inversion formula. The Lagrange inversion formula is a formula
that allows the explicit solution of equations of the form
f (z) = zφ( f (z))

(12.41)

for the unknown function f (z), where φ( f ) is a known function which at f = 0
is ﬁnite, non-zero, and differentiable.
Equation (12.41) has precisely the form of the equation for our generating
function, Eq. (12.28). What’s more, the Lagrange formula gives a solution for
f (z) in terms of the coefﬁcients of the series expansion of f (z) in powers of z,
which is precisely what we want in the present case, since the coefﬁcients are
the probabilities πs , which is what we want to calculate. The Lagrange formula
is thus perfectly suited to the problem in hand. Here we ﬁrst derive the general
form of the formula then apply it to the current problem.5
Let us write the function f (z) in Eq. (12.41) as a series expansion thus:
∞

f (z) = ∑ as zs ,

(12.42)

s =1

The coefﬁcient as in this expansion is given explicitly by
"


1 ds f ""
1 ds −1 d f
as =
=
.
s! dzs−1 dz
s! dzs "z=0
z =0

(12.43)

Cauchy’s formula for the nth derivative of a function g(z) at z = z0 says that
"
&
n!
g(z)
dn g ""
=
dz,
(12.44)
( z − z 0 ) n +1
dzn "z=z0
2πi
5

The formula derived here is not the most general form of the Lagrange inversion formula. It
is adequate for the particular problem we are interested in solving, but the full Lagrange inversion formula is even more powerful, and can solve a broader range of problems. For details, see
Wilf [329].

417

R ANDOM GRAPHS

where the integral is around a contour that encloses z0 in the complex plane
but encloses no poles in g(z). We will use an inﬁnitesimal circle around z0 as
our contour.
Applying Cauchy’s formula to (12.43) with g(z) = f  (z), z0 = 0, and n =
s − 1, we get
&
&
1
1 df
1
df
dz
=
,
(12.45)
as =
s
2πis
z dz
2πis
zs
where the second integral is now around a contour in f rather than z. In this
equation we are now thinking of z as being a function of f , z = z( f ), rather
than the other way around. We are perfectly entitled to do this—knowing
either quantity speciﬁes the value of the other.6
It will be important later that the contour followed by f surrounds the origin, so let us pause for a moment to demonstrate that it does. Our choice of
contour for z in the ﬁrst integral of Eq. (12.45) is an inﬁnitesimal circle around
the origin. Expanding Eq. (12.41) to leading order around the origin, we ﬁnd
that
f (z) = zφ( f (0)) + O(z2 ) = zφ(0) + O(z2 ),

(12.46)

where we have made use of the fact that f (0) = 0, which is easily seen from
Eq. (12.41) given that φ( f ) is non-zero and ﬁnite at f = 0 by hypothesis. In
the limit of small |z| where the terms of order z2 can be neglected, Eq. (12.46)
implies that f traces a contour about the origin if z does, since the two are
proportional to one another.
We now rearrange our original equation, Eq. (12.41), to give the value of z
in terms of f thus
f
,
(12.47)
z( f ) =
φ( f )
and then substitute into Eq. (12.45) to get
as =

1
2πis

&

[φ( f )]s
df.
fs

(12.48)

Since, as we have said, the contour encloses the origin, this expression can be
written in terms of a derivative evaluated at the origin by again making use of
Cauchy’s formula, Eq. (12.44):


1 ds −1
s
[φ( f )]
.
(12.49)
as =
s! d f s−1
f =0
6
The situation gets complicated if z( f ) is many-valued for some f , i.e., if f (z) is nonmonotonic. In our case, however, where the coefﬁcients in the expansion of f (z) are necessarily all non-negative because they are probabilities, f (z) is monotonically increasing and no such
problems arise.

418

12.7

0.4

|

PATH LENGTHS

c = 0.75

Probability πs

0.2

0

0.2

c = 1.5

0.1

0

1

2

3

4

5

6

7

8

9

10

Figure 12.5: Sizes of small components in the
random graph. This plot shows the probability πs that a randomly chosen vertex belongs
to a small component of size s in a Poisson
random graph with c = 0.75 (top), which is in
the regime where there is no giant component,
and c = 1.5 (bottom), where there is a giant
component.

Component size s

This is the Lagrange inversion formula. This remarkably simple formula gives
us, in effect, a complete series solution to Eq. (12.41).
To apply the formula to the current problem, of the component size distribution for the random graph, we set f (z) → h(z) and φ( f ) → ec(h−1) . Then the
coefﬁcients πs of h(z) are given by


1 ds−1 sc(h−1)
e−sc (sc)s−1
.
e
=
πs =
s! dhs−1
s!
h =0

(12.50)

These are the probabilities that a randomly chosen vertex belongs to a small
component of size s in a random graph with mean degree c. Figure 12.5 shows
the shape of πs as a function of s for two different values of c. As the plot
shows, the distribution is heavily skewed, with many components of small
size and only a few larger ones.

12.7

PATH LENGTHS

In Sections 3.6 and 8.2 we discussed the small-world effect, the observation
that the typical lengths of paths between vertices in networks tend to be short.
Most people ﬁnd the small-world effect surprising upon ﬁrst learning about it.

419

R ANDOM GRAPHS

See Section 6.10.1 for a discuss of geodesic distances
and diameters.

420

We can use the random graph model to shed light on how the effect arises by
examining the behavior of the network diameter in the model.
Recall that the diameter of a network is the longest geodesic distance between any two vertices in the same component of the network. As we now
show, the diameter of a random graph varies with the number n of vertices as
ln n. Since ln n is typically a relatively small number even when n is large, this
offers some explanation of the small-world effect, although it also leaves some
questions open, as discussed further below.
The basic idea behind the estimation of the diameter of a random graph is
simple. As discussed in Section 12.5, the average number of vertices s steps
away from a randomly chosen vertex in a random graph is cs . Since this number grows exponentially with s it doesn’t take very many such steps before the
number of vertices reached is equal to the total number of vertices in the whole
network; this happens when cs ≃ n or equivalently s ≃ ln n/ ln c. At this point,
roughly speaking, every vertex is within s steps of our starting point, implying
that the diameter of the network is approximately ln n/ ln c.
Although the random graph is, as we have said, not an accurate model of
most real-world networks, this is, nonetheless, believed to be the basic mechanism behind the small-world effect in most networks: the number of vertices
within distance s of a particular starting point grows exponentially s and hence
the diameter is logarithmic in n. We discuss the comparison with real-world
networks in more detail below.
The argument above is only approximate. It’s true that there are on average
cs vertices s steps away from any starting point so long as s is small. But once
cs becomes comparable with n the result has to break down since clearly the
number of vertices at distance s cannot exceed the number of vertices in the
whole graph. (Indeed it cannot exceed the number in the giant component.)
One way to deal with this problem is to consider two different starting
vertices i and j. The average numbers of vertices s and t steps from them
respectively will then be equal to cs and ct so long as we stay in the regime
where both these numbers are much less than n. In the following calculation
we consider only conﬁgurations in which both remain smaller than order n in
the limit n → ∞ so as to satisfy this condition.
The situation we consider is depicted in Fig. 12.6, with the two vertices i
and j each surrounded by a “ball” or neighborhood consisting of all vertices
with distances up to and including s and t respectively. If there is an edge between the “surface” (i.e., most distant vertices) of one neighborhood and the
surface of the other, as depicted by the dashed line, then it is straightforward
to show that there is also an edge between the surfaces of any pair of neighborhoods with larger s or t (or both). Turning that statement around, if there

12.7

i

|

PATH LENGTHS

j

t =2
s=3

Figure 12.6: Neighborhoods of two vertices in a random graph. In the argument given
in the text we consider the sets of vertices within distances s and t respectively of two
randomly chosen vertices i and j. If there is an edge between any vertex on the surface
of one neighborhood and any vertex on the surface of the other (dashed line), then there
is a path between i and j of length s + t + 1.

is no edge between the surfaces of our neighborhoods, then there is also no
edge between any smaller neighborhoods, which means that the shortest path
between i and j must have length greater than s + t + 1. The reverse is also
trivially true, that a shortest path longer than s + t + 1 implies there is no edge
between our surfaces. Thus the absence of an edge between the surfaces is
a necessary and sufﬁcient condition for the distance dij between i and j to be
greater than s + t + 1. This in turn implies that the probability P(dij > s + t + 1)
is equal to the probability that there is no edge between the two surfaces.
There are on average cs × ct pairs of vertices such that one lies on each
surface, and each pair is connected with probability p = c/(n − 1) ≃ c/n
(assuming n to be large) or not with probability 1 − p. Hence P(dij > s + t +
s+t
1) = (1 − p)c . Deﬁning for convenience  = s + t + 1, we can also write this
as
$
c %c−1
−1
P(dij > ) = (1 − p)c = 1 −
.
(12.51)
n
Taking logs of both sides, we ﬁnd
$
c%
c
ln P(dij > ) = c−1 ln 1 −
≃− ,
n
n

(12.52)

421

R ANDOM GRAPHS

where the approximate inequality becomes exact as n → ∞. Thus in this limit
P(dij > ) = exp −

c
.
n

(12.53)

The diameter of the network is the smallest value of  such that P(dij > )
is zero, i.e., the value such that no matter which pair of vertices we happen to
pick there is zero chance that they will be separated by a greater distance. In
the limit of large n, Eq. (12.53) will tend to zero only if c grows faster than n,
meaning that our smallest value of  is the value such that c = an1+ with
a constant and  → 0 from above. Note that we can, as promised, achieve
this while keeping both cs and ct smaller than order n, so that our argument
remains valid.
Rearranging for , we now ﬁnd our expression for the diameter:

=

ln a
(1 + ) ln n
ln n
,
+ lim
= A+
ln c →0
ln c
ln c

(12.54)

where A is a constant.7 Apart from the constant, this is the same result as
we found previously using a rougher argument. The constant is known—it
has a rather complicated value in terms of the Lambert W-function [114]—but
for our purposes the important point is that it is (asymptotically) independent
of n. Thus the diameter indeed increases only slowly with n, as ln n, making it
relatively small in large random graphs.
The logarithmic dependence of the diameter on n offers some explanation
of the small-world effect of Section 3.6. Even in a network such as the acquaintance network of the entire world, with nearly seven billion inhabitants (at the
time of writing), the value of ln n/ ln c can be quite small. Supposing each
person to have about a thousand acquaintances,8 we would get

=

ln n
ln 6 × 109
=
= 3.3 . . . ,
ln c
ln 1000

(12.55)

which is easily small enough to account for the results of, for example, the
small-world experiments of Milgram and others [93, 219, 311].
7

There are still some holes in our argument. In particular, we have assumed that the product of
the numbers of vertices on the surface of our two neighborhoods is cs+t when in practice this is only
the average value and there will in general be some variation. Also the calculation should really
be conﬁned to the giant component, since the longest path always falls in the giant component
in the limit of large n. For a careful treatment of these issues see, for instance, Fernholz and
Ramachandran [114].
8
This appears to be a reasonable ﬁgure. Bernard et al. [36] estimated the typical number of
acquaintances for people in the United States to be about 2000—see Section 3.2.1.

422

12.8

|

P ROBLEMS WITH THE RANDOM GRAPH

On the other hand, although this calculation gives us some insight into the
nature of the small-world effect, this cannot be the entire explanation. There
are clearly many things wrong with the random graph as a model of real social
networks, as we now discuss.

12.8

P ROBLEMS WITH THE RANDOM GRAPH

The Poisson random graph is one of the best studied models of networks. In
the half century since its ﬁrst proposal it has given us a tremendous amount of
insight into the expected structure of networks of all kinds, particularly with
respect to component sizes and network diameters. The fact that it is both
simple to describe and straightforward to study using analytic methods makes
it an excellent tool for investigating all sorts of network phenomena. We will
return to the random graph many times in the remainder of this book to help
us understand the way networks behave.
The random graph does, however, have some severe shortcomings as a
network model. There are many ways in which it is completely unlike the realworld networks we have seen in the previous chapters. One clear problem is
that it shows essentially no transitivity or clustering. In Section 12.4 we saw at
the clustering coefﬁcient of a random graph is C = c/(n − 1), which tends to
zero in the limit of large n. And even for the ﬁnite values of n appropriate to
real-world networks the value of C in the random graph is typically very small.
For the acquaintance network of the human population of the world, with its
n ≃ 7 billion people, each having about 1000 acquaintances [175], a random
graph with the same n and c would have a clustering coefﬁcient of
C≃

1000
≃ 10−7 .
7 000 000 000

(12.56)

Whether the clustering coefﬁcient of the real acquaintance network is 0.01 or
0.5 hardly matters. (It is probably somewhere in between.) Either way it is
clear that the random graph and the true network are in strong disagreement.9
The random graph also differs from real-world networks in many other
ways. For instance, there is no correlation between the degrees of adjacent
vertices—necessarily so, since the edges are placed completely at random. The
degrees in real networks, by contrast, are usually correlated, as discussed in
Section 8.7. Many, perhaps most, real-world networks also show grouping of
9
This disagreement, highlighted particularly by Watts and Strogatz [323], was one of the observations that prompted the current wave of interest in the properties of networks in the mathematical sciences, starting in the late 1990s.

423

R ANDOM GRAPHS

Fraction of vertices with degree k

0.4

Internet
Poisson distribution

0.3

0.2

0.1

0

10

5

Degree k

Figure 12.7: Degree distribution of the Internet and a Poisson random graph. The
dark bars in this plot show the fraction of vertices with the given degrees in the network
representation of the Internet at the level of autonomous systems. The lighter bars
represent the same measure for a random graph with the same average degree as the
Internet. Even though the two distributions have the same averages, it is clear that they
are entirely different in shape.

their vertices into “communities,” as discussed on Section 11.2.1, but random
graphs have no such structure. And there are many other examples of interesting structure in real networks that is absent from the random graph.
However, perhaps the most signiﬁcant respect in which the properties of
random graphs diverge from those of real-world networks is the shape of their
degree distribution. As discussed in Section 8.3, real networks typically have
right-skewed degree distributions, with most vertices having low degree but
with a small number of high-degree “hubs” in the tail of the distribution. The
random graph on the other hand has a Poisson degree distribution, Eq. (12.10),
which is not right-skewed to any signiﬁcant extent. Consider Fig. 12.7, for
example, which shows a histogram of the degree distribution of the Internet
(darker bars), measured at the level of autonomous systems (Section 2.1.1).
The right-skewed form is clearly visible in this example. On the same ﬁgure
we show the Poisson degree distribution of a random graph (lighter bars) with
the same average degree c as the Internet example. Despite having the same
averages, the two distributions are clearly entirely different. It turns out that

424

P ROBLEMS

this difference has a profound effect on all sorts of properties of the network—
we will see many examples in this book. This makes the Poisson random graph
inadequate to explain many of the interesting phenomena we see in networks
today, including resilience phenomena, epidemic spreading processes, percolation, and many others.
Luckily it turns out to be possible to generalize the random graph model to
allow for non-Poisson degree distributions. This development, which leads to
some of the most beautiful results in the mathematics of networks, is described
in the next chapter.

P ROBLEMS
12.1

Consider the random graph G (n, p) with mean degree c.

a) Show that in the limit of large n the expected number of triangles in the network
is 61 c3 . This means that the number of triangles is constant, neither growing nor
vanishing in the limit of large n.
b) Show that the expected number of connected triples in the network (as deﬁned on
page 200) is 12 nc2 .
c) Hence calculate the clustering coefﬁcient C, as deﬁned in Eq. (7.41), and conﬁrm
that it agrees for large n with the value given in Eq. (12.11).
12.2

Consider the random graph G (n, p) with mean degree c.

a) Argue that the probability that a vertex of degree k belongs to a small component
is (1 − S)k , where S is the fraction of the network occupied by the giant component.
b) Thus, using Bayes’ theorem (or otherwise) show that the fraction of vertices in
small components that have degree k is e−c ck (1 − S)k−1 /k!.
12.3 Starting from the generating function h(z) deﬁned in Eq. (12.26), or otherwise,
show that
a) the mean-square size of the component in a random graph to which a randomly
chosen vertex belongs is 1/(1 − c)3 in the regime where there is no giant component;
b) the mean-square size of a randomly chosen component in the same regime is
1/[(1 − c)(1 − 12 c)].
Note that both quantities diverge at the phase transition where the giant component
appears.

425

R ANDOM GRAPHS

12.4 In Section 7.8.2 we introduced the idea of a bicomponent. A vertex in a random
graph belongs to a bicomponent if two or more of its neighbors belong to the giant
component of the network (since the giant component completes a loop between those
neighbors forming a bicomponent). In principle, a vertex can also be in a bicomponent
if two or more of its neighbors belong to the same small component, but in practice this
never happens, since that would imply that the small component in question contained
a loop and, as we have seen, the small components in a random graph are trees and so
have no loops.
a) Show that the fraction of vertices in a random graph that belong to a bicomponent
is S2 = (1 − cu)(1 − u), where u is deﬁned by Eq. (12.14).
b) Show that this expression can be rewritten as S2 = S + (1 − S) ln(1 − S), where S
is the size of the giant component.
c) Hence argue that the random graph contains a giant bicomponent whenever it
contains an ordinary giant component.
12.5 The cascade model is a simple mathematical model of a directed acyclic graph,
sometimes used to model food webs. We take n vertices labeled i = 1 . . . n and place an
undirected edge between each distinct pair with independent probability p, just as in
the ordinary random graph. Then we add directions to the edges such that each edge
runs from the vertex with numerically higher label to the vertex with lower label. This
ensures that all directed paths in the network run from higher to lower labels and hence
that the network is acyclic, as discussed in Section 6.4.2.
a) Show that the average in-degree of vertex i in the ensemble of the cascade model
= (n − i) p and the average out-degree is kout
= (i − 1) p.
is kin
i
i
b) Show that the expected number of edges that connect to vertices i and lower from
vertices above i is (ni − i2 ) p.
c) Assuming n is even, what are the largest and smallest values of this quantity and
where do they occur?
In a food web this expected number of edges from high- to low-numbered vertices is a
rough measure of energy ﬂow and the cascade model predicts that energy ﬂow will be
largest in the middle portions of a food web and smallest at the top and bottom.
12.6 We can make a simple random graph model of a network with clustering or transitivity as follows. We take n vertices and go through each distinct trio of three vertices,
of which there are (n3 ), and with independent probability p we connect the members
of the trio together using three edges to form a triangle, where p = c/(n−2 1) with c a
constant.
a) Show that the mean degree of a vertex in this model network is 2c.
b) Show that the degree distribution is
 −c k/2
e c /(k/2)!
pk =
0

if k is even,
if k is odd.

c) Show that the clustering coefﬁcient, Eq. (7.41), is C = 1/(2c + 1).

426

P ROBLEMS

d) Show that when there is a giant component in the network its expected size S as
a fraction of network size satisﬁes S = 1 − e−cS(2−S) .
e) What is the value of the clustering coefﬁcient when the giant component ﬁlls half
of the network?

427

C HAPTER 13

R ANDOM GRAPHS WITH GENERAL DEGREE
DISTRIBUTIONS
This chapter describes more sophisticated random graph
models that mimic networks with arbitrary degree
distributions

I

N THE previous chapter we looked at the classic random graph model, in

which pairs of vertices are connected at random with uniform probabilities. Although this model has proved tremendously useful as a source of insight into the structure of networks, it also has, as described in Section 12.8, a
number of serious shortcomings. Chief among these is its degree distribution,
which follows the Poisson distribution and is quite different from the degree
distributions seen in most real-world networks. In this chapter we show how
we can create more sophisticated random graph models, which incorporate arbitrary degree distributions and yet are still exactly solvable for many of their
properties in the limit of large network size.
The fundamental mathematical tool that we will use to derive the results
of this chapter is the probability generating function. We have already seen in
Section 12.6 one example of a generating function, which was useful in the calculation of the distribution of component sizes in the Poisson random graph.
We begin this chapter with a more formal introduction to generating functions
and to some of their properties which will be useful in later calculations. Readers interested in pursuing the mathematics of generating functions further may
like to look at the book by Wilf [329].1
1
Professor Wilf has generously made his book available for free in electronic form. You can
download it from www.math.upenn.edu/~wilf/DownldGF.html.

428

13.1

13.1

|

G ENERATING FUNCTIONS

G ENERATING FUNCTIONS

Suppose we have a probability distribution for a non-negative integer variable, such that separate instances, occurrences, or draws of this variable are
independent and have value k with probability pk . A good example of such a
distribution is the distribution of the degrees of randomly chosen vertices in a
network. If the fraction of vertices in a network with degree k is pk then pk is
also the probability that a randomly chosen vertex from the network will have
degree k.
The generating function for the probability distribution pk is the polynomial
∞

g ( z ) = p0 + p1 z + p2 z2 + p3 z3 + . . . = ∑ p k z k .

(13.1)

k =0

Sometimes a function of this kind is called a probability generating function to
distinguish it from another common type of function, the exponential generating
function. We will not use exponential generating functions in this book, so for
us all generating functions will be probability generating functions.
If we know the generating function for a probability distribution pk then
we can recover the values of pk by differentiating:
"
1 dk g ""
.
(13.2)
pk =
k! dzk "z=0
Thus the generating function gives us complete information about the probability distribution and vice versa. The distribution and the generating function
are really just two different representations of the same thing. As we will see,
it is easier in many cases to work with the generating function than with the
probability distribution and doing so leads to many useful new results about
networks.
13.1.1

E XAMPLES

Right away let us look at some examples of generating functions. Suppose
our variable k takes only the values 0, 1, 2, and 3, with probabilities p0 , p1 ,
p2 , and p3 , respectively, and no other values. In that case the corresponding
generating function would take the form of a cubic polynomial:
g ( z ) = p0 + p1 z + p2 z2 + p3 z3 .

(13.3)

For instance, if we had a network in which vertices of degree 0, 1, 2, and 3
occupied 40%, 30%, 20%, and 10% of the network respectively then
g(z) = 0.4 + 0.3 z + 0.2 z2 + 0.1 z3 .

(13.4)
429

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

As another example, suppose that k follows a Poisson distribution with
mean c:
ck
(13.5)
p k = e− c .
k!
Then the corresponding generating function would be
∞

(cz)k
= ec ( z −1) .
k!
k =0

g ( z ) = e− c ∑

(13.6)

Alternatively, suppose that k follows an exponential distribution of the form
pk = C e−λk ,

(13.7)

with λ > 0. The normalizing constant is ﬁxed by the condition that ∑k pk = 1,
which gives C = 1 − e−λ and hence
pk = (1 − e−λ ) e−λk .
Then

∞

g ( z ) = (1 − e− λ ) ∑ (e− λ z ) k =
k =0

(13.8)
eλ − 1
,
eλ − z

(13.9)

so long as z < eλ . (If z ≥ eλ the generating function diverges. Normally,
however, we will be interested in generating functions only in the range 0 ≤
z ≤ 1 so, given that λ > 0 and hence eλ > 1, the divergence at eλ will not be a
problem.)
13.1.2

P OWER - LAW DISTRIBUTIONS

One special case of particular interest in the study of networks is the powerlaw distribution. As we saw in Section 8.4, a number of networks, including
the World Wide Web, the Internet, and citation networks, have degree distributions that follow power laws quite closely and this turns out to have interesting consequences that set these networks apart from others. To create and
solve models of these networks it will be important for us to be able to write
down generating functions for power-law distributions.
There are various forms that are used to represent power laws in practice
but the simplest choice, which we will use in many of our calculations, is the
“pure” power law
(13.10)
pk = C k −α ,
for constant α > 0. This expression cannot apply all the way down to k = 0,
however, or it would diverge. So commonly one stops at k = 1. The normalization constant C can then be calculated from the condition that ∑k pk = 1,
430

13.1

which gives

|

G ENERATING FUNCTIONS

∞

C ∑ k−α = 1.

(13.11)

k =1

The sum unfortunately cannot be performed in closed form. It is, however, a
common enough sum that it has a name—it is called the Riemann zeta function,
denoted ζ (α):
∞

ζ ( α ) = ∑ k −α .

(13.12)

k =1

Thus we can write C = 1/ζ (α) and

0
pk =
k−α /ζ (α)

for k = 0,
for k ≥ 1.

(13.13)

Although there is no closed-form expression for the zeta function, there exist
good numerical methods for calculating its value accurately, and many programming languages and numerical software packages include functions to
calculate it.
For this probability distribution the generating function is
g(z) =

1 ∞ −α k
k z.
ζ (α) k∑
=1

(13.14)

Again the sum cannot be expressed in closed form, but again it has a name—it
is called the polylogarithm of z and is denoted Liα (z):
∞

Liα (z) = ∑ k−α zk .

(13.15)

k =1

Thus we can write
g(z) =

Liα (z)
.
ζ (α)

(13.16)

This is not completely satisfactory. We would certainly prefer a closed-form
expression as in the case of the Poisson and exponential distributions of Eqs.
(13.6) and (13.9). But we can live with it. Enough properties of the polylogarithm and zeta functions are known that we can carry out useful manipulations
of the generating function. In particular, since derivatives of our generating
functions will be important to us, we note the following useful relation:
∞
∂ ∞ −α k
Liα−1 (z)
∂ Liα (z)
.
=
k z = ∑ k−(α−1) zk−1 =
∑
∂z
∂z k=1
z
k =1

(13.17)

We should note also that in real-world networks the degree distribution
does not usually follow a power law over its whole range—the distribution
431

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

is not a “pure” power law in the sense above. Instead, it typically obeys a
power law reasonably closely for values of k above some minimum value kmin
but below that point it has some other behavior. In this case the generating
function will take the form
∞

g(z) = Qkmin −1 (z) + C ∑ k−α zk ,

(13.18)

k =kmin

where Qn (z) = ∑nk=0 pk zk is a polynomial in z of degree n and C is a normalizing constant. The sum in Eq. (13.18) also has its own name: it is called the Lerch
transcendent.2 In the calculations in this book we will stick to the pure power
law, since it illustrates nicely the interesting properties of power-law degree
distributions and is relatively simple to deal with, but for serious modeling
one might sometimes have to use the cut-off form, Eq. (13.18).
13.1.3

N ORMALIZATION AND MOMENTS

Let us now look brieﬂy at some of the properties of generating functions that
will be useful to us. First of all, note that if we set z = 1 in the deﬁnition of the
generating function, g(z) = ∑k pk zk (Eq. (13.1)), we get
∞

g (1) = ∑ p k .

(13.19)

k =0

If the probability distribution is normalized to unity, ∑k pk = 1, as are all the
examples above, then this immediately implies that
g(1) = 1.

(13.20)

For most of the generating functions we will look at, this will be true, but not
all. As a counter-example, consider the generating function for the sizes of the
small components in the Poisson random graph deﬁned in Eq. (12.26). The
probabilities πs appearing in this generating function were the probabilities
that a randomly chosen vertex belongs to a small component of size s. If we
are in the regime where there is a giant component in the network then not all
vertices belong to a small component, and hence the probabilities πs do not
add up to one. In fact, their sum is equal to the fraction of vertices not in the
giant component.
The derivative of the generating function g(z) of Eq. (13.1) is
∞

g (z) = ∑ kpk zk−1 .
k =0

2

432

No, really. I’m not making this up.

(13.21)

13.1

|

G ENERATING FUNCTIONS

(We will use the primed notation g (z) for derivatives of generating functions
extensively in this chapter, as it proves much less cumbersome than the more
common notation dg/dz.)
If we set z = 1 in Eq. (13.21) we get
∞

g (1) = ∑ kpk = k ,

(13.22)

k =0

which is just the average value of k. Thus, for example, if pk is a degree distribution, we can calculate the average degree directly from the generating function by differentiating. This is a very convenient trick. In many cases we will
calculate a probability distribution of interest by calculating ﬁrst its generating
function. In principle, we can then extract the distribution itself by applying
Eq. (13.2) and so derive any other quantities we want such as averages. But
Eq. (13.22) shows us that we don’t always have to do this. Some of the quantities we will be interested in can be calculated directly from the generating
function without going through any intermediate steps.
In fact, this result generalizes to higher moments of the probability distribution as well. For instance, note that
z

∞

dg
d
z
dz
dz

= ∑ k2 pk zk ,

(13.23)

k =0

and hence, setting z = 1, we can write

k

=

2

d
z
dz



2

g(z)

.

(13.24)

z =1

It is not hard to show that this result generalizes to all higher moments as well:

km =
This result can also be written as
k

13.1.4

m

z

d
dz



m

g(z)

.

(13.25)

z =1

"
dm g ""
=
.
d(ln z)m "z=1

(13.26)

P OWERS OF GENERATING FUNCTIONS

Perhaps the most useful property of generating functions—and the one that
makes them important for the study of networks—is the following. Suppose
we are given a distribution pk with generating function g(z). And suppose
433

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

we have m integers k i , i = 1 . . . m, which are independent random numbers
drawn from this distribution. For instance, they could be the degrees of m
randomly chosen vertices in a network with degree distribution pk . Then the
probability distribution of the sum ∑im=1 k i of those m integers has generating
function [ g(z)]m . This is a very powerful result and it is worth taking a moment
to see how it arises and what it means.
Given that our integers are independently drawn from the distribution pk ,
the probability that they take a particular set of values {k i } is simply ∏i pki and
the probability πs that the values drawn add up to a speciﬁc sum s is the sum
of these probabilities over all sets {k i } that add up to s:
∞
∞


πs = ∑ . . . ∑ δ s, ∑i k i ∏im=1 pki ,
k 1 =0

(13.27)

k m =0

where δ( a, b) is the Kronecker delta. Then the generating function h(z) for the
distribution πs is
∞

h(z) = ∑ πs zs
s =0
∞

∞
∞


= ∑ zs ∑ . . . ∑ δ s, ∑i k i ∏im=1 pki
s =0
∞

k 1 =0
∞

k m =0

m

= ∑ . . . ∑ z ∑i k i ∏ p k i
k 1 =0

k m =0

∞

∞

i =1

m

= ∑ . . . ∑ ∏ pki zki =
k 1 =0

= g(z)

k m =0 i =1
m

.



∞

m

∑ pk zk

k =0

(13.28)

Thus, for example, if we know the degree distribution of a network, it is a
straightforward matter to calculate the probability distribution of the sum of
the degrees of m randomly chosen vertices from that network. This will turn
out to be important in the developments that follow.

13.2

T HE CONFIGURATION MODEL

Let us turn now to the main topic of this chapter, the development of the theory
of random graphs with general degree distributions.
We can turn the random graph of Chapter 12 into a much more ﬂexible
model for networks by modifying it so that the degrees of its vertices are no
longer restricted to having a Poisson distribution, and in fact it is possible to
434

13.2

|

T HE CONFIGURATION MODEL

modify the model so as to give the network any degree distribution we please.
Just as with the Poisson random graph, which can be deﬁned in several slightly
different ways, there is more than one way to deﬁne random graphs with general degree distributions. Here we describe two of them, which are roughly
the equivalent of the G (n, m) and G (n, p) random graphs of Section 12.1.
The most widely studied of the generalized random graph models is the
conﬁguration model. The conﬁguration model is actually a model of a random
See Section 8.3 for a disgraph with a given degree sequence, rather than degree distribution. That is,
cussion of the distinction
the exact degree of each individual vertex in the network is ﬁxed, rather than
between degree sequences
merely the probability distribution from which those degrees are chosen. This
and degree distributions.
in turn ﬁxes the number of edges in the network, since the number of edges
is given by Eq. (6.21) to be m = 12 ∑i k i . Thus this model is in some ways
analogous to G (n, m), which also ﬁxes the number of edges. (It is quite simple,
however, to modify the model for cases where only the degree distribution is
known and not the exact degree sequence. We describe how this is done at the
end of this section.)
Suppose then that we specify the degree k i that each vertex i = 1 . . . n in our network is to take. We can create a
random network with these degrees as follows. We give each
vertex i a total of k i “stubs” of edges as depicted in Fig. 13.1.
There are ∑i k i = 2m stubs in total, where m is the total number of edges. Then we choose two of the stubs uniformly at
random and we create an edge by connecting them to one another, as indicated by the dashed line in the ﬁgure. Then we
choose another pair from the remaining 2m − 2 stubs, connect
those, and so on until all the stubs are used up. The end reFigure 13.1: The conﬁguration model. Each
sult is a network in which every vertex has exactly the desired
vertex is given a number of “stubs” of edges
degree.
equal to its desired degree. Then pairs of stubs
More speciﬁcally the end result is a particular matching of
are chosen at random and connected together
the stubs, a particular set of pairings of stubs with other stubs.
to form edges (dotted line).
The process above generates each possible matching of stubs
with equal probability. Technically the conﬁguration model
is deﬁned as the ensemble in which each matching with the chosen degree
sequence appears with the same probability (those with any other degree sequence having probability zero), and the process above is a process for drawing networks from the conﬁguration model ensemble.
The uniform distribution over matchings in the conﬁguration model has
the important consequence that any stub in a conﬁguration model network is
equally likely to be connected to any other. This, as we will see, is the crucial
property that makes the model solvable for many of its properties.
435

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

There are a couple of minor catches with the network generation process
described here. First, there must be an even number of stubs overall if we
want to end up with a network consisting only of vertices and edges, with no
dangling stubs left over. This means that the sum ∑i k i of the degrees must
add up to an even number. We will assume that the degrees we have chosen
satisfy this condition, otherwise it is clearly not possible to create a graph with
the given degree sequence.
A second issue is that the network may contain self-edges or multiedges,
or both. There is nothing in the network generation process that prevents us
from creating an edge that connects a vertex to itself or that connects two vertices that are already connected by another edge. One might imagine that one
could avoid this by rejecting the creation of any such edges during the process, but it turns out that this is not a good idea. A network so generated is no
longer drawn uniformly from the set of possible matchings, which means that
properties of the model can no longer be calculated analytically, at least by any
means currently known. It can also mean that the network creation process
breaks down completely. Suppose, for example, that we come to the end of the
process, when there are just two stubs left to be joined, and ﬁnd that those two
both belong to the same vertex so that joining them would create a self-edge.
Then either we create the self-edge or the network generation process fails.
In practice, therefore, it makes more sense to allow the creation of both
multiedges and self-edges in our networks and the standard conﬁguration
model does so. Although some real-world networks have self-edges or multiedges in them, most do not, and to some extent this makes the conﬁguration
model less satisfactory as a network model. However, as shown below, the
average number of self-edges and multiedges in the conﬁguration model is a
constant as the network becomes large, which means that the density of selfedges and multiedges tends to zero in this limit. This means, to all intents and
purposes, that we can ignore the self-edges and multiedges in the large size
limit.3
A further issue with the conﬁguration model is that, while all matchings
of stubs appear with equal probability in the model, that does not mean that
all networks appear with equal probability because more than one matching
can correspond to the same network, i.e., the same topological connections
between vertices. If we label the stubs to keep track of which is which, then
3
Even for ﬁnite-sized networks the difference between the properties of a conﬁguration model
network and a similar network without self-edges and multiedges would only result in a correction of order 1/n into our results. For the large networks that are the focus of most modern network studies this means that the error introduced by allowing self-edges and multiedges is small.

436

|

13.2

a

b

b

c

e
d

d

e

c

d

e

c

f

b
f

c

e

b

d

a

d

f

a
f

b
e

a

c

b

d

f

b
f

d

e

b

c

a

c

f

a

a

T HE CONFIGURATION MODEL

e

a

d

f
c

e

Figure 13.2: Eight stub matchings that all give the same network. This small network is composed of three vertices
of degree two and hence having two stubs each. The stubs are lettered to identify them and there are two distinct
permutations of the stubs at each vertex for a total of eight permutations overall. Each permutation gives rise to a
different matching of stub to stub but all matchings correspond to the same topological conﬁguration of edges, and
hence there are eight ways in which this particular conﬁguration can be generated by the stub matching process.

there are typically many different ways we can join up pairs of labeled stubs to
create the same ﬁnal conﬁguration of edges. Figure 13.2 shows an example of
a set of eight matchings that all correspond to the same three-vertex network.
In general, one can generate all the matchings that correspond to a given
network by taking any one matching for that network and permuting the stubs
at each vertex in every possible way. Since the number of permutations of the
k i stubs at a vertex i is k i !, this implies that the number of matchings corresponding to each network is N ({k i }) = ∏i k i !, which takes the same value for
all networks, since the degrees are ﬁxed. This implies that in fact networks
occur with equal probability in the conﬁguration model: if there are Ω({k i })
matchings, each occurring with the same probability, then each network occurs
with probability N/Ω.
However, this is not completely correct. If a network contains self-edges
or multiedges then not all permutations of the stubs in the network result in
a new matching of stubs. Consider Fig. 13.3. Panel (a) shows a network with
the same degree sequence as those of Fig. 13.2, but a different matching of the
stubs that creates a network with one self-edge and a multiedge consisting of
two parallel single edges. In panel (b) we have permuted the stubs a and b
at the ends of the self-edge but, as we can see, this has not resulted in a new
matching of the stubs themselves. Stubs a and b are still connected to one
another just as they were before. (The network is drawn differently now, but
in terms of the matching and the topology of the edges nothing has changed
437

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

a

b

b

a

a

b

c

e

c

e

d

f

d

f

d

f

c

e

(a)

(b)

(c)

Figure 13.3: Permutations that do not produce new matchings. (a) The network shown
here has the same degree sequence as those of Fig. 13.2 but a different conﬁguration of
edges, having one self-loop and a multiedge consisting of two parallel edges. (b) If we
permute the stubs a and b of the self-edge we do not generate a new matching, because
a is still matched with b, just as before. (c) If we permute the stubs at either end of a
multiedge in exactly the same way we do not generate a new matching, since each stub
at one end of the multiedge is still matched with the same stub at the other end.

from panel (a).) In panel (c) we have identically permuted the stubs at both
ends of the multiedge. Again this has no effect on which stubs are matched
with which others.
In general, for each multiedge in a network a permutation of the stubs at
one end fails to generate a new matching if we simultaneously permute the
stubs at the other end in the same way. This means that the total number of
matchings is reduced by a factor of Aij !, since Aij is equal to the multiplicity
of the edge between i and j. Indeed, this expression is correct even for vertex
pairs not connected by a multiedge, if we adopt the convention that 0! = 1.
For self-edges there is a further factor of two because the interchange of the
two ends of the edge does not generate a new matching. Combining these
results, the number of matchings corresponding to a network turns out to be
N=

∏i k i !
,
∏i< j Aij ! ∏i Aii !!

(13.29)

where n!! = n(n − 2)(n − 4) . . . 2 with n even is the so-called double factorial
of n. Then the total probability of a particular network within the conﬁguration model ensemble is N/Ω as before. Since the denominator in Eq. (13.29)
depends not only on the degree sequence but also on the structure of the network itself, different networks do appear with different probabilities.
As we mentioned, however, the average densities of self-edges and multiedges in the conﬁguration model vanish as n becomes large, so that the vari438

13.2

|

T HE CONFIGURATION MODEL

ation in probabilities is relatively small in the large-n limit, but it nonetheless
does occasionally assume some importance and is therefore worth bearing in
mind (see, for instance, Ref. [220]).
As discussed above, we are sometimes (indeed often) interested in the case
where it is the degree distribution of the network that is speciﬁed rather than
the degree sequence. That is, we specify the probability distribution pk from
which the degree sequence is drawn rather than the sequence itself. We can
deﬁne an obvious extension of the conﬁguration model to this case: we draw
a degree sequence from the speciﬁed distribution and then generate a network
with that degree sequence using the technique described above. More precisely, we deﬁne an ensemble in which each degree sequence {k i } appears with
probability ∏i pki . Then if we can calculate an average value X ({k i }) for some
quantity of interest X in the standard conﬁguration model, the average value
in the extended model is given by
∞

∞

n

k 1 =0

k n =0

i =0

X = ∑ . . . ∑ X ({k i }) ∏ pki .

(13.30)

In practice the difference between the two models is not actually very great.
As we will see, the crucial parameter that enters into most of our conﬁguration
model calculations is the fraction of vertices that have each possible degree k.
In the extended model above, this fraction is, by deﬁnition, equal to pk in the
limit of large n. If, on the other hand, the degree sequence is ﬁxed then we simply calculate the fraction from the degree sequence and then use those numbers. In either the case the formulas for calculated quantities are the same.
13.2.1

E DGE PROBABILITY IN THE CONFIGURATION MODEL

A central property of the conﬁguration model is the probability pij of the occurrence of an edge between two speciﬁed vertices, i and j. Obviously if either
vertex i or vertex j has degree zero then the probability of an edge is zero, so let
us assume that k i , k j > 0. Now consider any one of the stubs that emerges from
vertex i. What is the probability that this stub is connected by an edge to any of
the stubs of vertex j? There are 2m stubs in total, or 2m − 1 excluding the one
connected to i that we are currently looking at. Of those 2m − 1, exactly k j of
them are attached to vertex j. So, given that any stub in the network is equally
likely to be connected to any other, the probability that our particular stub is
connected to any of those around vertex j is k j /(2m − 1). But there are k i stubs
around vertex i, so the total probability of a connection between i and j is
pij =

ki k j
.
2m − 1

(13.31)
439

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Technically, since we have added the probabilities of independent events, this
is really the average number of edges between i and j, rather than the probability of having an edge at all. But in the limit of large m, this number becomes
small (for given k i , k j ), and the average number of edges and the probability of
an edge become equal. Also in the limit of large m we can ignore the −1 in the
denominator and hence we can write
pij =

ki k j
.
2m

(13.32)

Note that, even though we assumed k i , k j > 0, this expression also gives the
right result if either degree is zero, namely that in that case the probability of
connection is zero.
We can use this result, for example, to calculate the probability of having
two edges between the same pair of vertices. The probability of having one
edge between vertices i and j is pij as above. Once we have one edge between
the vertices the number of available stubs at each is reduced by one, and hence
the probability of having a second edge is given by Eq. (13.32) but with k i and
k j each reduced by one: (k i − 1)(k j − 1)/2m. Thus the probability of having
(at least) two edges, i.e., of having a multiedge between i and j, is k i k j (k i −
1)(k j − 1)/(2m)2 and, summing this probability over all vertices and dividing
by two (to avoid double counting of vertex pairs), we ﬁnd that the expected
total number of multiedges in the network is
1
1
k i k j (k i − 1)(k j − 1) =
k ( k − 1) ∑ k j ( k j − 1)
2 n2 ∑ i i
2(2m)2 ∑
2
k
ij
i
j
 2
2
1 k − k
=
,
(13.33)
2
k
where
k =

1
ki ,
n∑
i

k2 =

1
k2i ,
n∑
i

(13.34)

and we have used 2m = k n (see Eq. (6.23)). Thus the expected number of
multiedges remains constant as the network grows larger, so long as k2 is
constant and ﬁnite, and the density of multiedges—the number per vertex—
vanishes as 1/n. We used this result in a number of our earlier arguments.4
Another way to derive the expression in Eq. (13.32) is to observe that there
are k i k j possible edges we could form between vertices i and j, while the total number of possible edges in the whole graph is the number of ways of
4
For networks with power-law degree distributions k2 diverges, as described in Section 8.4.2,
and in that case the density of multiedges may not vanish or may do so more slowly than 1/n.

440

13.2

|

T HE CONFIGURATION MODEL

choosing a pair of stubs from the 2m total stubs, or (2m
2 ) = m (2m − 1). The
probability that any particular edge falls between i and j is thus given by the
ratio k i k j /m(2m − 1), and if we make a total of m edges then the expected total number of edges between i and j is m times this quantity, which gives us
Eq. (13.31) again.
The only case in which this derivation is not quite right is for self-edges. In
that case the number of pairs of stubs is not k i k j but instead is (k2i ) = 12 k i (k i − 1)
and hence the probability of a self-edge from vertex i to itself is
pii =

k i ( k i − 1)
.
4m

(13.35)

We can use this result to calculate the expected number of self-edges in the
network, which is given by the sum over all vertices i:

∑ pii = ∑
i

i

k i ( k i − 1)
k2 − k
=
,
4m
2 k

(13.36)

This expression remains constant as n → ∞ provided k2 remains constant,
and hence, as with the multiedges, the density of self-edges in the network
vanishes as 1/n in the limit of large network size.
We can use Eqs. (13.32) and (13.35) to calculate a number of other properties of vertices in the conﬁguration model. For instance, we can calculate
the expected number nij of common neighbors that vertices i and j share. The
probability that i is connected to another vertex l is pil and the probability that
j is connected to the same vertex would likewise normally be p jl . However,
as with the calculation of multiedges above, if we already know that i is connected to l, then the number of available stubs at vertex l is reduced by one
and, rather than being given by the normal expression (13.32), the probability
of a connection between j and l is k j (k l − 1)/2m. Multiplying the probabilities for the two edges and summing over l, we then get our expression for the
expected number of common neighbors of i and j:
nij = ∑
l

= pij

k i k j ∑ l k l ( k l − 1)
k i k l k j ( k l − 1)
=
2m
2m
2m
n k
k2 − k
.
k

(13.37)

Thus the probability of sharing a common neighbor is equal to the probability pij = k i k j /2m of having a direct connection times a multiplicative factor
that depends only on the mean and variance of the degree distribution but not
on the properties of the vertices i and j themselves.
441

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

In this calculation we have ignored the fact that the probability of selfedges, Eq. (13.35), is different from the probability for other edges. As we
have seen, however, the density of self-edges in the conﬁguration model tends
to zero as n → ∞, so in that limit it is usually safe to make the approximation
that Eq. (13.32) applies for all i and j.
13.2.2

R ANDOM GRAPHS WITH GIVEN EXPECTED DEGREE

The conﬁguration model of the previous section is, as we have said, similar in
some ways to the standard random graph G (n, m) described in Section 12.1, in
which we distribute a ﬁxed number m of edges at random between n vertices.
In the conﬁguration model the total number of edges is again ﬁxed, having
value m = 12 ∑i k i , but in addition we now also ﬁx the individual degree of
every vertex as well.
It is natural to ask whether there is also an equivalent of G (n, p)—the model
in which only the probability of edges is ﬁxed and not their number—and
indeed there is. We simply place an edge between each pair of vertices i, j
with independent probabilities taking the form of Eq. (13.32). We deﬁne a
parameter ci for each vertex and then place an edge between vertices i and j
with probability pij = ci c j /2m. As with the conﬁguration model, we must
allow self-edges if the model is to be tractable, and again self-edges have to
be treated a little differently from ordinary edges. It turns out that the most
satisfactory deﬁnition of the edge probability is5

pij =
where m is now deﬁned by6

ci c j /2m
c2i /4m

∑ ci = 2m.

for i = j,
for i = j,

(13.38)

(13.39)

i

5
As before, pij should really be regarded as the expected number of edges between i and j
rather than the probability and in fact the proper formulation of the model is that we place a
Poisson-distributed number of edges with mean pij between each pair of vertices i, j. Thus the
model can in principle have multiedges as well as self-edges, just as in the conﬁguration model.
In the limit of large m and constant ci , however, the probability and the expected number again
become equal, and the density of multiedges tends to zero, so the distinction is unimportant.
6

Another way of putting this is that the average value Aij of an element of the adjacency
matrix is simply Aij = ci c j /2m for all i, j—recall that the diagonal element Aii of the adjacency
matrix is deﬁned to be twice the number of self-edges at vertex i, and this compensates for the
extra factor of two in Eq. (13.38).

442

13.2

|

T HE CONFIGURATION MODEL

With this choice the average number of edges in the network is
c2

ci c j

ci c j

∑ pij = ∑ 2m + ∑ 4mi = ∑ 4m = m,
i≤ j

i< j

i

(13.40)

ij

as before. We can also calculate the average number of ends of edges connected
to a vertex i, i.e., its average degree k i . Allowing for the fact that a self-edge
contributes two ends of edges to the degree, we get
k i = 2pii + ∑ pij =
j(=i )

ci c j
ci c j
c2i
+
=∑
= ci .
2m j(∑
2m
2m
j
=i )

(13.41)

In other words the parameters ci appearing in the deﬁnition of pij , Eq. (13.38),
are the average or expected degrees in this model, just as the parameter c in
G (n, p) is the average degree of a vertex. The actual degree of a vertex could
in principle take almost any value, depending on the luck of the draw about
which edges happen to get randomly created and which do not. In fact one can
show that the degree of vertex i will have a Poisson distribution with mean ci ,
meaning that in practice it will be quite narrowly distributed about ci , but there
will certainly be some variation, unless ci is zero.7 Note that ci does not have
7
The probabilities of edges between vertex i and each other vertex are independent, which
immediately implies that the degree has a Poisson distribution. This may be obvious to you—
if you’re a statistician, for example—but if not, here is a proof, which makes use of generating
functions.
The probability that there are edges connecting vertex i to any speciﬁc set of vertices, including
itself, is given by a product of factors pij for each edge present and (1 − pij ) for each edge not
present. This product can conveniently be written in the form

piiAii /2 (1 − pii )1− Aii /2 ∏ pij ij (1 − pij )1− Aij ,
A

j(=i )

where Aij is the standard adjacency matrix and we adopt the convention that 00 = 1 for any cases
where pij = 0. Note that it is important to separate out the term for pii as shown, since it takes a
slightly different form from the others. Recall that a self-edge is represented by a diagonal element
Aii = 2 in the adjacency matrix (see Section 6.2) and we must allow for this with the factors of two
above.
(i )
The probability pk that vertex i has degree exactly k is the sum of these probabilities over all
cases where there the ith row of the adjacency matrix adds up to k (including the 2s that appear
for self-edges, since a self-edge contributes +2 to the degree). We can write this sum as


A
(i )
pk = ∑ . . . ∑ . . . ∑ δ k, ∑ j Aij piiAii /2 (1 − pii )1− Aii /2 ∏ j(=i) pij ij (1 − pij )1− Aij ,
Ai1 =0,1

Aii =0,2

Ain =0,1

where δ( a, b) is the Kronecker delta. It is tricky to evaluate this sum directly because of the constraint imposed by the delta function, but we can do it using a generating function. Multiplying both sides of the equation by zk , summing over all k, and deﬁning the generating function
(i )
gi (z) = ∑k pk zk , we get

443

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

to be an integer, unlike the degrees k i appearing in the conﬁguration model.
Thus in this model we specify the expected number of edges m and the expected degree sequence {ci } of the network but not the actual number of edges
and actual degree sequence. This is again analogous to G (n, p), in which we
specify only the expected number of edges and not the actual number. Unfortunately, this means we usually cannot choose the degree distribution of our
network, because the distribution of the actual degrees k i is not the same as
the distribution of the expected degrees ci . This is a substantial disadvantage



∞

gi ( z ) = ∑ z k
k =0

=
=



∑ . . . ∑ . . . ∑ δ k, ∑ j Aij piiA /2 (1 − pii )1− A /2 ∏ pij (1 − pij )1− A

Ai1 =0,1

Aii =0,2

ii

Aij

ii

Ain =0,1

∑ . . . ∑ . . . ∑ z∑ A piiA /2 (1 − pii )1− A /2 ∏ pij (1 − pij )1− A
j

Ai1 =0,1

Aii =0,2

ii

ij

Aij

ii

Ain =0,1

ij

j(=i )

∑ . . . ∑ . . . ∑ ( pii z2 ) A /2 (1 − pii )1− A /2 ∏ ( pij z) A (1 − pij )1− A
ii

Ai1 =0,1

Aii =0,2

ij

j(=i )

ii

Ain =0,1

ij

ij

j(=i )

= (1 − pii + pii z2 ) ∏ (1 − pij + pij z)
j(=i )



c2
= 1 + i ( z2 − 1)
4m





ci c j



∏ 1 + 2m (z − 1) .

j(=i )

Taking logs of both sides and going to the limit of large size, where m → ∞ (with the ci remaining
ﬁnite), we then get

'
 

ci c j
c2
ln gi (z) = lim ln 1 + i (z2 − 1) + ∑ ln 1 +
( z − 1)
m→∞
4m
2m
j(=i )

=

ci c j
c2i 2
( z − 1) + ∑
( z − 1)
4m
2m
j(=i )

=

n c c
c2i 2
c2
i j
( z − 1) − i ( z − 1) + ∑
( z − 1)
4m
2m
2m
j =1

c2i 2
c2
( z − 1) − i ( z − 1) + ci ( z − 1)
4m
2m


ci ( z − 1)
,
= ci ( z − 1) 1 +
4m

=

where we have made use of Eq. (13.39) in the second-to-last line. For large m, the second term in
the square brackets becomes negligible compared to the ﬁrst and, taking exponentials again,
gi ( z ) = e c i ( z − 1 ) .
Now we can derive the probability distribution of the degree of vertex i by differentiating:
"
ck
1 dk gi ""
(i )
pk =
= e− c i i ,
k! dzk "z=0
k!
which is indeed a Poisson distribution, with mean ci , as promised.

444

13.3

|

E XCESS DEGREE DISTRIBUTION

of the model since the degree distribution is widely considered to be a crucial
property of networks.8
This is unfortunate, because this model is in other respects a very nice one.
It is straightforward to treat analytically and many of the derivations are substantially simpler for this model than for the conﬁguration model. Nonetheless, because we place such a premium on being able to choose the degree
distribution, this model is in fact hardly ever used in real calculations of the
properties of networks. Instead, most calculations are made using the conﬁguration model and this is the direction that we will take in this book as well. In
the following sections, we describe how one can make use of the machinery of
generating functions to calculate many of the properties of the conﬁguration
model exactly in the limit of large network size.

13.3

E XCESS DEGREE DISTRIBUTION

In the remainder of this chapter we describe the calculation of a variety of
properties of the conﬁguration model. We begin our discussion with some
fundamental observations about the model—and networks in general—that
will prove central to later developments.
Consider a conﬁguration model with degree distribution pk , meaning that
a fraction pk of the vertices have degree k. (We can consider either the standard
version of the model in which the degree sequence is ﬁxed, as in Section 13.2,
or the version of Eq. (13.30) in which only the distribution is ﬁxed but not the
exact degree sequence.) The distribution pk tells us the probability that a vertex
chosen uniformly at random from our network has degree k. But suppose
instead that we take a vertex (randomly chosen or not) and follow one of its
edges (assuming it has at least one) to the vertex at the other end. What is the
probability that this vertex will have degree k?
The answer cannot just be pk . For instance, there is no way to reach a vertex with degree zero by following an edge in this way, because a vertex with
degree zero has no edges. So the probability of ﬁnding a vertex of degree zero
is itself zero, and not p0 .
In fact, the correct probability for general k is not hard to calculate. We
know that an edge emerging from a vertex in a conﬁguration model network
has equal chance of terminating at any “stub” of an edge anywhere else in the
network (see Section 13.2). Since there are ∑i k i = 2m stubs in total, or 2m − 1
8

It is easy to see that there are some degree distributions that the model cannot reproduce at
all—any distribution for which pk is exactly zero for any k, for instance, since there is always a
non-zero probability that any vertex can have any degree.

445

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

excluding the one at the beginning of our edge, and k of them are attached
to any particular vertex with degree k, our edge has probability k/(2m − 1)
of ending at any particular vertex of degree k. In the limit of large network
size, where m becomes large (assuming the degree distribution, and hence the
average degree, remain constant), we can ignore the −1 and just write this as
k/2m.
Given that pk is the total fraction of vertices in the network with degree k,
the total number of such vertices is npk , and hence the probability of our edge
attaching to any vertex with degree k is
kp
k
× npk = k ,
2m
k

(13.42)

where k is the average degree over the whole network and we have made
use of the fact that 2m = n k , Eq. (6.23).
Thus the probability that we reach a vertex of degree k upon following
an edge in this way is proportional not to pk but to kpk . To put that another
way, the vertex you reach by following an edge is not a typical vertex in the
network. It is more likely to have high degree than a typical vertex. Physically,
the reasoning behind this observation is that a vertex with degree k has k edges
attached to it, and you can reach that vertex by following any one of them.
Thus if we choose an edge and follow it you have k times the chance of reaching
a vertex with degree k that you have of reaching a vertex with degree 1.
It is important to recognize that this is a property speciﬁcally of the conﬁguration model (or similar random graph models). In the real world, the
degrees of adjacent vertices in networks are often correlated (see Section 7.13)
and hence the probability of reaching a vertex of degree k when we follow an
edge depends on what vertex we are coming from.9 Nonetheless, it is found to
apply approximately to many real-world networks, which is one of the reasons
why insights gained from the conﬁguration model are useful for understanding the world around us.
Equation (13.42) has some strange and counter-intuitive consequences. As
an example, consider a randomly chosen vertex in the conﬁguration model
and let us calculate the average degree of a neighbor of that vertex. If we were
using the conﬁguration model to model a friendship network, for instance,
the average degree of an individual’s network neighbor would correspond to
the average number of friends their friend has. This number is the average
9
On the other hand, if we pick a random edge in a network and follow it to one of its ends, then
the degree of the vertex we reach is distributed according to (13.42), regardless of whether degrees
are correlated or not.

446

13.3

|

E XCESS DEGREE DISTRIBUTION

of the distribution in Eq. (13.42), which we get by multiplying by k and then
summing over k thus:10
average degree of a neighbor = ∑ k
k

kpk
k2
.
=
k
k

(13.43)

Note that the average degree of a neighbor is thus different from the average
degree k of a typical vertex in the network. In fact, it is in general larger, as
we can show by calculating the difference

σ2
k2
1  2
k − k 2 = k ,
− k =
k
k
k

(13.44)

where σk2 = k2 − k 2 is the variance of the degree distribution. The variance,
which is the square of the standard deviation, is necessarily non-negative and
indeed is strictly positive unless every single vertex in the network has the
same degree. Let us assume that there is some variation in the degrees so that
σk2 is greater than zero. The average degree k is also greater than zero, unless
all vertices have degree zero. Thus Eq. (13.44) implies that k2 / k − k > 0,
or
k2
> k .
(13.45)
k
In other words, the average degree of the neighbor of a vertex is greater than
the average degree of a vertex. In colloquial terms, “Your friends have more
friends than you do.”
At ﬁrst sight, this appears to be a very strange result. Certainly it seems
likely that there will be some vertices in the network with higher degree than
the average. But there will also be some who have lower degree and when
you average over all neighbors of all vertices surely the two should cancel out.
Surely the average degree of a neighbor should be the same as the average degree in the network as a whole. Yet Eq. (13.45) tells us that this is not so. And
the equation really is correct. You can create a conﬁguration model network
on a computer and average the degrees of the neighbors of every vertex, and
you’ll ﬁnd that the formula works to very high accuracy. Even more remarkably, as ﬁrst shown by Feld [113], you can do the same thing with real networks
and, although the conﬁguration model formula doesn’t apply exactly to these
networks, the basic principle still seems to hold. Here, for instance, are some
measurements for two academic collaboration networks, in which scientists
10
The ratio k2 / k that appears in Eq. (13.43) crops up repeatedly in the study of networks. It
appeared previously in Section 13.2.1 and it will come up in many later calculations.

447

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

are connected together by edges if they have coauthored scientiﬁc papers, and
for a recent snapshot of the structure of the Internet at the autonomous system
level:

Network
Biologists
Mathematicians
Internet

n
1 520 252
253 339
22 963

Average
degree
15.5
3.9
4.2

Average
neighbor degree
68.4
9.5
224.3

k2
k
130.2
13.2
261.5

According to these results a biologist’s collaborators have, on average, more
than four times as many collaborators as they do themselves. On the Internet, a node’s neighbors have more than 50 times the average degree! Note
that in each of the cases in the table the conﬁguration model value of k2 / k
overestimates the real average neighbor degree, in some cases by a substantial
margin.11 This is typical of calculations using simpliﬁed network models: they
can give you a feel for the types of effect one might expect to see, or the general
directions of changes in quantities. But they usually don’t give quantitatively
accurate predictions for the behavior of real networks.
The fundamental reason for the result, Eq. (13.45), is that when you go
through the vertices of a network and average the degrees of the neighbors
of each one, many of those neighbors appear in more than one average. In fact,
a vertex with degree k will appear as one of the neighbors of exactly k other
vertices, and hence appear in k of the averages. This means that high-degree
vertices are over-represented in the calculations compared with low-degree
ones and it is this bias that pushes up the overall average value.
In most of the calculations that follow, we will be interested not in the total
degree of the vertex at the end of an edge but in the number of edges attached
to that vertex other than the one we arrived along. For instance, if we want
to calculate the size of the component to which a vertex i belongs then we
will want to know ﬁrst of all how many neighbors i has, and then how many
neighbors those neighbors have, other than i, and so on.
The number of edges attached to a vertex other than the edge we arrived
along is called the excess degree of the vertex and it is just one less than the total
degree. Since the vertex at the end of an edge always has degree at least 1
(because of that edge) the minimum value of the excess degree is zero.
11
There is no reason in principle why the conﬁguration model should always overestimate the
average degree of a neighbor. In some cases it could underestimate too.

448

13.4

|

C LUSTERING COEFFICIENT

We can calculate the probability distribution of the excess degree from Eq.
(13.43). The probability qk of having excess degree k is simply the probability
of having total degree k + 1 and, putting k → k + 1 in Eq. (13.43), we get
qk =

( k + 1 ) p k +1
.
k

(13.46)

(Note that the denominator is still just k , and not k + 1 , as you can verify for
yourself by checking that Eq. (13.46) is correctly normalized so that ∑∞
k =0 q k =
1.)
The distribution qk is called the excess degree distribution and it will come up
repeatedly in the sections that follow. It is the probability distribution, for a
vertex reached by following an edge, of the number of other edges attached to
that vertex.

13.4

C LUSTERING COEFFICIENT

As a simple application of the excess degree distribution, let us calculate the
clustering coefﬁcient for the conﬁguration model. Recall that the clustering coefﬁcient is the average probability that two neighbors of a vertex are neighbors
of each other.
Consider then a vertex v that has at least two neighbors, which we will
denote i and j. Being neighbors of v, i and j are both at the ends of edges
from v, and hence the number of other edges connected to them, k i and k j
are distributed according to the excess degree distribution, Eq. (13.46). The
probability of an edge between i and j is then k i k j /2m (see Eq. (13.32)) and,
averaging both k i and k j over the distribution qk , we get an expression for the
clustering coefﬁcient thus:

2
ki k j
1 ∞
=
kqk
C = ∑ qki qk j
2m
2m k∑
k i ,k j =0
=0

2
∞
1
=
k ( k + 1 ) p k +1
2m k 2 k∑
=0

2
∞
1
=
(k − 1)kpk
2m k 2 k∑
=0
∞

=

1
n

k2 − k
k 3

2

,

(13.47)

where we have made use of 2m = n k , Eq. (6.23).
449

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Like the clustering coefﬁcient of the Poisson random graph, Eq. (12.11),
this expression goes as n−1 for ﬁxed degree distribution, and so vanishes in
the limit of large system size. Hence, like the Poisson random graph, the
conﬁguration model appears to be an unpromising model for real-world networks with high clustering. Note, however, that Eq. (13.47) contains the second moment k2 of the degree distribution in its numerator which can become
large, for instance in networks with power-law degree distributions (see Section 8.4.2). This can result in surprisingly large values of C in the conﬁguration
model. For further discussion of this point see Section 8.6.

13.5

G ENERATING FUNCTIONS FOR DEGREE DISTRIBUTIONS

In the calculations that follow, we will make heavy use of the generating functions for the degree distribution and the excess degree distribution of a network. We will denote these generating functions by g0 (z) and g1 (z) respectively. They are deﬁned by
∞

g0 ( z ) = ∑ p k z k ,

(13.48)

g1 ( z ) = ∑ q k z k .

(13.49)

k =0
∞
k =0

Although it will be convenient to have separate notations for these two commonly occurring functions, they are not really independent, since the excess
degree distribution is itself deﬁned in terms of the ordinary degree distribution via Eq. (13.46). Using Eq. (13.46) we can write g1 (z) as
g1 ( z ) =

1
k

∞

1

∞

∑ (k + 1) pk+1 zk = k ∑ kpk zk−1

k =0

k =0

1 dg0
.
=
k dz

(13.50)

But Eq. (13.22) tells us that the average vertex degree is k = g0 (1), so
g1 ( z ) =

g0 (z)
.
g0 (1)

(13.51)

Thus if we can ﬁnd g0 (z), we can also ﬁnd g1 (z) directly from it, without the
need to calculate the excess degree distribution explicitly.
For example, suppose our degree distribution is a Poisson distribution with
mean c:
ck
(13.52)
p k = e− c .
k!
450

13.6

|

N UMBER OF SECOND NEIGHBORS OF A VERTEX

Then its generating function is given by Eq. (13.6) to be
g0 ( z ) = e c ( z − 1 ) .

(13.53)

Applying Eq. (13.51), we then ﬁnd that
g1 ( z ) = e c ( z − 1 ) .

(13.54)

In other words, g0 (z) and g1 (z) are identical in this case. (This is one reason why calculations are relatively straightforward for the Poisson random
graph—there is no difference between the degree distribution and the excess
degree distribution in that case, a fact you can easily demonstrate for yourself
by substituting Eq. (13.52) directly into Eq. (13.46).)
A more complicated example is the power-law distribution, Eq. (13.10),
which has a generating function given by Eq. (13.16) to be
g0 ( z ) =

Liα (z)
,
ζ (α)

(13.55)

where Liα (z) is the polylogarithm function and α is the exponent of the power
law. Substituting this result into Eq. (13.51) and making use of Eq. (13.17) gives
g1 ( z ) =

Liα−1 (z)
Liα−1 (z)
,
=
z Liα−1 (1)
zζ (α − 1)

(13.56)

where we have made use of the fact that Liα (1) = ζ (α) (see Eqs. (13.12) and
(13.15)).

13.6

N UMBER OF SECOND NEIGHBORS OF A VERTEX

Armed with these results, we are now in a position to make some more detailed calculations of the properties of the conﬁguration model. The ﬁrst ques(2)
tion we will address is a relatively simple one: what is the probability pk that
a vertex has exactly k second neighbors in the network?
Let us break this probability down by writing it in the form
(2)

∞

p k = ∑ p m P (2) ( k | m ) ,

(13.57)

m =0

where P(2) (k |m) is the probability of having k second neighbors given that
we have m ﬁrst neighbors and pm is the ordinary degree distribution. Equation (13.57) says that the total probability of having k second neighbors is the
probability of having k second neighbors given that we have m ﬁrst neighbors,
451

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

vertex

first neighbors
second neighbors

Figure 13.4: Calculation of the number of second neighbors of a vertex. The number
of second neighbors of a vertex (top) is equal to the sum of the excess degrees of the
ﬁrst neighbors.

averaged over all possible values of m. We assume that we are given the degree
distribution pm ; we need to ﬁnd P(2) (k |m) and then complete the sum.
As illustrated in Fig. 13.4, the number of second neighbors of a vertex is
equal to the sum of the excess degrees of the ﬁrst neighbors. And as discussed
in the previous section, the excess degrees are distributed according to the distribution qk , Eq. (13.46), so that the probability that the excess degrees of our m
ﬁrst neighbors take the values j1 . . . jm is ∏rm=1 q jr . Summing over all sets of values j1 . . . jm , the probability that the excess degrees sum to k and hence that we
have k second neighbors is
∞
∞
 m

P(2) (k |m) = ∑ . . . ∑ δ k, ∑rm=1 jr ∏ q jr .
j1 =0

jm =0

(13.58)

r =1

Substituting this expression into (13.57), we ﬁnd that
∞
∞
∞
 m

(2)
pk = ∑ pm ∑ . . . ∑ δ k, ∑rm=1 jr ∏ q jr .
m =0

j1 =0

jm =0

(13.59)

r =1

By now, you may be starting to ﬁnd sums of this type familiar. We saw
them previously in Eqs. (12.25) and (13.27), for example. We can handle this
(2)
one by the same trick we used before: instead of trying to calculate pk directly,

452

13.6

|

N UMBER OF SECOND NEIGHBORS OF A VERTEX

we calculate instead its generating function g(2) (z) thus:
∞

(2)

g (2) ( z ) = ∑ p k z k
k =0
∞

∞
∞
∞
 m

= ∑ zk ∑ pm ∑ . . . ∑ δ k, ∑rm=1 jr ∏ q jr
k =0

m =0

j1 =0

∞

∞

∞

m =0

j1 =0

jm =0

∞

∞

∞

j1 =0

jm =0 r =1
m

r =1

jm =0

m

= ∑ pm ∑ . . . ∑ z∑r=1 jr ∏ q jr
m

r =1

m

= ∑ pm ∑ . . . ∑ ∏ q jr z jr
m =0
∞



∞

= ∑ pm ∑ q j z j
m =0

.

(13.60)

j =0

But now we notice an interesting thing: the sum in square brackets in the last
line is none other than the generating function g1 (z) for the excess degree distribution, Eq. (13.49). Thus Eq. (13.60) can be written as
∞

g(2) (z) = ∑ pm [ g1 (z)]m = g0 ( g1 (z)),

(13.61)

m =0

where g0 (z) is the generating function for the ordinary degree distribution,
deﬁned in Eq. (13.48). So once we know the generating functions for our two
basic degree distributions the generating function for the distribution of the
second neighbors is very simple to calculate.
In fact, there was no need to go through this lengthy calculation to reach
Eq. (13.61). We can derive the same result much more quickly by making
use of the “powers” property of generating functions that we derived in Section 13.1.4. There we showed (Eq. (13.28)) that, given a quantity k distributed
according to a distribution with generating function g(z), m independent quantities drawn from the same distribution have a sum whose distribution is given
by the generating function [ g(z)]m . We can apply this result here, by noting
that the m excess degrees of the ﬁrst neighbors of our vertex are just such a set
of independent quantities. Given that g1 (z) is the generating function for the
distribution of a single one of them (Eq. (13.49)), the distribution P(2) (k |m) of
their sum—which is the number of second neighbors—has generating function
[ g1 (z)]m . That is,
∞

∑ P(2) (k|m)zk = [ g1 (z)]m .

(13.62)

k =0

453

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

(2)

Now, using Eq. (13.57), the generating function for pk is
∞

∞

(2)

∞

g (2) ( z ) = ∑ p k z k = ∑ ∑ p m P (2) ( k | m ) z k
k =0 m =0

k =0
∞

∞

∞

m =0

k =0

m =0

= ∑ pm ∑ P(2) (k|m)zk = ∑ pm [ g1 (z)]m
= g0 ( g1 (z)).

(13.63)

In future calculations, we will repeatedly make use of this shortcut to get our
results, rather than taking the long route exempliﬁed in Eq. (13.60).
We can also use similar methods to calculate the probability distribution
of the number of third neighbors. The number of third neighbors is the sum
of the excess degrees of each of the second neighbors. Thus, if there are m
second neighbors, then the probability distribution P(3) (k |m) of the number of
third neighbors has generating function [ g1 (z)]m and the overall probability of
having k third neighbors is exactly analogous to Eq. (13.63):
∞

∞

(2) (3)

g (3) ( z ) = ∑ ∑ p m P

∞

(2)

∞

(3)

(k |m)zk = ∑ pm ∑ P (k |m)zk

m =0
k =0 m =0
∞
(2)
=
pm [ g1 (z)]m = g(2) ( g1 (z))
m =0

k =0

∑

= g0 ( g1 ( g1 (z))).

(13.64)

Indeed, the generating function for the number of neighbors at any distance d
can be expressed this way as
∞

∞

( d −1) ( d )

g(d) ( z ) = ∑ ∑ p m

P

(k |m)zk

k =0 m =0
∞
∞
∞
( d −1)
(d)
( d −1)
=
pm
P (k |m)zk =
pm [ g1 (z)]m
m =0
m =0
k =0

∑

∑

= g(d−1) ( g1 (z)).

∑

(13.65)

In other words g(d) (z) = g0 ( g1 (. . . g1 (z) . . .)), with d − 1 copies of g1 nested
inside a single g0 . This expression is correct at arbitrary distances on an inﬁnite
network. On a ﬁnite network it will break down if d becomes large enough but
will be accurate for small values of d.
These results are all very good, but what use are they? Even given the
generating function g(2) (z) it is typically quite difﬁcult to extract explicit probabilities for numbers of second neighbors in the network. For instance, if our
454

13.6

|

N UMBER OF SECOND NEIGHBORS OF A VERTEX

degree distribution were Poisson with mean c then g0 (z) = g1 (z) = ec(z−1) as
in Eqs. (13.53) and (13.54) and
g (2) ( z ) = ec (e

c ( z −1)

−1)

.

(13.66)

But to ﬁnd the actual probabilities we have to apply Eq. (13.2), which involves
calculating derivatives of g(2) (z). One can, with a little work, calculate the ﬁrst
few derivatives, but ﬁnding a general formula for the nth derivative is hard.12
What we can do, however, is calculate the average number of neighbors at
distance d. The average of a distribution is given by the ﬁrst derivative of its
generating function evaluated at z = 1 (see Eq. (13.22)) and the derivative of
Eq. (13.63) is
dg(2)
= g0 ( g1 (z)) g1 (z).
(13.67)
dz
Setting z = 1 and recalling that g1 (1) = 1 (Eq. (13.20)), we ﬁnd that the average
number c2 of second neighbors is
c2 = g0 (1) g1 (1).

(13.68)

But g0 (1) = k and
∞

g1 (1) = ∑ kqk
k =0

∞

=

1
k

=

1
( k 2 − k ).
k

∑ k ( k + 1 ) p k +1 =

k =0

1
k

∞

∑ (k − 1)kpk

k =0

(13.69)

where we have used Eq. (13.46). Thus the mean number of second neighbors
can also be written
(13.70)
c2 = k 2 − k .
We can take this approach further and calculate the mean number cd of
neighbors at any distance d. Differentiating Eq. (13.65) we get

dg(d)
= g(d−1) ( g1 (z)) g1 (z),
dz

(13.71)

and setting z = 1 we get


cd = g(d−1) (1) g1 (1) = cd−1 g1 (1).

(13.72)

12
In fact, the general derivative in this case can be expressed in terms of the so-called Bell
numbers. No closed-form solution exists for third-nearest neighbors or higher, however, nor for
most other choices of degree distribution.

455

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Making use of Eq. (13.68) to write g1 (1) = c2 /c1 where c1 = k , this can be
expressed in the simple form
c d = c d −1
which implies that
cd =

c2
c1

c2
,
c1

(13.73)

d −1

c1 .

(13.74)

In other words, once we know the mean numbers of ﬁrst and second neighbors, c1 and c2 , we know everything. What’s more, the average number of
neighbors at distance d either grows or falls off exponentially, depending on
whether c2 is greater or less than c1 . This observation is strongly reminiscent
of the argument we made in Section 12.5 for the appearance of a giant component in a random graph. There we argued that if the number of vertices you
can reach within a certain distance is increasing with that distance (on average)
then you must have a giant component in the network, while if it is decreasing there can be no giant component. Applying the same reasoning here, we
conclude that the conﬁguration model has a giant component if and only if we
have
(13.75)
c2 > c1 .
Using Eq. (13.70) for c2 and putting c1 = k , we can also write this condition
as k2 − k > k or
k2 − 2 k > 0.
(13.76)
This condition for the existence of a giant component in the conﬁguration
model was ﬁrst given by Molloy and Reed [224] in 1995.13

13.7

G ENERATING FUNCTIONS FOR THE SMALL COMPONENTS

In this section and the following one we examine the sizes of components in
the conﬁguration model. As we will see, the situation is qualitatively similar
13
This expression has an interesting history. In the 1940s Flory [123] considered a model of
branching polymers in which elemental units with a ﬁxed number of “legs”—vertices with uniform degree, in effect—joined together to form connected clumps. He showed that, if the system
was restricted to forming only trees, then there was a transition at which the polymer “gelled” to
create a clump of joined units which corresponds to our giant cluster and found the size of the
gel. In effect, Flory’s results were a special case of the solution given here for the uniform degree
distribution, although they were not expressed in the language of networks. It was not until much
later that Molloy and Reed, who were, as far as I know, unaware of Flory’s work, gave the full
solution for general degree distribution.

456

13.7

|

G ENERATING FUNCTIONS FOR THE SMALL COMPONENTS

to that for the Poisson random graph in that a conﬁguration model network
generally has at most one giant component, plus a large number of small components. We will approach the calculation of component sizes by a route different from the one we took for the Poisson random graph and examine ﬁrst
the properties of the small components. We will see that it is possible to calculate the distribution of the sizes of the small components by a method similar
to the one we used in the Poisson case. Then we can use these results to get
at the properties of the giant component: once we have the sizes of the small
components, we can subtract them from the size of the graph as a whole and
whatever is left, if anything, must be the giant component.
Let πs be the probability that a randomly chosen vertex belongs to a small
(non-giant) component of size s. We will calculate πs by ﬁrst calculating its
generating function
∞

h0 ( z ) = ∑ π s z s .

(13.77)

s =1

Note that the minimum value of s is 1, since every vertex belongs to a component of size at least one (namely itself).
By an argument exactly analogous to that of Section 12.6.1 we can show
that the small components in the conﬁguration model are trees (in the limit
of large n, provided the degree distribution is held constant as we go to the
limit). We can use this fact to derive an expression for the distribution of small
component sizes as follows.
Consider Fig. 13.5 (which is actually the same as the ﬁgure for the Poisson
random graph in the previous chapter (Fig. 12.3), but it works just as well as
an illustration of the conﬁguration model). If vertex i is a member of a small
component then that component is necessarily a tree. Just as in the Poisson
case, this implies that the sets of vertices reachable along each of its edges
(shaded areas in Fig. 13.5a) are not connected, other than via vertex i, since
if they were connected there would be a loop in the component and hence it
would not be a tree.
Now, taking a hint from our argument in the Poisson case, let us remove
vertex i from the network along with all its edges—see Fig. 13.5b. The shaded
areas in the ﬁgure are now not connected to one another at all and hence are
each now separate components in their own right. And the size of the component to which vertex i belongs on the original network is equal to the sum of
the sizes of these new components, plus one for vertex i itself.
A crucial point to notice, however, is that the neighbors n1 , n2 , . . . of vertex i
are, by deﬁnition, reached by following an edge. Hence, as we have discussed,
these are not typical network vertices, being more likely to have high degree

457

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

n1

n1
i

n3

n3

n2

n2

(a)

(b)

Figure 13.5: The size of one of the small components in the conﬁguration model. (a) The size of the component to
which a vertex i belongs is the sum of the number of vertices in each of the subcomponents (shaded regions) reachable
via i’s neighbors n1 , n2 , n3 , plus one for i itself. (b) If vertex i is removed the subcomponents become components in
their own right.

than the typical vertex. Thus the components that they belong to in Fig. 13.5b—
the shaded regions in the ﬁgure—are not distributed according to πs . Instead
they must have some other distribution. Let us denote this distribution by ρs .
More speciﬁcally, let ρs be the probability that the vertex at the end of an edge
belongs to a small component of size s after that edge is removed. Let us also
deﬁne the generating function for this distribution to be
∞

h1 ( z ) = ∑ ρ s z s .

(13.78)

s =0

We don’t yet know the value of ρs or its generating function and we will have
to calculate them later, but for the moment let us proceed with the information
we have.
Suppose that vertex i on the original network has degree k and let us denote
by P(s|k ) the probability that, after i is removed, its k neighbors belong to
small components of sizes summing to exactly s. Alternatively, P(s − 1|k ) is
the probability that i itself belongs to a small component of size s given that its
degree is k. Then the total probability πs that i belongs to a small component
of size s is this probability averaged over k thus:
∞

π s = ∑ p k P ( s − 1| k ).
k =0

458

(13.79)

13.7

|

G ENERATING FUNCTIONS FOR THE SMALL COMPONENTS

Substituting this expression into Eq. (13.77) we then get an expression for the
generating function for πs as follows:
∞

∞

∞

s =1 k =0
∞
∞

k =0

s =1

∞

h 0 ( z ) = ∑ ∑ p k P ( s − 1 | k ) z s = z ∑ p k ∑ P ( s − 1 | k ) z s −1

= z ∑ pk ∑ P(s|k )zs .
k =0

(13.80)

s =0

The ﬁnal sum in this expression is the generating function for the probability
that the k neighbors belong to small components whose size sums to s. But the
sizes of the small components are independent of one another and hence we
can use the “powers” property of generating functions (Section 13.1.4), which
tells us that the generating function we want is just equal to the generating
function for the size of the component any single neighbor belongs to—the
function that we denoted h1 (z) above—raised to the kth power. Thus
∞

h0 (z) = z ∑ pk [ h1 (z)]k = zg0 (h1 (z)).

(13.81)

k =0

We still don’t know the generating function h1 (z) but we can derive it now
quite easily. We consider the network in which vertex i is removed and ask
what is the probability ρs that one of the neighbors of i belongs to a component
of size s in this network. In the limit of large network size, the removal of the
single vertex i will have no effect on the degree distribution, so the network
still has the same distribution as before, which means that if the neighbor has
degree k then its probability of belonging to a component of size s is P(s − 1|k ),
just as before. Note, however, that the degree k does not follow the ordinary degree distribution. Since the neighbor was reached by following an edge from i,
its degree, discounting the edge to i that has been removed, follows the excess
degree distribution qk deﬁned in Eq. (13.46), rather than the ordinary degree
distribution. Thus
∞

ρ s = ∑ q k P ( s − 1| k ),

(13.82)

k =0

and, substituting this expression into Eq. (13.78), we have
∞

∞

∞

s =1 k =0

k =0

s =0

∞

h1 ( z ) = ∑ ∑ q k P ( s − 1| k ) z s = z ∑ q k ∑ P ( s | k ) z s .

(13.83)

As before, the last sum is the generating function for P(s|k ), which is equal
to [ h1 (z)]k , and hence
∞

h1 (z) = z ∑ qk [ h1 (z)]k = zg1 (h1 (z)).

(13.84)

k =0

459

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Collecting together our results, the generating functions for πs and ρs thus
satisfy
h0 (z) = zg0 (h1 (z)),

(13.85)

h1 (z) = zg1 (h1 (z)).

(13.86)

If we can solve the second of these equations for h1 (z) then we can substitute
the result into the ﬁrst equation and we have our answer for h0 (z). In practice,
it is often not easy to solve for h1 (z), and, even if it is, extracting the actual
component size distribution from the generating function can be difﬁcult. But
that does not mean that these results are useless. On the contrary, there are
many useful things we can deduce from them. One important quantity we can
calculate is the size of the giant component.

13.8

G IANT COMPONENT

Given the deﬁnition h0 (z) = ∑s πs zs , where πs is the probability that a randomly chosen vertex belongs to a small component of size s, we have h0 (1) =
∑s πs , which is the total probability that a randomly chosen vertex belongs to
a small component. Unlike most generating functions, it is not necessarily the
case that h(1) = 1 because there may be a giant component in the network.
If there is a giant component then some of the vertices do not belong to any
small component and ∑s πs will be less than 1. In fact, ∑s πs will be simply the
fraction of vertices that belong to small components and hence the fraction S
of vertices belonging to the giant component is
∞

S = 1 − ∑ πs = 1 − h0 (1) = 1 − g0 (h1 (1)),

(13.87)

s =0

where we have used Eq. (13.85). The value of h1 (1) we can get from Eq. (13.86):
h1 (1) = g1 (h1 (1)).

(13.88)

The quantity h1 (1) will occur frequently in subsequent developments, so for
convenience let us deﬁne the shorthand notation
u = h1 (1),

(13.89)

in which case Eqs. (13.87) and (13.88) can be written

460

S = 1 − g0 ( u ) ,

(13.90)

u = g1 ( u ) .

(13.91)

13.8

|

G IANT COMPONENT

In other words, u is a ﬁxed point of the function g1 (z)—a point where the
function is equal to its own argument—and if we can ﬁnd this ﬁxed point then
we need only substitute the result into Eq. (13.90) and we have the size of the
giant component.
Since g1 (1) = 1 (see Eq. (13.20) and the discussion that precedes it), there
is always a ﬁxed point of g1 at u = 1, but this solution gives S = 1 − g0 (1) =
0 and hence no giant component. If there is to be a giant component there
must be at least one other non-trivial solution to Eq. (13.91). We will see some
examples of such solutions shortly.
The quantity u = h1 (1) has a simple physical interpretation. Recall that
h1 (z) = ∑s ρs zs is the generating function for the probability ρs that the vertex
reached by following an edge belongs to a small component of size s if that
edge is removed. Thus h1 (1) = ∑s ρs is the total probability that such a vertex
belongs to a small component of any size, or equivalently the probability that
it doesn’t belong to the giant component.
This observation suggests an alternative and simpler derivation of Eqs.
(13.90) and (13.91) for the size of a giant component, as follows. To belong
to the giant component, a vertex A must be connected to the giant component
via at least one of its neighbors. Or equivalently, A does not belong to the giant component if (and only if) it is not connected to the giant component via
any of its neighbors. Let us deﬁne u to be the average probability that a vertex
is not connected to the giant component via its connection to some particular
neighboring vertex. If vertex A has k neighbors, then the probability that it
is not connected to the giant component via any of them is thus uk . And the
average of this probability over the whole network is ∑k pk uk = g0 (u), which
is the average probability that a vertex is not in the giant component. But this
probability is also, by deﬁnition, equal to 1 − S, where S is the fraction of the
graph occupied by the giant component and hence 1 − S = g0 (u) or
S = 1 − g0 ( u ) ,

(13.92)

which is Eq. (13.90) again.
Now let us ask what the value of u is. The probability that you are not
connected to the giant component via a particular neighboring vertex is equal
to the probability that that vertex is not connected to the giant component via
any of its other neighbors. If there are k of those other neighbors, then that
probability is again uk . But because we are talking about a neighboring vertex,
k is now distributed according to the excess degree distribution qk , Eq. (13.46),
and hence taking the average, we ﬁnd that u = ∑k qk uk or
u = g1 ( u ) ,

(13.93)
461

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

which is Eq. (13.91) again. Thus we have rederived our two equations for the
size of the giant component, but by a much shorter route. The main disadvantage of this method is that it only gives the size of the giant component and
not the complete generating function for all the other components as well, and
this is the reason why we took the time to go through the longer derivation.
There are many further results we can derive by knowing the entire generating
function, as we show in the next section.
13.8.1

E XAMPLE

Let’s take a look at a concrete example and see how calculations for the conﬁguration model work out in practice. Consider a network like that of the ﬁrst
example in Section 13.1.1 that has vertices only of degree 0, 1, 2 and 3, and no
vertices of higher degree. Then the generating functions g0 (z) and g1 (z) take
the form
g0 ( z ) = p 0 + p 1 z + p 2 z 2 + p 3 z 3 ,

(13.94)

g (z)
p1 + 2p2 z + 3p3 z2
g1 (z) = 0
=
g0 ( 1 )
p1 + 2p2 + 3p3
= q0 + q1 z + q2 z2 .

(13.95)

Equation (13.91) is thus quadratic in this case, u = q0 + q1 u + q2 u2 , which has
the solutions
(
1 − q1 ± (1 − q1 )2 − 4q0 q2
u=
.
(13.96)
2q2
However, we know that ∑k qk = 1, and hence in this case 1 − q1 = q0 + q2 .
Using this result to eliminate q1 we get
(
(q0 + q2 ) ± (q0 + q2 )2 − 4q0 q2
u=
2q2
( q0 + q2 ) ± ( q0 − q2 )
=
2q2
q0
= 1 or
.
(13.97)
q2
Thus, as expected we have a solution u = 1, but we also have another nontrivial solution which might imply that we have a giant component.
If q2 < q0 then this non-trivial solution gives u > 1. Since u is a probability
it cannot be greater than 1, so in this case we deﬁnitely do not have a giant
component. On the other hand, if q2 > q0 we have a viable non-trivial solution

462

13.8

u < 1 equal to
u=

q0
p1
=
,
q2
3p3

|

G IANT COMPONENT

(13.98)

where we have extracted values of q0 and q2 from Eq. (13.95). We can also write
the condition q2 > q0 in terms of the pk as
p3 > 13 p1 .

(13.99)

In other words, there can be a giant component if the number of vertices of
degree three exceeds one third the number of degree one. This is a remarkable
result. It says that the number of vertices of degree zero and degree two don’t
matter at all (except to the extent that their absence makes room for more vertices of the other degrees). As we will see, this is actually a general result—the
values of p0 and p2 never make any difference to the presence or absence of a
giant component. On the other hand, the size of the giant component for the
current example is given by Eq. (13.90) to be
S = 1 − g0 ( u ) = 1 − p 0 −

p3
p21
p2 p2
− 1 2 − 12.
3p3
9p3
27p3

(13.100)

Thus the size of the giant component does depend on p0 and p2 , even though
its presence or absence does not.
We have not, however, yet proved that a giant component actually does exist. In the regime where we have two solutions for u, one with u = 1 (no giant
component) and one with u < 1 (there is a giant component) it is unclear which
of these solutions we should believe. In Section 13.6, however, we showed that
there is a giant component in the network when the degree sequence satisﬁes
a speciﬁc condition, Eq. (13.76). In the next section, we show that in fact this
condition is always satisﬁed whenever a non-trivial solution u < 1 exists, and
hence that there is always a giant component when we have such a solution.
13.8.2

G RAPHICAL SOLUTIONS AND THE EXISTENCE OF THE GIANT
COMPONENT

The example given in the last section is unusual in that we can solve the ﬁxedpoint equation (13.91) exactly for the crucial parameter u. In most other cases
exact solutions are not possible, but we can nonetheless get a good idea of the
behavior of u by graphical means. The derivatives of g1 (z) are proportional to
the probabilities ρs and hence are all non-negative. That means that for z ≥ 0,
g1 (z) is in general positive, an increasing function of its argument, and upward
concave. It also takes the value 1 when z = 1. Thus it must look qualitatively
like one of the curves in Fig. 13.6. The solution of the ﬁxed-point equation
463

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

1

y = g1(u)

y

0.5

y=u

Figure 13.6: Graphical solution of Eq. (13.91). The solution of the equation u = g1 (u) is given by the point
at which the curve y = g1 (u) intercepts the line y = u.

0

0

1

0.5

u

u = g1 (u) is then given by the intercept of the curve y = g1 (u) with the line
y = u (the dotted line in the ﬁgure).
As we already know, there is always a trivial solution at u = 1 (top right
in the ﬁgure). But now we can see that there can be just one other solution
with u < 1 and only if the curve takes the right form. In particular, we have a
non-trivial solution at u < 1 if the slope g1 (1) of the curve at u = 1 is greater
than the slope of the dotted line. That is, if
g1 (1) > 1.

(13.101)

Using Eq. (13.49) for g1 (z), we have
∞

g1 (1) = ∑ kqk =

=

k =0
2

k

1
k

∞

1

∞

∑ k(k + 1) pk = k ∑ (k − 1)kpk

k =0

− k
.
k

k =0

(13.102)

Thus our condition for the solution at u < 1 is
k2 − k
> 1.
k

(13.103)

k2 − 2 k > 0,

(13.104)

or equivalently,

464

13.9

|

S IZE DISTRIBUTION FOR SMALL COMPONENTS

But this is none other than the condition for the existence of a giant component, Eq. (13.76). In other words, the conditions for the existence of a giant
component and the existence of the non-trivial solution to Eq. (13.91) are exactly the same and and hence, as promised, there is always a giant component
whenever a solution u < 1 exists for Eq. (13.91).
Writing k = n−1 ∑i k i and k2 = n−1 ∑i k2i , we can also write Eq. (13.104)
as
(13.105)
∑ ki (ki − 2) > 0.
i

But note now that, as before, vertices of degree zero and degree two make no
contribution to the sum, since terms in which k i = 0 or k i = 2 vanish. Thus we
can add as many vertices of degree zero or two to the network as we like (or
take them away) and it will make no difference to the existence or not of a giant
component. We noted a special case of this phenomenon in Section 13.8.1.

13.9

S IZE DISTRIBUTION FOR SMALL COMPONENTS

Having looked in some detail at the behavior of the giant component in the
conﬁguration model, let us return once more to the small components. In
Eqs. (13.85) and (13.86) we have—in theory at least—the generating functions
that give the entire distribution of sizes of the small components. Unfortunately, it is in most cases impossible to solve these equations exactly, but we
can still extract plenty of useful information from them. For example, we can
calculate the mean size of the component to which a randomly chosen vertex
belongs, which is given by the equivalent of Eq. (12.29) thus:
s =

h  (1)
h  (1)
∑s sπs
= 0
= 0
,
1−S
g0 ( u )
∑s πs

(13.106)

where we have used Eq. (13.90) in the ﬁnal equality. Differentiating Eq. (13.85)
we get
h0 (z) = g0 (h1 (z)) + zg0 (h1 (z))h1 (z)

= g0 (h1 (z)) + zg0 (1) g1 (h1 (z))h1 (z)
=

h0 ( z )
+ g0 (1)h1 (z)h1 (z),
z

(13.107)

where we have used Eq. (13.51) in the second equality and Eqs. (13.85) and
(13.86) in the third. Setting z = 1 we then get
h0 (1) = h0 (1) + g0 (1)h1 (1)h1 (1) = 1 − S + g0 (1)h1 (1)u,

(13.108)
465

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

where we have used Eqs. (13.87) and (13.89). To calculate h1 (1) we differentiate
Eq. (13.86) thus:
h1 (z) = g1 (h1 (z)) + zg1 (h1 (z))h1 (z)

=

h1 ( z )
+ zg1 (h1 (z))h1 (z),
z

(13.109)

h1 (z)/z
.
1 − zg1 (h1 (z))

(13.110)

or, rearranging,
h1 (z) =

Setting z = 1 in this expression gives
h1 (1) =

u
.
1 − g1 (u)

(13.111)

Combining Eqs. (13.106), (13.108), and (13.111), we then ﬁnd that
s = 1+

g0 (1)u2
.
g0 (u)[1 − g1 (u)]

(13.112)

Using values of S and u from Eqs. (13.90) and (13.91) we can then calculate s
from this equation.
A simple case occurs when we are in the region where there is no giant
component. In this region we have S = 0 and u = 1 by deﬁnition and hence
s = 1+

g0 (1)
.
1 − g1 (1)

(13.113)

Thus the average size of the component to which a vertex belongs diverges
precisely at the point where g1 (1) = 1, the point at which the curve in Fig. 13.6
is exactly tangent to the dotted line (the middle curve in the ﬁgure). This is, of
course, also the point at which the giant component ﬁrst appears.
Thus the picture we have is similar to that shown in Fig. 12.4 for the Poisson
random graph, in which the typical size of the component to which a vertex
belongs grows larger and larger until we reach the point, or phase transition,
where the giant component appears, at which it diverges. Beyond this point
the small components shrink in size again, although the overall mean component size, including the giant component, is inﬁnite.
Equation (13.113) can also be expressed in a couple of other forms that
may be useful in some circumstances. From Eq. (13.69) we know that g1 (1) =
( k2 − k )/ k and, putting g0 (1) = k also, we ﬁnd that
s = 1+
466

k 2
.
2 k − k2

(13.114)

13.9

|

S IZE DISTRIBUTION FOR SMALL COMPONENTS

This expression can be evaluated easily given only a knowledge of the degree
sequence and avoids the need to calculate any generating functions. Using the
notation introduced earlier in which c1 and c2 are the mean number of ﬁrst
and second neighbors of a vertex, with c2 given by Eq. (13.70), we can also
write (13.114) in the form
c21
s = 1+
,
(13.115)
c1 − c2
so that the average size of the component a vertex belongs to is dictated entirely by the mean numbers of ﬁrst and second neighbors.
13.9.1

AVERAGE SIZE OF A SMALL COMPONENT

As with the Poisson random graph, we must be careful about our claims in
the previous section. We have calculated the average size s of the component to which a randomly chosen vertex belongs but this is not the same thing
as the average size of a component, since more vertices belong to larger components, which biases the value of s . If we want the true average size R of
the small components, we must use Eq. (12.36), which we reproduce here for
convenience:
1−S
.
(13.116)
R=
∑s πs /s
The sum can be calculated as before using the equivalent of Eq. (12.37):
∞

πs
∑ s =
s =1

 1
0

h0 ( z )
dz.
z

(13.117)

Taking h0 (z)/z from Eq. (13.107), we get
∞

 1

πs

 1

dh0

dh1

∑ s = 0 dz dz − g0 (1) 0 h1 (z) dz dz

s =1

=

 1− S
0

dh0 − k

 u
0

h1 dh1

= 1 − S − 12 k u2 .
Then
R=

2
.
2 − k u2 / (1 − S )

(13.118)

(13.119)

Note that the value of this average at the transition point where S = 0 and
u = 1 is just 2/(2 − k ), which is normally perfectly ﬁnite.14 Thus the average
component size does not normally diverge at the transition (unlike s ).
14

The only exception is when k = 2 at the transition point.

467

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

13.9.2

C OMPLETE DISTRIBUTION OF SMALL COMPONENT SIZES

One of the most surprising results concerning the conﬁguration model is that
it is possible to derive an expression not just for the average size of the component to which a vertex belongs, but for the exact probability that it belongs to a
component of any speciﬁc size—the probability that it belongs to a component
of size ten, or a hundred, or a million. The derivation of this result is similar
to the derivation given in Section 12.6.3 for the corresponding quantity for the
Poisson random graph.
Since a component cannot have size zero, the generating function for the
probabilities πs has the form
∞

h0 ( z ) = ∑ π s z s ,

(13.120)

s =1

with the sum starting at 1. Dividing by z and differentiating s − 1 times, we
then ﬁnd that
 s −1

d
h0 ( z )
1
,
(13.121)
πs =
(s − 1)! dzs−1
z
z =0
(which is just a minor variation on the standard formula, Eq. (13.2)). Using
Eq. (13.85), this can also be written
 s −1

d
1
g
(
h
(
z
))
0 1
(s − 1)! dzs−1
z =0
 s −2

d
1


g (h1 (z))h1 (z)
=
.
(s − 1)! dzs−2 0
z =0

πs =

(13.122)

Now we make use of the Cauchy formula for the n derivative of a function,
which says that
"
&
dn f ""
n!
f (z)
=
dz,
(13.123)
"
n
dz z=z0
2πi
( z − z 0 ) n +1
where the integral is around a contour that encloses z0 in the complex plane
but encloses no poles in f (z). Applying this formula to Eq. (13.122) with z0 = 0
we get
& 
1
g0 (h1 (z)) dh1
dz.
(13.124)
πs =
2πi(s − 1)
z s −1
dz
For our contour, we choose an inﬁnitesimal circle around the origin.
Changing the integration variable to h1 , we can also write this as
πs =

468

1
2πi(s − 1)

&

g0 (h1 )
dh1 .
z s −1

(13.125)

13.9

|

S IZE DISTRIBUTION FOR SMALL COMPONENTS

Here we are regarding z now as a function of h1 , rather than the other way
around. Furthermore, since h1 (z) goes to zero as z → 0, the contour in h1
surrounds the origin too. (The proof is the same as for Eq. (12.46).)
Now we make use of Eq. (13.86) to eliminate z and write
πs =

1
2πi(s − 1)

=

g0 (1)
2πi(s − 1)

&

g1 ( h 1 )

&

g1 ( h 1 )

s −1 
g0 ( h 1 )
dh1
s −1
h1
s

h1s−1

dh1 ,

(13.126)

where we have made use of Eq. (13.51) in the second line. Given that the contour surrounds the origin, this integral is now in the form of Eq. (13.123) again,
and hence
 s −2

d
k
s
g
πs =
(
z
)
,
(13.127)
1
(s − 1)! dzs−2
z =0
where we have written g0 (1) = k .
The only exception to this formula is for the case s = 1, for which Eq.
(13.124) gives 0/0 and is therefore clearly incorrect. However, since the only
way to belong to a component of size 1 is to have no connections to any other
vertices, the probability π1 is trivially equal to the probability of having degree
zero:
(13.128)
π1 = p0 .
Equations (13.127) and (13.128) give the probability that a randomly chosen
vertex belongs to a component of size s in terms of the degree distribution. In
principle if we know pk we can calculate πs . It is not always easy to perform
the derivatives in practice and in some cases we may not even know the generating function g1 (z) in closed form, but at least in some cases the calculations
are possible. As an example, consider a network with the exponential degree
distribution
(13.129)
pk = (1 − e−λ )e−λk ,
with exponential parameter λ > 0. From Eqs. (13.9) and (13.51) the generating
functions g0 (z) and g1 (z) are given by
g0 ( z ) =

eλ − 1
,
eλ − z

g1 ( z ) =

2

eλ − 1
eλ − z

.

(13.130)

Then it is not hard to show that
s

dn
(2s − 1 + n)! g1 (z)
s
g1 ( z ) =
,
n
dz
(2s − 1)! (eλ − z)n

(13.131)
469

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

10

10

πs

10

-1

-2

10

10

0

-3

-4

0

20

40

60

80

100

Component size s

Figure 13.7: The distribution of component sizes in a conﬁguration model. The probability πs that a vertex belongs to a component of size s for the conﬁguration model
with an exponential degree distribution of the form (13.129) for λ = 1.2. The solid lines
represent the exact formula, Eq. (13.132), for the n → ∞ limit and the points are measurements of πs averaged over 100 computer-generated networks with n = 107 vertices
each.

and hence
πs =


2s−1
(3s − 3)!
e− λ ( s −1) 1 − e− λ
.
(s − 1)!(2s − 1)!

(13.132)

Figure 13.7 shows a comparison of this formula with the results of numerical
simulations for λ = 1.2 and, as we can see, the agreement between formula and
simulations is good—our calculations seem to describe the simulated random
graph well even though the graph is necessarily ﬁnite in size while the calculations are performed in the limit of large n.

13.10

P OWER - LAW DEGREE DISTRIBUTIONS

As we saw in Section 8.4, a number of networks have degree distributions
that approximately obey a power law. As an example of the application of the
machinery developed in this chapter, let us look at the properties of a random
graph with a power-law degree distribution.
Suppose we have a network with a “pure” power-law degree distribution

470

|

13.10

of the form


pk =

0
k−α /ζ (α)

P OWER - LAW DEGREE DISTRIBUTIONS

for k = 0,
for k ≥ 1.

(13.133)

(See Eq. (13.13).) Here α > 0 is a constant exponent and ζ (α) is the Riemann
zeta function:
∞

ζ ( α ) = ∑ k −α .

(13.134)

k =1

Using the results of the previous sections we can, for instance, say whether
there is a giant component in this network or not. Equation (13.76) tells us that
there will be a giant component if and only if
k2 − 2 k > 0.

(13.135)

In the present case
5

∞

1 ∞ − α +1
ζ ( α − 1)
k = ∑ kpk =
k
=
,
∑
ζ ( α ) k =1
ζ (α)
k =0
(13.136)

y = ζ(α − 2)

4

and
∞

1 ∞ − α +2
ζ ( α − 2)
=
.
∑k
ζ
(
α
)
ζ (α)
k =0
k =1
(13.137)
Thus there is a giant component if
k2 = ∑ k2 pk =

ζ (α − 2) > 2ζ (α − 1).

(13.138)

3

y
2

y = 2ζ(α − 1)

1

Figure 13.8 shows this inequality in graphical form.
The two curves in the ﬁgure show the values of ζ (α −
0
2
3
4
5
2) and 2ζ (α − 1) as functions of α and, as we can see,
the inequality (13.138) is satisﬁed only for sufﬁciently
Exponent α
low values of α, below the dotted line in the ﬁgure. In
fact a numerical solution of the equation ζ (α − 2) =
Figure 13.8: Graphical solution of Eq. (13.138). The
2ζ (α − 1) indicates that the network will have a giant
conﬁguration model with a pure power-law degree
component only for α < 3.4788 . . ., a result ﬁrst given
distribution (Eq. (13.133)) has a giant component if
by Aiello et al. [9] in 2000.
ζ (α − 2) > 2ζ (α − 1). This happens for values of α
In practice this result is of only limited utility bebelow the crossing point of the two curves.
cause it applies only for the pure power law. In general,
other distributions with power-law tails but different
behavior for low k will have different thresholds at which the giant component appears. There is however a general result we can derive that applies
to all distributions with power-law tails. In Section 8.4.2 we noted that the
471

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

second moment k2 diverges for any distribution with a power-law tail with
exponent α ≤ 3, while the ﬁrst moment k remains ﬁnite so long as α > 2.
This means that Eq. (13.135) is always satisﬁed for any conﬁguration model
with a power-law tail to its degree distribution so long as α lies in the range
2 < α ≤ 3, and hence there will always be a giant component no matter what
else the distribution does. For α > 3, on the other hand, there may or may not
be a giant component, depending on the precise functional form of the degree
distribution. (For α ≤ 2 it turns out that there is always a giant component,
although more work is needed to demonstrate this.) Note that, as discussed in
Section 8.4, most observed values of α for real-world networks lie in the range
2 < α ≤ 3 and hence we tentatively expect such networks to have a giant component, although we must also bear in mind that the conﬁguration model is a
simpliﬁed model of a network and is not necessarily a good representation of
any speciﬁc real-world network.
Returning to the pure power law let us calculate the size S of the giant
component, when there is one. The fundamental generating functions g0 (z)
and g1 (z) for the power-law distribution are given by Eqs. (13.55) and (13.56),
which we repeat here for convenience:
g0 ( z ) =

Liα (z)
,
ζ (α)

g1 ( z ) =

Liα−1 (z)
.
zζ (α − 1)

(13.139)

Here ζ (α) is the Riemann zeta function again and Liα (z) is the polylogarithm
∞

Liα (z) = ∑ k−α zk .

(13.140)

k =1

(See Eq. (13.15).) Now the crucial equation (13.91) for the probability u = h1 (1)
reads
u=

∞
∞
k − α +1 u k
Liα−1 (u)
∑
∑ ( k + 1 ) − α +1 u k
,
= k =1
= k =0
uζ (α − 1)
uζ (α − 1)
ζ ( α − 1)

(13.141)

where we have used the explicit deﬁnition of the polylogarithm for clarity.
In general there is no closed-form solution for this equation, but we do notice some interesting points. In particular, note that the sum in the numerator
is strictly positive for u ≥ 0, which means that if ζ (α − 1) diverges we will get
a solution u = 0. And indeed ζ (α − 1) does diverge. It diverges at α = 2 and
all values below, as one can readily verify from the deﬁnition, Eq. (13.134).15
15
Traditionally ζ ( x ) is actually deﬁned to have ﬁnite values below x = 1 by analytic continua− x , which diverges for
tion. But in our case we are really interested in the value of the sum ∑∞
k =1 k
all x ≤ 1.

472

13.11

|

D IRECTED RANDOM GRAPHS

Thus for α ≤ 2 we have u = 0 and Eq. (13.90) then tells us that the giant component has size S = 1 − g0 (0) = 1 − p0 . However, for our particular choice
of degree distribution, Eq. (13.133), there are no vertices with degree zero, and
hence p0 = 0 and S = 1. That is, the giant component ﬁlls the entire network
and there are no small components at all!
Technically, this statement is not quite correct. There is always some chance
that, for instance, a vertex of degree 1 will connect to another vertex of degree
1, forming a small component. What we have shown is that the probability that
a randomly chosen vertex belongs to a small component is zero in the limit of
large n, i.e., that what small components there are ﬁll a fraction of the network
that vanishes as n → ∞. In the language used by mathematicians, a randomly
chosen vertex “almost surely” belongs to the giant component, meaning it is
technically possible to observe another outcome, but the probability is vanishingly small.
Thus our picture of the pure power-law conﬁguration model is one in which
there is a giant component for values of α < 3.4788 . . . and that giant component ﬁlls essentially the entire network when α ≤ 2. In the region between
α = 2 and α = 3.4788 there is a giant component but it does not ﬁll the whole
network and some portion of the network consists of small component. If
α > 3.4788 . . . there are only small components. As a conﬁrmation of this
picture, Fig. 13.9 shows the size of the giant component extracted from a numerical solution of Eq. (13.141).16 As we can see it ﬁts nicely with the picture
described above.
We could in principle take our calculations further, calculating, for instance,
the mean size of the small components in the region α > 2 using Eq. (13.112),
or the entire distribution of their sizes using Eq. (13.127).

13.11

D IRECTED RANDOM GRAPHS

In this chapter we have studied random graph models that go a step beyond
the Poisson random graph of Chapter 12 by allowing us to choose the degree
distribution of our model network. This introduces an additional level of realism to the model that makes it substantially more informative. It is, however,
only a ﬁrst step. There are many other features we can add to the model to
make it more realistic still. We can for instance create random graph models
of networks with assortative (or disassortative) mixing [237], bipartite strucThe numerical solution is simple: we just choose a suitable starting value (u = 12 works
ﬁne) and iterate Eq. (13.141) until it converges. Fifty iterations are easily enough to give a highly
accurate result.
16

473

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Size of giant component S

1

0.5

0

1

2

3

4

Exponent α

Figure 13.9: Size of the giant component for the conﬁguration model with a powerlaw degree distribution. This plot shows the fraction of the network ﬁlled by the giant
component as a function of the exponent α of the power law, calculated by numerical
solution of Eqs. (13.91) and (13.141). The dotted lines mark the value α = 2 below which
the giant component has size 1 and the value α = 3.4788 above which there is no giant
component.

ture [253], or clustering [247]. All of these models are still exactly solvable
in the limit of large system size, although the solutions are more complicated
than for the models we have seen in this chapter. For instance, in the case of
the random graph with assortative mixing the fundamental generating function g1 (z) becomes a vector, the corresponding equation (13.86) for the distribution of component sizes becomes a vector equation, and the condition for
the existence of a giant component, Eq. (13.76), becomes a condition on the
determinant of a matrix.
We will not go into detail on all of the many random graph models that
have been proposed and studied, but in this section we take a look at one case,
that of the directed random graph, as an example of the types of calculation
that are possible.
13.11.1

G ENERATING FUNCTIONS FOR DIRECTED GRAPHS

As discussed in Section 6.4, many networks, including the World Wide Web,
metabolic networks, food webs, and others, are directed. The conﬁguration
model can be generalized to directed networks in a straightforward fashion,

474

13.11

|

D IRECTED RANDOM GRAPHS

although the generalization displays some new behaviors not seen in the undirected case. Our presentation follows that of Refs. [100] and [253].
To create a directed equivalent of the conﬁguration model, we must specify
a double degree sequence, consisting of an in-degree ji and an out-degree k i for
each vertex i. We can think of these as specifying the numbers of ingoing and
outgoing stubs of edges at each vertex. Then we create a network by repeatedly
choosing pairs of stubs—one ingoing and one outgoing—uniformly at random
and connecting them to make directed edges, until no unused stubs remain.
The result is a matching of the stubs drawn uniformly at random from the set
of all possible matchings, just as in the conﬁguration model, and the model
itself is deﬁned to be the ensemble of such directed networks in which each
matching appears with equal probability. (The only small catch is that we must
make sure that the total number of ingoing and outgoing stubs is the same, so
that none are left over at the end of the process. We will assume this to be the
case in the following developments.)
The probability that a particular outgoing stub at vertex w attaches to one
of the jv ingoing stubs at vertex v is
jv
jv
= ,
m
∑i ji

(13.142)

where m is the total number of edges and we have made use of Eq. (6.26).
Since the total number of outgoing stubs at w is k w , the total expected number
of directed edges from vertex w to vertex v is then jv k w /m, which is also the
probability of an edge from w to v in the limit of large network size, provided
the network is sparse. This is similar to the corresponding result, Eq. (13.32),
for the undirected conﬁguration model, but not identical—notice that there is
no factor of two now in the denominator.
As in the undirected case we can, if we prefer, work with the degree distribution, rather than the degree sequence. As discussed in Section 8.3, the
most correct way to describe the degree distribution of a directed network is
by a joint distribution: we deﬁne p jk to be the fraction of vertices in the network that have in-degree j and out-degree k. This allows for the possibility
that the in- and out-degrees of vertices are correlated. For instance, it would
allow us to represent a network in which the in- and out-degrees of each vertex
were exactly equal to one another.17 (This is rather an extreme example, but it
demonstrates the point.)
The joint degree distribution can be captured in generating function form
17

Given the joint degree distribution we can still, if we wish, calculate the distributions of in- or

475

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

by deﬁning a double generating function g00 ( x, y) thus:
∞

g00 ( x, y) = ∑ p jk x j yk .

(13.143)

j,k =0

(The two subscript zeros are the equivalent for the double generating function of the subscript zero in our previous generating function g0 (z) for the undirected network.) As in the undirected case, the generating function g00 ( x, y)
captures all the information contained in the degree distribution. Given the
generating function we can reconstruct the degree distribution by differentiating:
"
1 ∂ j ∂k g00 ""
.
(13.144)
p jk =
j! k! ∂x j ∂yk "
x,y=0

This is the equivalent for the directed case of Eq. (13.2) in the undirected case.
Just as in the undirected case the generating function satisﬁes certain conditions. First, since the degree distribution must be normalized according to
∑ jk p jk = 1, the generating function satisﬁes
g00 (1, 1) = 1.

(13.145)

Second, the average in- and out-degrees are given by
"
∞
∂g00 ""
j = ∑ jp jk =
,
∂x " x,y=1
j,k =0
"
∞
∂g00 ""
.
k = ∑ kp jk =
∂y " x,y=1
j,k =0

(13.146)
(13.147)

In a directed graph, however, the average in- and out-degrees are equal—see
Eq. (6.27)—so j = k and
"
"
∂g00 ""
∂g00 ""
=
.
(13.148)
∂x " x,y=1
∂y " x,y=1
For convenience we will denote the average in-degree and out-degree by c in
the equations that follow. Thus j = k = c.
out-degrees alone. They are given by
(in)

pj
.

476

∞

= ∑ p jk ,
k =0

(out)

pk

∞

= ∑ p jk .
j =0

13.11

|

D IRECTED RANDOM GRAPHS

We can also write down generating functions for the excess degree distribution of vertices reached by following an edge in the network. There are two
different ways of following a directed edge—either forward or backward. Consider ﬁrst the forward case. If we follow an edge forward to the vertex it points
to, then the probability of reaching a particular vertex will be proportional to
the number of edges pointing to that vertex, i.e., to its in-degree. Thus the joint
degree distribution of such a vertex is proportional not to p jk but to jp jk . As
before, we will be interested primarily in the number of edges entering and
leaving a vertex other than the one we arrived along. If j and k denote these
numbers then the total in-degree is j + 1 and the total out-degree is just k, so
the distribution we want is proportional to ( j + 1) p j+1,k or, correctly normalized, ( j + 1) p j+1,k /c. The double generating function for this excess degree
distribution is then
g10 ( x, y) =

=

∑ jk ( j + 1) p j+1,k x j yk
∑ jk jp jk x j−1 yk
=
∑ jk ( j + 1) p j+1,k
∑ jk jp jk
1 ∂g00
.
c ∂x

(13.149)

The backward case is similar. The appropriate excess degree distribution
for the vertex from which an edge originates is (k + 1) p j,k+1 /c and has generating function
g01 ( x, y) =

13.11.2

∑ jk (k + 1) p j,k+1 x j yk
1 ∂g00
.
=
c ∂y
(
k
+
1
)
p
∑ jk
j,k +1

(13.150)

G IANT COMPONENTS

A directed graph has various different types of component, as discussed in Sections 6.11.1 and 8.1.1, including strongly and weakly connected components,
in-components, and out-components. (Take a look at the “bow tie” diagram,
Fig. 8.2 on page 240, for a reminder of the deﬁnitions of the components.) In
general there can be both small and giant components of each of these types.
Let us look at the giant components.
A strongly connected component is a set of vertices in which every vertex is
reachable by a directed path from every other in the set. To put that a different
way, for a vertex to belong to a strongly connected component at least one of its
outgoing edges must lead to another vertex from which there is a path to the
strongly connected component, and at least one of its ingoing edges must lead
from a vertex to which there is path from the strongly connected component
(see ﬁgure).

Strongly
connected
component

A vertex belongs to a
strongly connected component if it has a directed
path to the component
and another from the
component.

477

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

Let v be the probability that the vertex to which a randomly chosen edge
in our graph leads has no directed path to the giant strongly connected component. For this to happen, it must be that none of the other outgoing edges
from that vertex themselves have such a path. If the vertex has out-degree k,
this happens with probability vk . But j and k are distributed according to the
excess degree distribution ( j + 1) p j+1,k /c and hence, averaging over both, we
ﬁnd that
1 ∞
(13.151)
v = ∑ ( j + 1) p j+1,k vk = g10 (1, v).
c j,k=0
Similarly, consider the vertex from which a randomly chosen edge originates and let u be the probability that there is no path from the giant strongly
connected component to that vertex. Then u is the solution to
u = g01 (u, 1).

(13.152)

Now consider a vertex with in-degree j and out-degree k. The probability
that there is no path to the vertex from the giant strongly connected component
via any of the vertex’s j ingoing edges is u j and the probability that there is such
a path is 1 − u j . Similarly the probability that there is a path from the vertex
to the giant strongly connected component is 1 − vk . And the probability that
there are both—and hence that the vertex itself belongs to the giant strongly
connected component—is the product of these two, or (1 − u j )(1 − vk ). Averaging this expression over the joint distribution of j and k we then ﬁnd that
the average probability Ss that a vertex lies in the giant strongly connected
component, which is also the size of the giant strongly connected component
measured as a fraction of the network size, is
∞

Ss = ∑ p jk (1 − u j )(1 − vk )
j,k =0
∞

∞

∞

∞

j,k =0

j,k =0

j,k =0

j,k =0

= ∑ p jk − ∑ p jk u j − ∑ p jk vk + ∑ p jk u j vk
= 1 − g00 (u, 1) − g00 (1, v) + g00 (u, v),

(13.153)

with u and v given by Eqs. (13.151) and (13.152).
As discussed in Section 6.11, each strongly connected component in a network also has an in-component and an out-component associated with it—the
sets of vertices from which it can be reached, and which can be reached from
it. The in- and out-components of the giant strongly connected component are
usually called the giant in- and out-components. By their deﬁnition, both are

478

13.11

|

D IRECTED RANDOM GRAPHS

supersets of the giant strongly connected component itself, and we can calculate the size of both for our directed random graph. In fact, we have performed
most of the calculation already.
A vertex with out-degree k fails to belong to the giant in-component only
if none of its outgoing edges leads to a vertex that has a path to the strongly
connected component. This happens with probability vk , where v is as above.
Averaging over j and k, we ﬁnd the probability Si that the vertex does belong
to the giant in-component (which is also the size of the giant in-component) to
be
∞

Si = 1 − ∑ p jk vk = 1 − g00 (1, v).

(13.154)

j,k =0

Similarly the size of the giant out-component is given by
So = 1 − g00 (u, 1).

(13.155)

Using these results we can also write an expression for the combined size
of the giant strongly connected component and its in- and out-components—
the entire “bow tie” in Fig. 8.2. Since the giant in- and out-components both
include the giant strongly connected component as a subset, their sum is equal
to the size of the whole bow tie except that it counts the strongly connected
part twice. Subtracting Ss to allow for this overcounting we then ﬁnd the size
of the bow tie to be
(13.156)
Si + So − Ss = 1 − g00 (u, v),
and the fraction of the network not in the bow tie is just g00 (u, v). (We could
have derived this result by more direct means, just by noting that a vertex
not in the bow tie has a path neither to nor from the giant strongly connected
component.)
And what about the giant weakly connected component? A weakly connected component in a directed graph is a normal graph component of connected vertices in which we ignore the directions of all the edges. At ﬁrst
glance one might imagine that the size of the giant weakly connected component was just equal to the combined size Si + So − Ss of the in-, out-, and
strongly connected components calculated above. This, however, is not correct because the deﬁnition of the giant weakly connected component includes
some vertices that are not in the in-, out-, or strongly connected components.
An example would be any vertex that is reachable from the giant in-component
but that does not itself have a path to the strongly connected component and
hence is not in the giant in-component. Thus the size of the giant weakly connected component is, in general, larger than Si + So − Ss . Nonetheless, we can

479

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

still calculate the size of the giant weakly connected component by an argument quite similar to the ones we have already seen.
A vertex belongs to the giant weakly connected component if any of its
edges, ingoing or outgoing, are connected to a vertex in that component. Let u
now be the probability that a vertex is not connected to the giant weakly connected component via the vertex at the other end of one of its ingoing edges
and let v be the equivalent probability for an outgoing edge. Then the probability that a vertex with in-degree j and out-degree k is not in the giant weakly
connected component is u j vk and the probability that it is in the giant weakly
connected component is 1 − u j vk . Averaging over the joint distribution p jk of
the two degrees we then ﬁnd that the size Sw of the giant weakly connected
component is
(13.157)
Sw = ∑ p jk − ∑ p jk u j vk = 1 − g00 (u, v).
jk

jk

We can derive the value of u by noting that the vertex at the end of an
ingoing edge is not in the giant weakly connected component with probability
u j vk again, but with j and k being the numbers of edges excluding the edge we
followed to reach the vertex. These numbers are distributed according to the
appropriate excess degree distribution and, performing the average, we ﬁnd
that
(13.158)
u = g01 (u, v).
Similarly we can show that
v = g10 (u, v),

(13.159)

and Eqs. (13.157) to (13.159) between them give us our solution for the size of
the giant weakly connected component.
13.11.3

T HE APPEARANCE OF THE GIANT COMPONENTS

As in the undirected random graph, there may or may not be giant components in the direct random graph, depending on the degree distribution. We
can derive conditions for the existence of the giant components using the machinery developed above. The calculation is easiest for the giant in- and outcomponents. Their size is given by Eqs. (13.154) and (13.155). Given that
g00 (1, 1) = 1 (Eq. (13.145)), these equations give a non-zero size only if u or
v is less than 1. Looking at Eq. (13.151) for the value of v we see a similar situation to that depicted in Fig. 13.6: we can have a solution with v < 1, and hence
a giant in-component, only if
"
∂g10 ""
> 1,
(13.160)
∂y " x,y=1
480

13.11

or equivalently if

"
∂2 g00 ""
> c,
∂x∂y " x,y=1

|

D IRECTED RANDOM GRAPHS

(13.161)

where we have made use of Eqs. (13.148) and (13.149). Similarly we can have
a giant out-component only if
"
∂g01 ""
> 1,
(13.162)
∂x " x,y=1
or equivalently,

"
∂2 g00 ""
> c.
∂x∂y " x,y=1

(13.163)

Interestingly, Eqs. (13.161) and (13.163) are identical, meaning that the conditions for the giant in- and out-components to appear are the same. If there is a
phase transition at which one appears, the other also appears at the exact same
moment.18
We can express (13.161) directly in terms of the degree distribution if we
want. Substituting from Eq. (13.143) we ﬁnd that
"
∞
∂2 g00 ""
=
jkp jk
(13.164)
∑
∂x∂y " x,y=1 j,k=0
and hence the giant in- and out-components appear if
∞

∑ jkp jk > c.

(13.165)

j,k =0

If we prefer we can write c = ∑ j jp jk = ∑ j kp jk to give the alternative form
∞

∑ (2jk − j − k) p jk > 0.

(13.166)

j,k =0

This result is the equivalent for a directed network of Eq. (13.76) for the undirected case.
The calculation for the giant strongly connected component is similar. From
Eq. (13.153) we see that Ss = 0 unless at least one of u and v is non-zero,
18
Strictly we have not shown that a giant component actually appears if the condition (13.161)
is satisﬁed. We have only shown that (13.161) is a necessary condition for a giant component to
appear. However, we can go through an argument similar to the one we made for the undirected
case in Section 13.6 to convince ourselves that there must be a giant component when the condition
is satisﬁed.

481

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

so the condition for the existence of a giant strongly connected component is
the same as for the in- and out-components, Eq. (13.166). In other words, the
giant in-, out-, and strongly connected components all appear or disappear
simultaneously.
The giant weakly connected component, however, is different. It is possible
for there to be a giant weakly connected component in a network but no giant
strongly connected component and hence the condition for the existence of a
giant weakly connected component must be different from that for the other giant components. For instance, a network in which all vertices have either only
ingoing edges or only outgoing edges can have a giant weakly connected component but trivially has no strongly connected component of size greater than
one, since there are only paths to or from each vertex, but not both. Weakly
connected components, however, are generally of less interest than strongly
connected ones, and the calculation of the condition for the existence of the
giant weakly connected component is non-trivial, so we leave it as an exercise
for the motivated reader and move on to other things.
13.11.4

S MALL COMPONENTS

We can also calculate the distribution of small components in a directed random graph. In fact the distribution of small strongly connected components is
trivial: there aren’t any. Or more properly the probability that a randomly chosen vertex belongs to a strongly connected component of size greater than one
other than the giant strongly connected component is zero in the limit of large
network size. To see this, recall that the small components in the undirected
conﬁguration model take the form of trees (see Section 13.7). If we consider
a small strongly connected component in a directed network and ignore the
directions of its edges, then the same argument we used before indicates that
the resulting subgraph will also be a tree. But a tree has no loops in it, which
leads to a contradiction because a strongly connected component must have
loops—the paths in either direction between any pair of vertices form a loop.
Thus, we conclude, there cannot be any small strongly connected components
of size greater than one in the network.
In fact, this is not precisely true. In a random network there is always some
chance that, for example, two vertices will each have a directed edge to the
other, forming a strongly connected component of two vertices. In the limit
of large n, however, the probability that a randomly chosen vertex belongs to
such a component tends to zero. A detailed calculation shows that on average
there is only a constant number of short loops in the network and their density
vanishes as 1/n in the limit of large network size.
482

P ROBLEMS

There can however be small in- and out-components. In a directed network, each strongly connected component has its own in- and out-components.
In the present model, as we have said, we have no small strongly connected
components, other than single vertices, so the component structure consists of
the giant in- and out-components and then a large number of small in- and
out-components for single vertices. Let us ask what the probability is that a
randomly chosen vertex has a small out-component of size s, i.e., that there are
s vertices including itself that can be reached by directed paths starting from
the vertex. We can calculate the distribution of sizes by the same method we
used for the undirected case. We deﬁne a generating function h1 (y) for the
distribution of the size of the out-component of a vertex reached by following
an edge in the forward direction, which then satisﬁes an equation of the form
of Eq. (13.86), except that the generating function g1 for the excess degree distribution is replaced by the corresponding generating function for the directed
network, Eq. (13.149), giving
h1 (y) = yg10 (1, h1 (y)).

(13.167)

And the generating function h0 (y) for the size of the out-component to which
a randomly chosen vertex belongs is then
h0 (y) = yg00 (1, h1 (y)).

(13.168)

We can write similar equations for in-components too and, armed with these
equations, we can ﬁnd the average size of the in- or out-component to which
a vertex belongs, or even ﬁnd the entire distribution of component sizes using
the equivalent of Eq. (13.127).

P ROBLEMS
13.1

Consider the binomial probability distribution pk = (nk) pk (1 − p)n−k .

a) Show that the distribution has probability generating function g(z) = ( pz + 1 −
p)n .
b) Find the ﬁrst and second moments of the distribution from Eq. (13.25) and hence
show that the variance of the distribution is σ2 = np(1 − p).
c) Show that the sum of two numbers drawn independently from the same binomial
k
2n−k
.
distribution is distributed according to (2n
k ) p (1 − p )

483

R ANDOM GRAPHS WITH GENERAL DEGREE DISTRIBUTIONS

13.2 Consider a conﬁguration model in which every vertex has the same degree k.
a) What is the degree distribution pk ? What are the generating functions g0 and g1
for the degree distribution and the excess degree distribution?
b) Show that the giant component ﬁlls the whole network for all k ≥ 3.
c) What happens when k = 1?
πs that a vertex
d) When k = 2 show that in the limit of large n the probability
(
belongs to a component of size s is given by πs = 1/ 2 n(n − s) .
13.3 Consider the conﬁguration model with exponential degree distribution pk = (1 −
e−λ )e−λk with λ > 0, so that the generating functions g0 (z) and g1 (z) are given by
Eq. (13.130).
a) Show that the probability u of Eq. (13.91) satisﬁes the cubic equation
u3 − 2eλ u2 + e2λ u − (eλ − 1)2 = 0.
b) Noting that u = 1 is always a trivial solution of this equation, show that the nontrivial solution corresponding to the existence of a giant component satisﬁes the
quadratic equation u2 − (2eλ − 1)u + (eλ − 1)2 = 0, and hence that the size of the
giant component, if there is one, is

S = 32 − eλ − 34 .
c) Show that the giant component exists only if λ < ln 3.
13.4 Equation (13.74) tells us on average how many vertices are a distance d away
from a given vertex.
a) Assuming that this expression works for all values of d (which is only a rough
approximation to the truth), at what value of d is this average number of vertices
equal to the number n in the whole network?
b) Hence derive a rough expression for the diameter of the network in terms of c1
and c2 , and so argue that conﬁguration model networks display the small-world
effect in the sense that typical geodesic distances between vertices are O(log n).
13.5 Consider a network model in which edges are placed independently between
each pair of vertices i, j with probability pij = K f i f j , where K is a constant and f i is a
number assigned to vertex i. Show that the expected degree ci of vertex i within the
model is proportional to f i , and hence that the only possible choice of probability with
this form is pij = ci c j /2m, as in the model of Section 13.2.2.
13.6 As described in Section 13.2, the conﬁguration model can be thought of as the
ensemble of all possible matchings of edge stubs, where vertex i has k i stubs. Show that
for a given degree sequence the number Ω of matchings is
Ω=

(2m)!
,
2m m!

which is independent of the degree sequence.

484

P ROBLEMS

13.7 Consider the example model discussed in Section 13.8.1, a conﬁguration model
with vertices of degree three and less only and generating functions given by Eqs. (13.94)
and (13.95).
a) In the regime in which there is no giant component, show that the average size of
the component to which a randomly chosen vertex belongs is
s = 1+

( p1 + 2p2 + 3p3 )2
.
p1 − 3p3

b) In the same regime ﬁnd the probability that such a vertex belongs to components
of size 1, 2, and 3.
13.8

Consider a directed random graph of the kind discussed in Section 13.11.

a) If the in- and out-degrees of vertices are uncorrelated, i.e., if the joint in/outdegree distribution p jk is a product of separate functions of j and k, show that a
giant strongly connected component exists in the graph if and only if c(c − 1) > 0,
where c is the mean degree, either in or out.
b) In real directed graphs the degrees are usually correlated (or anti-correlated). The
correlation can be quantiﬁed by the covariance ρ of in- and out-degrees. Show
that in the presence of correlations, the condition above for the existence of a giant
strongly connected component generalizes to c(c − 1) + ρ > 0.
c) In the World Wide Web the in- and out-degrees of the vertices have a measured
covariance of about ρ = 180. The mean degree is around c = 4.6. On the basis of these numbers, do we expect the Web to have a giant strongly connected
component?

485

C HAPTER 14

M ODELS OF NETWORK FORMATION
A discussion of models of the formation of networks,
particularly models of networks that grow by addition of
vertices, such as the World Wide Web or citation
networks

T

HE MODELS described in Chapters 12 and 13 provide an excellent tool for

studying the structural features of networks, such as giant and small components, degree distributions, the lengths of paths in networks, and so forth.
Moreover, as we will see in later chapters, they can also serve as a convenient
basis for further modeling work, such as the modeling of network resilience or
of the spread of diseases over contact networks.
But there is another important class of network model that has an entirely
different purpose. In the models we have seen so far, the parameters of the
network, such as the number of vertices and edges or the degree distribution,
are ﬁxed from the outset—chosen by the modeler to have some desired values.
For instance, if we are interested in networks with power-law degree distributions, we make a random graph model with a power-law degree distribution as
in Section 13.10 and then explore its structure analytically or computationally.
But models of this kind offer no explanation of why the network should have
a power-law degree distribution in the ﬁrst place. In this chapter we describe
models of a different kind that offer such an explanation.
The models in this chapter are generative network models. That is, they model
the mechanisms by which networks are created. The idea behind models such
as these is to explore hypothesized generative mechanisms to see what structures they produce. If the structures are similar to those of networks we observe in the real world, it suggests—though does not prove—that similar generative mechanisms may be at work in the real networks. The best-known
example of a generative network model, and the one that we study ﬁrst in this
486

14.1

|

P REFERENTIAL ATTACHMENT

chapter, is the “preferential attachment” model for the growth of networks
with power-law degree distributions. Later in the chapter we examine a number of other models, including generalizations of preferential attachment models, vertex copying models, and models based on optimization.

14.1

P REFERENTIAL ATTACHMENT

As discussed in Section 8.4, many networks are observed to have degree distributions that approximately follow power laws, at least in the tail of the distribution. Examples include the Internet, the World Wide Web, citation networks,
and some social networks and biological networks. The power law is a somewhat unusual distribution and its occurrence in empirical data is often considered a potential indicator of interesting underlying processes.1 A natural
question to ask therefore is how might a network come to have such a distribution? This question was ﬁrst directly considered in the 1970s by Price [275],
who proposed a simple and elegant model of network formation that gives
rise to power-law degree distributions.
Price was interested in, among other things, the citation networks of scientiﬁc papers, having authored an important early paper on the topic in the
1960s in which he pointed out the power-law degree distribution seen in these
networks [274]. In considering the possible origins of the power law, Price was
inspired by the work of economist Herbert Simon [299], who noted the occurrence of power laws in a variety of (non-network) economic data, such as the
distribution of people’s personal wealth. Simon proposed an explanation for
the wealth distribution based on the idea that people who have money already
gain more at a rate proportional to how much they already have. This seems
a reasonable supposition. Wealthy individuals make money by investing the
money they have, and the return on their investment is essentially proportional to the amount invested. Simon was able to show mathematically that
this “rich-get-richer” effect can give rise to a power-law distribution and Price
adapted Simon’s methods, with relatively little change, to the network context.
Price gave a name to Simon’s mechanism:2 he called it cumulative advantage, although it is more often known today by the name preferential attachment, which
was coined in 1999 by Barabási and Albert [27]. In this book we use principally
the latter term, which has become the accepted name in recent years.
1

See Section 4.2 for a discussion of citation networks.

For a discussion see, for instance, Refs. [222] and [244].

2

Simon himself called the mechanism the Yule process, in recognition of the statistician Udny
Yule, who had studied a simple version many years earlier [333].

487

M ODELS OF NETWORK FORMATION

Price’s model of a citation network is as follows. We assume that papers
are published continually (though they do not have to be published at a constant rate) and that newly appearing papers cite previously existing ones. As
discussed in Section 4.2, the papers and citations form a directed citation network, the papers being the vertices and the citations being the directed edges
between them. Since no paper ever disappears after it is published, vertices in
this network are created but never destroyed.
Let the average number of papers cited by a newly appearing paper be c.
In the language of graph theory, c is the average out-degree of the network; in
the language of publishing, c is the average size of the bibliography of a paper.
The model allows for the actual sizes of the bibliographies to ﬂuctuate about c.
So long as the distribution of sizes satisﬁes a few basic sanity conditions,3 only
the average value is important for the behavior of the model in the limit of
large network size. In real citation networks the sizes of bibliographies also
vary from one ﬁeld to another and depend on when papers were published,
the average bibliography having grown larger over the years in most ﬁelds,
but these effects are neglected in the model.
The crucial central assumption of Price’s model is that a newly appearing
paper cites previous ones chosen at random with probability proportional to
the number of citations those previous papers already have. In this most basic of
models there is no question of which papers are most relevant topically or
which papers are most original or best written or the difference between research articles and reviews, or any of the many other factors that certainly
affect real citation patterns. The model is thus very much a simpliﬁed representation of the citation process. As we have seen with the random graphs of
previous chapters, however, even simple models can lead to real insights. We
certainly need to remember that the model only represents one aspect of the
citation process—and a hypothetical one at that—but with this in mind let us
press on and see what we can discover.
As with personal wealth, it is not implausible that the number of citations
a paper receives could increase with the number it already has. When one
reads papers, one often looks up the other works that those papers cite and
reads some of them too. If a work is cited often, then, all other things being
equal, we are more likely to come across it than a less cited work. And if we
3
The main condition on the distribution is that it should have ﬁnite variance. This rules out,
for example, cases in which bibliographies have a power-law distribution of sizes with exponent
less than three. Empirical evidence suggests that real bibliographies have an unexceptionable
distribution of sizes with a modest and ﬁnite variance, so the assumptions of Price’s model are
met.

488

14.1

|

P REFERENTIAL ATTACHMENT

read it and like it, then perhaps we will cite it ourselves if we write a paper on
the same topic. This does not mean that the probability of a paper receiving
a citation is precisely proportional to the number of citations the paper has
already, but it does at least give some justiﬁcation for why the rich should get
richer in this paper citation context.
In fact, upon further thought, it’s clear that the probability of receiving a
new citation cannot be precisely proportional to the number of citations a paper
already has. Except under unusual circumstances, papers start out life with
zero citations, which, with a strict proportionality rule, would mean that their
probability of getting new citations would also be zero and so they would have
zero citations for ever afterwards. To get around this hitch, Price proposed that
in fact the probability that a paper receives a new citation should be proportional to the number that it already has plus a positive constant a. (In fact, Price
only considered one special case a = 1 in his original model, but there seems
to be no particular reason to limit ourselves to this case, so we will treat the
case of general a > 0.)
The constant a in effect gives each paper a number of “free” citations to get
it started in the race—each paper acts as though it started off with a citations
instead of none. An alternative interpretation is that a certain fraction of citations go to papers chosen uniformly at random without regard for how many
citations they current have, while the rest go to papers chosen in proportion
to current citation count.4 This gives all papers a chance to accrue citations,
even if they currently have none. (We discuss this interpretation in more detail
in Section 14.1.1, where we use it to construct a fast algorithm for simulating
Price’s model.)
We also need to specify what the starting state of the network is, how we
initialize the model to begin with. It turns out in fact that in the limit of large
network size the predictions of the model don’t depend on the initial conditions, but we could, for instance, start the network out with a small set of
initial papers having zero citations each.
Thus, in summary, Price’s model consists of a growing network of papers
and their citations in which vertices (papers) are continually added but none
are ever taken away, each paper cites on average c others (so that the mean
out-degree is c), and the cited papers are chosen at random5 with probability
4

The two fractions are in fact a/(c + a) and c/(c + a), respectively, as shown in Section 14.1.1.

5

There is nothing in the deﬁnition of Price’s model to prevent a paper from listing the same
other paper twice in its bibliography, something that doesn’t happen in real citation networks. In
the language of graph theory, such double citations would correspond to directed multiedges in
the citation network (see Section 6.1) while true citation networks are simple graphs having no

489

M ODELS OF NETWORK FORMATION

See Section 6.4.2 for a
discussion of acyclic networks.

proportional to their in-degree plus a constant a.
One important property of Price’s model is immediately apparent: it generates purely acyclic networks, since every edge points from a more recently
added vertex to a less recently added one, i.e., backward in time. Thus all directed paths in the network point backward in time and hence there can be no
closed loops, because to close a loop we would need edges pointing forward
in time as well. This ﬁts well with the original goal of the model as a model of
citation, since citation networks are acyclic, or very nearly so (see Section 4.2).
On the other hand it ﬁts poorly with some other directed networks such as the
World Wide Web, although the model is still sometimes used as a model for
power-law distributions in the Web.
Armed with our deﬁnition of Price’s model, we will now write down equations governing the distribution of the in-degrees of vertices, i.e., the numbers
of citations received by papers in terms of the parameters c and a, and hence
solve for the degree distribution and various other quantities, at least in the
limit of large network size. We will discuss models of both directed and undirected graphs in this chapter, so we will need to be careful to distinguish indegree in the directed case from ordinary undirected degree in the undirected
case. Previously in this book we have done this by denoting the in-degree of a
vertex i by kin
i (see Section 6.9), but this notation can make our equations quite
difﬁcult to read, so in the interests of clarity we will in this chapter adopt instead the notation introduced by Dorogovtsev et al. [99] in which the in-degree
of vertex i is denoted qi . Degrees in undirected graphs will still be denoted k i
just as before.
So consider Price’s model of a growing network and let pq (n) be the fraction of vertices in the network that have in-degree q when the network contains n vertices—this is the in-degree distribution of the network—and let us
examine what happens when we add a single new vertex to the network.
Consider one of the citations made by this new vertex. In the model, the
probability that the citation is to a particular other vertex i is proportional to
qi + a, where a is a positive constant. Since the citation in question has to be
to some paper, this probability must be normalized such that its sum over all i
is 1. In other words the correctly normalized probability must be
qi + a
qi + a
qi + a
=
,
=
n q + na
n(c + a)
∑i ( qi + a )

(14.1)

multiedges. However, as with random graph models, the probability of generating a multiedge
vanishes in the limit of large network size and so the predictions of the model in this limit are
not altered by allowing them, and doing so makes the mathematical treatment of the model much
simpler.

490

14.1

|

P REFERENTIAL ATTACHMENT

where we have written the average in-degree as q = n−1 ∑i qi . In the second
equality we have made use of the fact that the average out-degree of the network is c by deﬁnition, and that the average in- and out-degrees of a directed
network are equal (see Eq. (6.27)) so that q = c.
Each newly appearing paper cites c others on average, so the expected
number of new citations to vertex i upon appearance of our new paper is c
times Eq. (14.1). And there are npq (n) vertices with degree q in our network
and hence the expected number of new citations to all vertices with degree q is
npq (n) × c ×

q+a
c(q + a)
p q ( n ).
=
n(c + a)
c+a

(14.2)

Now we can write down a so-called master equation for the evolution of the
in-degree distribution as follows. When we add a single new vertex to our
network of n vertices, the number of vertices in the network with in-degree q
increases by one for every vertex previously of in-degree q − 1 that receives a
new citation,6 thereby becoming a vertex of in-degree q. From Eq. (14.2) we
know that the expected number of such vertices is
c(q − 1 + a)
p q −1 ( n ).
c+a

(14.3)

Similarly, we lose one vertex of in-degree q every time such a vertex receives
a new citation, thereby becoming a vertex of in-degree q + 1. The expected
number of such vertices receiving citations is
c(q + a)
p q ( n ).
c+a

(14.4)

The number of vertices with in-degree q in the network after the addition of a
single new vertex is (n + 1) pq (n + 1) which, putting together the results above,
is given by

(n + 1) pq (n + 1) = npq (n) +

c(q − 1 + a)
c(q + a)
p q −1 ( n ) −
p q ( n ).
c+a
c+a

(14.5)

The ﬁrst term on the right-hand side here represents the number of vertices
previously of in-degree q, the second term represents the vertices gained, and
the third term the vertices lost.
In theory, it also increases by one if a vertex of in-degree q − 2 receives two new citations,
and similarly for larger numbers of citations. This, however, would create a multiedge, and multiedges, as we have said, are vanishingly improbable in the limit of large network size, so we can
ignore this possibility.
6

491

M ODELS OF NETWORK FORMATION

Equation (14.5) applies for all values of q except q = 0. When q = 0 there
are no vertices of lower degree that can gain an edge to become vertices of
degree zero, and hence the second term in Eq. (14.5) doesn’t appear. On the
other hand, we gain a vertex of degree zero whenever a new vertex is added
to the network, since by hypothesis papers have no citations when they are
ﬁrst published. Since exactly one vertex is added in going from a network of n
vertices to a network of n + 1, the appropriate equation for q = 0 is:

(n + 1) p0 (n + 1) = np0 (n) + 1 −

ca
p0 ( n ).
c+a

(14.6)

Now let us consider the limit of large network size n → ∞ and calculate
the asymptotic form of the degree distribution in this limit.7 Taking the limit
n → ∞ and using the shorthand pq = pq (∞), Eqs. (14.5) and (14.6) become
c
( q − 1 + a ) p q −1 − ( q + a ) p q
c+a
ca
p0
p0 = 1 −
c+a
pq =

for q ≥ 1,

(14.7)

for q = 0.

(14.8)

The second of these equations we can easily rearrange to give an explicit expression for the fraction p0 of degree-zero vertices:
p0 =

1 + a/c
.
a + 1 + a/c

(14.9)

The solution for q ≥ 1 is a little more complicated, though only a little. Rearranging Eq. (14.7) for pq we ﬁnd that
pq =

q+a−1
p q −1 .
q + a + 1 + a/c

(14.10)

We can use this equation to calculate pq iteratively for all values of q starting
from our solution for p0 , Eq. (14.9). First, we set q = 1 in Eq. (14.10) to get
p1 =

a
a
(1 + a/c)
p0 =
.
a + 2 + a/c
( a + 2 + a/c) ( a + 1 + a/c)

(14.11)

Now we can use this result to calculate p2 :
p2 =

a+1
( a + 1) a
(1 + a/c)
p1 =
,
a + 3 + a/c
( a + 3 + a/c)( a + 2 + a/c) ( a + 1 + a/c)

(14.12)

7
Strictly we should ﬁrst prove that the degree distribution has an asymptotic form in the limit
of large n and doesn’t go on changing forever, but for the purposes of the present discussion let us
assume that there is an asymptotic form.

492

14.1

|

P REFERENTIAL ATTACHMENT

and
a+2
p2
a + 4 + a/c
( a + 2)( a + 1) a
(1 + a/c)
=
,
( a + 4 + a/c)( a + 3 + a/c)( a + 2 + a/c) ( a + 1 + a/c)

p3 =

(14.13)

and so forth. It’s easy to see that for general q the correct expression must be
pq =

(1 + a/c)
(q + a − 1)(q + a − 2) . . . a
.
(q + a + 1 + a/c) . . . ( a + 2 + a/c) ( a + 1 + a/c)

(14.14)

This is effectively a complete solution for the degree distribution of Price’s
model, but there is a little more we can do to write it in a useful form. We make
use of the gamma function,
Γ( x ) =

 ∞
0

t x−1 e−t dt,

(14.15)

which has the useful property that8
Γ( x + 1) = xΓ( x )

(14.16)

for all x > 0. Iterating this formula, we see that
Γ( x + n)
= ( x + n − 1)( x + n − 2) . . . x.
Γ( x )

(14.17)

Using this result in Eq. (14.14) we can write
pq = (1 + a/c)

Γ(q + a)Γ( a + 1 + a/c)
.
Γ( a)Γ(q + a + 2 + a/c)

(14.18)

This expression can be simpliﬁed further by writing it in terms of Euler’s
beta function, which is deﬁned by
B( x, y) =

Γ( x )Γ(y)
.
Γ( x + y)

(14.19)

If we multiply both the numerator and the denominator of Eq. (14.18) by Γ(2 +
a/c) = (1 + a/c)Γ(1 + a/c), we ﬁnd that
pq =

8

Γ(q + a)Γ(2 + a/c)
Γ( a + 1 + a/c)
×
,
Γ(q + a + 2 + a/c)
Γ( a)Γ(1 + a/c)

(14.20)

The proof of this result is simple, making use of integration by parts:
Γ ( x + 1) =

 ∞
0

∞

t x e−t dt = − t x e−t 0 + x

 ∞
0

t x−1 e−t dt = xΓ( x ),

where the boundary term [. . .] disappears at both limits.

493

M ODELS OF NETWORK FORMATION

or
pq =

B(q + a, 2 + a/c)
.
B( a, 1 + a/c)

(14.21)

Note that this expression is not only correct for q ≥ 1 but also gives the correct
value when q = 0.
One of the nice things about Eq. (14.21) is that it depends on q only via the
ﬁrst argument of the upper beta function. Thus if we want to understand the
shape of the degree distribution we need only to understand the behavior of
this one function.
In particular, let us examine the behavior for large q and ﬁxed a and c.
For large values of its ﬁrst argument, we can rewrite the beta function using
Stirling’s approximation for the gamma function [2]
√
1
(14.22)
Γ( x ) ≃ 2π e−x x x− 2 ,
which means that
Γ( x )Γ(y)
e− x x x − 2
≃
1 Γ ( y ).
Γ( x + y)
e−(x+y) ( x + y) x+y− 2
1

B( x, y) =
But

( x + y)

x +y− 12

=x

x +y− 12



y
1+
x

 x+y− 12

≃ x x + y − 2 ey ,
1

(14.23)

(14.24)

where the last equality becomes exact in the limit of large x. Then
e− x x x − 2
1

B( x, y) ≃

1
e−(x+y) x x+y− 2 ey

Γ ( y ) = x − y Γ ( y ).

(14.25)

In other words, the beta function B( x, y) falls off as a power law for large values
of x, with exponent y.
Applying this ﬁnding to Eq. (14.21) we then discover that for large values
of q the degree distribution of our network goes as pq ∼ (q + a)−α , or simply
pq ∼ q−α

(14.26)

when q  a, where the exponent α is
a
α = 2+ .
c

(14.27)

Thus Price’s model for a citation network gives rise to a degree distribution
with a power-law tail. This is very much in keeping with the degree distributions of real citation networks, which, as we saw in Fig. 8.8, appear to have
clear power-law tails.
494

14.1

|

P REFERENTIAL ATTACHMENT

Note that the exponent α = 2 + a/c is strictly greater than two (since a and
c are both strictly positive). Most measurements put the exponent of the power
law for citation networks around α = 3 (see Table 8.1), which is easily achieved
in the model by setting the constants a and c equal. In a typical experimental situation the exponent α and the parameter c, the mean size of a paper’s
bibliography, are easily measured, but the parameter a, which represents the
number of “free” effective citations a paper receives upon publication, is not.
Typically therefore the value of a is extracted by rearranging Eq. (14.27) to give
a = c ( α − 2).
While it is delightful that Price’s simple model generates a power-law degree distribution similar to that seen in real networks, we should not take the
details of the model too seriously, nor the exact relation between the parameters and the exponent of the power law. As we noted at the start of this section, the model is highly simpliﬁed and substantially incomplete as a model
of the citation process, omitting many factors that are undoubtedly important
for real citations, including the quality and relevance of papers, developments
and fashions in the ﬁeld of study, the reputation of the publishing journal and
of the author, and many others besides. Still, Price’s model is striking in its
ability to reproduce one of the most interesting features of citation networks
using only a small number of reasonable assumptions, and many scholars believe that it may capture the fundamental mechanism behind the observed
power-law degree distribution.
14.1.1

C OMPUTER SIMULATION OF P RICE ’ S MODEL

When Price proposed his model in the 1970s, analytic treatments like the one
above were essentially the only tool available for understanding the behavior
of such models. Today, however, we can go further and study the operation of
the model explicitly by performing computer simulations following the rules
Price laid down. In addition to providing a useful check on our solution for
the degree distribution, such simulations also allow us to generate real examples of networks on our computer. We can then measure these networks to
determine the values, within the model, of any network quantities we like—
path lengths, correlations, clustering coefﬁcients, and so forth—including ones
for which we do not at present have an analytic solution. Researchers have
also made use of simulated networks as a convenient but still relatively realistic substrate for other kinds of calculation, including solutions of dynamical
models, percolation processes, opinion formation models, and others.
In principle, simulation of Price’s model appears straightforward. Typically one simulates the model with the out-degrees of vertices ﬁxed to be
495

M ODELS OF NETWORK FORMATION

exactly equal to c, where c is restricted to integer values. (In the original
model and our analysis above, c was only the average out-degree—actually
out-degree could ﬂuctuate about the average.) Then the only complicated part
of the simulation is the selection of the vertices that receive new edges, which
has to be done in a random but non-uniform way as a function of the vertices’ current in-degree. There are standard techniques for simulating such
non-uniform random processes and one can without too much labor create
a simple program that carry out the steps of the model. This, however, is
not usually the best way to proceed. A naive direct simulation of this kind
becomes slow when the network gets large, which limits the size of the network that can be generated. Luckily, there is a much faster way to perform the
simulation that allows larger networks to be generated in shorter times, while
still being simple to program on a computer. This method, ﬁrst proposed by
Krapivsky and Redner [187], works as follows.
When we create a new edge in Price’s model we attach it to a vertex chosen
in proportion to in-degree plus a constant a. Let us denote by θi the probability
that an edge attaches to vertex i, which from Eq. (14.1) is given by
θi =

qi + a
.
n(c + a)

(14.28)

Now consider an alternative process in which upon creating a new edge we
do one of two things. With some probability φ we attach the edge to a vertex
chosen strictly in proportion to its current in-degree, i.e., with probability
qi
qi
= .
nc
∑j qj

(14.29)

Alternatively, with probability 1 − φ, we attach to a vertex chosen uniformly
at random from all n possibilities, i.e., with probability 1/n. Then the total
probability θi of attaching to vertex i in this process is
θi = φ

1
qi
+ (1 − φ ) .
n
nc

(14.30)

Now let us make the choice φ = c/(c + a), so that
θi =

c qi
c
+ 1−
c + a nc
c+a

1
qi + a
=
.
n(c + a)
n

(14.31)

This, however, is precisely equal to the probability θi , Eq. (14.28), of selecting a
vertex in the Price model and the two processes thus choose vertices with the
exact same probabilities.
So an alternative way of performing a step of Price’s model is the following:

496

14.1

|

P REFERENTIAL ATTACHMENT

1
2
3
4

5

1 1 3 4 1 2 2
Figure 14.1: The vertex label list used in the simulation of Price’s model. The list
(bottom) contains one entry for the target of each edge in the network (top). In this
example, there are three edges that point to vertex 1 and hence there are three elements
containing the number 1 in the list. Similarly there are two containing the number 2,
because vertex 2 is the target of two edges. And so forth.

With probability c/(c + a) choose a vertex in strict proportion to indegree. Otherwise choose a vertex uniformly at random from the set
of all vertices.
The choice between the two parts can be achieved, for example, by generating
a random number r in the range 0 ≤ r < 1. If r < c/(c + a) then we choose a
vertex in proportion to in-degree. Otherwise we choose uniformly.
Choosing a vertex uniformly is easily accomplished. Choosing a vertex in
proportion to in-degree is only slightly harder. It can be done rapidly by noting
that choosing in proportion to in-degree is equivalent to picking an edge in the
network uniformly at random and choosing the vertex which that edge points
to. By deﬁnition this makes a vertex with in-degree q exactly q times as likely
to be chosen as a vertex with in-degree 1, since it has q opportunities to be
chosen, one for each of the edges that point to it.
To turn this observation into a computer algorithm we make a list, stored
for instance in an ordinary array, of the target of each directed edge in the
network. That is, the list’s elements contain the vertex labels i of the vertices
to which each edge points. Figure 14.1 shows an example for a small network.
Note that the edges do not have to be in any particular order. Any order will
do. Nor does the size of the array used to store the list have to match the
length of the list exactly; it can contain empty elements at the end as shown
in the ﬁgure. Indeed, since making already existing arrays larger is difﬁcult
in most computer languages, it makes sense to initially create an array that is

497

M ODELS OF NETWORK FORMATION

large enough to hold the longest list we will need. (This means that it should
have length nc if the out-degree of vertices is constant. If out-degree is allowed
to ﬂuctuate then the longest list might be a bit larger or smaller than nc, in
which case one might create an array of size nc plus a few percent, to be on the
safe side.)
Once we have our list, choosing a vertex in proportion to its in-degree becomes a trivial operation: we simply choose an element uniformly at random
from the list and our vertex is identiﬁed by the contents of that element. When
a new edge is added to the network, we must also update the list by adding
the target of that edge to the end of the list.
Thus our algorithm for creating a new edge is the following:
1. Generate a random number r in the range 0 ≤ r < 1.
2. If r < c/(c + a), choose an element uniformly at random from the list of
targets.
3. Otherwise choose a vertex uniformly at random from the set of all vertices.
4. Create an edge linking to the vertex thus selected, and add that vertex to
the end of the list of targets.
Each step in this process can be accomplished in constant time and hence the
growth of a network of n vertices can be accomplished in time O(n) (provided
other parts of the program are implemented efﬁciently so that they also take
constant time per step).
Figure 14.2a shows the degree distribution of a 100-million-node network
generated computationally in this fashion, and the power-law form in the tail
of the distribution is clearly visible. A practical problem, however, is the noise
in the tail of the histogram, which makes the exact form of the distribution
hard to gauge. This is exactly the same problem as we encountered for realworld data in Section 8.4.1: the bins in the tail of the histogram have relatively
few samples in them and so the statistical ﬂuctuations are large as a fraction
of the number of samples. Indeed, in many respects simulation data often
behave in similar ways to experimental data and they can often be treated
using the same techniques. In this case we can take a hint from Section 8.4.1
and plot a cumulative distribution function instead of a histogram. To recap,
the cumulative distribution function Pq is
∞

Pq = ∑ pq ,

(14.32)

q =q

(see Eq. (8.4)) and is expected to have a power-law tail with an exponent α −
1 = 1 + a/c, one less than the exponent of the degree distribution itself. Fig498

14.1

|

P REFERENTIAL ATTACHMENT

ure 14.2b shows the cumulative distribution of degrees for our simulation and
we now see a much cleaner power-law behavior over several decades in q.
For comparison we can also calculate the cumulative distribution function
analytically from our solution of the model. To do this, we make use of the
standard integral form for the beta function:9
B( x, y) =

 1
0

u x−1 (1 − u)y−1 du.

(14.33)

Using this expression we ﬁnd that
∞

Pq = ∑ pq =
q =q

∞
1
∑
B( a, 1 + a/c) q =q

1
=
B( a, 1 + a/c)

 1
0

 1
0

∞



uq +a−1 (1 − u)1+a/c du



u a−1 ∑ uq (1 − u)1+a/c du
q =q

 1

1
uq+a−1 (1 − u) a/c du
B( a, 1 + a/c) 0
B(q + a, 1 + a/c)
=
.
B( a, 1 + a/c)

=

(14.34)

Given that B( x, y) goes as x −y for large x (Eq. (14.25)), this implies that indeed
the cumulative distribution function has a power-law tail with exponent 1 +
a/c.
In Fig. 14.2b we show Eq. (14.34) along with the simulation data, and the
simulation and analytic solution agree well, as we would hope.

The integral form can be derived by making use of the deﬁnition of B( x, y) in terms of gamma
functions and the integral form of the gamma function, Eq. (14.15):
9

B( x, y) =

Γ( x )Γ(y)
1
=
Γ( x + y)
Γ( x + y)

 ∞
0

s x−1 e−s ds

 ∞
0

ty−1 e−t dt.

We change variables to u = s/(s + t), v = s + t (which implies s = uv, t = (1 − u)v and a Jacobian
of v), giving
B( x, y) =

=

1
Γ( x + y)
1
Γ( x + y)

 1
0

 ∞

du

 ∞
0

0

v dv (uv) x−1 e−uv (1 − u)v

v x+y−1 e−v dv

 1
0

y−1 −(1−u)v

e

u x−1 (1 − u)y−1 du.

The ﬁrst integral, however, is equal to Γ( x + y) by Eq. (14.15) and hence we recover Eq. (14.33).

499

10
10

-3

-4

10
10

(a)

-2

10
10

-1

-5

-6

10

-7

10

-8

10

0

10

1

10

2

10

In-degree q

3

10

4

Fraction of vertices with in-degree q or greater

Fraction of vertices with in-degree q

M ODELS OF NETWORK FORMATION

10
10
10

-1

(b)

-2

10
10

0

-3

-4

10

-5

10

0

10

1

10

2

10

3

10

4

In-degree q

Figure 14.2: Degree distribution in Price’s model of a growing network. (a) A histogram of the in-degree distribution
for a computer-generated network with c = 3 and a = 1.5 which was grown until it had n = 108 vertices. The
simulation took about 80 seconds on the author’s computer using the fast algorithm described in the text. (b) The
cumulative distribution function for the same network. The points are the results from the simulation and the solid line
is the analytic solution, Eq. (14.34).

14.2

T HE MODEL OF B ARAB ÁSI AND A LBERT

Price’s model of a growing network is an elegant one and the existence of an
exact solution showing that its degree distribution has a power-law tail makes
a persuasive case for preferential attachment as a possible origin for power-law
behavior. At least until recently, however, Price’s work in this area was not well
known outside of the information science community. Preferential attachment
did not become widely accepted as a mechanism for generating power laws in
networks until much later, in the 1990s, when it was independently discovered
by Barabási and Albert [27], who proposed their own model of a growing network (along with the name “preferential attachment”). The Barabási–Albert
model, which is certainly the best known generative network model in use today, is similar to Price’s, though not identical, being a model of an undirected
rather than a directed network.
In the model of Barabási and Albert, vertices are again added one by one
to a growing network and each vertex connects to a suitably chosen set of
previously existing vertices. The connections, however, are now undirected

500

14.2

|

T HE MODEL OF B ARAB ÁSI AND A LBERT

and the number of connections made by each vertex is exactly c (unlike Price’s
model, where the number of connections was required only to take an average
value of c but might vary from step to step). Note that this implies that c must
be an integer, since a vertex cannot have non-integer degree. Connections are
made to vertices with probability precisely proportional to the vertices’ current
degree. Notice that there is no in- or out-degree now because the network is
undirected. Connections are made simply in proportion to the (undirected)
degree. We will denote the degree of vertex i by k i to distinguish it from the
directed in-degree qi of the last section. As before, vertices and edges are only
ever added to the network and never taken way, which means, among other
things, that there are no vertices with degree k < c. The smallest degree in the
network is always k = c.
One can write down a solution for the model of Barabási and Albert using
a master equation method similar to that of Section 14.1,10 but in fact there is
no need, because it is straightforward to show that the model is equivalent to
a special case of Price’s model. Imagine that, purely for the purposes of our
discussion, we give each edge added to the network a direction, running from
the vertex just added to the previously existing vertex that the edge connects
to. That is each edge runs from the more recent of the two vertices it connects
to the less recent. In this way we convert our network into a directed network
in which each vertex has out-degree exactly c (since this is the number of outgoing edges a vertex starts with and it never gains any more). And the total
degree k i of a vertex in the sense of the original undirected network is the sum
of the vertex’s in-degree and out-degree, which is k i = qi + c where qi is the
in-degree as before.
But given that the probability of an edge attaching to a vertex is simply
proportional to k i , it is thus also proportional to qi + c, which is the same as in
Price’s model if we make the particular choice a = c. Thus the distribution of
in-degrees in this directed network is the same as for Price’s model with a = c,
which we ﬁnd from Eq. (14.21) to be
pq =

B(q + c, 3)
.
B(c, 2)

(14.35)

To get the distribution of the total degree we then simply replace q + c by k to
get
⎧
⎪
⎨ B(k, 3)
for k ≥ c,
B(c, 2)
(14.36)
pk =
⎪
⎩0
for k < c.
10

See for instance [99] or [189].

501

M ODELS OF NETWORK FORMATION

This expression can be simpliﬁed further by making use of Eq. (14.17) to
write
Γ ( k ) Γ (3)
Γ (3)
,
(14.37)
=
B(k, 3) =
Γ ( k + 3)
k (k + 1)(k + 2)
and similarly
B(c, 2) =
so that
pk =

Γ (2)
,
c ( c + 1)

Γ (3)
c ( c + 1)
2c(c + 1)
=
Γ(2) k (k + 1)(k + 2)
k (k + 1)(k + 2)

(14.38)

(14.39)

for k ≥ c, where we have used (14.17) again to get rid of the remaining gamma
functions. In the limit where k becomes large, this gives
p k ∼ k −3 ,

(14.40)

and hence the Barabási–Albert model generates a degree distribution with a
power-law tail that always has an exponent α = 3.
Equation (14.39) was ﬁrst derived by Krapivsky et al. [189] and independently by Dorogovtsev et al. [99]. A more detailed treatment was later given
by Bollobás et al. [48], which clariﬁes precisely the domain of validity of the
solution and the possible deviations from the expected value of pk .
The model of Barabási and Albert can be simulated efﬁciently on a computer by exploiting the same mapping to Price’s model and the simulation
method described in Section 14.1.1. Again we regard the network as a directed
one and maintain a list of targets of every directed edge, i.e., the vertices that
the edges point to. Then, setting a = c, the algorithm of Section 14.1.1 becomes
particularly simple: with probability 12 we choose an element from our list uniformly at random and take the contents of that element as our target vertex.
Otherwise we choose a target uniformly at random from the set of all vertices
currently in existence. Then we create a new edge from the vertex just added
to the target we have selected and also add that target to the end of our list.
The Barabási–Albert model is attractive for its simplicity—it doesn’t require
the offset parameter a of Price’s model and hence has one less parameter to
worry about. It is also satisfying that one can write the degree distribution
without using special functions such as the beta and gamma functions that
appear in the solution of Price’s model. The price one pays for this simplicity
is that the model can no longer match the exponents observed in real networks,
being restricted to just a single exponent value α = 3.

502

14.3

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

The models of Price and of Barabási and Albert were proposed as explanations
for the observed power-law degree distributions in networks such as the Web,
citation networks, and others, and for this reason the degree distribution is the
property of these models that has attracted most interest. However, it is not
the only property that can be calculated. The master equation method can be
extended to the calculation of a number of other properties, many of which are
interesting in their own right. We describe a few of these calculations in this
section.
14.3.1

D EGREE DISTRIBUTION AS A FUNCTION OF TIME OF CREATION

Consider a network grown according to Price’s model of Section 14.1. Older
vertices in the network—those added earlier in the growth process—have more
time to acquire links from other vertices and hence we might expect that they
would on average have higher in-degree. This indeed turns out to be the case,
as we can show by calculating the degree distribution as a function of the time
at which vertices are created.
Let pq (t, n) be the average fraction of vertices in our directed network that
were created at time t and have in-degree q when the network has n vertices
total. The time of creation is measured in terms of the number of vertices, the
ﬁrst vertex having t = 1 and the last having t = n. Alternatively, you can just
think of t as counting the vertices from 1 to n, recording the order in which
they were added. Strictly t need not reﬂect actual time, because the vertices
need not have been added at a constant rate, but if we know the real times at
which vertices were added we can easily convert between our timescale and
real time.
We can write down a master equation for the evolution of pq (t, n) as follows. Upon the addition of a new vertex to the network, the expected number
of new edges acquired by previously existing vertices with in-degree q is independent of time of those vertices creation and, following Eq. (14.2), is given
by
q+a
c(q + a)
pq (t, n),
=
(14.41)
npq (t, n) × c ×
n(c + a)
c+a
with the parameters c and a deﬁned as in Section 14.1. Then the master equation takes the form

(n + 1) pq (t, n + 1) = npq (t, n) +

c
(q − 1 + a) pq−1 (t, n) − (q + a) pq (t, n) .
c+a
(14.42)

503

M ODELS OF NETWORK FORMATION

The only exception to this equation is, as before, for the case of q = 0, where
we get
ca
p0 (t, n).
(n + 1) p0 (t, n + 1) = np0 (t, n) + δtn −
(14.43)
c+a
Notice the Kronecker delta, which adds a single vertex of in-degree zero if
t = n, but none otherwise.
These equations, though correct, don’t make much sense in the limit of
large n, since the fraction of vertices created at time t goes to zero in this limit
because only one vertex is created at any particular t. So instead we change
variables to a rescaled time
t
(14.44)
τ= ,
n
which takes values between zero (oldest vertices) and one (youngest vertices).
At the same time we also change from pq (t, n) to a density function πq (τ, n)
such that πq (τ, n) dτ is the fraction of vertices that have in-degree q and fall in
the interval from τ to τ + dτ. The number of vertices in the interval dτ is n dτ,
which implies that πq dτ = pq × n dτ and hence
πq (τ, n) = npq (t, n).

(14.45)

Being a density function, πq does not vanish as n → ∞.
The downside of this variable change is that τ is no longer constant for a
given vertex. A vertex created at time t has rescaled time t/n when there are n
vertices in the network but t/(n + 1) when there are n + 1. Thus, in terms of τ
and πq , Eq. (14.42) becomes
πq

n
τ, n + 1
n+1

= πq (τ, n)


πq−1 (t, n)
πq (t, n)
c
+
.
(q − 1 + a)
− (q + a)
c+a
n
n
(14.46)

Now we consider the limit where n → ∞. If we deﬁne the shorthand notation
πq (t) = πq (t, ∞) and the small quantity  = 1/n, Eq. (14.42) becomes


πq (τ ) − πq τ − τ
c
+
(q − 1 + a)πq−1 (τ ) − (q + a)πq (τ ) = 0, (14.47)

c+a
where we have dropped terms of order 2 .
As n → ∞, we have  → 0 and the ﬁrst two terms become a derivative
thus:
πq (τ ) − πq (τ − τ )
dπq
,
(14.48)
lim
=τ
 →0

dτ
504

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

and so our master equation becomes a differential equation in this case:
τ

dπq
c
+
(q − 1 + a)πq−1 (τ ) − (q + a)πq (τ ) = 0.
c+a
dτ

(14.49)

The corresponding equation for q = 0 is
τ

dπ0
ca
π0 (τ ) = 0,
−
c+a
dτ

(14.50)

so long as τ < 1. For the special case τ = 1 the δtn in Eq. (14.43) presents a
problem, but on the other hand for τ = 1 we know what the answer is anyway:
there is always exactly one vertex created at time t = n, which has in-degree
zero, so π0 (1) = 1 in the language of our rescaled variables.11 In effect, this
just provides a boundary condition on π0 (τ ). The corresponding boundary
condition for q ≥ 1 is πq (1) = 0, since there are no vertices with t = n and
q ≥ 1.
We can solve Eqs. (14.49) and (14.50) by starting with a solution for q = 0
and working up through increasing values of q. This is similar to our solution
for the degree distribution, Eq. (14.21), except that the equations we are solving
are now differential equations.
The solution for the q = 0 case is straightforward—Eq. (14.50) is homogeneous in π0 and can be solved by standard methods. You can easily verify that
the solution is π0 (τ ) = Aτ ca/(c+a) where A is an integration constant. The constant is ﬁxed by the boundary condition π0 (1) = 1, which implies that A = 1
and hence
(14.51)
π0 (τ ) = τ ca/(c+a) .
As a check, we can integrate over τ to get the total fraction of vertices with
in-degree zero:
 1
1 + a/c
τ ca/(c+a) dτ =
,
(14.52)
a + 1 + a/c
0
which agrees nicely with our previous result for the same quantity, Eq. (14.9).
Now we can use this solution to ﬁnd π1 (τ ). Equation (14.49) tells us that
τ

dπ1
c
c
ca ca/(c+a)
aπ0 (τ ) = −
τ
−
( a + 1) π1 ( τ ) = −
.
c+a
c+a
dτ
c+a

(14.53)

This is again just an ordinary ﬁrst-order differential equation, although an inhomogeneous one this time (i.e., it has a driving term on the right-hand side).
It may not be immediately obvious that π0 (1) must equal 1. There is one vertex in the time
interval between τ = 1 and τ = 1 − 1/n and it always has in-degree zero. One vertex is a fraction
1/n of the whole network, so there is 1/n of the network in an interval of width 1/n, which
corresponds to a density π0 (1) = 1.
11

505

M ODELS OF NETWORK FORMATION

We tackle it in standard fashion. First we ﬁnd the general solution for the
homogeneous equation in which the right-hand side is set to zero, which is
Bτ c(a+1)/(c+a) where B is an integration constant. Then we ﬁnd any (nongeneral) solution to the full equation with the driving term included—the obvious one is aτ ca/(c+a) —and sum the two. The constant is ﬁxed by the boundary condition π1 (1) = 0, which implies that B = − a, and we get


π1 (τ ) = aτ ca/(c+a) 1 − τ c/(c+a) .
(14.54)
Now, by a similar method, we can use this solution to solve for π2 (τ ), and
so forth to higher and higher values of q. The algebra is tedious, but with
persistence you can show that the next two results are

2
(14.55)
π2 (τ ) = 12 a( a + 1)τ ca/(c+a) 1 − τ c/(c+a) ,


3
π3 (τ ) = 16 a( a + 1)( a + 2)τ ca/(c+a) 1 − τ c/(c+a) .
(14.56)
These results suggest the general solution (ﬁrst given by Dorogovtsev et al.
[99])

q
1
a( a + 1) . . . ( a + q − 1) τ ca/(c+a) 1 − τ c/(c+a)
πq (τ ) =
q!

q
Γ(q + a)
=
τ ca/(c+a) 1 − τ c/(c+a) ,
(14.57)
Γ ( q + 1) Γ ( a )
where we have made use again of the convenient property of the gamma function derived in Eq. (14.17) as well as the result that Γ(n + 1) = n! when n is a
positive integer.12 With a little work you can verify that this is indeed a complete solution of Eq. (14.49) for all q. As a check we can also integrate over τ to
ﬁnd the total fraction of vertices with in-degree q and conﬁrm that the result
agrees with Eq. (14.21). We leave this calculation as an exercise for the reader.13
Let us take a moment to examine the structure of our solution for πq (τ )
and see what it tells us about the network. The general shape of the solution
is shown in Fig. 14.3. Panel (a) shows the distribution of creation times τ for
vertices of given in-degree q for various values of q and for each value there is
a clear peak in the distribution, indicating that vertices of a given degree are
concentrated around a particular era in the growth of the graph. As degree
increases, that era gets earlier, so that the times of creation of vertices that ultimately achieve high in-degree are strongly concentrated around the beginning
of the growth process.
To prove this we set x = 1 in Eq. (14.17) to get Γ(n + 1)/Γ(1) = n(n − 1) . . . 1 = n! and from
∞
Eq. (14.15) we have Γ(1) = 0 e−t dt = 1.
12

13

506

Hint: you will probably need Eq. (14.33).

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

Fraction of vertices πq(τ )

0.3

(a)

(b)

0.2

0.1

0

0

0.5

Rescaled time τ

1 0

10

20

In-degree q

Figure 14.3: Distribution of vertices in Price’s model as a function of in-degree and
time of creation. The two panels show the distribution πq (τ ), Eq. (14.57), for c = 3 and
a = 1.5 as (a) a function of τ for (top to bottom) q = 1, 2, 5, 10, and 20, and (b) a function
of q for τ = 0.01 (ﬂattest curve), 0.05, 0.1, 0.5, and 0.9 (steepest curve).

Panel (b) of Fig. 14.3 shows the distribution of in-degrees for vertices created at a selection of different times τ. This distribution also has a peak, then
falls off sharply as q becomes large.14 Indeed the distribution falls off roughly
exponentially as q becomes large, as we can see from Eq. (14.57) by writing
Γ(q + a)
Γ(q + a)
1
=
=
,
qB(q, a)
Γ ( q + 1) Γ ( a )
qΓ(q)Γ( a)

(14.58)

where we have used Euler’s beta function again, Eq. (14.19). As shown in
Section 14.1, the beta function has a power-law tail B( x, y) ∼ x −y for large x
(Eq. (14.25)) so πq goes with q as

q
(14.59)
πq (τ ) ∼ q a−1 1 − τ c/(c+a) .
In other words it decays exponentially except for a leading algebraic factor.
Thus the degree distribution for vertices with speciﬁc values of τ does not follow a power law. The power-law behavior seen in the full degree distribution
14
Actually, the peak only exists for small values of τ and disappears once τ becomes large
enough. There are no peaks in the degree distribution for the τ = 0.5 and τ = 0.9 curves in
Fig. 14.3b.

507

M ODELS OF NETWORK FORMATION

of the model, Eq. (14.21), only appears when we integrate over all times τ.
However, the decay of the exponential in Eq. (14.59) is slower for smaller τ, so
older vertices are more likely to have high in-degree than younger ones, as we
saw in Fig. 14.3.
To investigate this point further, we can calculate the mean in-degree γ(τ )
for a vertex created at time τ thus:
∞

γ(τ ) = ∑ qπq (τ ) = a(τ −c/(c+a) − 1).

(14.60)

q =0

Figure 14.4 shows the shape of γ(τ ) for a variety of choices of the parameters and, as we expect,
the mean value of the in-degree increases with decreasing τ and eventually diverges as τ approaches
zero. Notice, though, that no vertex ever actually
30
has τ = 0. The ﬁrst vertex added to the network has
t = 1, so the smallest value of τ is 1/n. Nonethea=1
less, we see that vertices added to the network early
20
a=2
have an enormous advantage in terms of in-degree
a=4
over those added even a little later. For a citation
a=8
network, for instance, this suggests that the early
a = 16
10
papers in a ﬁeld will receive substantially more citations than later ones, purely because they were
published ﬁrst.
Indeed, this is a pattern seen in many different
0
0
0.2
0.4
0.8
1
0.6
areas, not just in networks. In any situation where
success begets more success, ﬁrst movers are exRescaled time τ
pected to have a large advantage over others. Any
small lead gained early in the process is quickly amFigure 14.4: Average in-degree of vertices as a funcpliﬁed by the preferential attachment process into
tion of their time of creation. The average in-degree
a bigger lead and soon the lucky ﬁrst movers ﬁnd
of vertices in Price’s network model as a function of the
themselves racing ahead of the pack. Those who
rescaled time τ = t/n at which they were added to the
enter the game later may experience chance ﬂucnetwork, in the limit of large n for various values of the
tuations that give them a small boost, but since
parameter a. The out-degree parameter c was in each case
there are probably many others already ahead of
c = 2a, so that the exponent of the power-law degree disthem, that boost is not ampliﬁed signiﬁcantly betribution α = 2 + a/c (Eq. (14.27)) is 2.5 for all curves,
cause most of the wealth is already going to the
which is a typical value for real-world networks.
leaders under the preferential attachment rule.
A nice demonstration of this process, although
not in the ﬁeld of networks, has been given by Salganik et al. [288], who examined the behavior of a group of people downloading popular music onMean degree for vertices created at time τ

40

508

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

line. Salganik et al. created a website on which participants could download
and listen to songs by little-known artists for free. Participants were told how
many times each song had previously been downloaded and Salganik and coworkers found that there was a clear preferential attachment effect: songs with
many previous downloads were downloaded far more than those with few.
As a result there was a strong ﬁrst-mover advantage, with songs that took an
early lead beneﬁting from the preferential attachment and turning that lead
into a much larger one, resulting in a roughly power-law distribution in the
numbers of downloads.
To test the theory that they were seeing a preferential attachment process
rather than actual differences in song quality leading to different download
rates, Salganik et al. then changed the download numbers reported for each
song, deliberately misrepresenting the number of times each had been downloaded. They discovered when they did this that the songs with the highest
reported numbers of downloads were still downloaded most often, even though
the reported numbers no longer corresponded to true popularity.15 These results strongly suggest that success is, at least in this context and at least in part,
a result of previous success and that a good way to be successful is to get in at
the beginning and get an early lead. Of course, that may be easier said than
done. Many people would like to get in at the beginning of a new ﬁeld of scientiﬁc research or a new business opportunity, but it’s not always clear how
one should do it.
Returning to our network growth model, it is also interesting to ask how
the expected in-degree of a vertex varies with its age after it enters the network. This differs from the expected degree for a particular τ calculated above
because a given vertex does not have a ﬁxed value of τ. The value of τ = t/n
for a vertex decreases as time passes because n is increasing. For this reason
the behavior of individual vertices is more easily understood in terms of our
original non-rescaled time t, which does remain constant.
So let t again be the time at which a vertex is added to the network and let s
be the subsequent elapsed time, i.e., the age of the vertex. Necessarily we have
s + t = n and hence
t
t
.
(14.61)
τ= =
t+s
n
Substituting this expression into Eq. (14.60), we then ﬁnd the expected in15

Salganik et al. did ﬁnd a weak effect of song quality—songs that had proved popular when
the download numbers were reported faithfully continued to do better than expected even when
the download numbers were misreported.

509

M ODELS OF NETWORK FORMATION

degree γt (s) of the vertex added at time t, as a function of its age s, to be

γt ( s ) = a

1+

s
t

c/(c+ a)


−1 .

(14.62)

When a vertex is ﬁrst added to the network and s  t, we can expand in the
small quantity s/t to give
γt ( s ) ≃

ca
c+a

s
.
t

(14.63)

In other words, the in-degree of a vertex initially grows linearly with the age of
the vertex, on average, but with a constant of proportionality that is smaller the
later the vertex entered the network—again we see that there is a substantial
advantage for vertices that enter early.
As the vertex ages, there is a crossover to another regime around the point
s = t, i.e., at the point where the vertex switches from being in the younger
half of the population to being in the older. For s  t,
γt ( s ) ≃ a

s
t

c/(c+ a)

,

(14.64)

which has a similar form to Eq. (14.63) but with a different exponent, c/(c + a),
which is always less than 1, so the growth is slower than linear but still favors
vertices that appear early. Figure 14.5 shows the behavior of γt (s) with time
for vertices created at a selection of different times t.
All of these results can be applied to the Barabási–Albert model as well
by setting a = c with c an integer and writing the formulas in terms of total
degree k = q + c rather than in-degree. For instance, the joint degree/time
distribution, Eq. (14.57), becomes
πk (τ ) =

√ k−c
k−1 √ 
τ 1− τ
k−c

(14.65)

for k ≥ c and πk (τ ) = 0 for k < c. This result was ﬁrst given by Krapivsky and
Redner [187] for the case c = 1.
14.3.2

S IZES OF IN - COMPONENTS

The in-components of vertices in our growing networks have some interesting
properties. Recall that the in-component of vertex i is the set of vertices from
which i can be reached by following a directed path through the network (see
Section 6.11). In a citation network, for instance, the in-component of paper A
510

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

Average in-degree γt(s)

20

10

0

0

2000

4000

6000

8000

10000

Time since creation of network

Figure 14.5: Average in-degree of vertices created at different times. The curves show
the average in-degrees in Price’s model of vertices created at times (top to bottom) t =
100, 200, 400, 1000, 2000, and 4000 as a function of time since the creation of the network.
The model parameters were c = 3 and a = 1.5.

is the set of all papers from which A can be reached by following some trail
of successive citations. The reader reading any paper in the in-component can
look up other papers in its bibliography, ﬁnd those papers and look up further
ones in their bibliographies and so forth, and ultimately reach paper A. One can
think of the in-component as representing the set of all papers that “indirectly
cite” paper A and the size of the in-component can be considered a measure of
the total impact of paper A.
We can study the distribution of in-component sizes by a method similar to the one we used for the degree distribution. Consider Fig. 14.6, which
shows a sketch of the in-component of a single vertex A. We have drawn the
in-component as a tree, which is accurate so long as the size s of the component
is small, s  n. Just as in the random graph models of Chapters 12 and 13, the
probability of a small component having an extra edge that destroys its tree
structure vanishes in the limit of large n (see Section 12.6.1). We must be careful however. As we will shortly see, it is possible for the sizes of in-components
to become comparable with n in preferential attachment models, in which case
the arguments below break down. For the moment, however, let us proceed

511

M ODELS OF NETWORK FORMATION

under the assumption that our component is a tree.
Our in-component will grow in size as vertices and edges are added
to the network. Speciﬁcally, it will grow larger every time a newly
added edge links to any of its members. The probability of a new edge
linking to vertex i is given by Eq. (14.1) and summing this probability
over all vertices in the in-component C gives a total probability of


1
qi + a
as
(14.66)
+
q
=
i
∑ ,
∑ n(c + a) n(c + a)
i ∈C
i ∈C

A

Figure 14.6: The in-component of
a vertex A. The total number of incoming links attached to vertices
in an in-component is equal to the
number of vertices in the component minus 1. Note that there are,
in general, many edges outgoing
from vertices in the in-component
(shown in gray) which connect to
vertices not in the in-component
and which can thus be ignored for
the purposes of our calculation.

where s is the number of vertices in the in-component.
Considering Fig. 14.6, we see that every incoming edge in the incomponent is necessarily also an outgoing edge from another vertex
in the in-component, and moreover that there is exactly one such outgoing edge from each vertex in the in-component, except for A itself.
(There are also other outgoing edges from vertices in the in-component,
as shown in gray in the ﬁgure, but these connect to vertices outside the
component itself and play no part in our calculation.) Thus the total
number ∑i∈C qi of incoming edges is equal to the number of vertices in
the in-component minus one, which means our probability of connection, Eq. (14.66), can also be written as

(1 + a ) s − 1
1
.
( as + s − 1) =
n(c + a)
n(c + a)

(14.67)

Let us deﬁne ps (n) to be the probability that a randomly chosen
vertex has an in-component of size s when the network has n vertices
(still assuming s  n). Then nps (n) is the number of in-components of
size s and, given that each new vertex arrives with c outgoing links, the
total number of in-components of size s receiving a new link upon the
addition of a new vertex to the network is
c
(1 + a ) s − 1
[(1 + a)s − 1] ps (n).
(14.68)
=
nps (n) × c ×
n(c + a)
c+a

Now, by an argument similar to the one used to derive Eq. (14.5), we can show
that ps (n) satisﬁes the master equation

(n + 1) ps (n + 1) = nps (n)


c + ca
1
1
s−1−
p s −1 ( n ) − s −
ps (n) .
+
c+a
1+a
1+a

(14.69)

The only exception is for in-components of size 1, the smallest size possible,
for which
ca
p1 ( n ).
(n + 1) p1 (n + 1) = np1 (n) + 1 −
(14.70)
c+a
512

14.3

|

F URTHER PROPERTIES OF PREFERENTIAL ATTACHMENT MODELS

The +1 here represents the fact that there is one new in-component of size 1
created for each vertex added.
We now take the limit n → ∞ and write ps = ps (∞) to get


c + ca
1
1
s−1−
p s −1 − s −
ps
(14.71)
ps =
1+a
c+a
1+a
for s ≥ 2 and

ca
p1 .
(14.72)
c+a
The solution of these equations follows exactly the same lines as the solution
for degree distribution. The ﬁnal result is


B s − 1/(1 + a), β
,
(14.73)
ps = 
B 1 − 1/(1 + a), β − 1
p1 = 1 −

where B( x, y) is the Euler beta function, Eq. (14.19), and
β = 1+

1 + a/c
.
1+a

(14.74)

As we have seen previously, the beta function has a power-law tail B( x, y) ∼
x −y (see Eq. (14.25)), so the in-component size distribution also has a powerlaw tail:
(14.75)
ps ∼ s− β ,
although with an exponent β that is in general different from that of the degree distribution (see Eq. (14.27)). Indeed, note that for the normal situation
where c ≥ 1 we have 1 < β ≤ 2, which is puzzling: power laws with β ≤ 2
have no ﬁnite mean, but for any ﬁnite value of n our network must certainly
have a ﬁnite average component size. The solution to this conundrum is relatively simple, however. As we pointed out above, our calculations are only
valid for component sizes s  n. For larger sizes the method will break down
and the power-law behavior will be lost. In physical terms, in-components
clearly cannot be larger than the size of the whole network, and so we must
expect ﬁnite-size effects that cut off the size distribution as s approaches n.
In mathematical terms, the components stop being trees as their size becomes
comparable with n and hence Eq. (14.67) ceases to be correct.
It’s also possible to derive solutions for the component size distribution as
a function of the time of creation of a vertex or the age of a vertex, just as we
did for the degree distribution in the ﬁrst part of this section. Indeed there are
many more properties of these models that can be calculated using the master
equation approach, which is an immensely useful technique for problems such
as these. Life, however, is short, and there are many other interesting matters
to look into, so we will move on to other things.

See Section 8.4.2 for a discussion of the mean and
other moments of powerlaw distributions.

513

M ODELS OF NETWORK FORMATION

14.4

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

Many extensions and generalizations of preferential attachment models have
been suggested, typically addressing questions about what happens when we
vary the details of the model deﬁnition or attempt to make the model more
faithful to the way real networks grow. For instance:
1. By contrast with citations, links in the Web are not permanent. They can
and frequently do disappear as well as appear, and links can be added
between vertices not just at the moment a vertex is created but at any
later time too.
2. Entire web pages also disappear as well as appear.
3. There is no obvious reason why the preferential attachment process has
to be linear in the degree. What happens if it is non-linear?
4. Not all vertices are created equal. Some papers or websites might be
intrinsically more interesting or important by virtue of their content and
hence attract more links. Can this process be incorporated into the model?
In this section we describe modiﬁcations of the preferential attachment process
that address each of these questions. In the interests of simplicity, we describe
the developments in the context of the Barabási–Albert model, rather than the
more general Price model. Generalizations of Price’s model are certainly possible but the algebra is in many cases unwieldy, and the main conclusions are
easier to understand in the context of the simpler model.
14.4.1

A DDITION OF EXTRA EDGES

Price proposed his model of a growing network with citation networks in
mind. Since the bibliography of a paper cannot be changed after the paper is
published, the edges in a citation network are effectively frozen in place from
the moment they are ﬁrst created, and Price’s model mimics this behavior with
edges being added only at the moment a vertex is created and never moved or
removed thereafter.
This is not true of all networks, however. The World Wide Web, for example, is constantly changing. Links between web pages can, and often are,
added or removed after the pages are created. This state of ﬂux is not captured
by Price’s model or by the Barabási–Albert model of Section 14.2. Yet the Web
still has a power-law degree distribution. This leads us to wonder whether it is
possible to create a generalized model that includes the addition and removal
of edges after vertices are created but still generates power-law distributions.
It turns out that we can indeed, as we now describe.
We ﬁrst consider the relatively simple case in which edges are added to
our network but never taken away, which has been studied by a number of
514

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

authors [11, 96, 190]. The case of edge removal is more complex and is considered in the following section. The model we consider is a generalization
of the Barabási–Albert model in which vertices are added to the network one
by one as before and each starts out with c undirected edges which attach to
other vertices with probability proportional to degree k. But we now include
a second process in the model as well: at each step some number w of extra
edges are added to the network with both ends attaching to vertices chosen in
proportional to degree. Thus when the network has n vertices it will have a
total of n(c + w) edges. (In fact, it is only necessary that an average number w
of extra edges be added at each step. The actual number can ﬂuctuate around
this ﬁgure, provided the ﬂuctuations satisfy some modest constraints on their
size, and the net result, in the limit of large network size, will be the same. This
allows us to give w a non-integer value if we wish.)
This model turns out to be quite easy to solve given the results of previous sections. The only difference between it and the standard Barabási–Albert
model is that, instead of c new ends of edges attaching to old vertices for every new vertex added, we now have c + 2w new ends of edges—two extra for
each of the w extra edges. The probability of attachment of any one of those
edges to a particular vertex i is k i / ∑i k i as before. The sum in the denominator is equal to twice the number of edges in the network (see Eq. (6.20)), or
∑i k i = 2n(c + w).
Then, if pk (n) denotes the fraction of vertices with degree k when the network has n vertices in total, the number of vertices of degree k receiving a new
edge, per vertex added, is
npk (n) × (c + 2w) ×

k
c + 2w
kpk (n).
=
2( c + w )
2n(c + w)

(14.76)

We can use this result to write a master equation for pk (n) thus:

(n + 1) pk (n + 1) = npk (n) +

c + 2w
(k − 1) pk−1 (n) − kpk (n) ,
2( c + w )

(14.77)

for k > c and

(n + 1) pc (n + 1) = npc (n) + 1 −

c + 2w
cpc (n),
2( c + w )

(14.78)

for k = c. (There are, as before, no vertices of degree less than c.) Taking the
limit of large n and writing pk = pk (∞), these equations simplify to
c + 2w
(k − 1) pk−1 − kpk
2( c + w )
c + 2w
cpc
pc = 1 −
2( c + w )

pk =

for k > c,

(14.79)

for k = c.

(14.80)

515

M ODELS OF NETWORK FORMATION

Rearranging these equations along the lines of Eqs. (14.9) to (14.21), we then
ﬁnd that
B(k, α)
,
(14.81)
pk =
B(c, α − 1)
where B( x, y) is the Euler beta function again, Eq. (14.19), and
α = 2+

c
.
c + 2w

(14.82)

Since B( x, y) goes as x −y for large x (Eq. (14.25)), our degree distribution
has a power-law tail with exponent α. For the special case of w = 0, in which
no additional edges are added to the network, we recover the standard result
α = 3 for the Barabási–Albert model; for w > 0 we get exponents in the range
2 < α < 3, which agrees nicely with the values typically observed for degree
distributions on the Web (see Table 8.1). Bear in mind though that the Web is
a directed network while the model described here is undirected. If we want
to build a model of a directed network we would need to start with something
like the Price model of Section 14.1. Generalizations of Price’s model that include addition of extra edges as above are certainly possible—see for example
Krapivsky et al. [190].
14.4.2

R EMOVAL OF EDGES

Now consider the case of a network in which edges can be removed. To keep
things simple let us ﬁrst consider the case where edges can be removed at any
time but are only added at the initial creation of a vertex, as in the standard
Barabási–Albert model. (In a moment we will consider the general case of
addition and removal at any time.)
There are many ways in which edges could be removed from a network,
but let us consider the most basic case in which they are simply deleted uniformly at random. What then is the probability that a particular vertex i loses
an edge when a single edge is removed from the network? When an edge
is deleted both of its two ends vanish. Given that the deletion is uniformly
random, the probability that one of those two ends is attached to vertex i is
simply proportional to the total number of ends attached to i, which is equal to
the degree k i . Properly normalized, the probability that vertex i loses an edge
is thus 2k i / ∑i k i , the factor of two coming from the two ends of the edge. In
other words, the random deletion of edges is like a type of preferential attachment in reverse: the higher the degree of the vertex, the more likely it is to lose
an edge.
So consider the undirected network model in which vertices with degree c
are added to the network following the normal preferential attachment scheme
516

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

and an average of v edges are deleted at random for each vertex added. (As
with the model of Section 14.4.1 the actual number of edges deleted can ﬂuctuate about the mean and v can take a non-integer value if we wish.) In order
that the number of edges in the network grow, rather than shrinking to zero
and vanishing, we require that the net number of edges added per vertex c − v
be positive, i.e., v < c. Then when the network has n vertices the number of
edges will be n(c − v).
In writing down a master equation for this model there are several processes we need to consider. As before, the number of vertices with degree k
increases whenever a vertex of degree k − 1 gains a new edge and decreases
when a vertex of degree k gains a new edge. By an argument analogous to the
one leading to Eq. (14.76), the number of vertices of degree k gaining an edge
per vertex added to the network is
npk (n) × c ×

k
c
=
kpk (n).
2n(c − v)
2( c − v )

(14.83)

But we also now have a new process in which a vertex can lose an edge, which
means that the number of vertices of degree k also increases when a vertex of
degree k + 1 loses an edge and decreases when a vertex of degree k loses an
edge. The number of vertices of degree k losing an edge per vertex added is
given by
k
v
kpk (n),
(14.84)
=
npk (n) × 2v ×
2n(c − v)
c−v
with the factor of 2v reﬂecting the fact that each of the v edges removed has
two ends.
Another important thing to notice is that, by contrast with the original
Barabási–Albert model, vertices can now have any degree k ≥ 0—vertices
can lose any or all of their edges, right down to the last one, so there is no
restriction k ≥ c on the degree as before.
Our master equation now takes the form
c
( k − 1 ) p k −1 ( n )
2( c − v )
v
c + 2v
+
( k + 1 ) p k +1 ( n ) −
kpk (n) (14.85)
c−v
2( c − v )

(n + 1) pk (n + 1) = npk (n) +

for k = c and
c
( c − 1 ) p c −1 ( n )
2( c − v )
v
c + 2v
+
( c + 1 ) p c +1 ( n ) −
cpc (n)
c−v
2( c − v )

(n + 1) pc (n + 1) = npc (n) + 1 +

(14.86)

517

M ODELS OF NETWORK FORMATION

for k = c. These two equations can conveniently be combined by writing
c
( k − 1 ) p k −1 ( n )
2( c − v )
2v
c + 2v
( k + 1 ) p k +1 ( n ) −
kpk (n),
+
2( c − v )
2( c − v )
(14.87)

(n + 1) pk (n + 1) = npk (n) + δkc +

where δkc is the Kronecker delta, which is 1 if k = c and 0 otherwise.
The only exception to this master equation is for the case k = 0, where the
term proportional to k − 1 vanishes because there are no vertices of degree −1.
A simple way of enforcing this exception is to deﬁne p−1 (n) = 0 for all n, in
which case Eq. (14.87) then applies for all k ≥ 0. We will adopt this convention
henceforth.
The model as we have described it so far incorporates the processes of vertex addition and edge removal, but, given Eq. (14.87), it is only a small extra
step to incorporate the edge addition process of Section 14.4.1 as well. If as
before we add w extra edges per vertex added, then c + w − v edges are added
net per vertex, and our master equation becomes
c + 2w
( k − 1 ) p k −1 ( n )
2( c + w − v )
v
c + 2w + 2v
+
( k + 1 ) p k +1 ( n ) −
kpk (n).
c+w−v
2( c + w − v )
(14.88)

(n + 1) pk (n + 1) = npk (n) + δkc +

The equation for edge removal only, Eq. (14.87), can then be considered a special case of this equation with w = 0. As before, we require that the net number
of edges added per vertex be positive, or v < c + w.
Now taking the limit as n → ∞ and writing pk = pk (∞) we ﬁnd that
c + 2w
( k − 1 ) p k −1
2( c + w − v )
v
c + 2w + 2v
+
( k + 1 ) p k +1 −
kpk .
c+w−v
2( c + w − v )

pk = δkc +

(14.89)

This equation differs in a crucial way from the master equations we have
encountered previously, such as Eq. (14.7), because the right-hand side contains terms for vertices of three different degrees (k − 1, k, and k + 1) rather
than just two. This makes the equation substantially more difﬁcult to solve.
We can no longer simply rearrange to derive an expression for pk in terms of
pk−1 and then apply that expression repeatedly to itself. A solution is still pos518

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

sible, but it’s not simple. Here we give just an outline of the method. The gory
details, for those interested in them, are spelled out by Moore et al. [226].16
The basic strategy for solving Eq. (14.89) is to use a generating function of
the kind we introduced in Section 13.1. We deﬁne
∞

g(z) = ∑ pk zk .

(14.90)

k =0

Substituting for pk from Eq. (14.89) we get
∞

g(z) = ∑ δkc zk +
k =0

+

∞
c + 2w
( k − 1 ) p k −1 z k
∑
2 ( c + w − v ) k =0

∞
2v
c + 2w + 2v ∞
( k + 1 ) p k +1 z k −
kpk zk .
∑
2 ( c + w − v ) k =0
2(c + w − v) k∑
=0

(14.91)

The ﬁrst term on the right is simple—it is equal to zc . The others require a little
more care. Consider the second term, for example. Note that the ﬁrst term
in the sum, the term for k = 0, is necessarily zero because, as we have said,
p−1 = 0. Hence we can write
∞

∞

∞

k =0

k =1

∑ (k − 1) pk−1 zk = ∑ (k − 1) pk−1 zk = ∑ kpk zk+1
k =0

∞

= z2 ∑ kpk zk−1 = z2
k =0

d ∞
pk zk
dz k∑
=0

dg
= z2 ,
dz

(14.92)

where in the ﬁrst line we have made the substitution k − 1 → k and in the
second line we have made use of the fact that the k = 0 term is again zero
(because of the factor of k).
For the third and fourth terms in (14.91) we can similarly write
∞

∞

∞

k =0

k =1

k =0

∑ (k + 1) pk+1 zk = ∑ kpk zk−1 = ∑ kpk zk−1 =

and

∞

∞

k =0

k =0

dg

∑ kpk zk = z ∑ kpk zk−1 = z dz .

dg
,
dz

(14.93)

(14.94)

16
In fact, Moore et al. give a solution for a model in which vertices rather than edges are deleted,
but the two can be treated by virtually the same means. The calculation given here is adapted from
their work with only minor changes.

519

M ODELS OF NETWORK FORMATION

Combining Eqs. (14.91) to (14.94) and rearranging, we then get

(c + 2w)z − 2v
dg
+ g(z) = zc .
(1 − z )
dz
2( c + w − v )

(14.95)

This is a ﬁrst-order linear differential equation and is solvable by standard—if
tedious—methods. To cut a long story short, one can ﬁnd an integrating factor
for the left-hand side and hence express the solution in terms of an integral
that, provided v < 12 c + w, can be reduced by repeated integration by parts to
give
 k
(1 − x/k)k α−2
pk = Ak−α
x
dx,
(14.96)
k
0 (1 − γx/k )
for k ≥ c, where A is a k-independent constant and
v−w
,
c + 2w − 2v
2v
γ=
.
c + 2w
α = 2+

(14.97)
(14.98)

The remaining integral can be written in terms of hypergeometric functions,
but we can ﬁnd the asymptotic behavior of the degree distribution for large k
more directly by noticing that as k becomes large


x
1−
k

so that
pk ∼ k

−α

k

 ∞
0



→e ,
x

γx
1−
k

e−(1−γ)x x α−2 dx =

k

→ eγx ,

(14.99)

Γ ( α − 1) − α
k .
(1 − γ ) α −1

(14.100)

Thus we once again ﬁnd that our degree distribution has a power-law tail,
with an exponent given this time by Eq. (14.97). Note that this exponent can
take values both greater than and less than two. What’s more for the case
where v = 12 c + w it actually becomes inﬁnite. Moore et al. [226] show that
at this point we lose the power-law behavior and the distribution becomes
instead a stretched exponential. Up until this point, however, the distribution
still follows a power law, albeit with a very large exponent as v grows larger.
For values of v > 12 c + w, the solution becomes nonsensical, with a negative
value of α, and one must return to the original differential equation (14.95) to
ﬁnd the solution for this case. We leave the developments, however, as an
exercise for the especially avid reader.
Before we leave this topic, however, let us point out that the methods used
to solve Eq. (14.89) can also be used to calculate what happens when we remove not edges but vertices from our network. Loss of vertices does occur in
520

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

some networks, such as the World Wide Web, so it is potentially of interest to
ask what effect it has on the degree distribution. In fact, the solution for this
case is very similar to the solution for loss of edges, with a power-law distribution and an exponent that depends on the vertex loss rate, diverging as the
rate of loss approaches the rate at which vertices are added. The details can be
found in [226].
14.4.3

N ON - LINEAR PREFERENTIAL ATTACHMENT

In the models we have considered so far, the probability that a new edge attaches to a vertex is linear in the degree of the vertex. Although this is a reasonable ﬁrst guess about the way things might be, it’s certainly also possible that
attachment processes might not be linear. Indeed, there is some empirical evidence that this is the case. For instance, Jeong et al. [165] looked at the growth of
several real-world networks, measuring the rate at which nodes acquired new
edges. To avoid problems associated with the fact that the rate can depend not
only on degree but also on the total size n of the network (see Eq. (14.1)), they
restricted their observations to relatively short intervals of time. The measured
rates, plotted as a function of vertex degree, showed that for some networks
there was a roughly linear preferential attachment effect, but for others attachment appeared to be non-linear, going as some power γ of the degree with γ
being signiﬁcantly different from 1. (The values they observed were around
γ = 0.8.)
What effect would non-linear preferential attachment have on the degree
distribution of our network? Should we still expect to see power-law behavior
in the non-linear case? The answers to these questions depend on the particular functional form of the attachment probability and there are an inﬁnite
variety of functional forms. We will look at some speciﬁc examples shortly, but
for the moment let us keep the discussion completely general. Following an
approach introduced by Krapivsky et al. [189], we deﬁne an attachment kernel,
denoted ak , which speciﬁes the functional form of the attachment probability.
For the model of Barabási and Albert, where attachment is simply proportional
to degree, the attachment kernel would be ak = k. For the non-linear attachment observed by Jeong et al. and discussed above, it would be ak = kγ . Note
that the attachment kernel is not a probability, merely a functional form. The
correctly normalized probability that a newly added edge attaches to a speciﬁc
vertex i having degree k i is ak / ∑i aki .
So consider again a growing undirected network of the type discussed in
previous sections and let pk (n) be the fraction of vertices with degree k when
the network has n vertices. As before, an average of c new edges are added
521

M ODELS OF NETWORK FORMATION

to the network with each new vertex, but preferential attachment is now nonlinear, governed by the attachment kernel ak , which means that, by analogy
with Eq. (14.2), the expected number of vertices of degree k receiving a new
connection when a single new vertex is added to the network is
npk (n) × c ×
where
μ(n) =

ak
c
=
a k p k ( n ),
μ(n)
∑i ak i

1 n
a k i = ∑ a k p k ( n ).
n i∑
=1
k

(14.101)

(14.102)

Now the master equation for pk (n) is

(n + 1) pk (n + 1) = npk (n) +

c
a k −1 p k −1 ( n ) − a k p k ( n ) .
μ(n)

(14.103)

As before the term in pk−1 (n) represents new vertices of degree k created when
vertices of degree k − 1 receive new edges and the last term in pk (n) represents
vertices of degree k lost when they gain new edges to become vertices of degree
k + 1.
The only exception to this equation is for vertices of degree c, for which

(n + 1) pc (n + 1) = npc (n) + 1 −

c
a c p c ( n ).
μ(n)

(14.104)

(And there are no vertices of degree less than c, since all vertices are created
with degree c initially and edges are never removed.)
Taking the limit as n → ∞ and writing pk = pk (∞) and μ = μ(∞), these
equations become
c
a k −1 p k −1 − a k p k
(14.105)
pk =
μ
for k > c and

pc = 1 −

cac
pc .
μ

(14.106)

Note that μ depends via Eq. (14.102) on the degree distribution, which we don’t
yet know. For now, however, it will be enough that μ is independent of k; we
will derive an expression for its exact value in a moment.
Equations (14.105) and (14.106) can be rearranged to give
μ/c
ac + μ/c

(14.107)

a k −1
p k −1 .
ak + μ/c

(14.108)

pc =
and
pk =
522

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

Applying the latter repeatedly we get
a k −1 a k −2 . . . a c
pc
( ak + μ/c) . . . ( ac+1 + μ/c)
μ
ak . . . ac
=
cak ( ak + μ/c) . . . ( ac + μ/c)

 −1
μ k
μ
1
=
+
.
cak ∏
car
r =c

pk =

(14.109)

All we need to complete our solution is the value of μ. Taking Eq. (14.102)
and letting n → ∞, we get

 −1
μ ∞ k
μ
.
μ = ∑ ak pk = ∑ ∏ 1 +
c k=c r =c
car
k=c
∞

(14.110)

Canceling μ from both sides we arrive at the equation
∞

k 

μ
∑ ∏ 1 + car
k=c r =c

 −1

= c.

(14.111)

In principle we should be able to solve this equation for μ and substitute the
result into Eq. (14.109) to get the complete degree distribution. In practice,
unfortunately, the equation is not solvable in closed form for most choices of
the attachment kernel ak , although an approximate value for μ can usually be
calculated numerically on a computer. Even without knowing μ, however, we
can still ﬁnd the overall functional form of pk , which is enough to answer many
of the questions we are interested in.
As an example, consider a network of the type observed by Jeong et al. [165]
and discussed above in which attachment goes as kγ for some positive constant γ, and let us assume that (as found by Jeong et al.) we have γ < 1. The solution for this particular choice was given by Krapivsky et al. [189] and shows
a number of interesting features.
Putting ak = kγ in Eq. (14.109) gives

 −1
μ k
μ
pk = γ ∏ 1 + γ
.
ck r=c
cr

(14.112)

This degree distribution turns out not have a power-law tail, by contrast with
the case of linear preferential attachment. In other words the power-law form
is sensitive to the precise shape of the attachment kernel. We can see this by
writing
 −1

 k
k 
μ
μ
(14.113)
∏ 1 + crγ = exp − ∑ ln 1 + crγ
r =c
r =c
523

M ODELS OF NETWORK FORMATION

and then expanding the logarithm as a Taylor series in μ/cr γ :
μ

k

∑ ln 1 + crγ

r =c

∞

s

(−1)s
s
r = c s =1

μ
c

∞

s k

k

= −∑ ∑

(−1)s
s
s =1

=−∑

μ
c

r −sγ

∑ r−sγ .

(14.114)

r =c

The sum over r cannot be expressed in closed form, but we can approximate it
using the trapezoidal rule,17 which says that for any function f (r ):
b

 b





∑ f (r) = a f (r) dr + 12 f (a) + f (b) + O f  (b) − f  (a) .

(14.115)

r=a

(For those not familiar with it, the derivation of the trapezoidal rule is illustrated in Fig. 14.7.18 )
In our case f (r ) = r −sγ and Eq. (14.115) gives




k1−sγ

k

∑ r−sγ = As + 1 − sγ + 12 k−sγ + O k−(sγ+1) ,

(14.116)

r =c

where As is a constant depending on s (and on c) but not on k.
Consider now what happens when k becomes large. Since γ > 0, the term
in k−sγ and all subsequent terms vanish as k → ∞ and Eq. (14.114) becomes
μ

k

∑ ln 1 + crγ

r =c

∞

(−1)s
s
s =1

≃ A−∑

μ
c

s

k1−sγ
,
1 − sγ

(14.117)

s
where A is a k-independent constant equal to ∑∞
s=1 A s (− μ/c ) /s.
This expression can be simpliﬁed still further by noting that, in the limit
k → ∞, all terms in k1−sγ where 1 − sγ < 0 also vanish. Thus for any given
value of γ we need keep terms in k up to only a certain value of s. The simplest
case is when 21 < γ < 1. In this case only the term for s = 1 grows as k
increases, all others vanishing, and
k

μ

∑ ln 1 + crγ

r =c

≃ A+

μk1−γ
c (1 − γ )

(14.118)

as k → ∞.
17

Also called the trapezium rule in British English.

Explicit expressions are known for the correction terms (the terms in f  ( a) and f  (b))—they
are given in terms of the Bernoulli numbers by the so-called Euler–Maclaurin formula [2]—but
they’re not necessary in our application because the correction terms vanish anyway.
18

524

|

14.4

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

f (r)

a

a+1 a+2 ...

b

r
Figure 14.7: The trapezoidal rule. The trapezoidal rule approximates a sum by an
integral (or vice versa). The sum of the function f (r ) from r = a to r = b (dotted
lines) is equal to the sum of the areas of the rectangular bars, which is also equal to
the area shaded in gray. This shaded area can be approximated by the integral of f (r )
between a and b (smooth curve) plus the two extra rectangular sections at either end
(hatched), which have area 21 f ( a) and 12 f (b) respectively. Add everything up and we
get Eq. (14.115). The error in the approximation is equal to the sum of the relatively
small regions between the curve and the shaded area.

Now, combining Eqs. (14.112), (14.113), and (14.118), we ﬁnd that the asymptotic form of pk is
μk1−γ
pk ∼ k−γ exp −
,
(14.119)
c (1 − γ )
for 12 < γ < 1.
Distributions of this general form, in which the dominant contribution to
the probability falls off as the exponential of a power of k, are called stretched
exponentials. Since the exponent 1 − γ is less than one, the distribution falls
off more slowly than an ordinary exponential in k, which is why we called it
“stretched.”19 On the other hand, the distribution still falls off a good deal
19

Although, confusingly, people often still call it a stretched exponential even when the expo-

525

M ODELS OF NETWORK FORMATION

faster than the power law that we found in the case of linear preferential attachment, and this is really the important point here. This calculation reveals
that the power-law distribution in the Barabási–Albert model is a special feature of the linear attachment process assumed by that model. (Note that this
observation is valid even though we haven’t calculated the value of the constant μ. The general functional form of the degree distribution doesn’t depend
on the value of the constant.)
For other values of γ the calculation is similar but involves more terms in
Eq. (14.117). For instance, if 13 < γ < 12 then the terms in k1−sγ for s = 1 and 2
both grow as k becomes large while all others vanish, and we ﬁnd that
μ

k

∑ ln 1 + crγ

r = k 0 +1

μk1−γ
μ2 k1−2γ
− 2
,
c(1 − γ) 2c (1 − 2γ)

(14.120)

μk1−γ
μ2 k1−2γ
.
+ 2
c(1 − γ) 2c (1 − 2γ)

(14.121)

≃ A+

which gives
pk ∼ k−γ exp −

In between the solutions (14.119) and (14.121) there is a special case solution
when γ is exactly equal to 12 . For γ = 12 and s = 2 the integral in Eq. (14.115)
gives rise not to a power of k but to a log and Eq. (14.114) becomes
μ

k

∑ ln 1 + crγ

r =c

≃ A+

2μ √
μ2
k − 2 ln k,
c
2c

(14.122)

all other terms vanishing in the limit of large k. Substituting this expression
into Eq. (14.113), we then arrive at
pk ∼

√ μ2 /c2 −1
2μ √
k
exp −
k ,
c

(14.123)

for γ = 12 .
We can continue in this vein ad inﬁnitum. There are distinct solution forms
for 14 < γ < 13 and 15 < γ < 14 and so forth, as well as special case solutions
for γ = 13 , 14 , 15 , and so forth. Figure 14.8 shows the degree distribution for the
case γ = 0.8, along with the asymptotic form (14.119). Note the convex form of
the curve on the semilogarithmic scales, which indicates a function decaying
slower than an exponential.
One can also calculate the degree distribution for superlinear preferential
attachment, i.e., for values of γ greater than one. This case also shows some
nent is greater than one. This case should really be called a “squeezed exponential.”

526

14.4

10

Degree distribution pk

10

10

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

0

-1

-2

10

10

|

-3

-4

10

-5

0

50

100

Degree k

Figure 14.8: Degree distribution for sublinear
preferential attachment. This plot shows the
fraction pk of vertices with degree k in a growing
network with attachment kernel kγ as described
in the text. In this case γ = 0.8 and c = 3.
The points are results from computer simulations, averaged over 100 networks of (ﬁnal) size
107 vertices each. The solid line is the exact solution, Eq. (14.112), evaluated numerically. The
dashed line is the asymptotic form, Eq. (14.119),
with the overall constant of proportionality chosen to coincide with the exact solution for large
values of k.

interesting behaviors: it turns out that for γ > 1 the typical behavior is for one
vertex to emerge as a “leader” in the network, gaining a non-zero fraction of all
edges, with the rest of the vertices having small degree (almost all having degree less than some ﬁxed constant). Readers interested in these developments
can ﬁnd them described in detail in Ref. [189].
14.4.4

V ERTICES OF VARYING QUALITY OR ATTRACTIVENESS

The models of growing networks we have examined so far assume that all vertices of a given degree are equally likely to gain a new edge. In these models,
for example, all papers that have never been cited before are equally likely to
get new citations. All websites that no one has linked to yet are equally likely
to receive links.
In the real world, of course, nothing could be farther from the truth. There
are huge differences in the perceived importance and quality of scientiﬁc papers or websites that mean some are far more likely to gain edges than others.
A website, for instance, that provides a useful service, such as a directory or
an encyclopedia, will almost certainly receive new links at a higher rate than
most people’s personal home pages. Indeed, search engines use the numbers
of links web pages receive precisely as a measure of which pages people ﬁnd
most useful. Similarly, people look at the numbers of citations a paper receives
to try to gauge how inﬂuential that paper has been. These approaches would

See Sections 7.4 and 19.1 for
a discussion of the operation of search engines.

527

M ODELS OF NETWORK FORMATION

not work unless there were some correlation between the degree and the perceived quality of a vertex.
If one allows for variations in the intrinsic quality or attractiveness of vertices, then, presumably it will have an effect on the degree distribution. It
seems entirely possible that, with such effects at work, the power laws generated by preferential attachment models might completely disappear, leaving
us at a loss to explain how power laws might arise in real-world networks. In
this section we study a model of the growth of a network proposed by Bianconi
and Barabási [42,43] that includes effects of varying node quality—or ﬁtness as
they call it. As we will see, the power-law behavior of traditional models disappears once vertex ﬁtness enters the picture, although the distribution for
vertices of a given ﬁtness still follows a power law.
The model of Bianconi and Barabási is deﬁned as follows. Vertices are
added one by one with each attaching by undirected edges to c prior vertices,
just as before. Now, however, each vertex i has a ﬁtness ηi that is assigned
at the moment of the vertex’s creation and never changed thereafter. The ﬁtnesses are real numbers with values drawn from some distribution ρ(η ), so
that the probability of a value falling between η and η + dη is ρ(η ) dη. Each
of the c new edges added with each new vertex attaches to a previously existing vertex with probability proportional to an attachment kernel ak (η ) that
depends now on both the degree k of the target vertex and its ﬁtness η. (In fact,
Bianconi and Barabási examined only the special case ak (η ) = ηk. The general
model considered here was proposed and solved subsequently by Krapivsky
and Redner [188].)
This model can be solved by the same method as the model of Section 14.4.3.
We deﬁne pk (η, n) dη to be the fraction of vertices with degree k and ﬁtness in
the interval η to η + dη when the network has n vertices. Writing down a master equation as before and taking the limit n → ∞ we arrive at equations that
read
c
a k −1 ( η ) p k −1 ( η ) − a k ( η ) p k ( η )
(14.124)
pk (η ) =
μ
for k > c and
pc (η ) = ρ(η ) −

cac (η )
p c ( η ),
μ

(14.125)

where pk (η ) = pk (η, ∞) and μ is again the appropriate normalizing factor
μ=

∞
1 n
a k i ( ηi ) = ∑
∑
n i =1
k=c

 ∞
−∞

ak (η ) pk (η ) dη.

(14.126)

(See Eq. (14.110).) Note that the +1 of Eq. (14.106) has been replaced by ρ(η )
in Eq. (14.125), because the average number of new vertices of degree c added
528

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

to the network with ﬁtness in the interval η to η + dη is not 1 but ρ(η ).
Following the same steps that led to Eq. (14.109), we can solve the master
equation to show that
 −1
k 
μ
μ
1+
,
pk (η ) = ρ(η )
car (η )
cak (η ) ∏
r =c

(14.127)

and the value of μ can be determined by substituting this result back into
Eq. (14.126) (although usually an analytic solution is not possible and the equations must be solved numerically).
As an example consider the case where the attachment kernel is linear in
the degree, ak (η ) = ηk, which was studied by Bianconi and Barabási.20 Since
ak (η ) is (proportional to) a probability it cannot be negative, so we must restrict
η to non-negative values. Then the product in Eq. (14.127) becomes
k 

μ
∏ 1 + cηk
r =c

 −1

k

k
r =c k + μ/cη

=∏

Γ(k + 1)Γ(c + μ/cη )
Γ(c)Γ(k + 1 + μ/cη )
cηk B(k, 1 + μ/cη )
,
=
μ
B(c, μ/cη )

=

(14.128)

where we have made use of Eq. (14.17) and B( x, y) is Euler’s beta function,
Eq. (14.19), again. Substituting into Eq. (14.127), we then ﬁnd that
pk (η ) = ρ(η )

B(k, 1 + μ/cη )
.
B(c, μ/cη )

(14.129)

We showed previously that the beta function goes as a power law B( x, y) ∼
x −y for large values of its ﬁrst argument (Eq. (14.25)) so Eq. (14.129) implies that
the distribution of the degrees of vertices with a particular value of the ﬁtness η
has a power-law tail with exponent
α(η ) = 1 +

μ
.
cη

(14.130)

However, the overall degree distribution for the entire network may or may
not have a power-law tail, depending on the distribution ρ(η ). It is clear that it
is a power law for some choices of ρ(η )—for example the trivial choice where
20
The most general form of linear kernel would be ak (η ) = f (η ) k where f (η ) is an increasing
function of η. However, this form can be turned into the one above by a simple change of variables
to η  = f (η ), so in fact we are not losing any generality by assuming ak (η ) = ηk.

529

M ODELS OF NETWORK FORMATION

all vertices have the same η, which just reduces to the original Barabási–Albert
model. If η is broadly distributed, however, the degree distribution will be a
sum over power laws with a wide range of different exponents, which will not
in general yield another power law.
The solution above does not tell the whole story. There are some interesting
features of this model that are missing from Eq. (14.129). To see this, let us
calculate the average degree of a vertex in our network. This might seem like
a pointless exercise—the average degree must take the value 2c since exactly c
edges are added for every vertex—but in fact the calculation is quite revealing.
The average degree is given by
∞  ∞

k =∑

=

k=c 0
 ∞
0

∞  ∞

kpk (η ) dη = ∑

k=c 0

kρ(η )

B(k, 1 + μ/cη )
dη
B(c, μ/cη )

∞

ρ(η )
k B(k, 1 + μ/cη ) dη.
B(c, μ/cη ) k∑
=c

(14.131)

The sum can be performed by making use of the integral form of the beta
function, Eq. (14.33), and gives21
∞

c

∑ k B(k, 1 + μ/cη ) = 1 − cη/μ B(c, μ/cη ).

(14.132)

k=c

An important point to notice, however, is that this result only works if η <
μ/c. If η ≥ μ/c the sum diverges making the average degree in the network
inﬁnite, which cannot be the case since, as we have said, the average degree is
always 2c. To avoid the divergence we will impose the restriction that ρ(η ) = 0
for all η ≥ η0 , where η0 is a constant in the range 0 ≤ η0 < μ/c. (The interesting
question of what happens to the network if we choose a ρ(η ) that violates this
condition is dealt with below.)
Combining Eqs. (14.131) and (14.132), we then ﬁnd that
k =c

 η0
0

ρ(η ) dη
.
1 − cη/μ

(14.133)

And since k = 2c this immediately implies that
 η0
0

ρ(η ) dη
= 2.
1 − cη/μ

(14.134)

We haven’t yet calculated a value for the constant μ, but even without it
this equation tells us something interesting. The integral is a monotonically
21

530

The calculation is essentially the same as the one leading to Eq. (14.34).

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

decreasing function of μ: it takes its smallest value of 1 when μ → ∞, and its
largest value when μ → cη0 . (Recall that η0 < μ/c so μ can get no smaller
than cη0 .) But if this largest value is still less than two then there is no way to
satisfy Eq. (14.134) and no value of μ such that Eq. (14.133) gives the correct
answer for k . In the limit μ → cη0 the denominator of the integrand equals
1 − η/η0 , which tends to zero at the upper limit of the integral, but provided
ρ(η ) also tends to zero in this limit the integral can take a ﬁnite value and, as
we will see in a moment, this value can certainly be less than two for some
choices of ρ(η ).
How can it be that our solution does not give the correct value for the
average degree? Have we made a mistake somewhere? More importantly,
what does the network actually do in this regime?
The answer to this conundrum turns out to be a subtle and interesting one.
The important point is that there are some behaviors of the vertex degrees in
a growing network that cannot be captured by a simple probability distribution pk . In particular, if there are a ﬁxed, ﬁnite number of vertices in the network with degrees that scale in proportion to the size n of the entire network,
those vertices do not appear in the degree distribution: because there are only
a ﬁxed number of them they constitute a fraction 1/n of the network and hence
contribute zero to the degree distribution as n → ∞. Nonetheless, they make
a non-zero contribution to the average degree of the network in the limit of
large n and hence must be taken into account in the calculation of k .
Bianconi and Barabási referred to the appearance of such vertices in the
network as “condensation” by analogy with similar behaviors seen in lowtemperature physics,22 and to the vertices themselves as a condensate. For some
choices of ρ(η ) this kind of condensation does indeed occur and a condensate
of “superhubs” with very high degree forms in the network.
Suppose we are in such a regime and let us write the sum of the degrees
of the vertices in the condensate as K. Then the full expression for the average
degree, including the condensate, becomes
k =



∞
∞
K
K
+∑
kpk (η ) dη = + c
n
n k=c 0

 η0
0

ρ(η ) dη
.
1 − cη/μ

(14.135)

Clearly, no matter what the value of the integral, it is now always possible to
22

Bianconi and Barabási, who are physicists, solved their model initially by showing that it can
be mapped onto the standard physics problem of “Bose–Einstein condensation” in an ensemble
of non-interacting bosons. For a physicist already familiar with Bose–Einstein condensation, this
provides a quick and elegant way of deriving a solution. For non-physicists, on the other hand,
the mapping is probably not very illuminating.

531

M ODELS OF NETWORK FORMATION

achieve k = 2c by making K sufﬁciently large. The appropriate value of K is
given by setting k = 2c and rearranging thus:


 η0
ρ(η ) dη
.
(14.136)
K = nc 2 −
1 − cη/μ
0
Again, the largest value of the integral is achieved when μ → cη0 , which means
that


 η0
ρ(η ) dη
.
(14.137)
K > nc 2 −
1 − η/η0
0
So if the value of this integral is less than two, then in order to get the correct
value for the average degree we require that K scales with the size n of the
network just as we hypothesized.
As an example, suppose the distribution of ﬁtnesses takes the form ρ(η ) =
A(η0 − η )τ , where τ is a positive exponent and A is a normalization constant
whose value is easily shown to be A = (τ + 1)/η0τ +1 . Then the integral in
Eq. (14.137) is
 η0
0

ρ(η ) dη
τ+1
=
1 − η/η0
η0τ

 η0
0

1
(η0 − η )τ −1 dη = 1 + ,
τ

and
K > nc 1 −

1
.
τ

(14.138)

(14.139)

If τ < 1 then this result tells us only that K ≥ 0, which is trivially true. But if
τ > 1 then the sum of the degrees in the condensate must vary in proportion
to the network size n.
Thus, depending on our choice for the distribution of ﬁtnesses, the network
can show two different behaviors. In one case, the distributions of the degrees
of vertices with any given ﬁtness follow a power law with a ﬁtness-dependent
exponent, but no vertices in the network are special or distinguished by any
particular behavior. In the other case, a condensate forms consisting of one
or more “superhubs,” which connect to a non-zero fraction of all other vertices. None of the remaining non-condensate vertices show any special behavior, however; they still have power-law degree distributions for each value of
ﬁtness, with the same exponents as before. Some authors have likened the condensation phase of the model to the monopolistic dominance of a market by
a single vendor or a small number of vendors—once one vertex (vendor) gets
a non-zero fraction of all edges (business), preferential attachment guarantees
that it will go on doing so thereafter.
We still do not have a complete solution of the model, because we are missing the value of μ which is required to evaluate Eq. (14.136). Unfortunately, to
532

14.4

|

E XTENSIONS OF PREFERENTIAL ATTACHMENT MODELS

calculate μ we need to know the exact form of the condensate. In most discussions of the model in the literature it is assumed that the condensate consists of
just a single vertex of degree K at or close to the maximum ﬁtness η0 , in which
case we can evaluate μ using Eq. (14.126). Including the contribution from the
condensate vertex, this equation becomes
μ=

∞
a K ( η0 )
+∑
n
k=c

 ∞
−∞

ak (η ) pk (η ) dη,

(14.140)

and, setting ak (η ) = ηk again and making use of Eqs. (14.129) and (14.132), we
then ﬁnd
 η0
ρ(η ) dη
η0 K
+
= 1.
(14.141)
nμ
μ/cη
−1
0
Equations (14.136) and (14.141) together now give us two equations in the two
unknowns K and μ, which we can, at least in theory, solve for both given ρ(η ),
although in practice closed-form solutions are rare because the integrals are
non-trivial.
There is, however, no reason why the condensate must consist of just a single vertex. It could in principle consist of more than one. It could even consist
not of a ﬁxed number of vertices but of a growing number provided the number grows slower than linearly with the size of the network, so that again the
condensate makes no contribution to the degree distribution pk in the limit of
large n. In the latter case, the superhubs that make up the condensate would
have degrees that themselves scaled sublinearly with system size, but would
still become arbitrarily large as n → ∞. To the best of the author’s knowledge, it is not known how to predict which of these behaviors will happen for
a given choice of ρ(η ). Indeed, an exact prediction may not even be possible:
computer simulations of the model appear to indicate that the exact nature of
the condensate—how many vertices it contains and how their degrees grow
with system size—is not deterministic but depends on the details of ﬂuctuations taking place in the early growth of the network. If one performs repeated
computer simulations with the same choice of ρ(η ), the macroscopic behavior
of the condensate varies from one run of the program to another.23
23
The model is, in this respect, reminiscent of the much simpler and older model of a growing
system called Pólya’s urn. In this model an urn (i.e., a large pot) initially contains two balls, one
green and one red. Repeatedly we draw one ball at random from the urn and replace it with two
of the same color. In the limit where the number of balls becomes large, the fraction of green (or
red) balls tends to a constant, but the value of that constant is entirely unpredictable—it depends
on the details of the ﬂuctuations in the numbers of balls at the early stages of the growth process
and all values of the constant are equally likely in the n → ∞ limit.

533

M ODELS OF NETWORK FORMATION

We have also assumed in our discussion that the distribution of the ﬁtness
is bounded, that there is a maximum value η0 that the ﬁtness can take. What
happens if this assumption is violated? In this case there will of course still be a
ﬁttest vertex in the network and the network cannot “tell” whether the ﬁtness
distribution is bounded above that point or extends to η = ∞, and hence the
behavior of the model will be the essentially the same as in the bounded case.
The main difference from the bounded case is that the value of the highest
ﬁtness may change from time to time, which also changes the value of μ via
Eq. (14.126). However, the changes in the highest ﬁtness become rarer and
rarer as time goes by24 so that asymptotically the behavior of the system is the
same in the bounded and unbounded cases for arbitrarily long periods of time.

Many other extensions and variations of preferential attachment models
have been studied in addition to the ones described in this chapter. If you’re
interested in learning more, there are a number of review articles that go into
the subject in some detail—see Refs. [12], [46], and [98]. The rest of this chapter
is devoted to the discussion of other models of network formation and growth
that don’t rely on preferential attachment.

14.5

V ERTEX COPYING MODELS

Preferential attachment models offer a plausible, if simpliﬁed, explanation for
power-law degree distributions in networks such as citation networks and
the World Wide Web. Preferential attachment, however, is by no means the
only mechanism by which a network can grow, nor even the only mechanism
known to generate power laws. In the remainder of this chapter we look at a
number of other models and mechanisms for the formation of networks, starting in this section with models based on vertex copying.
In Section 14.1 we introduced the preferential attachment mechanism and
suggested a possible explanation of its origin in citation networks, that a reader
perusing the literature in a given academic ﬁeld would encounter citations to
frequently cited papers more often than citations to less cited ones, and hence
would be more likely to cite those frequently cited papers themselves. Another
way of saying this is that, in effect, researchers are copying citations from the
24
The statistics of these leader changes are themselves non-trivial. They obey a so-called record
dynamics, an interesting non-stationary process that has been studied in its own right, for example
by Sibani and Littlewood [296].

534

14.5

|

V ERTEX COPYING MODELS

bibliographies of papers they read.25
Kleinberg et al. [180] have proposed an alternative mechanism for network
formation that takes this idea one step further. What if people simply copied
the entire bibliography of a single paper to create the new bibliography of their
own paper? This would then create a new vertex in the network with the same
pattern of outgoing edges as the vertex they copied from.
As we will see, this process, with slight modiﬁcations, can give rise to a
power-law degree distribution. First, however, we note that the process as
stated has some problems. To begin with, it’s clearly rather far-fetched. Authors of papers do take note of who other authors have cited, but it seems unlikely that an author would copy the entire bibliography from someone else’s
paper. Moreover, if they did just copy the entire bibliography then previously
cited papers would get new citations as a result, but there would be no way
for papers to receive citations if they had never been cited before.
Both of these problems can be solved by changing the model a little. Instead
of assuming that the bibliography of the new paper is copied wholesale from
the bibliography of an older one, let us assume that only some fraction of the
entries in the old bibliography are copied. Then the remainder of the new
bibliography is ﬁlled out with references to other papers. These other papers
could be selected in a variety of way, but a simple choice would be to select
them uniformly at random from the entire network.
These modiﬁcations insure that bibliographies are now no longer copied
in their entirety and papers with no previous citations have a chance of being
cited. The model is, however, still not a very plausible model of a real citation network. But, like Price’s preferential attachment model (which is also
not very realistic), it can be regarded as a simpliﬁed and tractable version of
the vertex copying mechanism that allows us to investigate quantitatively the
consequences of that mechanism.26 The precise deﬁnition of the model is as
25
We use the word “copying” ﬁguratively here, but in fact there is evidence to suggest that
some people really do just copy citations from other papers, possibly without even looking at the
cited paper. Simkin and Roychowdhury [297,298] have noted that there is a statistically surprising
regularity to the typographical errors people make in citing papers. For instance, many different
authors will use the same wrong page number in citing a particular paper, which suggests that
rather than copying the citation from the paper itself, they have copied it from an erroneous entry
in another bibliography. This does not prove that they did not read the paper in question, but it
makes it more likely—if they had actually looked up the paper, there is a good chance they would
have noticed that they had the page number wrong.
26
Kleinberg et al. themselves proposed a different model of the copying process in their paper,
but their model is quite complex and doesn’t lend itself easily to analysis. The model described
here is a simpliﬁed realization that possesses the important features of the process while remaining
relatively tractable. We note also that Kleinberg et al. were not in fact concerned with citation

535

M ODELS OF NETWORK FORMATION

follows.
Let us suppose for simplicity that each new vertex added to our network
has the same out-degree c. In the language of citations, the bibliographies are
all the same size. For each vertex added we choose uniformly at random a
previous vertex and go one by one through the c entries in the bibliography of
that previous vertex. For each entry we either (a) with probability γ < 1 copy
that entry to the bibliography of the new vertex or (b) with probability 1 − γ
add to the bibliography of the new vertex a citation to another vertex chosen
uniformly at random from the entire network. The end result is a bibliography
for the new vertex in which, on average, γc of the entries are copied from the
old vertex and the remainder are chosen at random. In effect, we have made
an imperfect copy of the old vertex in which the destinations of some fraction
of the outgoing edges have been randomly reassigned.
We also need to specify the starting state of the network, but, as with our
preferential attachment models, it turns out that the asymptotic properties of
the network do not depend on the state we choose. Thus the choice is not
particularly important, but we could, for instance, specify a starting network
consisting of some number n0 > c vertices in which each points randomly to c
of the others.
We can solve for the degree distribution of the network generated by this
model as follows. Let us ask what the probability is that vertex i receives a
new incoming edge upon the addition of a new vertex to our network. For i
to receive a new edge, one of two things has to happen. Either the newly
added vertex happens to copy connections from a vertex that already points
to vertex i, in which case with probability γ the connection to i will itself get
copied, or i could be one of the vertices chosen at random to receive a new
edge. Let us treat these two processes separately.
Suppose that a particular existing vertex happens to have a link to our vertex i. The probability that a newly added vertex will choose to copy its own
links from this existing vertex is simply 1/n, since the source for the copies
is chosen uniformly at random from the whole network. Thus if i has indegree qi , the chance that any one of the qi vertices that point to it gets chosen
is qi /n. And the chance that the link from that vertex to i gets copied is γ, for
a total probability of γqi /n.
The average number of random links that a newly added vertex makes—
ones not copied from a previous vertex—is 1 − γ for each of its c outgoing
networks in their paper. Their focus was the World Wide Web. We use the language of citation
networks here to emphasize the parallels with Price’s model, but the discussion could equally
have been framed in the language of the Web.

536

14.5

|

V ERTEX COPYING MODELS

edges, or (1 − γ)c overall. And the probability that our vertex i happens to
be the target of one of these random links is 1/n, for an overall probability of
(1 − γ)c/n.
Putting everything together, the total probability that vertex i gets a new
link is27
γqi
γqi + (1 − γ)c
(1 − γ ) c
.
(14.142)
+
=
n
n
n
Deﬁning pq (n) as before to be the fraction of vertices with in-degree q when
the network has n vertices, the total expected number of vertices of in-degree q
receiving a new edge is
npq (n) ×

γq + (1 − γ)c
= γq + (1 − γ)c pq (n).
n

(14.143)

But now we notice a remarkable fact. If we deﬁne a new constant a by
a=c
then
γ=

1
−1 ,
γ

(14.144)

c
c+a

(14.145)

and Eq. (14.143) becomes
γq + (1 − γ)c pq (n) =

c(q + a)
p q ( n ),
c+a

(14.146)

which is exactly the same as the probability (14.2) for the equivalent quantity
in Price’s model.
We can now use this probability to write down a master equation for the
evolution of the degree distribution pq , which will be precisely the same as the
master equation (14.5) for Price’s model and all subsequent developments follow through just as in Section 14.1. The end result is that our vertex copying
model behaves precisely as the Price model does, but with a value of a speciﬁed now in terms of the parameter γ by Eq. (14.144). Thus, for example, the
degree distribution in the limit of large n will obey Eq. (14.21) and hence will
asymptotically follow a power law with exponent α given by Eq. (14.27) to be
α = 2+

a
1
= 1+
c
γ

(14.147)

27
In simply adding together our probabilities we are technically writing down an expression
for the expected number of new edges the vertex receives, rather than the probability of receiving
a new edge. However, in the limit of large n the two become the same.

537

M ODELS OF NETWORK FORMATION

This gives exponents in the range from 2 to ∞, with the value depending on
how faithfully vertices are copied. Faithful copies (γ close to one) give exponents close to two, while sloppy copies give exponents that can be arbitrarily
large. Other properties of Price’s model carry over as well, such as the distribution of in-degree as a function of age given in Eq. (14.57).
This is not to say, however, that vertex copying generates networks identical in every respect to preferential attachment. With vertex copying, for instance, many of the links that a newly appearing vertex makes are typically
copied from the same other vertex and hence most vertices in the network will
have connections that are similar to those of at least one other vertex. In preferential attachment models, on the other hand, there is no such correlation between the connections of different vertices—each link is chosen independently
from the available possibilities at the time it is created and not copied from
anywhere else. The two networks therefore, while they may have the same
degree distribution, are different in the details of their structure.
In addition to being interesting in its own right, the vertex copying model
serves as a useful cautionary tale concerning the mechanisms of network formation. We have seen that many real networks have degree distributions that
follow a power law, at least approximately, and that preferential attachment
models can generate such degree distributions. A natural conclusion is that
real networks are the product of preferential attachment processes, and this
may indeed be correct. We should be careful, however, not to jump immediately to conclusions because, as we have now seen, there exists at least one
other mechanism—vertex copying—that produces precisely the same degree
distribution. Without further information we have no way of telling which of
these mechanisms is the correct one, or whether some other third mechanism
that we have not yet thought of is at work.
One could in principle examine details of the structure of speciﬁc realworld networks in an attempt to tell which, if either, of our two mechanisms is
the better model for their creation. For instance, one might examine a network
to see if there appear to be pairs of vertices whose outgoing connections are
approximate copies of one another. In fact, in real citation networks it turns
out that there are many such pairs, an observation that appears to lend weight
to the vertex copying scenario. However, we must remember that both of our
models are much simpliﬁed and it’s likely that neither of them is an accurate
representation of the way real networks are created. A simple explanation for
vertices in citation networks with similar patterns of links is that they correspond to papers on similar topics and so tend to cite the same literature; there
is no need to assume that one of them copied from the other. As a result, it
may not be possible to distinguish ﬁrmly between preferential attachment and
538

Fraction of vertices with in-degree q

14.5

|

V ERTEX COPYING MODELS

0

10

-2

10

-4

10

(a)

(b)

(c)

(d)

-6

10

1

10

100

1

10

100

1

10

100

1

10

100

In-degree q
Figure 14.9: Distribution of in-degrees in the metabolic networks of various organisms. Jeong et al. [166] examined
the degree distributions of the known portions of the metabolic networks of 43 organisms, ﬁnding some of them to
follow power laws, at least approximately. Show here are the in-degree distributions for (a) the archaeon A. fulgidus,
(b) the bacterium E. coli, (c) the worm C. elegans (a eukaryote), and (d) the aggregated in-degree distribution for all 43
organisms. After Jeong et al. [166].

vertex copying in many cases.
There are, however, some cases where preferential attachment appears to
be an implausible candidate to explain the structure of a network, and in some
of these cases vertex copying is the most promising remaining option. A good
example comes from the realm of biology, where vertex copying is considered a strong candidate for explaining the structure of metabolic networks and
protein–protein interaction networks. As discussed in Chapter 5, these are
networks of chemical and physical interactions between molecules in the cell
and, although our knowledge of their structure is currently quite incomplete,
there is at least tentative evidence to suggest that they have power-law degree
distributions—see Fig. 14.9 and Refs. [164] and [166]. It seems unlikely, however, that preferential attachment is the cause of these power laws: there is no
obvious mechanism by which preferential attachment could take place in this
context. Vertex copying, on the other hand, may be a reasonable candidate.
Consider for example a protein interaction network. As described in Section 5.1.3, proteins in the cell are created by the processes of molecular transcription and translation from codes stored in the cell’s DNA. The section of
code that deﬁnes a single protein is called a gene and it turns out that genes
are sometimes inadvertently copied when cells reproduce.
When a cell splits in two to reproduce, its DNA is copied so that each half

539

M ODELS OF NETWORK FORMATION

of the split cell will have a complete copy. The cellular machinery responsible
for the copying is highly reliable, but not perfect. Very occasionally, a section
of DNA will be copied twice, giving rise to a repeated section, which can mean
that the new cell has two copies of a certain gene or genes where the old cell
had only one. Many examples of such repeated sections are known in the
human genome and the genomes of other animals and plants.
Another common type of copying error is the point mutation, whereby individual nucleotides—letters in the DNA code—are copied incorrectly. Over the
course of many cell divisions, point mutations can accumulate, and as a result
two initially identical versions of the same gene can become no longer identical, with some fraction of their bases changed to new and (roughly speaking)
random values. These processes typically happen slowly over the course of
evolutionary time, taking thousands or even millions of years. The end result,
however, is that a gene is copied and then mutated to be slightly different from
the original.
And these processes are reﬂected in the network of protein interactions.
Typically both copies of a duplicated gene in a genome can generate the corresponding protein; the subsequent mutation of one or both copies can result in
the two producing similar but slightly different versions of the protein, different enough in some cases to also have slightly different sets of interactions in
the network. Some interactions may be common to both proteins but, just as
in our vertex copying model, some may also be different.
This picture is made more plausible by the fact that changes in genes are
not purely random but are subject to Darwinian selection under which some
gene mutations are more advantageous than others. A cell with two copies of
a particular protein may gain a selective advantage if those copies do slightly
different things, rather than needlessly duplicating functionality that a single
copy alone could achieve. Thus it seems possible that nature may actually
favor duplicated proteins that have slightly different functions and hence different sets of network connections. Moreover an examination of the data for
real-world protein–protein interaction networks turns up many examples of
pairs of proteins that are similar but not identical in their patterns of interactions, and gene duplication is widely, if not universally, believed to be the
cause.
Several models of vertex copying and mutation in biological networks have
been proposed and studied. The model proposed by Solé et al. [302], for example, is very similar to the model described above, the main difference being
that it is a model of an undirected network rather than a directed one. Another
model, put forward by Vázquez et al. [317], is also similar but includes a mechanism whereby the connections of the copied vertex can be changed as well as
540

14.6

|

N ETWORK OPTIMIZATION MODELS

those of the copying vertex. Although the latter mechanism would make little sense in a model of a citation network (the bibliography of a paper never
changes after publication), it is appropriate in the biological context, where all
genes are potentially mutating all the time.

14.6

N ETWORK OPTIMIZATION MODELS

In the models we’ve looked at so far in this chapter, network structure is determined by the way in which the network grows—how newly added vertices
connect to others, where newly added edges get placed, and so forth. Furthermore, the structure of these networks is for the most part a result of a succession of random processes, often decentralized and quite blind to the large-scale
structure they are creating.
An alternative network formation mechanism, important in certain types
of network, is structural optimization. In some cases, such as transportation
networks (Section 2.4) or distribution networks (Section 2.5), a network has
been speciﬁcally designed to achieve a particular goal or goals, such as the delivery of mail or packages around the country or the transportation of airline
passengers to their destinations, and the structure of the network can heavily
inﬂuence the efﬁciency with which that goal is accomplished. Networks of airline routes, for example, are typically based on a hub-and-spoke arrangement
with a small number of busy airport hubs and a large number of minor destinations.28 (Package delivery companies also use a similar scheme.) The reason is
that it makes little sense to ﬂy airplanes directly between minor destinations—
there will typically be very few passengers interested in the service and the
planes will be half empty. By ensuring that the only ﬂights in and out of minor
destinations are to and from major hubs, one concentrates the passengers on
those routes, ensuring fuller planes while still giving the passengers a reasonably short journey.
In other words, the hub-and-spoke design of the airline networks optimizes
the network, making it more efﬁcient, and hence more proﬁtable, for the airline. In such cases, the structure of the network is explained not by a growth
mechanism but by the fact that the network has been designed to optimize certain characteristics. In this section we look brieﬂy at some models of network
optimization.
28

This is a relatively recent development, at least in the United States, where industry regulations made the hub-and-spoke system impractical until 1978. After regulations were lifted the
hub-and-spoke system was rapidly adopted by most of the major airlines. Hub-and-spoke systems
were also adopted by the package delivery industry around the same time.

541

M ODELS OF NETWORK FORMATION

14.6.1

T RADE - OFFS BETWEEN TRAVEL TIME AND COST

The example given above of an airline network is a good place for us to start.
Airline networks are, in fact, highly optimized: the airline industry operates
on very small (sometimes even negative) proﬁt margins, and optimization of
operations to trim even a tiny percentage off their enormous costs can make
a substantial difference to the bottom line. Airlines employ large staffs of researchers whose sole task is to ﬁnd new ways to optimize aspects of their business, including particularly their network of routes. At the same time, airlines
need to keep their customers happy if they are to avoid losing market share
to their competitors. This means, for instance, that they need to provide short,
quick routes between as many pairs of destinations as possible—travelers are
strongly averse to long journeys that wear them out or waste their time. The
twin goals of cost-efﬁcient operation and short routes are to some extent at
odds with one another. The quickest way to get passengers from any place
to any other, for example, would be to ﬂy separate planes between every pair
of airports in the country, but this would be immensely costly. The observed
structure of real airline networks is a compromise response to the conﬂicting
needs of the company and its passengers.
The optimization problems faced by real airlines are, inevitably, hugely
complex, involving as they do organizations with thousands of employees,
billions of dollars worth of material resources, and rapidly changing parameters such as fuel costs, consumer demand, and the nature of the competition.
Nonetheless, there is insight to be gained by creating and studying simpliﬁed
models of the optimization process in the same way that simple models of, for
example, citation networks can grant us insight despite the many features of
real citation processes that they omit.
One of the simplest models of network optimization is that proposed by
Ferrer i Cancho and Solé [117], which balances two elements of exactly the
types discussed above. In this model the cost of maintaining and operating the
network is represented by the number of edges m in the network. This would
be equivalent to saying that the cost of running an airline is proportional to
the number of routes it operates. Obviously this is a vast simpliﬁcation of the
real situation, but let us accept it for the moment and see where it leads. The
customer satisfaction half of the equation is represented by the mean geodesic
distance  between vertex pairs. In our airline example  would be the average
number of legs required to journey from one point to another, which is certainly one element of customer satisfaction, though not the only one. Technically,  is a dissatisfaction measure, since large values correspond to disgruntled
customers.

542

14.6

|

N ETWORK OPTIMIZATION MODELS

We would like to design a network that minimizes both m and  but this
is in general not possible: the minimum value of  is achieved by placing an
edge between every pair of vertices, but this maximizes the value of m. Thus
our two goals are, as discussed above, at odds with one another and the best
we can hope for is a reasonable compromise between them. In search of such
a compromise, Ferrer i Cancho and Solé studied the quality function
E(m, ) = λm + (1 − λ),

(14.148)

where λ is a parameter in the range 0 ≤ λ ≤ 1. For any given network and
a given value of λ we can calculate E(m, ); the value of  for instance can
be computed using the breadth-ﬁrst search algorithm of Section 10.3. Ferrer i
Cancho and Solé considered networks of a given number of vertices n and then
asked what happens when we try to minimize E(m, ) by varying the position
of the edges in that network to ﬁnd the smallest value possible. If λ = 1, then
E = m and this process is equivalent to just minimizing the number of edges
without regard for path lengths. If λ = 0 then E =  and we are minimizing
only average path length without regard for m. For values in between, we are
striking a balance between number of edges and path length, with the precise
weight of each term controlled by our choice of λ.
At some level, this model is a trivial one. Observe that the value of  becomes formally inﬁnite if there is any pair of vertices in the network that is not
connected by a path—i.e., if the network has more than one component—since
the distance between such pairs is by convention considered inﬁnite (see Section 6.10.1). Thus the minimum value of E must be for a connected network, a
network with just one component. Observe also that the minimum value of m
for a connected network is m = n − 1, where n is the number of edges. This is
the value for a tree, which is the connected network with the smallest number
of edges (see Section 6.7).
Provided λ is reasonably large, so that we place a moderate amount of
weight on minimizing m, the network with the best value of E(m, ) is then
found by giving m its minimum value of n − 1, which constrains the network
to be a tree, and searching through the set of possible trees to ﬁnd the one that
minimizes . In fact, the latter task has a simple, known solution: the minimum value of  among trees with n vertices is obtained by the star graph, the
network in which there is a single central hub connected by a single edge to
each of the n − 1 remaining vertices. By deﬁnition there are always exactly m
pairs of vertices with geodesic distance one in any network—the pairs that are
directly connected by an edge—which means that in a tree there are n − 1 such
pairs. Among the set of all trees, therefore, the value of the mean distance 
is governed by the numbers of pairs with distances of two or more, since the

A star graph of 25 vertices.

543

M ODELS OF NETWORK FORMATION

number with distance one is ﬁxed. But in the star graph all other pairs have
distance exactly two—the shortest (indeed only) path from any (non-hub) vertex to any other is the path of length two via the hub. Thus there can be no
other tree with a smaller value of .
Thus, for sufﬁciently large λ, the optimum network under the quality function (14.148) is always the star graph. This is satisfying to some extent: it offers
a simple explanation of why the hub-and-spoke system is so efﬁcient. It offers
short journeys while still being economic in terms of the number of different
routes the airline has to operate. But it is also, as we have said, somewhat trivial. The model shows essentially only the one behavior. For smaller values of λ
other behaviors are possible, but it turns out that the value of λ has to be really
small: non-star-graph solutions only appear when29
λ<

2
n2 + 2

.

(14.149)

Since the expression on the right-hand side dwindles rapidly as n becomes
29
The derivation of this result is as follows. If λ is sufﬁciently large then, as we have shown,
the optimal network is the star graph. If we now reduce λ slowly then at some point we enter a
regime in which the cost of adding an edge is sufﬁciently offset by the corresponding reduction in
the mean geodesic distance that it becomes worthwhile to add edges between the “spoke” vertices
in the star graph. To calculate the point at which such additions become beneﬁcial let us take
our star graph and add to it some number r of extra edges. Necessarily these edges fall between
the spoke vertices, since there is nowhere else for them fall, and in doing so they form paths of
length one between pairs of vertices whose previous shortest path was of length two. The shortest
paths between no other vertices are affected by the addition. Thus the total number of vertex pairs
connected by paths of length 1 is n − 1 + r and all the rest have paths of length two. Then the mean
geodesic distance, as deﬁned in Eq. (7.31) is

=

(n − 1 + r ) + 2[ 12 n(n − 1) − (n − 1 + r )]
1
( n − 1)2 − r
dij = 2
=2
.
∑
2
2
n ij
n
n2

(The leading factor of two comes from the fact that the sum over i, j counts each pair of vertices
twice.)
Substituting this expression, along with m = n − 1 + r, into Eq. (14.148) then gives


2( λ − 1)
( n − 1)2 − r
λ
r.
=
constant
+
+
E = λ ( n − 1 + r ) + 2(1 − λ )
n2
n2
This will decrease with growing r only if the quantity in square brackets [. . .] is negative, i.e., if
λ<

2
.
n2 + 2

If this condition is satisﬁed then it becomes advantageous to add edges between the spoke vertices,
and to keep on doing so until the network becomes a complete graph, with every vertex connected
to every other. Thus there is a discontinuous transition between two behaviors—the star graph and
the complete graph—at the point λ = 2/(n2 + 2). Real distribution and transportation networks
appear to be in the star-graph regime.

544

14.6

|

N ETWORK OPTIMIZATION MODELS

large, the optimal network is the star graph for almost all values of λ, even for
networks of quite modest size.
In their paper, however, Ferrer i Cancho and Solé did not perform precisely
the calculation we have done here. Instead, they took a different and interesting approach, in which they looked for local minima of E(m, ), rather than the
global minimum. They did this numerically, starting with a random network,
repeatedly choosing a pair of vertices at random, and either connecting them
by an edge if they were not already connected or deleting the edge between
them if they were. Then they compared the value of E before and after the
change. If E decreased or stayed the same, they kept the change. If not, they
reverted back to the state of the network before the change. The whole procedure was then repeated until the value of E stopped improving, meaning
in practice that a long string of attempted changes were rejected because they
increased E.
An algorithm of this kind is called a random hill climber or greedy algorithm.
The networks it ﬁnds are networks for which the value of E cannot be reduced
any further by the addition or removal of any single edge. This does not mean,
however, that no lower values of E exist: there may be states of the network
that differ by more than one edge—the addition and deletion of whole regions
of the network—that have better values of E. But if so, the algorithm will not
ﬁnd them. It comes to a halt at a local minimum where no single-edge change
will improve the value of E.
When studied in this way, the model shows an interesting behavior. For
large values of λ, where the addition of an edge costs a great deal in terms of
the value of E, the algorithm rapidly runs into trouble and cannot ﬁnd a way to
improve the network, long before it gets anywhere close to the optimum huband-spoke arrangement. When λ is small, on the other hand, the algorithm
typically manages to ﬁnd the star graph solution. The result is a spectrum of
networks that range from a random-looking tree to a star-graph, as shown in
Fig. 14.10.
What’s more, Ferrer i Cancho and Solé found that the degree distributions
of their networks show interesting behavior, passing from an exponential distribution for large λ, though a transition point with a power-law degree distribution, to approximately star-like graphs for small λ in which one vertex gets
a ﬁnite fraction of all the edges and the remaining vertices have low degree.
This spectrum is reminiscent of the behavior of continuous phase transitions
such as the transition at which a giant component appears in a random graph
(see Section 12.5), in which an initially exponential distribution of component
sizes passes through a transition to a regime in which one component gets a
ﬁnite fraction of all vertices and the rest are small.
545

M ODELS OF NETWORK FORMATION

Figure 14.10: Networks generated by the optimization model of Ferrer i Cancho and Solé. The optimization model
described in the text generates a range of networks, all trees or approximate trees, running from (a) distributed networks
with exponential degree distributions, through (b) power-law degree distributions, to (c) star graphs in which there is
just one major hub. Figure adapted from [117]. Original ﬁgure Copyright 2003 Springer-Verlag Berlin Heidelberg.
Reproduced with kind permission of Springer Science and Business Media.

Sadly, this observation does not go any further than an intriguing hint. The
work of Ferrer i Cancho and Solé is entirely numerical and they do not give
any analytic treatment of the model. In addition there are some other problems with the model. In particular, it is not clear why one should look at local
minima of E rather than global ones: the researchers who work for real airlines
are certainly capable of realizing when they are stuck in a local optimum and
better proﬁts are available by changing the network in some substantial way
that moves them to a different and better optimum. It seems likely therefore
that, to the extent that real networks show interesting structural behavior of
the type observed here, it is not a result of getting stuck in local minima and
hence that a model with a different approach is needed.
One such model, proposed by Gastner and Newman [137], generalizes that
of Ferrer i Cancho and Solé by considering not only number of legs in a journey
but also the geographic distance traveled. Suppose that airline travelers are
principally concerned not with the number of legs in their journey but with
the total time it takes them to travel from origin to destination. Number of legs
can be regarded as a simple proxy for travel time, but a better proxy would be
to take the length of those legs into account as well as their number. The travel
time contributed to a journey by one leg is composed of the time spent in the
airport (checking in, waiting, embarking, taxiing, disembarking, etc.) plus the
time spent in the air. A simple formula would be to assume that the former
is roughly constant, regardless of the distance being traveled, while the latter
546

14.6

|

N ETWORK OPTIMIZATION MODELS

is roughly proportional to the distance traveled. Thus, the time taken by a leg
from vertex i to vertex j in our network would be
tij = μ + νrij ,

(14.150)

where μ and ν are constants and rij is the distance ﬂown from i to j. By varying
the values of μ and ν, we can place more or less emphasis on the ﬁxed “airport”
time cost versus the time spent in the air.
Gastner and Newman used this expression for travel time in place of the
simple hop-count of the model of Ferrer i Cancho and Solé, redeﬁning  to be
the average shortest-path distance between pairs of vertices when distances
are measured in terms of travel time. The quality function E is deﬁned just as
before, Eq. (14.148), but using this new deﬁnition of .
Despite the superﬁcial similarity between this model and that of Ferrer i
Cancho and Solé there is a crucial difference between the two: the model of
Gastner and Newman depends on actual spatial distances between airports
and hence requires that the vertices of the network be placed at some set of positions on a map. The model of Ferrer i Cancho and Solé by contrast depends
only on the network topology and has no spatial element. There are various
ways in which the vertices can be positioned on the map. Gastner and Newman, for instance, speciﬁcally considered the map of the United States and
took the real US population distribution into account, placing vertices with
greater density in areas with greater populations. While this adds a level of
realism to the calculations, the interesting behavior of their model can be seen
without going so far. In the examples given here we consider a ﬁctional map in
which vertices are just placed uniformly at random in a square with periodic
boundary conditions.
Another important difference between the two models is that Gastner and
Newman considered the global optimum of the quality function rather than
local optima as Ferrer i Cancho and Solé did. In practice, unfortunately, the
global optimum is hard to ﬁnd, so one often has to make do with approximate optima. Gastner and Newman used the numerical optimization technique called simulated annealing to ﬁnd good approximations to the global
optimum, but we should bear in mind that they are only approximations.
Figure 14.11 shows optimal or approximately optimal networks for various
values of the parameters μ and ν. The leftmost frames of the ﬁgure correspond
to small μ and large ν, meaning that the cost to the traveler of a trip is roughly
proportional to the total mileage traveled and the number of legs has little
effect. In this case, the best networks are ones that allow travelers to travel in
roughly straight lines from any origin to any destination. As the ﬁgure shows,
the networks are roughly planar in appearance. They look reminiscent of road
547

M ODELS OF NETWORK FORMATION

Figure 14.11: Networks generated by the spatial network model of Gastner and Newman. The four frames show
networks that optimize or nearly optimize the quality function, Eq. (14.148), with  deﬁned according to the prescription
of Gastner and Newman [137] in which the lengths of edges in the network are chosen to represent the approximate
travel time to traverse the edge. Travel time has two components, a ﬁxed cost per edge and a cost that increases with the
Euclidean length of an edge. The frames show the resulting networks as the relative weight of these two components
is varied between the extremes represented by the network on the left, for which all of the weight is on the Euclidean
length, and by the network on the right, for which cost is the same for all edges. The resulting structures range from
road-like in the former case, to airline-like in the latter. Adapted from Gastner [135].

networks, rather than airline routes, and this is no coincidence. Travel times
for road travelers are indeed dominated by total mileage: there is almost no
“per leg” cost associated with road travel, since it takes only a few seconds to
turn from one road onto another. It is satisfying to see therefore that the simple
model of Gastner and Newman generates networks that look rather like real
road maps in this limit.
The rightmost frames in the ﬁgure show optimal networks for large μ and
small ν—the case where it is mostly the number of legs that matters and the
length of those legs is relatively unimportant. As we saw for the model of
Ferrer i Cancho and Solé, the best networks in this case are star-like hub-andspoke networks, and this is what we see in the present model too.
Thus this model interpolates between road-like and airline-like networks
as the parameters are varied from one extreme to the other. Note that the
parameter λ governing the cost of building or maintaining the network is held
constant in Fig. 14.11. In principle, we could vary this parameter too, which
would affect the total number of edges in the network. For higher λ sparser
networks with fewer edges would be favored, while for lower λ we would see
denser networks.
The work of Gastner and Newman still suffers from the drawback that the
results are numerical only. More recently, however, some results for the model
have been derived analytically by Aldous [15]. The interested reader is encouraged to consult his paper.
548

P ROBLEMS

P ROBLEMS
14.1 Consider the growing network model of Price, as described in Section 14.1.
a) From the results given in this chapter write down an expression in terms of the parameters a and c for the expected in-degree of the ith vertex added to the network
just before the jth vertex is added, where i < j.
b) Hence show that the average probability of a directed edge from j to i in a network
with n vertices, where n ≥ j, is
Pij =

ca −c/(c+a)
i
( j − 1)−a/(c+a) .
c+a

14.2 Consider Price’s model as a model of a citation network, applied to publications
in a single ﬁeld, a ﬁeld that is currently, say, ten years old.
a) Suppose that you are the author of the tenth paper published in the ﬁeld. How
long will it be from now before the expected number of citations your paper has
within the ﬁeld is equal to the expected number that the ﬁrst paper published
currently has?
b) Derive an expression for the average number of citations per paper to papers published between times τ1 and τ2 , where time is deﬁned as in Eq. (14.44).
c) Reasonable values of the model parameters for real citation networks are c = 20
and a = 5. For these parameter choices, what is the average number of citations
to a paper in the ﬁrst 10% of those published? And what is the average number
for a paper in the last 10%?
These perhaps surprising numbers are examples of the ﬁrst-mover advantage discussed
in Section 14.3.1—the substantial bias of citation numbers in favor of the ﬁrst papers
published in a ﬁeld.
14.3 Consider a model of a growing directed network similar to Price’s model described in Section 14.1, but without preferential attachment. That is, vertices are added
one by one to the growing network and each has c outgoing edges, but those edges
now attach to existing vertices uniformly at random, without regard for degrees or any
other vertex properties.
a) Derive master equations, the equivalent of Eqs. (14.7) and (14.8), that govern the
distribution of in-degrees q in the limit of large network size.
b) Hence show that in the limit of large size the in-degrees have an exponential distribution pq = Ce−λq , where C is a normalization constant and λ = ln(1 + 1/c).
14.4 Consider a model network similar to the model of Barabási and Albert described
in Section 14.2, in which undirected edges are added between vertices according to a
preferential attachment rule, but suppose now that the network does not grow—it starts
off with a given number n of vertices and neither gains nor loses any vertices thereafter.
In this model, starting with an initial network of n vertices and some speciﬁed arrangement of edges, we add at each step one undirected edge between two vertices, both of
which are chosen at random in direct proportion to degree k. Let pk (m) be the fraction
of vertices with degree k when the network has m edges in total.

549

M ODELS OF NETWORK FORMATION

a) Show that when the network has m edges, the probability that vertex i will get a
new edge upon the addition of the next edge is k i /m.
b) Write down a master equation giving pk (m + 1) in terms of pk−1 (m) and pk (m).
Be sure to give the equation for the special case of k = 0 also.
c) Eliminate m from the master equation in favor of the mean degree c = 2m/n
and take the limit n → ∞ with c held constant to show that pk (c) satisﬁes the
differential equation
dpk
= (k − 1) pk−1 − kpk .
c
dc
k
d) Deﬁne a generating function g(c, z) = ∑∞
k =0 pk ( c ) z and show that it satisﬁes the
partial differential equation
c

∂g
∂g
+ z (1 − z )
= 0.
∂z
∂c

e) Show that g(c, z) = f (c − c/z) is a solution of this differential equation, where
f ( x ) is any differentiable function of x.
f) The particular choice of f depends on the initial conditions on the network. Suppose the network starts off in a state where every vertex has degree one, which
means c = 1 and g(1, z) = z. Find the function f that corresponds to this initial
condition and hence ﬁnd g(c, z) for all values of c and z.
g) Show that, for this solution, the degree distribution as a function of c takes the
form
( c − 1 ) k −1
pk (c) =
,
ck
except for k = 0, for which p0 (c) = 0 for all c.
Note that this distribution decays exponentially in k, implying that preferential attachment does not, in general, generate a power-law degree distribution if the network is
not also growing.
14.5 Consider a model of a growing network similar to Price’s model described in Section 14.1, but in which the parameter a, which governs the rate at which vertices receive
new incoming links when their current in-degree is zero, varies from vertex to vertex.
That is the probability of a new edge attaching to vertex i is proportional to qi + ai ,
where qi is the current in-degree and ai is a speciﬁed parameter. In the context of citation networks, for example, ai could be considered a measure of the intrinsic merit of a
paper, controlling as it does the rate at which the paper gets citations immediately after
ﬁrst publication, when qi = 0. (This differs from the model discussed in Section 14.4.4,
where the preferential attachment term was multiplied by a varying factor to represent
variations in the merit or ﬁtness of vertices.)
a) Suppose that ai is drawn at random from some stationary distribution with a welldeﬁned mean. Show that, in the limit of large n, the probability that the (n + 1)th
vertex added to the network attaches to a previous vertex i with in-degree qi is
c(qi + ai )/n(c + ā), where ā is the average value of ai .

550

P ROBLEMS

b) Hence show that the in-degree distribution of the network satisﬁes the same master equations, (14.7) and (14.8), as Price’s model, but with a replaced by ā.
(It immediately follows that the degree distribution of the network is also the same as
for Price’s model with the same substitution.)
14.6 Consider the following simple model of a growing network. Vertices are added
to a network at a rate of one per unit time. Edges are added at a mean rate of β per unit
time, where β can be anywhere between zero and ∞. (That is, in any small interval δt
of time, the probability of an edge being added is β δt.) Edges are placed uniformly at
random between any pair of vertices that exist at that time. They are never moved after
they are ﬁrst placed.
We are interested in the component structure of this model, which we will tackle
using a master equation method. Let ak (n) be the fraction of vertices that belong to
components of size k when there are n vertices in the network. Equivalently, if we
choose a vertex at random from the n vertices currently in the network, ak (n) is the
probability the vertex will belong to a component of size k.
a) What is the probability that a newly appearing edge will fall between a component of size r and another of size s? (You can assume that n is large and the probability of both ends of an edge falling in the same component is small.) Hence, what
is the probability that a newly appearing edge will join together two pre-existing
components to form a new one of size k?
b) What is the probability that a newly appearing edge joins a component of size k
to a component of any other size, thereby creating a new component of size larger
than k?
c) Thus write down a master equation that gives the fraction of vertices ak (n + 1) in
components of size k when there are n + 1 vertices in total.
d) The only exception to the previous result is that components of size 1 appear at a
rate of one per unit time. Write a separate master equation for a1 (n + 1).
e) If a steady-state solution exists for the component size distribution, show that it
satisﬁes the equations

(1 + 2β) a1 = 1,

k −1

(1 + 2βk) ak = βk ∑ a j ak− j .
j =1

f) Multiply by zk and sum over k from 1 to ∞ and hence show that the generating
function g(z) = ∑k ak zk satisﬁes the ordinary differential equation
2β

1 − g/z
dg
.
=
1−g
dz

Unfortunately, the solution to this equation is not known, so for the moment at least we
do not have a complete solution for the component sizes in the model.

551

C HAPTER 15

O THER NETWORK MODELS
A brief introduction to two specialized network models,
the small-world model and the exponential random graph

T

HE RANDOM graph and preferential attachment models of previous chap-

ters are the most widely studied of network models, but they are not the
only ones. Many other models have been proposed, either as a way of shedding light on speciﬁc observed features of networks or as tools to help in the
analysis of network data. In this chapter we describe brieﬂy two of the bestknown additional types of network models, the small-world model and exponential random graphs.

15.1

T HE SMALL - WORLD MODEL

One of the least well-understood features of real-world networks is transitivity, the propensity for two neighbors of a vertex also to be neighbors of one
another. (See Section 7.9 for an introduction to the phenomenon of transitivity.) Neither the random graph models of Chapters 12 and 13 nor the models
of network growth discussed in Chapter 14 generate networks with any significant level of transitivity, as quantiﬁed by the clustering coefﬁcient, Eq. (7.41).
The Poisson random graph of Chapter 12, for instance, has a clustering coefﬁcient c/(n − 1), where c is the mean degree of a vertex (see Eq. (12.11)). Thus
the clustering coefﬁcient vanishes as n becomes large for constant c. In practice, as discussed in Section 7.9, this often results in values of the clustering
coefﬁcient that are orders of magnitude smaller than those observed in real
networks.
It is not that difﬁcult to come up with a network model that does have a
high clustering coefﬁcient. For example, a simple triangular lattice, as shown

552

15.1

|

T HE SMALL - WORLD MODEL

in Fig. 15.1, has signiﬁcant transitivity.
There are twice as many triangles in such a lattice as there are
vertices, for a total of 2n triangles in a network of n vertices. At the
same time there are (62) = 15 connected triples for each vertex, so,
following Eq. (7.41), the clustering coefﬁcient is
C=

(number of triangles) × 3
2n × 3
2
=
= = 0.4.
(number of connected triples)
15n
5

(15.1)

A value of 0.4 is comparable with the clustering coefﬁcients measured for many social networks (see Section 7.9 again). Moreover,
this value does not depend on the size of the network, as the value
for the random graph (and many other models) does, so it remains
large even as the network size diverges.
Figure 15.1: A triangular lattice. Any
Another simple model network with high transitivity is depicted
vertex in a triangular lattice, such as the
in Fig. 15.2a. Unlike the triangular lattice, this model allows the
one highlighted here, has six neighbors
value of the clustering coefﬁcient to be varied. In this model the
and hence (62) = 15 pairs of neighbors,
vertices are arranged on a one-dimensional line, and each vertex is
of which six are connected by edges,
6
connected by an edge to the c vertices nearest to it, where for congiving a clustering coefﬁcient of 15
=
0.4 for the whole network, regardless of
sistency c should be an even number. To make analytic treatment
size.
easier, we can apply periodic boundary conditions to the line, effectively bending it around into a circle, as in Fig. 15.2b.
To calculate the number of triangles in such a network, we observe that a
trip around any triangle must consist of two steps in the same direction around
(a)

(b)

Figure 15.2: A simple one-dimensional network model. (a) Vertices are arranged on
a line and each is connected to its c nearest neighbors, where c = 6 in this example.
(b) The same network with periodic boundary conditions applied, making the line into
a circle.

553

O THER NETWORK MODELS

Traversing a “triangle” in
our circle model means
taking two steps forward
around the circle and one
step back.

the circle—say clockwise—followed by one step back to close the triangle. The
number of triangles per vertex in the whole network is then equal to the number of such triangles that start from any given point.
Note, however, that the third and ﬁnal step in the triangle can go at most 12 c
units or lattice spacings around the circle, since this is the length of the longest
link in the network. And the number of ways to choose the two steps forward
is simply the number of distinct ways of choosing the target vertices for those
1
1
steps from the 12 c possibilities, which is (c/2
2 ) = 4 c ( 2 c − 1). Thus the total
number of triangles is 14 nc( 21 c − 1).
The number of connected triples centered on each vertex is just (2c ) = 12 c(c −
1) and hence the total number of connected triples is 12 nc(c − 1).
Putting these results together, the clustering coefﬁcient for the complete
network is
1
nc( 1 c − 1) × 3
3( c − 2)
.
(15.2)
=
C= 4 1 2
4( c − 1)
nc
(
c
−
1
)
2
As c is varied, this clustering coefﬁcient ranges from zero for c = 2 up to a
maximum of 34 when c → ∞. And, as with the triangular lattice, the value
does not fall off with increasing network size, since Eq. (15.2) is independent
of n.
While this simple “circle model” and the triangular lattice both give large
values of the clustering coefﬁcient, they are clearly unsatisfactory in other respects as models of networks. One obvious problem is the degree distribution.
The circle model, for instance, gives all vertices the same degree c. In the language of graph theory the model generates a regular graph, which is entirely
unlike most real-world networks with their broad distributions of vertex degree. This problem however could quite easily be solved by making a circle of
vertices with varying degrees instead of constant ones.
A more serious problem with models of this type is that they are “large
worlds”—they don’t display the small-world effect characteristic of essentially
every observed network in the real world and discussed previously in Sections 3.6 and 8.2. The small-world effect is the observation that the geodesic or
shortest-path distance between most pairs of vertices in a network is small—
typically just a few steps even in networks with billions of vertices such as the
acquaintance network of the entire world population.
The shortest distance between two vertices in the circle model above is
straightforward to calculate: the farthest one can move around the ring in a
single step is 12 c lattice spacings, so two vertices m lattice spacings apart are

554

15.1

|

T HE SMALL - WORLD MODEL

connected by a shortest path of 2m/c steps.1 Averaging over the complete
range of m from 0 to 21 n then gives a mean shortest path of n/2c. In a network
such as the acquaintance network of the world, with n = O(109 ) people each
acquainted with, say, c = O(103 ) others, this expression yields an average
shortest path length on the order of a million steps, which is wildly off the
mark—a more realistic ﬁgure would be six or maybe ten, but not a million.
By contrast, the random graph studied in Chapter 12 does capture the smallworld effect rather well (as indeed do most of the other network models discussed in previous chapters). As shown in Section 12.7, the typical shortest
path between connected vertices in a random graph has length about ln n/ ln c
which has a value on the order of 93 = 3 for the acquaintance network above.
On the other hand, as we have said, the random graph has an unrealistically
low clustering coefﬁcient.
Thus we have two models, our simple circle model and the random graph,
that between them each capture one property of real networks—high transitivity and short path lengths—but neither captures both. This leads us to ask
whether it is possible to create a hybrid of the two that, like real-world networks, displays both high transitivity and short path lengths simultaneously.
The small-world model, proposed in 1998 by Watts and Strogatz [323], does exactly this.
The small-world model, in its original form, interpolates between our circle
model and the random graph by moving or rewiring edges from the circle to
random positions. The detailed structure of the model is shown in Fig. 15.3a.
Starting with a circle model of n vertices in which every vertex has degree c, we
go through each of the edges in turn and with some probability p we remove
that edge and replace it with one that joins two vertices chosen uniformly at
random.2 The randomly placed edges are commonly referred to as shortcuts
because, as shown in Fig. 15.3a, they create shortcuts from one part of the circle
to another.
1

Strictly it’s 2m/c, where  x  is the smallest integer not less than x.

2

In fact, in the original small-world model, as deﬁned by Watts and Strogatz, only one end
of each edge—say the more clockwise end—was rewired and the other left where it was. This,
however, results in a model that never becomes a true random graph even when all edges are
rewired, as one can easily see, since each vertex is still attached to half of its original edges and
hence would have degree at least 12 c. In a true random graph there is no such constraint on degrees;
vertices can have degrees of any value between zero and n − 1. The original model also imposed
some other constraints, such as the constraint that no two edges may connect the same vertex pair.
This constraint could be imposed in the version we discuss here, although it makes little difference
in practice, since the number of such multiedges is of order 1/n in the limit of large n and therefore
the multiedges make a small contribution to any results if the network is large.

555

O THER NETWORK MODELS

(a)

(b)

Figure 15.3: Two versions of the small-world model. (a) In the original version of the
small-world model, edges are with independent probability p removed from the circle
and placed between two vertices chosen uniformly at random, creating shortcuts across
the circle as shown. In this example n = 24, c = 6, and p = 0.07, so that 5 out of 72
edges are “rewired” in this fashion. (b) In the second version of the model only the
shortcuts are added and no edges are removed from the circle.

The parameter p in the small-world model controls the interpolation between the circle model and the random graph. When p = 0 no edges are
rewired and we retain the original circle. When p = 1 all edges are rewired
to random positions and we have a random graph. For intermediate values
of p we generate networks that lie somewhere in between. Thus for p = 0
the small-world model shows clustering (so long as c > 2—see Eq. (15.2)) but
no small-world effect. For p = 1 it does the reverse. The crucial point about
the model is that as p is increased from zero the clustering is maintained up to
quite large values of p while the small-world behavior, meaning short average
path lengths, already appears for quite modest values of p. As a result there
is a substantial range of intermediate values for which the model shows both
effects simultaneously, thereby demonstrating that the two are in fact entirely
compatible and not exclusive at all.
Unfortunately, it is hard to demonstrate this result rigorously because the
small-world model as deﬁned above is difﬁcult to treat by analytic means. For
this reason we will in this chapter study a slight variant of the model, which is
easier to treat [254]. In this variant, shown in Fig. 15.3b, edges are added between randomly chosen vertex pairs just as before, but no edges are removed
from the original circle. This leaves the circle intact, which makes our calculations much simpler. For ease of comparison with the original small-world
model, the deﬁnition of the parameter p is kept the same: for every edge in the

556

15.1

|

T HE SMALL - WORLD MODEL

circle we add with independent probability p an additional shortcut between
two vertices chosen uniformly at random.3
A downside of this version of the model is that it no longer becomes a
random graph in the limit p = 1. Instead it becomes a random graph plus the
original circle. This, however, turns out not to be a signiﬁcant problem, since
most of the interest in the model lies in the regime where p is small and in this
regime the two models differ hardly at all; the only difference is the presence in
the second variant of a small number of edges around the circle that would be
absent in the ﬁrst, having been rewired. Henceforth, we will study the variant
model in which no edges are removed and we will refer to it, as others have,
as the small-world model, although the reader should bear in mind that there
are two slightly different models that carry this name.
15.1.1

D EGREE DISTRIBUTION

In the circle model described in the last section every vertex has the same degree c—the network is a regular graph. Once we add shortcuts to the circle
to make the small-world model, the degree of a vertex is c plus the number of
shortcut edges attached to it. The deﬁnition of the small-world model says that
for each of the non-shortcut edges around the circle, of which there are 12 nc, we
add a shortcut with probability p at a random location, so that there are 12 ncp
shortcuts on average and ncp ends of shortcuts. This means that cp shortcuts
on average end at any particular vertex. And the speciﬁc number s of shortcuts
attached to any one vertex is Poisson distributed with mean cp thus:
ps = e−cp

(cp)s
.
s!

(15.3)

The total degree of a vertex is k = s + c. Putting s = k − c into Eq. (15.3) then
gives us the degree distribution of the small-world model:
pk = e−cp

(cp)k−c
(k − c)!

(15.4)

for k ≥ c and pk = 0 if k < c.
Figure 15.4 shows the form of this distribution for c = 6, p = 12 . As we can
see, the distribution has an unusual peaked shape with a lower cut-off, quite
unlike the degree distributions we saw for real networks in Section 8.3. In this
respect, therefore, the small-world model does not mimic well the structure of
3
Equivalently, one could just say that the number of shortcuts added is drawn from a Poisson
distribution with mean 12 ncp.

557

Figure 15.4: The degree distribution of the smallworld model. The frequency distribution of vertex
degrees in a small-world model with parameters
c = 6 and p = 21 .

Fraction of vertices with degree k

O THER NETWORK MODELS

0.2

0.1

0

5

10

15

Degree k

networks in the real world. On the other hand, the model was never intended
to mimic real-world degree distributions. What it does do well is mimic the
clustering and short path lengths seen in real networks.
15.1.2

C LUSTERING COEFFICIENT

The clustering coefﬁcient C is deﬁned by Eq. (7.41), which we reproduce here:
C=

(number of triangles) × 3
.
(number of connected triples)

(15.5)

To evaluate C for the small-world model we need to calculate the numbers of
triangles and connected triples in the network. Let us start with the former.
Since the underlying circle in the model is unchanged by the addition of
shortcuts, every triangle in that circle, of which there are, as before, 14 nc( 21 c −
1), is still present. Some new triangles are also introduced by the shortcuts.
For example, vertex pairs 12 c + 1 to c steps apart on the circle are connected by
one or more paths of length two, and if the same vertices are also connected by
a shortcut those paths are turned into triangles.
The number of such paths of length two is clearly proportional to n—if we
double the length of the circle we double the number of paths. The average
number of shortcuts in the small-world model is, as we have said, 12 ncp and
there are (n2 ) places they can fall, meaning that any particular pair of vertices is

558

15.1

|

T HE SMALL - WORLD MODEL

connected with probability
1
2 ncp

1
2 n ( n − 1)

=

cp
,
n−1

(15.6)

or just cp/n in the limit of large n. The number of paths of length two that are
completed by shortcuts to form triangles is thus proportional to n × cp/n = cp,
which is a constant. This means that in the limit of large network size we can
safely ignore these triangles, because they will be negligible compared to the
O(n) triangles in the main circle.
Triangles can also be formed from two or three shortcuts, but these also
turn out to be negligible in number. Thus, to leading order in n, the number of
triangles in the small-world model is simply equal to the number in the circle,
which is 14 nc( 21 c − 1).
And what about the number of connected triples? Once again, all connected triples in the circle model are still present in the small-world model. As
shown in Section 15.1, there are 12 nc(c − 1) such triples. There are, however,
also triples created by a shortcut combining with an edge in the circle. There
are 12 ncp shortcuts and c edges that they can form a triple with at each of their
two ends, for a total of 12 ncp × c × 2 = nc2 p connected triples.
There are also triples created by pairs of shortcuts. If a vertex is connected
to m shortcuts then there are (m2 ) triples made of two shortcuts centered on that
vertex and, averaging over the Poisson distribution of m, with mean cp, the
expected number of connected triples centered at a vertex is 12 c2 p2 , for a total
of 12 nc2 p2 triples over all vertices.
Thus the expected total number of connected triples of all types in the
whole network is 21 nc(c − 1) + nc2 p + 12 nc2 p2 . Substituting the numbers of
triangles and triples into Eq. (15.5), we then ﬁnd that
1
1
4 nc ( 2 c − 1) × 3
1
2
2 2
2 nc ( c − 1) + nc p + 2 nc p

C= 1

=

3( c − 2)
.
4(c − 1) + 8cp + 4cp2

(15.7)

Note that this becomes the same as Eq. (15.2), as it should, when p = 0. And as
p grows it becomes smaller, with a minimum value of C = 34 (c − 2)/(4c − 1)
when p = 1. For instance when c = 6, the minimum value of the clustering
3
= 0.130 . . . (This behavior contrasts with that of the original
coefﬁcient is 23
Watts–Strogatz version of the small-world model in which edges are removed
from the circle. In that version the clustering coefﬁcient tends to zero as n → ∞
when p = 1, since the network becomes a random graph at p = 1.)
559

O THER NETWORK MODELS

0.5

C/Cmax

or

/max

1

0

0.001

0.01

0.1

1

Shortcut probability p

Figure 15.5: Clustering coefﬁcient and average path length in the small-world model.
The solid line shows the clustering coefﬁcient, Eq. (15.7), for a small-world model with
c = 6 and n = 600, as a fraction of its maximum value Cmax = 34 (c − 2)/(c − 1) = 0.6,
plotted as a function of the parameter p. The dashed line shows the average geodesic
distance between vertices for the same model as a fraction of its maximum value max =
n/2c = 50, calculated from the mean-ﬁeld solution, Eq. (15.14). Note that the horizontal
axis is logarithmic.

Figure 15.5 shows a plot of the clustering coefﬁcient as a function of p for a
small-world network with c = 6.
15.1.3
See Section 6.10.1 for a
discussion of geodesic distances in networks.

560

AVERAGE PATH LENGTHS

Calculating the average path length in the small-world model, i.e., the mean
geodesic or shortest-path distance between pairs of vertices, is harder than
calculating the degree distribution or clustering coefﬁcient. Indeed, no exact
expression for mean distance has yet been found, though some approximate
expressions are known and have been found in simulations of the model to be
reasonably accurate.
One thing that is known about path lengths in the model is how they scale
with the model parameters. Consider the simple case of a small-world model

15.1

|

T HE SMALL - WORLD MODEL

with c = 2, so that around the circle each vertex is connected only to its immediate neighbors, and consider the following dimensional argument. We deﬁne
a length measure in our network by saying that the distance covered by an
edge in the network is one length unit—a meter say, or a foot.4 Then we can
ask what other quantities in the model have the dimensions of length. One
candidate is the distance around the whole circle, which is just n.
But there is another length in the model also, which is the mean distance
between the ends of shortcuts around the circle. Suppose there are s shortcuts
in our network, which means there 2s ends of shortcuts. (We know in fact that
s = 21 ncp, but the point of this argument will be clearer if we stick with the
simple notation s for the moment.) Then the average distance ξ between ends
around the circle is
n
(15.8)
ξ= .
2s
Once we specify the two distances n and ξ, we have speciﬁed the entire model,
because once we have n the value of ξ ﬁxes s, which ﬁxes p, which is the only
free parameter in the model given that c = 2.
Now consider the ratio of the length of the average shortest path in the
network, which we will denote , to the length of the path around the entire
circle, which is n. This ratio can, by deﬁnition, be written as a function of n
and ξ, since n and ξ specify the entire model. However, it is also the ratio of
two distances, meaning that it is dimensionless, and hence can be a function
of only of dimensionless combinations of n and ξ. But there is only one such
dimensionless combination, the ratio n/ξ. Thus it must be the case that


= F (n/ξ ) = F (2s),
n

(15.9)

where F ( x ) is some function that doesn’t depend on any of the parameters, a
universal function in the language of scaling theory.
In other words, the mean geodesic distance  between vertices in the smallworld model with c = 2 is simply equal to the number of vertices n times some
function of the number of shortcuts:

 = nF (2s).

(15.10)

And what happens for larger values of c? When we increase c the lengths of
the shortest paths between vertices decrease. If we keep everything the same
4
We consider all edges, including the shortcuts, to be the same length, even though the shortcuts are drawn as being longer in ﬁgures like Fig. 15.3. We are regarding the network as a purely
topological object, not a spatial one.

561

O THER NETWORK MODELS

in our model—number of vertices, number of shortcuts—but increase c from
two to four, then we will roughly halve the shortest path between any pair of
vertices. This is because we now have edges connecting next-nearest neighbor vertices around the circle as well as nearest neighbors, which means that
we can traverse a given distance around the circle in half as many hops as we
could previously. If the path incorporates any shortcuts then that part of the
distance doesn’t change—the shortcuts are as long as they ever were. However, if the density of shortcuts is low then most of the hops in most paths will
be around the circle rather than along shortcuts and to a good approximation
we can say that the length of the paths has simply halved. Similarly, for general values of c the length of the paths is decreased by a factor of 21 c over its
value for the c = 2 case.
Thus, provided the density of shortcuts is low, the equation corresponding
to Eq. (15.10) for general values of c is:

=

2n
F (2s).
c

(15.11)

We can derive an alternative form by making use of the fact that the number
of shortcuts is s = 12 ncp, which gives us  = 2(n/c) F (ncp). In fact, conventionally we absorb the leading factor of two into the deﬁnition of F, deﬁning a
new universal function f ( x ) = 2F ( x ), so that

=

n
f (ncp).
c

(15.12)

This scaling form, ﬁrst proposed by Barthélémy and Amaral [31], tells us how
the average path length in the small-world model depends on the model parameters n, c, and p when the density of shortcuts is low.
The catch is that we don’t know the form of the function f ( x ). We can,
however, get an idea of its shape by numerical simulation of the model. We can
generate random small-world networks and measure the mean distance  between their vertices using breadth-ﬁrst search (Section 10.3). Equation (15.12)
tells us that if we perform such measurements for many different networks
with many different values of the parameters we should ﬁnd that the combination c/n is equal to the same function of ncp in all of them:
c
= f (ncp).
n

(15.13)

Figure 15.6 shows the results of such simulations for many different networks,
and indeed we see that all of the points in the ﬁgure follow, roughly speaking,
a single curve. This is the curve of f ( x ).
562

15.1

|

T HE SMALL - WORLD MODEL

0.5

c=2
c = 10

c
n
0.25

0

0.1

1

10

100

ncp
Figure 15.6: Scaling function for the small-world model. The points show numerical
results for c/n as a function of ncp for the small-world model with a range of parameter values n = 128 to 32 768 and p = 1 × 10−6 to 3 × 10−2 , and two different values of c
as marked. Each point is averaged over 1000 networks with the same parameter values. The points collapse, to a reasonable approximation, onto a single scaling function
f (ncp) in agreement with Eq. (15.13). The dashed curve is the mean-ﬁeld approximation to the scaling function given in Eq. (15.14).

Another approach is to try to calculate f ( x ) approximately in some fashion.
Various approaches have been tried, including series approximations, distributional approximations, and mean-ﬁeld methods. A mean-ﬁeld approximation,
for example, gives the result [251]
)
2
x
.
(15.14)
tanh−1
f (x) = √
2
x
+
4
x + 4x
The methods used to derive this form become exact in the limit of either very
small or very large numbers of shortcuts in the network,5 but in between
around x = 1 they are only approximate. The form of Eq. (15.14) is shown
as the dashed line in Fig. 15.6 and indeed we see that it agrees well with the
5
Note that the number of shortcuts can be large even when the density of shortcuts remains
small, as it must for the scaling form (15.12) to be valid at all.

563

O THER NETWORK MODELS

numerical results at the ends of the range but less well in the middle.
This, however, is enough for us to prove that the small-world model is
indeed a “small world.” Consider Eq. (15.14) for large values of x. Making use
of the standard identity
tanh−1 u = 21 ln
we can write f ( x ) as
f (x) = √

1+u
,
1−u

√

1
x2 + 4x

ln √

1 + 4/x + 1
,
1 + 4/x − 1

(15.15)

(15.16)

and then taking the limit of large x we ﬁnd
f (x) =

ln x
x

(15.17)

for x  1. Substituting this into Eq. (15.12), we then have

=

ln(ncp)
c2 p

(15.18)

for ncp  1. Recalling that ncp is simply twice the number of shortcuts in the
network, this implies that, provided the number of shortcuts in the network is
signiﬁcantly greater than 1, the average distance between vertices will increase
logarithmically with n, i.e., very slowly, for ﬁxed c and p. Thus the number of
vertices in the network can become very large and the value of  will remain
small, which is precisely the phenomenon we call the small-world effect.
Moreover, since only the number of shortcuts, and not the number per vertex, has to be large, the model tells us that the addition of only a small density
of random shortcuts to a large network can produce small-world behavior.
This helps explain why most real-world networks show the small-world effect. Most networks contain long-range connections and have at least some
randomness in them—very few are perfectly regular or have only short-range
connections—so we should not be surprised to see small-world behavior in
almost all cases.
It is important to notice that the small-world model not only shows the
small-world effect, but that it does so at the same time as displaying clustering. Since the number of shortcuts in the network is 12 ncp, we can always
make it much larger than one simply by increasing the size n of the network,
while keeping c and p constant. At the same time, the clustering coefﬁcient,
Eq. (15.7), is independent of n and hence retains its (non-zero) value as n → ∞.
In this limit, therefore, we simultaneously have non-zero clustering and the
564

15.2

|

E XPONENTIAL RANDOM GRAPHS

small-world effect, demonstrating conclusively that the two are not at odds
with one another—it is perfectly possible to have both in the same network at
the same time.
Figure 15.5 shows a plot of the approximate value of  as a function of p
from Eqs. (15.12) and (15.14) for a small-world model with n = 600 vertices
and c = 6, along with the curve for the clustering coefﬁcient of the same model
that we plotted earlier and, as we can see, there is a substantial range of values
of p in which the value of  is low while the value of C is high.
Many other properties and quantities can be calculated for the small-world
model, either analytically or numerically. For a short review of results concerning the model see Ref. [232].

15.2

E XPONENTIAL RANDOM GRAPHS

Many of the networks we observe in the real world exist in only one instantiation, one example that we can study. There’s only one Internet, for instance,
and only one World Wide Web. But is the precise structure of such a network—
the precise pattern of connections in the Internet, say—the only possible structure the network could have? Common sense suggests that it is not. For a start,
the Internet evolves in time, so we see different structures if we look at different times and all of them are by deﬁnition plausible structures for the network.
More importantly, it’s clear that, had circumstances been slightly different, the
Internet could easily have evolved to have a different topology, but one that in
practical terms would probably have worked about as well as the present one.
On the other hand, we can say that the structure of such an alternate Internet would probably have been “similar” to the real Internet, in some sense.
That is, all reasonable choices for the structure of the Internet have some basic
features in common, even if they differ in smaller details. Similar considerations also apply to other types of network, including social networks, biological networks, and information networks.
In some cases the questions we want to answer about a networked system
can be tackled by studying the structure of only a single observed example—
the real Internet for instance. But there are other cases where we would like to
know about the entire set of possible networks that could represent a system. If
we are studying some social process in a social network, for instance, such as
opinion formation or the spread of a disease, we can measure a social network
and then calculate or simulate the effects of the process of interest on that network. More often, however, we would like to know how the process behaves
on social networks generally, rather than on the one particular network we
have measured.
565

O THER NETWORK MODELS

Considerations of this kind lead us to consider ensemble models of networks, an ensemble, in this context, meaning a set of possible networks plus a
probability distribution over them. We have seen some examples of ensemble
models in previous chapters, such as the random graphs of Chapters 12 and 13.
In this section we introduce a beautiful and general formalism for ensemble
network models called the exponential random graph, which includes random
graphs as special cases but also extends to many other network ensembles that
describe all sorts of network phenomena.6
Elegant though this formalism is, however, it also has some serious drawbacks. For reasons that are still not entirely understood, exponential random
graphs fail as models of some common network phenomena such as transitivity (see Section 7.9). We will examine the nature of some of these failures
towards the end of the chapter.
15.2.1

D EFINITION OF THE EXPONENTIAL RANDOM GRAPH

Suppose we want to create an ensemble of networks with a given set of properties, such as a given number of edges or a given value of the clustering coefﬁcient. We can do that, as ordinary random graph models do, by ﬁxing absolutely the values of the quantity or quantities of interest and then drawing
uniformly from the set of all networks with the desired values. For instance,
if we draw uniformly from the set of all graphs with a given number of edges
we have the G (n, m) random graph model of Section 12.1.
In many cases, however, this approach is not exactly what we want. If we
observe that a social network, for example, has a given number of edges, it
does not necessarily mean that every possible social network for the given
community would have exactly that many edges. Had the world evolved
slightly differently, the number of edges might well have turned out differently as well.
Often, therefore, a better approach is to ﬁx the average value of the property or properties of interest. We might ﬁx the average number of edges, for
instance, so that some networks in our ensemble have more than the average
and some have less, but over the whole ensemble we get the right average
value. Moreover, we can arrange that networks with numbers of edges close
to the desired value have higher probabilities in the ensemble than networks
further away, so that the ensemble is dominated by networks with properties
close to the desired ones. The exponential random graph provides an elegant
6
In the sociology literature exponential random graphs are also called p-star models (sometimes
written “p∗ ”).

566

15.2

|

E XPONENTIAL RANDOM GRAPHS

way of achieving these goals.
Suppose, therefore, that we have some set of network measures whose numerical values we want to ﬁx. Examples might include number of edges or
mean degree of a vertex, degrees of individual vertices, number of triangles or
clustering coefﬁcient, and so forth. Let us denote these measures by x1 , x2 , . . .
Now consider the set G of all simple graphs7 with n vertices and let us
deﬁne an ensemble by giving each graph G in the set a probability P( G ), normalized so that
(15.19)
∑ P(G) = 1.

Recall that a simple graph
is a graph with no multiedges and no self-edges—
see Section 6.1.

G ∈G

The mean or expectation value xi of a network measure xi within this ensemble is given by
x i = ∑ P ( G ) x i ( G ),
(15.20)
G ∈G

where xi ( G ) is the value of xi measured on the graph G (e.g., number of edges
in graph G, number of triangles, etc.).
Now, following the prescription outlined above, let us ﬁx the mean value
of each of our measures within our ensemble. If we do this, then Eq. (15.20) is
turned around and becomes a constraint on the probability distribution over
graphs:
(15.21)
∑ P ( G ) xi ( G ) = xi ,
G ∈G

where xi is now a speciﬁed number. We have one such constraint for each
network measure.
The number of measures, however, is typically quite small—maybe only
one or two, maybe hundreds or even thousands, but usually nowhere near the
number of graphs in our ensemble. The number of simple graphs of n vertices is 2n(n−1)/2 , which becomes very large even for relatively modest values
of n. This means that the constraints in Eqs. (15.19) and (15.21) do not specify the probability distribution P( G ) completely. Indeed, they leave an enormous amount of ﬂexibility about the values of P( G ). There are many more
unknowns P( G ) than there are constraints in our equations and hence a wide
range of choices of P( G ) that will satisfy the constraints. How do we choose
between them?
This question, of making the best choice of a probability distribution given
only a relatively small number of constraints on that distribution, is one that
7

One can also deﬁne exponential random graphs models for sets that include non-simple
graphs, but the case considered here of simple graphs is the most commonly studied one.

567

O THER NETWORK MODELS

is familiar to physicists and statisticians, having been studied for over a hundred years since the pioneering work of Willard Gibbs in the latter part of the
nineteenth century. The solution is remarkably simple, although deriving it is
not. It can be shown that the best choice of probability distribution is the one
that maximizes the Gibbs entropy
S = − ∑ P( G ) ln P( G ),

(15.22)

g ∈G

subject to the known constraints.
One may well ask what we mean by “best choice” in this context. The
maximum entropy choice is best in the sense that it makes the minimum assumptions about the distribution other than those imposed upon us by the constraints. There are choices of distribution we could make that would satisfy the
constraints but would effectively make additional assumptions. For instance,
some choices might make a particular graph or graphs highly probable while
other graphs, only slightly different, are given far lower probabilities. These
would be considered “bad” choices in the sense that they assume things about
the ensemble for which we have no supporting evidence. The Gibbs entropy
is precisely a measure of the amount of “assumption” that goes into a particular choice of distribution P( G ), or more precisely it is the amount of “antiassumption” or ignorance, and by maximizing it we minimize unjustiﬁed assumptions as much as possible. The derivation of the formula, Eq. (15.22),
would take us some way away from our central topic of networks, so we will
not go through it here, but the interested reader is encouraged to look for example at the books by Grandy [142] and Cover and Thomas [82].
The maximization of the entropy, subject to the constraints of Eqs. (15.19)
and (15.21), can be achieved by the method of Lagrange multipliers. The optimum is the set of values of the P( G ) that maximizes the quantity




− ∑ P( G ) ln p( G ) − α 1 − ∑ P( G ) − ∑ β i xi − ∑ P( G ) xi ( G ) ,
G ∈G

G ∈G

i

G ∈G

(15.23)
where α and β i are Lagrange multipliers whose values will be determined
shortly. Differentiating with respect to the probability P( G ) of a particular
graph G and setting the result to zero, we then ﬁnd that

− ln P( G ) − 1 + α + ∑ β i xi ( G ) = 0,

(15.24)



P( G ) = exp α − 1 + ∑ β i xi ( G ) ,

(15.25)

i

which implies

i

568

15.2

|

E XPONENTIAL RANDOM GRAPHS

or

e H (G)
,
Z
where Z = e1−α is called the partition function and
P( G ) =

H ( G ) = ∑ β i xi ( G )

(15.26)

(15.27)

i

is the graph Hamiltonian.8
It remains to ﬁx the values of Z and β i (for all i). Z is ﬁxed by the normalization condition, Eq. (15.19), which requires that
1

∑ P(G) = Z ∑ eH(G) = 1,

(15.28)

Z = ∑ e H (G) .

(15.29)

G ∈G

and hence

G ∈G

G ∈G

There is no equivalent general formula for the values of the β i . They are calculated by substituting Eq. (15.26) into Eq. (15.21) and solving the resulting set of
non-linear simultaneous equations, but the particular solution depends on the
form of the Hamiltonian. We will see some examples of the process shortly.
There are some cases in which we are interested in an exponential random
graph only as a class of models. That is, we are concerned not as much with
the model’s properties for a particular set of values { β i } as with the behavior
of the model in general. In such cases we can regard the β i as free parameters controlling the structure of the network, much as the edge probability p
controls the structure of the network in a Poisson random graph.
15.2.2

E XPECTATION VALUES

Once we have determined the probability distribution P( G ) over graphs, we
can use it to calculate estimates of quantities of interest within the ensemble.
The most common objects of interest are expectation values (i.e., averages) of
quantities, the expectation value of a quantity y in the ensemble being given
by
1
y = ∑ P( G ) y( G ) =
(15.30)
∑ e H ( G ) y ( G ).
Z
G ∈G
G ∈G
8

Sometimes the graph Hamiltonian is deﬁned to be minus this quantity and a corresponding
minus sign is introduced in Eq. (15.26). This is by analogy with similar quantities in statistical
physics, where the Hamiltonian is an energy function and lower energies correspond to higher
probabilities. In studies of networks, however, the deﬁnitions are most commonly as given here.

569

O THER NETWORK MODELS

In effect, this calculation gives us a “best estimate” of the value of y. That is,
given a certain set of observations or constraints on our network, embodied in
Eq. (15.21), but no other information about the network structure, we can calculate a best-guess ensemble of networks subject to those constraints and then
use that ensemble to calculate the expectation value of the quantity y, giving
us a best guess at the value of that quantity given only the constraints. Thus
the exponential random graph model enables us to answer questions of the
type, “If I know certain things, A, B, and C, about a network, what is my best
estimate of some other thing D?” For instance, if I know the average degree of
a vertex in a network, what is my best estimate of the degree distribution? Or
the clustering coefﬁcient? The exponential random graph gives a rigorous and
principled answer to questions of this kind.
An interesting special case arises when the quantity y that we want to estimate is itself one of the set of network measures xi that we used to specify
our ensemble in the ﬁrst place. You might ask why we would want to do
this, given that, by hypothesis, we already know the expectation values of
these quantities—they are precisely the quantities that we used as inputs to
our model in the ﬁrst place. The answer is that we still need to ﬁx the parameters β i and we do this by calculating the expectation values xi for given β i
and then varying the β i until the xi take the desired values.
The value of xi within the ensemble is given by
xi =

=

1
1 ∂
e∑i β i xi ( G ) x i ( G ) =
e∑i β i xi ( G )
∑
Z G∑
Z
∂β
i G ∈G
∈G
1 ∂Z
∂ ln Z
=
,
∂β i
Z ∂β i

(15.31)

where we have made use of Eq. (15.29). The quantity
F = ln Z

(15.32)

is called the free energy of the ensemble and Eq. (15.31) can be written simply
as
∂F
xi =
.
(15.33)
∂β i
To calculate xi , therefore, all we need to do is calculate the partition function Z, from it evaluate the free energy, and then differentiate.
Calculating expectation values for other quantities is harder, and indeed
this is one of the main practical problems with exponential random graphs:
the actual calculations of quantities of interest can be very difﬁcult and in many
cases can only be performed using numerical methods. If we are clever, however, we can still use the machinery embodied in Eq. (15.33) in some cases. The
570

15.2

|

E XPONENTIAL RANDOM GRAPHS

trick is to introduce an extra term involving y into our Hamiltonian thus:
H ( G ) = ∑ β i xi ( G ) + μy( G ).

(15.34)

i

If we set the parameter μ to zero, then the answers we get out of our calculations will be unchanged from before and hence will still be correct. However,
we can now differentiate with respect to μ (at the point μ = 0) to calculate the
expectation value of y:
"
∂F ""
y =
.
(15.35)
∂μ "μ=0
This allows us again to calculate just the one sum, the partition function Z,
and from it calculate the free energy and thus the average y . The catch is
that we have to calculate Z for general (non-zero) values of μ so that we can
perform the derivative—we only set μ to zero at the end of the calculation. In
many cases it can be quite difﬁcult to calculate Z in this way, which makes the
exponential random graph, though elegant, technically tricky.
15.2.3

S IMPLE EXAMPLES

Probably the simplest example of an exponential random graph model is the
model in which we ﬁx the expected number of edges in an undirected network and nothing else. Following the formalism above, this gives us a graph
Hamiltonian, Eq. (15.27), of H = βm, where m is the number of edges. Then
individual graphs appear in the ensemble with probability
eβm
,
Z

(15.36)

Z = ∑ eβm .

(15.37)

P( G ) =
where

G

Thus higher values of β in this model correspond to denser networks, those
with more edges.
To make further progress with this model we need a way to perform the
sum over graphs G in Eq. (15.37). The standard way to achieve this is to sum
over possible values of the elements Aij of the adjacency matrix. In this case
we are considering undirected graphs, so we need to specify only the matrix
elements above the diagonal or those below it, but not both, since the matrix
is symmetric. And since we are restricting ourselves to simple graphs the only
allowed values of Aij are 0 and 1 if i = j and Aii = 0.

571

O THER NETWORK MODELS

We can write the number of edges m in terms of the adjacency matrix thus:
m = ∑ Aij ,

(15.38)

i< j

and hence the partition function is
Z = ∑ exp β ∑ Aij
i< j

{ Aij }

= ∑ ∏e

βAij

= 1+e

n
β (2)



∑ eβA = ∏ 1 + eβ
ij

i < j Aij =0,1

{ Aij } i < j



=∏



i< j

,

(15.39)

where the notation { Aij } indicates summation over all allowed values of the
adjacency matrix.
From this expression we can calculate the free energy:9
F = ln Z =



n
ln 1 + eβ ,
2

(15.40)

and thus, using Eq. (15.33), the average number of edges in the model is
m =

∂F
=
∂β

1
n
.
2 1 + e− β

(15.41)

If we have a particular desired value that m should take, we can now achieve
it by rearranging this expression to ﬁnd the appropriate value for the Lagrange
multiplier β thus:
m
.
(15.42)
β = ln n
(2) − m
We can also calculate, for example, the probability pvw that there will be an
edge between a particular pair of vertices v, w, which is given by the average
of the corresponding element Avw of the adjacency matrix. From Eq. (15.30) we
9
Those familiar with free energy in its original thermodynamic context may ﬁnd this expression odd because it varies with network size as n2 to leading order. In thermodynamic systems, by
contrast, free energy is always directly proportional to system size. However the degrees of freedom or “particles” in our network are really the edges (or absence of edges) between vertex pairs,
not the vertices themselves, and there are (n2 ) vertex pairs, which is why Eq. (15.40) is proportional
to (n2 ).

572

15.2

|

E XPONENTIAL RANDOM GRAPHS

have
pvw = Avw =

1
Avw exp β ∑ Aij
Z {∑
i< j
A }
ij

=

∑ Avw =0,1 Avw eβAvw
∑ Avw =0,1 eβAvw

1
m
=
= n .
−
β
1+e
(2)

(15.43)

Thus the probability of an edge between a given pair of vertices is the same
in this model for every pair. In other words, this model is just the ordinary
Poisson random graph of Chapter 12 with p = m /(n2 ). The random graph
can thus be regarded as a special case of the more general exponential random
graph model.
The random graph, as we saw in Chapter 12, is in many respects a poor
model of real-world networks. In particular, its degree distribution is Poissonian and hence very different from the highly right-skewed degree distributions
in most observed networks. It is natural to ask, therefore, whether we can
make an exponential random graph model that has a more realistic degree distribution. There are a number of ways of doing this, but one of the simplest
is to create a model in which we specify the expected degree of each vertex
within the ensemble. That is, we create an exponential random graph model
with the graph Hamiltonian
(15.44)
H = ∑ βi ki ,
i

where k i is the degree of vertex i. Note that we do not also need a term that ﬁxes
the average number of edges in this model, since ﬁxing the average degree of
each vertex already ﬁxes the average number of edges (see Eq. (6.20)).
We can write the degrees in terms of the adjacency matrix as
k i = ∑ Aij ,

(15.45)

j

and hence write the Hamiltonian as
H = ∑ β i Aij
ij

= ∑ β i Aij + ∑ β i Aij = ∑ β i Aij + ∑ β j A ji
i< j

i> j

= ∑( β i + β j ) Aij ,

i< j

i< j

(15.46)

i< j

where in the second line we have interchanged the dummy variables i and
j and in the third line we have made use of A ji = Aij . We have also again
assumed that there are no self-edges, so that Aii = 0 for all i.
573

O THER NETWORK MODELS

Now we can write the partition function as
Z = ∑ exp
{ Aij }

∑( βi + β j ) Aij
i< j

=∏



= ∏ 1 + eβi + β j ,

∑ e( β + β ) A
i

j

ij

i < j Aij =0,1

(15.47)

i< j

and the probability of an edge between vertices u and v is
pvw = Avw =

1
Avw exp
Z {∑
A }
ij

∑( βi + β j ) Aij
i< j

e( βv + βw ) Avw

∑ Avw =0,1 Avw
∑ Avw =0,1 e( βv + βw ) Avw
1
=
.
−(
1 + e βv +βw )

=

(15.48)

Thus edges in this model now have different probabilities. Of particular interest is the case of a sparse network, one in which the probability of any individual edge is small, pvw  1. (As we have seen throughout this book, most
real-world networks are very sparse.) To achieve this, we need e−( βv + βw )  1
in Eq. (15.48), which means that
pvw ≃ eβv eβw .

(15.49)

In other words, in a sparse network the probability of an edge is simply a
product of two terms, one for each of the vertices at either end of the edge.
Moreover, it turns out that these terms are simply related to the expected degrees of the vertices. The expected degree of vertex v, for instance, is just the
sum of the expected number pvw of edges between it and every other vertex:
k v = ∑ pvw = eβv ∑ eβw ,

(15.50)

eβv = C k v ,

(15.51)

w

so that

w

where C = 1/ ∑w eβw .
Thus pvw = C2 k v k w in this model, and since we require that ∑vw pvw =
∑v k v = 2 m (see Eqs. (6.19) and (6.20)), it’s then straightforward to show
that
kv kw
pvw =
.
(15.52)
2 m

574

15.2

|

E XPONENTIAL RANDOM GRAPHS

Once again, this is a model we have seen before. It is the random graph
model that we studied in Section 13.2.2 in which we specify the expected degrees of vertices (rather than their exact degrees, as in the more common conﬁguration model).
We can also create exponential random graph models of directed networks.
For instance, we can make a model in which the constrained quantities are the
expected values of the in- and out-degrees of a directed network by using a
Hamiltonian of the form
in
out out
H = ∑ βin
i ki + ∑ β j k j .
i

(15.53)

j

out
= ∑i(= j) Aij , we have
Writing kin
i = ∑ j(=i ) Aij and k j


out
Aij .
H = ∑ βin
i + βj

(15.54)

i= j

The ensemble is now a distribution over (simple) directed graphs, which
means that the adjacency matrix is in general asymmetric and each element
Aij can take its own value. Thus the partition function is


 in

in
out
out
Z = ∑ exp ∑ β i + β j Aij = ∏ ∑ e( βi + β j ) Aij
{ Aij }



= ∏ 1+e

i= j

out
βin
i +β j

i = j Aij =0,1


,

(15.55)

i= j

and the probability of an edge from w to v is
pvw = Avw =

1
Avw exp
Z {∑
A }
ij



i= j

out
( βin
v + β w ) Avw

∑ Avw =0,1 Avw e
in
out
∑ Avw =0,1 e( βv + βw ) Avw
1
=
in
out .
−(
1 + e βv +βw )

=



Aij
∑ βini + βout
j

(15.56)

In the case of a sparse network this becomes
pvw ≃ eβv eβw =
in

out

kin
kout
v
w
,
m

(15.57)

by an argument similar to the one leading to Eq. (15.52). This expression is
similar to that for the corresponding quantity in the directed version of the
conﬁguration model (see page 475), and indeed the model above is the equivalent for the directed case of the random graph in which we specify the expected
degrees of the vertices rather than the exact degrees.
575

O THER NETWORK MODELS

15.2.4

R ECIPROCITY MODEL

We now turn to some more complex examples of exponential random graphs,
ones that are not equivalent to models we have already seen. The ﬁrst example we look at is the “reciprocity model” proposed by Holland and Leinhardt [157].
As discussed in Section 7.10, many directed networks exhibit the phenomenon of reciprocity, whereby edges between vertices tend to be reciprocated.
If I say that you are my friend, for example, then it is likely that you will also
say that I am your friend. We can create an exponential random graph model
of reciprocity by ﬁxing the expected number of reciprocated edges in the network. The number of reciprocated edges, mr is given by mr = ∑i= j Aij A ji , so
we need to introduce a term proportional to this into our graph Hamiltonian.
We can also introduce other terms, such as terms to ﬁx the expected degrees of
vertices as in the previous section. Here let us look the simple case where we
ﬁx only the number of edges as we did with the Poisson random graph. The
number of edges in a simple directed network is given by m = ∑i= j Aij and
hence our Hamiltonian takes the form
H = β ∑ Aij + γ ∑ Aij A ji
i= j

i= j




= ∑ β Aij + A ji + 2γAij A ji ,

(15.58)

i< j

where β and γ are free parameters that can be varied to create the desired
numbers of edges and reciprocated edges. This is actually a simpliﬁed version
of the model proposed by Holland and Leinhardt, but it will serve our purpose
nicely, and it is easy to solve.
The partition function for this model is
Z = ∑ exp
{ Aij }

=∏

∑





∑ β Aij + A ji + 2γAij A ji
i< j



∑ eβ( A + A )+2γA A = ∏ 1 + 2eβ + e2(β+γ)
ij

i < j Aij =0,1 A ji =0,1



= 1 + 2eβ + e2( β+γ)

(n2 )

ji

ij



ji

i< j

.

(15.59)

The free energy for the network is then
F=

576



n
ln 1 + 2eβ + e2( β+γ) ,
2

(15.60)

15.2

|

E XPONENTIAL RANDOM GRAPHS

and, applying Eq. (15.33), we ﬁnd that the expected numbers of edges and
reciprocated edges are
m =

∂F
eβ + e2( β+γ)
= n ( n − 1)
,
∂β
1 + 2eβ + e2( β+γ)

mr =

∂F
e2( β+γ)
= n ( n − 1)
.
∂γ
1 + 2eβ + e2( β+γ)

(15.61)

In Section 7.10 we deﬁned the reciprocity r of a directed network to be the
fraction of edges that are reciprocated, which in our model is given by the
ratio
mr
1
r=
.
(15.62)
=
−(
m
1 + e β+2γ)
Thus we can control both the number of edges and the level of reciprocity in
the network by suitable choices of β and γ.
15.2.5

T WO - STAR MODEL

After ordinary random graphs, probably the simplest undirected exponential
random graph is the so-called two-star model. In this model one speciﬁes the
expected number m of edges in the network and the expected number m2
of two-stars, meaning a vertex connected by edges to two others (which we
called a “connected triple” in other circumstances—see Eq. (7.41) on page 200).
Varying the number of two-stars allows us to control the extent to which edges
in the network “stick together,” meaning they share common vertices. If we
ﬁx only the number of edges in a network, then those edges may stick together
or they may not, but if we also give the network a lot of two-stars, then the
edges have to stick together to make the required number of two-stars. Thus
the two-star model allows us to control the “clumpiness” of the network, the
extent to which the edges gather together in clumps or are distributed more
randomly.
The number of two-stars in a network is
m2 = ∑ ∑

∑ Aij Aik = 12 ∑ Aij ∑ ( Aik + A jk ),
i= j

i j(=i ) k (=i,j)

A two-star is a vertex connected by edges to two
other vertices.

(15.63)

k (=i,j)

and the number of edges is, as before, m = ∑i< j Aij = 12 ∑i= j Aij . Thus the
Hamiltonian is
H = 12 β ∑ Aij + 12 γ ∑ Aij
i= j

= 12



i= j

∑ ( Aik + A jk )

k (=i,j)



∑ Aij β + γ ∑ ( Aik + A jk ) ,
i= j

(15.64)

k (=i,j)

577

O THER NETWORK MODELS

We encountered mean-ﬁeld
theory brieﬂy earlier in
the chapter, in our study
of the small-world model,
though we did not elaborate on it there.
See
Eq. (15.14) and the associated discussion.

where β and γ are our two parameters.
We can solve this model using mean-ﬁeld theory, a technique borrowed from
statistical physics. We note that the term ∑k(=i,j) Aik is simply the number of
edges attached to vertex i, excluding any edge between i and j. All vertex
pairs are equivalent in this model—vertices have no individual properties to
distinguish them—so the mean probability Aij of an edge between any pair
is the same. If we denote this probability by p then the expected value of the
term above is just
*
+
(15.65)
∑ Aik = ∑ Aik = ∑ p = (n − 2) p.
k (=i,j)

k (=i,j)

k (=i,j)

But, assuming that the network is large, this is, to a good approximation,
just np, which is the mean degree of a vertex.
The mean-ﬁeld approach consists of replacing the actual term in the Hamiltonian with the expected value np. We also make the same replacement for
the term ∑k(=i,j) A jk . These replacements are a good approximation so long
as np  1 since for large values of np the statistical variation from vertex to
vertex around the expected value becomes negligible. If the value of p is kept
ﬁxed as we make our network larger then np will always be large in the limit
n → ∞. Thus, in the limit of large network size, this mean-ﬁeld approximation
is a good one.
In this large-n regime, making the replacement described above, we have




H = 12 β + 2γnp ∑ Aij = β + 2γnp m,

(15.66)

i= j

where m is the number of edges as before.
Now, however, this is the same as the Hamiltonian for the ordinary Poisson
random graph in Section 15.2.3, except for the replacement β → β + 2γnp, so
we can immediately write down the partition function and other quantities using the results of that section. In particular, Eq. (15.41) tells us that the average
number of edges in the network will be
m =

n
1
.
2 1 + e−( β+2γnp)

(15.67)

But the average number of edges is related to the mean probability of an edge
by m = (n2 ) p and hence
p=

578

m
1
= 12 tanh( 12 β + γnp) + 1 .
n =
−(
(2)
1 + e β+2γnp)

(15.68)

15.2

|

E XPONENTIAL RANDOM GRAPHS

This gives us a self-consistent equation that we can solve to ﬁnd p as a function of the parameters β and γ, and once we have p we can solve for other
properties of the network by treating it as a normal Poisson random graph.
For convenience in solving for p, let us deﬁne B = 12 β and C = 12 γn so that
Eq. (15.68) becomes
(15.69)
p = 21 [tanh( B + 2Cp) + 1].
There is no known closed-form solution for this equation in general, but we
can visualize the solution easily enough using a graphical method. If we make
plots of the lines y = p and y = 12 [tanh( B + 2Cp) + 1] as functions of p on the
same axes, they will intersect at the solution (or solutions) of Eq. (15.69). Three
such plots are shown in Fig. 15.7 for different choices of the parameters.
Consider ﬁrst panel (a), which shows the curve of y = 21 [tanh( B + 2Cp) + 1]
for C = 21 and three different values of B (solid lines). Varying B merely
shifts the entire curve horizontally without changing its overall shape. For
each curve there is a single point of intersection with the line y = p, indicated
by a small circle. As B is varied this intersection point moves smoothly between high and low values of p. Thus in this regime we can tune the density of
the network to any desired value by varying the parameter B (or equivalently
the parameter β = 2B).
Now take a look at the last panel in Fig. 15.7, panel (c), which shows curves
for C = 32 and again three difference values of B. Again varying B shifts the
curve horizontally, but now there is an important difference. Because of the
higher value of C, the shape of the curve has changed. It is steeper in the middle than it was previously and as a result it is now possible at suitable values
of B for the curve to intersect with the line y = p not just in one place but in
three different places. In this regime there are three different possible solutions
for p for the same values of the parameters. In fact it turns out that the middle
solution is unphysical and only the two outer solutions are realized in practice. These two, however, correspond to very different networks. One has very
high density with many edges while the other is very sparse with few edges.
Yet both solutions are real. If one were to simulate the two-star model on a
computer, generating networks at random according to the model prescription, one would in this regime sometimes ﬁnd a high-density network and
sometimes a low-density one for the same parameter values, and one would
not be able to predict in advance which would occur.
This peculiar behavior is called spontaneous symmetry breaking. It is a behavior well known to physicists, who study it in condensed matter physics, where
it gives rise to the phenomenon of ferromagnetism, and in particle physics,
where it gives rise to the phenomenon of particle mass. In network models,

579

O THER NETWORK MODELS

(a)

1

y
0.5

-0.5

0

0.5

1

1.5

p
(b)

1

y
0.5

-0.5

0

0.5

1

1.5

p
(c)

1

y
0.5

-0.5

0

0.5

1

1.5

p

Figure 15.7: Graphical solutions of the properties of the two-star model. Curves for
y = 12 [tanh( B + 2Cp) + 1] for varying values of B and (a) C = 12 , (b) C = 1, and
(c) C = 32 . The points where the curves intersect the line y = p (dotted line in each
panel) are solutions of Eq. (15.69).

580

15.2

|

E XPONENTIAL RANDOM GRAPHS

1

Coexistence region

C=1

C = 1.5

p
0.5

C = 0.5

-2

-1

0

B
Figure 15.8: Edge probability in the two-star model. Plot of solutions of Eq. (15.69) for
the edge probability p as a function of B for the same three values of C as were used
in the three panels of Fig. 15.7. Note that there are two possible solutions within the
coexistence region for the case C = 23 , and more importantly that for this case there is
no value of B that gives any intermediate value of p. For C = 32 the only possible values
of p lie either above about 0.8 or below about 0.2.

however, it is primarily an annoyance, and sometimes a grave weakness. A
model that can produce two radically different classes of network for the same
values of the model parameters is, at the least, troubling. But worse, for values
of C as in Fig. 15.7c there some values of p that are simply impossible to reach.
Figure 15.8 shows the values of the solutions for p for the cases depicted in
Fig. 15.7 as a function of B and, as we have said, p is a smooth function of B
for the C = 12 case, so that any value of p is reachable. For the case of C = 32 ,
however, there are only very high and very low values of p. There is no value
of B that produces intermediate values of p and hence no way in this model
to generate graphs with such intermediate values if C = 32 . If we wanted to
generate a graph with p = 12 , for instance, there is simply no way to do it in
the two-star model when C = 32 .
This is a fundamental problem with the two-star model and with many

581

O THER NETWORK MODELS

other exponential random graphs. We will see in the following section an example of an exponential random graph where this kind of behavior renders
the model essentially useless as a model of a network.
Panel (b) of Fig. 15.7 shows the borderline case that falls between panels (a)
and (c). When the parameter C is such that the curve of y = 12 [tanh( B +
2Cp) + 1] has gradient exactly one at its steepest point then we are right on
the boundary between the two different types of behavior. In the present case,
this happens at C = 1. If C is increased any further beyond this point, spontaneous symmetry breaking occurs. Below it, there is no symmetry breaking. In
the physics jargon this transition is called a continuous phase transition and the
point at which it occurs is called a critical point.10
Note that, even when the value of C is greater than 1 and we are above
the critical point, spontaneous symmetry breaking still only occurs within a
certain range of values of B, as Fig. 15.7c shows. If B is either too small or
too large then there is only one solution to Eq. (15.69) (the two outer curves
in Fig. 15.7c). The portion of parameter space where there are two solutions
is called the coexistence region. The boundaries of the coexistence region correspond to the values of B such that the curve is tangent to the line y = p, as
shown in Fig. 15.9. Put another way, we are on the boundary when the point
at which the curve has gradient one falls on the line y = p. The gradient of
y = 12 [tanh( B + 2Cp) + 1] is given by
dy
= C sech2 ( B + 2Cp),
dp

(15.70)

and setting this equal to one and making use of sech2 x = 1 − tanh2 x, we have
1 − tanh2 ( B + 2Cp) =

1
.
C

(15.71)

But p is also a solution of Eq. (15.69), so tanh( B + 2Cp) = 2p − 1 and Eq. (15.71)
becomes 1 − (2p − 1)2 = 1/C, or
p2 − p +

1
= 0,
4C

(15.72)

10
We encountered continuous phase transitions previously in Chapters 12 and 13—the point
at which the giant component ﬁrst appears in a random graph is a continuous phase transition,
although admittedly it is not obvious that there is a connection between the behavior of the giant
component and that seen in Fig. 15.7. The study of phase transitions is an intriguing and beautiful
branch of physics that has important implications in areas as diverse as superconductivity, elementary particles, and the origin of the universe. Readers interested in learning more are encouraged
to consult, for example, the book by Yeomans [331].

582

15.2

|

E XPONENTIAL RANDOM GRAPHS

1
y

0.5

0

-0.5

1

0.5

1.5
p

Figure 15.9: The boundaries of the coexistence region in the two-star model. The
ends of the coexistence region for a given value of C correspond to those values of B
that place the curve y = 12 [tanh( B + 2CP) + 1] precisely tangent to the line y = p.

which has solutions
p = 12 1 ±

√

1 − 1/C .

(15.73)

Rearranging Eq. (15.69) for B and substituting for p we then ﬁnd that
B = tanh−1 (2p − 1) − 2Cp
√
√
= ± tanh−1 1 − 1/C − C 1 ± 1 − 1/C ,

(15.74)

where we either take both the plus signs or both the minus signs.
Figure 15.10 shows a plot of this result in the form of a phase diagram of the
two-star model showing the different regimes or “phases” of the model as a
function of its two parameters. The two lines corresponding to the solutions
in Eq. (15.74) form the boundaries of the coexistence region. Inside this region
there are values of p than cannot be reached for any choice of parameters.
Outside it, we can generate networks with any value of p.
15.2.6

S TRAUSS ’ S MODEL OF TRANSITIVE NETWORKS

As our last example in this chapter, we look at another exponential random
graph model that shows spontaneous symmetry breaking, the transitive network model of Strauss [306]. Where the two-star model is something of a toy
model—useful for demonstrating the mathematics, but not especially important in practice—the model of this section is one of some importance, and the
583

O THER NETWORK MODELS

C
10

1

100

Low density

−1

B

Coexistence
region

−10
High density

−100

Figure 15.10: Phase diagram of the two-star model. The phases of the two-star model
as a function of the parameters B and C. Density generally increases as B becomes more
negative and for C > 1 there is a coexistence region at intermediate values of B in which
spontaneous symmetry breaking occurs. Notice that the scales are logarithmic and that
B < 0. (There are no other phases for positive B or negative C, so these values are
not shown.) Adapted from Park and Newman [260]. Original ﬁgure Copyright 2009
American Physical Society. Reproduced with permission.

fact that it shows pathological behavior with the variation of its parameters is
a puzzle and a signiﬁcant hindrance to progress, one that has not, at least at
the time of writing, been fully resolved.
Strauss’s model is a model of a simple undirected network that shows
clustering or transitivity, the propensity for triangles to form in the network,
which, as discussed in Section 7.9, is a common phenomenon, particularly in
social networks. In this model one speciﬁes the expected number of edges m
in the network and also the expected number of triangles m3 . The number of
triangles can be expressed in terms of the elements of the adjacency matrix as
m3 = 13 ∑ Aij A jk Aki ,
ijk

584

(15.75)

15.2

|

E XPONENTIAL RANDOM GRAPHS

where the factor of 13 accounts for the fact that each triangle in the network
appears three times in the sum. The number of edges is just m = 12 ∑ij Aij .
(For simplicity of notation we have included the diagonal terms in these sums.
They are zero since the network is simple, so it makes no difference whether
we include them or not.) Thus the graph Hamiltonian is
H = 12 β ∑ Aij + 13 γ ∑ Aij A jk Aki .
ij

(15.76)

ijk

This model, like the two-star model, can be solved exactly in the limit of
large network size using a mean-ﬁeld technique. The details of the calculation
are more complicated than for the two-star model. As well as replacing sums
of the form ∑k Aik by their average value, we also make a similar replacement
for sums of the form ∑k A jk Aki , and the values of these two quantities are expressed self-consistently in terms of each other. We will not go into the details
of the calculation here—the interested reader is invited to consult Ref. [261].
The end result, however, is similar to that for the two-star model: there is a
phase transition in the model beyond which the system develops a coexistence
region where there are two distinct solutions to the equations, both of which
are realized in simulations of the model. One solution corresponds to a network of high density and the other a network of low density but, as in the
two-star case, there is in this regime no choice of model parameters that will
give networks of medium density and as a result there is a wide range of networks that simply cannot be generated by this model. If one were to observe a
network in the real world whose properties fell within this unattainable range,
then Strauss’s model could not be used to mimic its properties.
This is a fundamental problem with Strauss’s model and with many similar exponential random graphs. The entire point of a model such as this one
is to create model networks with properties similar to those seen in real networks. Moreover, this model in particular and exponential random graphs in
general seem at ﬁrst sight to be a very logical approach to the creation of such
networks: from a statistical point of view the construction of the model using a maximum entropy ensemble is natural and should, one might imagine,
give sensible answers. The fact that it does not is a disturbing ﬁnding that is
still not properly understood. That there are ranges of network properties that
simply cannot be created using the model, while at the same time real-world
networks can and do display properties in these ranges, indicates that there is
a fundamental ﬂaw or gap in our reasoning, or perhaps in our understand of
the nature of networks themselves. Strauss himself was already aware of these
issues when he proposed his model in the 1980s, and the fact that they are still
unresolved indicates that there are some difﬁcult issues here.
585

O THER NETWORK MODELS

P ROBLEMS
15.1 Consider the following variation on the small-world model. Again we have a
ring of n vertices in which each is connected to its c nearest neighbors, where c is even.
And again a shortcut is added to the network with probability p for each edge around
the ring, but now instead of connecting random vertex pairs, each shortcut connects a
random vertex to the same single hub vertex in the center of the network:

This model could be, for example, a model of a (one-dimensional) world connected
together by a bus or train (the central vertex) whose stops are represented by the shortcuts.
Show that the mean distance between two vertices in this network in the limit of
large n is  = 2(c2 p + 1)/c2 p (which is a constant, independent of n).
15.2 One of the difﬁculties with the original small-world model depicted in Fig. 15.3a
is that vertices can become disconnected from the rest of the network by the rewiring
process. For instance, a single vertex can become disconnected if all of its incident edges
around the ring are rewired and it has no shortcuts.
a) Show that the probability of this happening to any given vertex is [ pe− p ]c .
b) Hence, how large must the network be before we expect that one vertex will be
disconnected, if c = 6 and p = 0.01?
15.3 Consider an undirected exponential random graph model in which the Hamiltonian takes the form H = ∑i< j Θij Aij , where the Θij are parameters we control.
a) Derive an expression for the free energy.
b) Hence show that the probability of an edge between vertices i and j is 1/(eΘij + 1).
15.4 Consider the mean-ﬁeld solution of the two-star model, as described in Section 15.2.5 for the case β = −γn, or equivalently B = −C in the notation of Eq. (15.69).
Let us deﬁne an order parameter x = 2p − 1.
a) Show that the order parameter obeys the equation x = tanh Cx.

586

P ROBLEMS

b) Sketch the solutions to this equation as a function of C. Argue that the order
parameter must be zero on one side of the phase transition at C = 1 but takes
non-zero values on the other.

587

This page intentionally left blank

PART V
P ROCESSES ON NETWORKS

589

This page intentionally left blank

C HAPTER 16

P ERCOLATION AND NETWORK RESILIENCE
A discussion of one of the simplest of processes taking
place on networks, percolation, and its use as a model of
network resilience

T

HE ULTIMATE goal in studying networks is to better understand the be-

havior of the systems networks represent. For instance, we study the
structure of the Internet to understand better how Internet trafﬁc ﬂows or why
communications protocols function the way they do or how we could change
or rearrange the network to make it perform better. We study biochemical
networks like metabolic networks because we hope they will lead to an understanding of the complex chemical processes taking place in the cell or perhaps
to algorithmic tools that can help us extract biological insights from the large
volumes of data generated by modern laboratory techniques.
Studies of the structure of networks, such as those discussed in the previous
chapters of this book, are only one step towards this kind of understanding.
Another important step is to make the connection between network structure
and function: once we have measured and quantiﬁed the structure of a network, how do we turn the results into predictions or conclusions about how
the overall system will behave? Unfortunately, progress in this area has been
far slower than progress on characterizing structure, which is why a majority of this book is devoted to the discussion of structure. Nonetheless, there
are some areas in which substantial progress has been made and illuminating
theories and models developed. Among these are studies of network failure
and resilience, of dynamical systems on networks, and of epidemic and other
spreading processes. The remaining chapters of this book are devoted to a
description of our current understanding of these and similar network processes. We begin in this chapter with a study of one of the simplest of network
processes, percolation, which leads to an elegant theory of the robustness of
591

P ERCOLATION AND NETWORK RESILIENCE

networked systems to the failure of their components.

16.1

P ERCOLATION

Imagine taking a network and removing some fraction of its vertices, along
with the edges connected to those vertices—see Fig. 16.1. This process is called
percolation (or, more precisely, site percolation—see below), and can be used as a
model of a variety of real-world phenomena. The failure of routers on the Internet, for instance, can be formally represented by removing the corresponding vertices and their attached edges from a network representation of the Internet. In fact, about 3% of the routers on the Internet are non-functional for
one reason or another at any one time, and it is a question of some practical interest what effect this will have on the performance of the network. The theory
of percolation processes can help us answer this question.
Another example of a percolation phenomenon is the vaccination or immunization of individuals against the spread of disease. As discussed in Chapter 1, and at greater length in Chapter 17, diseases spread through populations
over the networks of contacts between individuals. But if an individual is vaccinated against a disease and therefore cannot catch it, then that individual
does not contribute to the spread of the disease. Of course, the individual is
still present in the network, but, from the point of view of the spread of the
disease, might as well be absent, and hence the vaccination process can again
be formally represented by removing vertices.
One can see immediately that percolation processes can give rise to some
interesting behaviors. The vaccination of an individual in a population, for
example, not only prevents that individual from becoming infected but also
prevents them from infecting others, and so has a “knock-on” effect in which
the beneﬁt of vaccinating one individual is felt by more than one. As we will
show, this knock-on effect means that in some cases the vaccination of a relatively small fraction of the population can effectively prevent the spread of
disease to anyone, an outcome known as herd immunity.
Similar effects crop up in our Internet example, although in that case they
are usually undesirable. The removal or failure of a single router on the Internet prevents that router from receiving data, but also prevents data from reaching others via the failed one, forcing trafﬁc to take another route—possibly
longer or more congested—or even cutting off some portions of the network
altogether. One of the goals of percolation theory on networks is to understand
how the knock-on effects of vertex removal or failure affect the network as a
whole.
Sometimes it is not the vertices in the network that fail but the edges. For
592

16.1

(a) φ = 1

(b) φ = 0.7

(c) φ = 0.3

(d) φ = 0

|

P ERCOLATION

Figure 16.1: Percolation. A depiction of the site percolation process on a small network
for various values of the occupation probability φ. Gray denotes vertices that have
been removed, along with their associated edges, and black denotes those that are still
present. The networks in panels (a) and (b) are above the percolation threshold while
those in panels (c) and (d) are below it.

instance, communication lines on the Internet can fail, disconnecting routers
from one another, even though the routers themselves are still functioning perfectly. Phenomena like this can be modeled using a slightly different percolation process in which edges rather than vertices are removed from the appropriate network. If we need to distinguish between the two types of percolation
process we could refer to them as vertex percolation on the one hand and edge
percolation on the other, but in fact they are more commonly called site percolation and bond percolation, a nomenclature that derives from studies of percola-

593

P ERCOLATION AND NETWORK RESILIENCE

tion on low-dimensional lattices in physics and mathematics.1 In this chapter
we will focus principally on site percolation (i.e., removal of vertices) but bond
percolation (removal of edges) will become important in Chapter 17 when we
look at epidemic processes.
There is more than one way in which vertices can be removed from a network. In the simplest case they could be removed purely at random: we could
for example take away some speciﬁed fraction of the vertices chosen uniformly
at random from the entire network. This is the most commonly studied form
of site percolation, and indeed for many people the word “percolation” refers
speciﬁcally to this particular process. But there are many other ways in which
vertices could be removed and “percolation” as used in this chapter is considered to include all of them. One popular alternative removal scheme is
to remove vertices according to their degree in some fashion. For instance,
we could remove vertices in order of degree from highest to lowest, an approach that turns out to make an effective vaccination strategy for the control
of disease. Other approaches have also been considered occasionally, such as
removing vertices with high betweenness centrality. Let us begin, however, by
examining the simplest case of uniformly random removal.

16.2

U NIFORM RANDOM REMOVAL OF VERTICES

Consider a network in which some fraction of the vertices, selected uniformly
at random, are removed. As discussed above, in many real-world situations
“removal” does not imply actual physical removal of the vertices, but only that
they are non-functional in some way, such as routers that have failed on the
Internet, or vaccinated individuals in a network of disease-causing contacts.
Traditionally the percolation process is parametrized by a probability φ,
which is probability that a vertex is present or functioning in the network.
In the parlance of percolation theory, one says that the functional vertices are
occupied and φ is called the occupation probability. Thus φ = 1 indicates that
all vertices in the network are occupied (i.e., no vertices have been removed)
and φ = 0 indicates that no vertices are occupied (i.e., all of them have been
removed).2
1
If you’re interested in the study of percolation in physics the book by Stauffer and
Aharony [304] contains a lot of interesting material on the subject, although most of it is not directly relevant to percolation on networks.
2
In most of the physics literature on percolation the occupation probability is denoted p, but
we use φ because the letter p is used for many other things in the theory of networks and could
cause confusion.

594

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

Now look again at Fig. 16.1 and consider panel (a), in which φ = 1, all
vertices are present or occupied, and all vertices are connected together into
a single component. (The network could have more the one component, but
in this example it has only one.) Now look at the other panels. In panel (b) a
few vertices have been removed, but those that remain are all still connected
together by the remaining edges. In panel (c) still more vertices have been
removed, and now so many are gone that the remaining vertices are no longer
all connected together, having split into two small components. In the ﬁnal
panel, panel (d), all vertices have been removed and there is no network left at
all.
The behavior we see in this small example is typical of percolation processes. When φ is large the vertices tend to be connected together, forming a
giant component that ﬁlls most of the network (although there may be small
components also). But as φ is decreased there comes a point where the giant
component breaks apart and we are left only with small components. Conversely, if we increase φ from zero we ﬁrst form small components, which then
grow in size and eventually coalesce to form a giant component that ﬁlls a
large fraction the network.
The formation or dissolution of a giant component in this fashion is called
a percolation transition. When the network contains a giant component we say
that it percolates and the point at which the percolation transition occurs is
called the percolation threshold.
The percolation transition is similar in many ways to the phase transition in
the Poisson random graph at which a giant component forms (see Section 12.5).
In the random graph we vary not the fraction of occupied vertices but the
probability of connection between those vertices. In both cases, however, when
enough of the network is removed the giant component is destroyed and we
are left with only small components.
In studies of percolation the “components” that remain after vertices have
been removed are in fact usually called clusters, another term inherited from
the physics and mathematics literature and one that we will use here—it will
be useful to distinguish between the “components” of the underlying network
and the “clusters” of the percolation process. That is, we will use “component”
to refer to connected groups of vertices on the original network before any
vertices have been removed and “cluster” to refer to those after removal. The
giant component of the percolation process, if there is one, is thus properly
called the giant cluster.3
3
In most of the literature on percolation theory, the giant cluster is called the spanning cluster.
The reason is that most work on percolation has considered low-dimensional lattices such as the

595

P ERCOLATION AND NETWORK RESILIENCE

The percolation transition plays a central role in our interpretation of percolation phenomena. In a network like the Internet, for example, there has to
be a giant cluster if the network is to perform its intended function as a communications network. If the network has only small clusters, as in Fig. 16.1c,
then every vertex has a connection to, at most, a handful of others and is cut off
from everyone else. If there is a giant cluster, on the other hand, then the members of that giant cluster, who are a ﬁnite fraction of all vertices in the network,
are connected and can communicate with one another, although the remainder
of the network is still cut off. Thus the presence of a giant cluster is an indicator
of a network that is at least partly performing its intended function, while the
size of the giant cluster tells us exactly how much of the network is working.
16.2.1

U NIFORM REMOVAL IN THE CONFIGURATION MODEL

To gain some understanding of the percolation transition and the giant cluster,
let us consider the behavior of the site percolation process on networks generated using the conﬁguration model of Chapter 13, a simple but useful model
of a network with a speciﬁed degree distribution. We can calculate the properties of the giant percolation cluster in the conﬁguration model by a method
similar to the one we used for the giant component of conﬁguration model in
Section 13.8.
Consider a conﬁguration model network with degree distribution pk and a
percolation process on that network in which vertices are present or occupied
with occupation probability φ as above. Now consider one of the vertices that
is present in the network (i.e., one that has not been removed). If that vertex
is to belong to the giant cluster it must be connected to it via at least one of
its neighbors. Equivalently, it is not a member of the giant cluster if and only
if it is not connected to the giant cluster via any of its neighbors. Following
the notation of Section 13.8, let us deﬁne u to be the average probability that a
vertex is not connected to the giant cluster via a particular neighbor. Then if
the vertex in question has degree k, the total probability of its not belonging to
the giant cluster is uk . And if we then average over the probability distribution
pk of the degree we ﬁnd that the average probability of not being in the giant
square lattice. On such lattices the giant cluster is distinguished by being the only cluster that
spans the lattice from one side to the other in the limit of large n. There is no equivalent phenomenon for percolation on general networks, however, since networks don’t have “sides,” so the
concept of spanning is not a useful one.

596

|

16.2

U NIFORM RANDOM REMOVAL OF VERTICES

cluster is ∑k pk uk = g0 (u), where
∞

g0 ( z ) = ∑ p k z k

(16.1)

k =0

is the generating function for the degree distribution, as deﬁned previously in
Eq. (13.48). Then the average probability that a vertex does belong to the giant
cluster is 1 − g0 (u).
Bear in mind, however, that this is for a vertex that is itself assumed not
to have been removed from the network. Vertices that have been removed are
obviously not members of the giant cluster either. Thus out of all the original
vertices in the network the total fraction S that are in the giant cluster is equal
to the fraction φ that have not been removed times the probability 1 − g0 (u)
that they are in the giant cluster:
S = φ[1 − g0 (u)].

(16.2)

We still need to calculate the value of u, which is the average probability
that a vertex is not connected to the giant cluster via a particular neighboring vertex. There are two ways to not be connected to the giant cluster via a
neighbor: either the neighbor in question—let us call it vertex A—has been removed, which happens with probability 1 − φ, or it is present (probability φ)
but it is not itself a member of the giant cluster. The latter happens if A is not
connected to the giant cluster via any of its other neighbors. Suppose there
are k of these. Then the probability that none of them connects us to the giant
cluster is uk . Adding everything together, the total probability that we are not
connected to the giant cluster via A is 1 − φ + φuk .
Since A is reached by following an edge, the value of k in this case is distributed according to the excess degree distribution
qk =

( k + 1 ) p k +1
,
k

(16.3)

(see Section 13.3) where k is the average degree in the network. Averaging
over this distribution, we then arrive at an expression for the average probability u thus:
∞

∞

k =0

k =0

u = ∑ qk (1 − φ + φuk ) = 1 − φ + φ ∑ qk uk

= 1 − φ + φg1 (u),
where

(16.4)
∞

g1 ( z ) = ∑ q k z k

(16.5)

k =0

597

P ERCOLATION AND NETWORK RESILIENCE

is the generating function for the excess degree distribution, deﬁned previously in Eq. (13.49), and we have made use of the normalization condition
∑k qk = 1.
Equations (16.2) and (16.4) give us a complete solution for the size of the giant cluster in our network.4 In practice it is often not possible to solve Eq. (16.4)
in closed form, but there is an elegant graphical representation of the solution
as follows.
Consider Fig. 16.2a, which gives a sketch of the form of the function g1 (u).
The exact form of the curve will depend on the degree distribution, but we
know the general shape: g1 is a polynomial with all coefﬁcients non-negative
(because they are probabilities), so it must have a non-negative value and all
derivatives non-negative for u ≥ 0. Thus in general it is an increasing function
of u and curves upward as shown in the ﬁgure.
To get the function 1 − φ + φg1 (u) that appears on the right-hand side of
Eq. (16.4) we ﬁrst multiply g1 (u) by φ then add 1 − φ. Graphically that is
equivalent to compressing the unit square of Fig. 16.2a (along with the curve it
contains) until it has height φ and then shifting it upward a distance 1 − φ as
shown in Fig. 16.2b. The point or points at which the resulting curve crosses
the line y = u (dotted line in Fig. 16.2b) are then the solutions to Eq. (16.4).
In Fig. 16.2b there are two such solutions. One is a trivial solution at u = 1.
This solution always exists because g1 (1) = 1 for any correctly normalized
excess degree distribution qk . But there is also a non-trivial solution with u < 1,
indicated by the dot in the ﬁgure. Only if we have such a non-trivial solution
can there be a giant cluster in the network and the value of u for this solution
gives us the size of the giant cluster via Eq. (16.2). (The u = 1 solution gives
S = 0 in Eq. (16.2) and so doesn’t give us a giant cluster.)
Now consider Fig. 16.2d, which shows the equivalent graphical solution of
Eq. (16.4) for a smaller value of φ. Now the curve of the generating function
has been compressed more and the result is that the non-trivial solution for u
has vanished. Only the trivial solution at u = 1 remains and so in this regime
there can be no giant cluster.
Figure 16.2c shows the borderline case between cases (b) and (d). The nontrivial solution for u vanishes at the point shown, where the curve just meets
the dotted line. Mathematically this is the point at which the curve is tangent
4
This solution of the percolation problem has a history stretching back some years. In 1961,
Fisher and Essam [120] derived a solution for percolation on regular trees (called Cayley trees or
Bethe lattices in physics), which is equivalent to the solution given here for the case where every
vertex has the same degree. The developments for general degree distributions, however, were
not given till some decades later [62, 74].

598

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

1
(b)  > c


0.5

1
0

0

0.5

1

u
1

1

(c)  = c

(a)

g1(u)



0.5

0.5

1

0

0

0.5

1

0

0

0.5

u

1

u
1

Figure 16.2: Graphical solution of Eq. (16.4). The
generating function g1 (u) for the excess degree
distribution, panel (a), is compressed by a factor
of φ and shifted upward to give the functional
form y = 1 − φ + φg1 (u). The resulting curve
is shown for three different values of φ in panels (b), (c), and (d). In panel (b) φ is sufﬁciently
large that there is a nontrivial solution where the
curve crosses the dotted line y = u. In panel (d)
φ is smaller and there is only a trivial solution at
u = 1. Panel (c) shows the borderline case where
the curve is tangent to the dotted line at u = 1.

(d)  < c



0.5

1

0

0

0.5

1

u

599

P ERCOLATION AND NETWORK RESILIENCE

to the dotted line at u = 1, i.e., the point where its gradient at u = 1 is 1. In
other words the percolation threshold occurs when



d 
1 − φ + φg1 (u)
= 1.
(16.6)
du
u =1
Performing the derivative we then ﬁnd that the value of φ at the transition,
which we call the critical value, denoted φc , is
φc =

1
.
g1 (1)

(16.7)

We can express the critical value more directly in terms of the degree distribution by making use of the deﬁnitions of the generating function g1 and
the excess degree distribution, Eqs. (16.3) and (16.5). Substituting one into the
other and differentiating, we ﬁnd that
g1 (1) =

1
k

∞

1

∞

∑ k ( k + 1 ) p k +1 = k ∑ k ( k − 1 ) p k

k =0

k =0

k2 − k
=
,
k

(16.8)

and hence the critical occupation probability φc is given by
φc =

k2

k
,
− k

(16.9)

an expression ﬁrst given by Cohen et al. [74].
This equation tells us the minimum fraction of vertices that must be present
or occupied in our conﬁguration model network for a giant cluster to exist.
Thus, for instance, if we were to consider the conﬁguration model as a simple
model of the Internet, we would want to make φc low, so that the network will
have a giant cluster even when some fraction of vertices are non-functional,
and hence go on functioning as a communication network. We can arrange this
by making sure that k2  k for the network. If, for instance, the network
had a Poisson degree distribution,
p k = e− c

ck
,
k!

(16.10)

where c is the mean degree, then k = c and k2 = c(c + 1), so
φc =
600

1
.
c

(16.11)

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

Then if we can make c large we will have a network that can withstand the
loss of many of its vertices. For c = 4, for example, we would have φc = 14 ,
meaning that 34 of the vertices would have to fail before the giant cluster is
destroyed. A network that can tolerate the loss of a large fraction of its vertices
in this way is said to be robust against random failure.
The degree distribution of the Internet, however, is not Poissonian. In fact,
as discussed in Section 8.4, the Internet’s degree distribution appears roughly
to follow a power law with an exponent α ≃ 2.5 (see Table 8.1). As we showed
in Section 8.4.2, power laws with exponents in the range 2 < α < 3, which
includes most real-world examples, have a ﬁnite mean k , but their second
moment k2 diverges. In this case Eq. (16.9) implies that φc = 0. In other
words, no matter how many vertices we remove from the network there will
always be a giant cluster. Scale-free networks—those with power-law degree
distributions—are thus highly robust networks that can survive the failure
of any number of their vertices, a point ﬁrst highlighted in the work of Albert et al. [14].
In practice, as discussed in Section 8.4.2, the second moment of the degree
distribution is never actually inﬁnite in any ﬁnite network. Even for ﬁnite n
though it can still become very large, which can result in non-zero but very
small values of φc , so that the network is still highly robust.
The structure of the real Internet is not the same as that of a conﬁguration
model with the same degree distribution. It has all sorts of layers and levels of
structure engineered into it, as discussed in Section 2.1. Nonetheless, it does
appear to be quite robust to random removal of its vertices. For instance, Albert et al. [14] simulated the behavior of the Internet as vertices were randomly
removed from its structure and found that performance is hardly affected at
all by the removal of even a signiﬁcant fraction of vertices. (Performance is
of course completely destroyed for the vertices that are themselves removed,
but for the remaining ones the effects are relatively minor.) These and related
results are discussed further in Section 16.3.
Network robustness also plays an important role in the vaccination example mentioned at the start of the chapter. A disease spreading over a contact
network between individuals can only reach a signiﬁcant fraction of the population if there is a giant cluster in the network. If the network contains only
small clusters then an outbreak of the disease will be hemmed in by vaccinated individuals and unable to spread further than the small cluster in which
it starts. Thus one does not have to vaccinate the entire population to prevent
disease spread. One need only vaccinate enough of them to bring the network
below its percolation threshold. This is the herd immunity effect mentioned
earlier.
601

P ERCOLATION AND NETWORK RESILIENCE

g1(u)

In this example, network robustness is a bad thing. The fewer individuals
we have to vaccinate to destroy the giant cluster the better. Thus small values
of φc are bad in this case and large values are good. Unfortunately, we usually
don’t have much control over the degree distributions of contact networks, so
we may be stuck with a low value of φc whether we like it or not. In particular, if the network in question has a power-law (or approximately power-law)
degree distribution, then φc may be very small, implying that almost all vertices have to be vaccinated to wipe out the disease. Some contact networks do
indeed appear to have roughly power-law degree distributions [167, 197, 198]
and it may be very difﬁcult to eradicate some diseases as a result [264].
It is interesting to ask how the special behavior
1
of power-law networks shows up in the graphical
solution of Fig. 16.2. The answer is that, since g1 (1)
is inﬁnite in the power-law case (because k2 diverges in Eq. (16.8) while k remains ﬁnite), the
curve of g1 (u) has inﬁnite slope at u = 1. Thus
g1 (u) must look something like Fig. 16.3. Because
of the inﬁnite slope, it makes no difference how
0.5
much we compress the function (as in Fig. 16.2)—
the curve will always drop below the line of y = u
before coming back up again and crossing it to give
a non-trivial solution for u.
The position of the percolation threshold is not
the only quantity important in assessing the robustness of a network. The size of the giant cluster
0
0
1
0.5
also plays a role because it tells us what fraction of
the network will be connected and functional. To
u
ﬁnd the size of the giant cluster we need to solve
Eq. (16.4) for u and then substitute the result back
Figure 16.3: Generating function for the excess degree
into Eq. (16.2). In many cases, as we have said, we
distribution in a scale-free network. The generating
cannot solve for u exactly, but in some cases we can.
function g1 (u) for a network with a power-law degree
Consider, for example, a network with an exponendistribution has a derivative that diverges as u → 1,
tial degree distribution given by
though the value of the generating function remains ﬁpk = (1 − e−λ ) e−λk ,

nite and tends to 1 in this limit. Thus the function looks
generically like the curve sketched here.

(16.12)

where λ > 0 and the leading factor of 1 − e−λ insures that the distribution is properly normalized. Then, as shown in Section 13.9.2, we have
g0 ( z ) =

602

eλ − 1
,
eλ − z

g1 ( z ) =

eλ − 1
eλ − z

2

,

(16.13)

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

and Eq. (16.4) becomes
u(eλ − u)2 − (1 − φ)(eλ − u)2 − φ(eλ − 1)2 = 0.

(16.14)

This is a cubic equation, which is ugly (though not impossible) to solve. In
this case, however, we don’t have to solve it directly. We observe instead that
u = 1 is always a solution of Eq. (16.4) and hence that our cubic equation must
contain a factor of u − 1. A few moments work reveals that indeed this is the
case. Equation (16.14) factorizes as

(u − 1) u2 + (φ − 2eλ )u + φ − 2φeλ + e2λ = 0.

(16.15)

Thus the two other solutions for u satisfy the quadratic equation
u2 + (φ − 2eλ )u + φ − 2φeλ + e2λ = 0.

(16.16)

Of these two solutions one is greater than one for λ > 0 and so cannot be our
probability u. The other is

u = eλ − 12 φ − 14 φ2 + φ(eλ − 1).
(16.17)
Now we can plug this value back into Eq. (16.2) to get an expression for the
size of the giant cluster as a fraction of the whole network:


2 (eλ − 1 )
(
S = φ 1−
φ + φ2 + 4φ(eλ − 1)
(


φ − φ2 + 4φ(eλ − 1)
= φ 1 − 2 (eλ − 1 ) 2
φ − (φ2 + 4φ(eλ − 1))

= 32 φ − 14 φ2 + φ(eλ − 1).
(16.18)
Notice that the solution for u, Eq. (16.17), can become greater than 1 for
sufﬁciently small φ, which is unphysical. In this regime the only acceptable
solution is the trivial u = 1 solution, which gives S = 0 and so there is no
giant cluster when this happens. This gives us an alternative way to derive the
position of the percolation transition. The transition takes place at the point
where Eq. (16.17) equals one, i.e., when

(16.19)
eλ − 1 − 12 φ = 14 φ2 + φ(eλ − 1).
Squaring both sides and rearranging for φ we ﬁnd that the percolation threshold falls at
(16.20)
φc = 12 (eλ − 1).
603

P ERCOLATION AND NETWORK RESILIENCE

It is left as an exercise to demonstrate that this is the same result we get if we
apply the general formula, Eq. (16.7).
Note also that if λ becomes sufﬁciently large then the value of φc given by
Eq. (16.20) can become greater than one. For values of λ this large there is no
percolation transition and the system never percolates because φ can never be
greater than φc . The value of λ at which we enter this regime is the value at
which 12 (eλ − 1) = 1, which gives λ = ln 3. Upon closer inspection, it turns
out that this is precisely the point at which the network itself loses its giant
component,5 which explains why percolation is not possible beyond this point.
For λ > ln 3 the network has no giant component, and hence it is not possible
to have a giant cluster even if every vertex in the network is present. (A similar
result of course applies to all networks—a giant percolation cluster is never
possible in a network without a giant component.)
Figure 16.4 shows a plot of the value of S for our exponential network with
λ = 12 as a function of φ. For small φ there is a region in which there are
only small clusters and no giant cluster. When we pass through the percolation transition, marked by the dotted line in the ﬁgure, a giant cluster appears
and grows smoothly from zero as φ increases. This is an example of what a
physicist would call a continuous phase transition.6 We saw other examples in
Sections 13.9 and 15.2.5.
The overall behavior shown in Fig. 16.4 is typical of percolation in networks. For most degree distributions we expect S to take a similar form with
a continuous phase transition, as we can demonstrate by the following argument. Suppose the generating function g1 (u) is well-behaved near u = 1,
having all its derivatives ﬁnite,7 then we can expand it about this point as
g1 (u) = g1 (1) + (u − 1) g1 (1) + 12 (u − 1)2 g1 (1) + O(u − 1)3
u−1 1
= 1+
+ 2 (u − 1)2 g1 (1) + O(u − 1)3 ,
φc

(16.21)

where we have made use of g1 (1) = 1 (see Eq. (13.20)) and Eq. (16.7). Substi5

From Eq. (13.101) we know that a conﬁguration model network has a giant component if and
only if g1 (1) > 1, and thus loses its giant component at the point where g1 (1) = 1. Substituting
from Eq. (16.13), our network loses its giant component when 2/(eλ − 1) = 1, i.e., when λ = ln 3.
See also Problem 13.3 on page 484 for another derivation of this result.
6

A phase transition is continuous if the quantity of interest, also called the order parameter (S in
this case), is zero on one side of the transition and non-zero on the other, but its value is continuous at the transition itself. The alternative to a continuous phase transition is a ﬁrst-order phase
transition, in which the order parameter jumps discontinuously as it crosses the transition point.
7

604

This excludes the power-law case shown in Fig. 16.3, which is discussed separately below.

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

Size of giant cluster S

0.6

0.4

0.2

0

0

0.2

0.4

0.6

0.8

1

Occupation probability φ

Figure 16.4: Size of the giant cluster for site percolation in the conﬁguration model.
The curve indicates the size of the giant cluster for a conﬁguration model with an exponential degree distribution of the form (16.12) with λ = 12 , as given by Eq. (16.18). The
dotted line indicates the position of the percolation transition, Eq. (16.20).

tuting into Eq. (16.4), we then ﬁnd that
u = 1+

φ
(u − 1) + 12 φ(u − 1)2 g1 (1) + O(u − 1)3
φc

or
u−1 =

2
g1 (1)

φc − φ
+ O( u − 1)2 .
φc φ

(16.22)

(16.23)

We can similarly expand g0 (u) as
g0 (u) = g0 (1) + (u − 1) g0 (1) + O(u − 1)2

= 1+

2 k φc − φ
+ O(φ − φc )2 ,
g1 (1) φc φ

(16.24)

where we have used g0 (1) = 1 and Eqs. (13.22) and (16.23). Substituting into
Eq. (16.2) then gives us
S=

2 k φ − φc
+ O(φ − φc )2 ,
g1 (1) φc

(16.25)
605

P ERCOLATION AND NETWORK RESILIENCE

In other words, S varies linearly with φ − φc just above the percolation transition, going to zero continuously as we approach the transition from above.
Thus we would expect the percolation transition for essentially all degree distributions to look generically like the curve in Fig. 16.4, with a continuous
phase transition as we pass the percolation threshold.8
This result is important, because it implies that the giant cluster becomes
very small as we approach the percolation transition from above. In other
words, the network may be “functional” in the sense of having a giant cluster,
but the functional portion of the network is vanishingly small. If the network
is a communication network, for example, then a ﬁnite fraction of all the vertices in the network can communicate with one another so long as there is a
giant cluster, but that fraction becomes very small as we approach the percolation threshold, meaning that in practice most vertices are cut off. Thus one
could argue that it is misleading to interpret the percolation threshold as the
point where the network stops functioning: in effect most of it has stopped
functioning before we reach this point. To fully describe the functional state of
the network one should specify not only whether it contains a giant cluster but
also what the size of that cluster is.
It is also important to note that the sharp percolation transition of Fig. 16.4
is only truly seen in an inﬁnite network. For networks of ﬁnite size—which
is all real networks, of course—the transition gets rounded off. To see this,
consider the behavior of the giant cluster in a ﬁnite-sized network. Technically,
in fact, there is no giant cluster for an individual ﬁnite network. The proper
deﬁnition of the giant cluster, like the giant component in a random graph,
is as a cluster whose size scales in proportion to the size of the network (see
Section 12.5). But it makes no sense to talk about the scaling of a cluster with
network size when the size of the network is ﬁxed. In practice, therefore, we
normally consider instead the largest cluster, which is a reasonable proxy for
the giant cluster in a ﬁnite-size network. Its size as a fraction of the size of the
network should be a reasonable approximation to the size of the giant cluster
given by our theory when we are above the percolation transition.
Below the transition the largest cluster will be small in size, but not zero,
and hence ﬁlls a small but non-zero fraction of the network, in rough but not
perfect agreement with the theoretical prediction S = 0. Furthermore, this
non-zero value grows as we approach the transition point because small clusters in general, including the largest one, grow as the occupation probability φ
increases. The net result is a slight rounding of the sharp transition predicted
8
To be more precise, the transition is a second-order transition—one where the order parameter
is continuous at the transition but its derivative is not.

606

16.2

|

U NIFORM RANDOM REMOVAL OF VERTICES

by the theory, which is often visible, for example, in computer simulations of
percolation on smaller networks. Effects such as this that show up only in
ﬁnite-sized systems are known as ﬁnite size effects.
Even in the limit of large network size there are exceptions to the behavior of Fig. 16.4 and Eq. (16.25). Consider a network with a power-law degree
distribution with exponent 2 < α < 3, as discussed above. In this case our
assumption that the derivatives of g1 are ﬁnite does not hold (see Fig. 16.3
and the accompanying discussion), so the argument above breaks down. Not
only does the percolation threshold fall at φc = 0 for power-law networks, but
the giant cluster does not grow linearly as φ increases. In general it will grow
slower than linearly, the exact functional form depending on the shape of g1 (u)
near u = 1. For example, a typical form is
1 − g1 ( u ) = c ( 1 − u ) β ,

(16.26)

S

φ

The phase transition at
which the giant cluster appears is only sharp in an inﬁnite system (solid line). In
a ﬁnite sized system it gets
rounded off (dashed line).

near u = 1 with c and β positive constants. Provided β < 1 this makes the gradient of g1 (u) (and all higher derivatives) inﬁnite at u = 1 while still ensuring
that g1 (1) = 1. With this form for g1 (u), Eq. (16.4) implies

Then9

1 − u = (cφ)1/(1− β) .

(16.27)

g0 (u) ≃ g0 (1) + g0 (1)(u − 1) = 1 + k (u − 1),

(16.28)

close to u = 1, with k ﬁnite so long as the power-law exponent α > 2, and
hence the giant cluster has size
S = φ[1 − g0 (u)] ≃ φ k (1 − u) ∼ φ(2− β)/(1− β) ,

(16.29)

which goes to zero faster than linearly10 as φ → 0 since (2 − β)/(1 − β) > 1 if
β < 1.
9
If we want to be more careful and keep track of the correction terms we can make use of
Eq. (13.51) and integrate Eq. (16.26) to show that g0 (u) = 1 − k (1 − u) + c(1 − u) β+1 /( β + 1).
The last term vanishes faster than those before it as u → 1 because β > 0 and hence g0 (u) ≃
1 − k (1 − u). This is at ﬁrst slightly surprising—one would imagine that the correction term
ought to be O(1 − u)2 —but this type of behavior is common with power-law distributions.
10
To the extent that one can regard a power-law network as having a percolation transition
at φ = 0 it is interesting to ask what the order of this transition is. The answer is unclear since
Eq. (16.29) doesn’t perfectly ﬁt the standard forms for continuous phase transitions. If we deﬁne a
transition to be second-order if the order parameter is continuous at the transition and third-order
if its derivative is continuous, then the transition is third-order in this case. But one could also
argue that the transition is of fractional order between two and three since it varies from zero as a
fractional power of the occupation probability φ.

607

P ERCOLATION AND NETWORK RESILIENCE

Size of giant cluster S

0.6

0.4

0.2

0

0

0.2

0.4

0.6

0.8

1

Occupation probability φ

Figure 16.5: Size of the giant cluster for a network with power-law degree distribution. The size of the giant cluster for a scale-free conﬁguration model network with
exponent α = 2.5, a typical value for real-world networks. Note the non-linear form of
the curve near φ = 0, which means that S, while technically non-zero, becomes very
small in this regime. Contrast this ﬁgure with Fig. 16.4 for the giant cluster size in a
network with an exponential degree distribution.

Thus we expect the giant cluster to become very small as φ → 0. Figure 16.5
shows the equivalent of Fig. 16.4 for a scale-free network with exponent α =
2.5, derived from numerical solutions of Eqs. (16.2) and (16.4) and the nonlinear form of S close to φ = 0 is clear.
This result mitigates somewhat our earlier statement that scale-free networks are highly robust because φc = 0. It is true that the percolation threshold
is zero in these networks and hence that there is a giant cluster for any positive φ, but that giant cluster can become exceedingly small. A communication
network with a power-law degree distribution, for instance, might be formally
functional for very small values of φ, but in practice the fraction of vertices
that could communicate with one another would be so small that the network
would probably not be of much use.

608

16.3

16.3

|

N ON - UNIFORM REMOVAL OF VERTICES

N ON - UNIFORM REMOVAL OF VERTICES

In the ﬁrst part of this chapter we have considered percolation phenomena
in the case where vertices are removed from a network uniformly at random.
This is the classical form of percolation long studied by physicists and mathematicians. When discussing networks, however, it is interesting also to consider other ways in which vertices might be removed. In Section 16.1, for
example, we mentioned the possibility of removing vertices in order of their
degrees, starting with the highest degrees and working down. This might be
effective, for example, as a vaccination strategy for preventing the spread of
disease: should they become infected, the high degree vertices in the network
clearly present a disease risk to their many neighbors, so perhaps vaccinating
them ﬁrst would be a sensible approach.
Let us consider a generalization of our percolation process in which the
occupation probability of a vertex can now depend on its degree. We deﬁne
φk to be the probability that a vertex with degree k is present or occupied in
our network. If φk is a constant, independent of k, then we recover the uniform
scenario of previous sections. On the other hand, if φk = 1 for all vertices with
degree k < k0 for some constant k0 , and φk = 0 for all vertices with k ≥ k0 , then
we effectively remove from the network all vertices with degree k0 or greater.
A host of other choices are also possible, resulting in more complex removal
patterns.
Let us again look at percolation on conﬁguration model networks and as
before deﬁne u to be the average probability a vertex is not connected to the
giant cluster via one of its neighbors. If the vertex has degree k then the probability that it is not connected to the giant cluster via any of its neighbors is uk
and the probability that it is connected to the giant cluster is 1 − uk . But in order to belong to the giant cluster, the vertex itself must also be present, which
happens with probability φk , so the probability of it being a member of the
giant cluster is φk (1 − uk ).
Now we average over the probability distribution pk of the degree to ﬁnd
the average probability of being in the giant cluster and get
∞

∞

∞

k =0

k =0

k =0

S = ∑ pk φk (1 − uk ) = ∑ pk φk − ∑ pk φk uk

= f 0 (1) − f 0 ( u ),
where

(16.30)
∞

f 0 (z) = ∑ pk φk zk .

(16.31)

k =0

609

P ERCOLATION AND NETWORK RESILIENCE

Notice that this new generating function is not normalized in the conventional
fashion—the value f 0 (1) that appears in Eq. (16.30) is not in general equal to
one. Instead it is given by
∞

f 0 (1) = ∑ pk φk = φ,

(16.32)

k =0

which is the average probability that a vertex is occupied.
We can calculate the value of u using an approach similar to that for the
uniform percolation scenario. The value of u is the probability that you are
not connected to the giant cluster via your neighbor, which happens if either
the neighbor is not occupied or if it is occupied but it is not connected to the
giant cluster via any of its other neighbors. Let k now be the excess degree of
the neighboring vertex. Then the probability that the neighbor is not occupied
is 1 − φk+1 . Notice that the index is k + 1 because φk is deﬁned in terms of
the total degree of a vertex, which is one greater than the excess degree (see
Section 13.3). The probability that the neighbor is occupied but is itself not
connected to the giant cluster is φk+1 uk . Adding up the terms and averaging
over the distribution qk of the excess degree, we then ﬁnd that
∞

u = ∑ qk (1 − φk+1 + φk+1 uk ) = 1 − f 1 (1) + f 1 (u),

(16.33)

k =0

where

∞

f 1 (z) = ∑ qk φk+1 zk

(16.34)

k =0

and we have used ∑k qk = 1.
Like f 0 (z), the function f 1 (z) is not normalized to unity. The deﬁnition of
f 1 (z) looks slightly odd because of the subscript k + 1. If we prefer we can
write it using the full expression for the excess degree distribution, Eq. (16.3),
which gives
f 1 (z) =

1
k

1
=
k

∞

∑ (k + 1) pk+1 φk+1 zk

k =0
∞

∑ kpk φk zk−1 ,

(16.35)

k =1

which has a more symmetric look about it. Note also that
f 1 (z) =

610

f 0 (z)
,
g0 (1)

(16.36)

16.3

|

N ON - UNIFORM REMOVAL OF VERTICES

where g0 (z) is deﬁned as before. This expression can be useful for calculating
f 1 (z) once f 0 (z) has been found.
Equations (16.30) and (16.33), which were ﬁrst given by Callaway et al. [62],
give us a complete solution for the size of the giant cluster for our generalized
percolation process.
As an example of their use, consider again a network with exponential degree distribution given by Eq. (16.12) and suppose we remove all vertices that
have degree k0 or greater. That is, we choose

1
if k < k0 ,
φk =
(16.37)
0
otherwise.
Then we have
k 0 −1
eλ − 1
,
f 0 (z) = (1 − e−λ ) ∑ e−λk zk = (1 − e−λk0 zk0 ) λ
e −z
k =0

(16.38)

and
f 1 (z) =

f 0 (z)
g0 (1)

= (1 − e−λk0 zk0 ) − k0 e−λ(k0 −1) zk0 −1 (1 − e−λ z)

eλ − 1
eλ − z

2

.

(16.39)

For this choice Eq. (16.33) becomes a polynomial equation of order k0 and
unfortunately such equations are not solvable exactly for their roots (unless
k0 ≤ 4). It is, however, fairly easy to ﬁnd the roots numerically, especially
given that we know that the root of interest in this case lies in the range between zero and one, and then we can calculate the size of the giant cluster
from (16.30).
Figure 16.6a shows the results of such a calculation, plotted as a function
of k0 . Looking at this ﬁgure, consider what happens as we lower k0 from an
initial high value, effectively removing more and more of the high-degree vertices in our network. As the ﬁgure shows, the size of the giant cluster decreases
only slowly at ﬁrst. This is because there are not many vertices of very high
degree in the network, so very few have been removed. Once k0 passes a value
around 10, however, our attack on the network starts to become evident in a
shrinking of the giant cluster, which becomes progressively more rapid until
the size of the cluster reaches zero around k0 = 5.
One might be forgiven for thinking that Fig. 16.6a portrays a network quite
resilient to the removal of even its highest-degree vertices: it appears that we
have to remove vertices all the way down to degree ﬁve in order to break up
611

P ERCOLATION AND NETWORK RESILIENCE

0.6

Size of giant cluster S

(a)

(b)

0.4

0.2

0

0

5

10

15

Maximum degree k0

0

0.5

1

Fraction of vertices present

Figure 16.6: Size of the giant percolation cluster as the highest degree vertices in a
network are removed. (a) The size of the giant cluster in a network with an exponential
degree distribution pk ∼ e−λk with λ = 12 as vertices are removed in order of degree,
starting from those with the highest degree. The curve is shown as a function of the
degree k0 of the highest-degree vertex remaining in the network. Technically, since k0
must be an integer, the plot is only valid at the integer points marked by the circles; the
curves are just an aid to the eye. (b) The same data plotted now as a function of the
fraction φ of vertices remaining in the network.

the giant cluster. This impression is misleading, however, because it fails to
take account of the fact that the vast majority of vertices in the network are of
very low degree, so that even when we have removed all vertices with degree
greater than ﬁve, we have still removed only a small fraction of all vertices.
Perhaps a more useful representation of the solution is to plot it as a function of the fraction φ of occupied vertices in the network, which is
φ = f 0 (1) = 1 − e−λk0 .

(16.40)

Figure 16.6b shows the result replotted in this way and reveals that the giant cluster in fact disappears completely when only about 8% of the highestdegree vertices in the network have been removed. By contrast, when we removed vertices uniformly at random, as shown in Fig. 16.4, we had to remove
nearly 70% of the vertices to destroy the giant cluster. Though the difference
612

|

N ON - UNIFORM REMOVAL OF VERTICES

1

Size of giant component S

(a)

(b)

0.03

0.02
0.5

0

α = 2.2
α = 2.5
α = 2.8

0.92

0.96

Fraction of vertices present

0.01

1

2

2.5

3

3.5

Fraction of vertices removed

16.3

0

Exponent α

Figure 16.7: Removal of the highest-degree vertices in a scale-free network. (a) The size of the giant cluster in a
conﬁguration model network with a power-law degree distribution as vertices are removed in order of their degree,
starting with the highest-degree vertices. Only a small fraction of the vertices need be removed to destroy the giant
cluster completely. (b) The fraction of vertices that must be removed to destroy the giant cluster as a function of the
exponent α of the power-law distribution. For no value of α does the fraction required exceed 3%.

is startling, however, it is also intuitively reasonable. The high-degree vertices
have a lot of connections, all of which are lost if we remove those vertices.
These results suggest, for example, that were we able to ﬁnd the highest
degree vertices in a network of disease-causing contacts and vaccinate them to
effectively remove them from the network, it would be a much more efﬁcient
strategy for disease control than simply vaccinating at random.
A particularly striking example of the effect described here arises in networks with power-law degree distributions. In these networks, as we have
seen, uniform removal of vertices never destroys the giant cluster, provided the
exponent of the power-law lies between two and three. By contrast, removal
of the highest-degree vertices in these networks has a devastating effect. Once
again we cannot solve for S in closed form in the power-law case but it is reasonably straightforward to perform a numerical solution. Figure 16.7a shows
the equivalent of Fig. 16.6b for the power-law case, and as we can see the giant cluster disappears extraordinarily rapidly as the high-degree vertices are
removed. Only a few percent of the vertices need be removed to completely
destroy the giant cluster, the exact value depending on the exponent of the
power law.
613

P ERCOLATION AND NETWORK RESILIENCE

Indeed, if we want to calculate only the fraction that need be removed to
destroy the giant cluster, we can do so by observing once again that the phase
transition at which the giant cluster appears or disappears falls at the point
where the non-trivial solution of Eq. (16.33) appears or disappears, which is
the point at which the right-hand side of the equation is tangent to the line
y = u at u = 1. That is, the general criterion for the transition point is
f 1 (1) = 1.

(16.41)

(Alternatively, we could say that the giant cluster exists if and only if f 1 (1) >
1.) Again, exact solutions are often not possible but we can solve numerically.
Doing this for the power-law case we ﬁnd the results shown in Figure 16.7b,
which plots the fraction of vertices that need be removed to destroy the giant
cluster as a function of the exponent α. As we can see, the curve peaks around
α = 2.2 at a value just below 3%. Thus in no case need we remove more than
3% to destroy the connectivity in the network.
Scale-free networks are thus paradoxically both robust and fragile, a point
ﬁrst emphasized by Albert et al. [14]. On the one hand, they are remarkably robust to the random failure of their vertices, with the giant cluster persisting no
matter how many vertices we remove. (Although one should bear in mind the
proviso of Section 16.2.1 that the size of the giant cluster matters also, and this
becomes very small when the fraction φ of occupied vertices tends to zero.) On
the other hand, scale-free networks are very fragile to attacks targeted speciﬁcally at their highest-degree vertices. We need remove only the tiniest fraction
of the high-degree hubs in such a network to entirely destroy the giant cluster.
The fragility of scale-free network to such targeted attack is both bad news
and good news. Some networks we wish to defend against possible attack. The
Internet is an example: a communication network that can easily be brought
down by a malicious adversary targeting just a few of its most crucial vertices
may be a disaster waiting to happen.
On the other hand, results like these could also be exploited to help eradicate or reduce disease by targeting vaccination efforts at network hubs. It is
worth noting, however, that it’s not necessarily easy to ﬁnd the hubs in a network, so that implementation of a targeted vaccination strategy may be difﬁcult. In most cases one does not know the entire network and so cannot simply
pick out the high-degree vertices from a list.
One intriguing way of getting around this problem has been put forward
by Cohen et al. [76], who suggest that we make use of the structure of the
network itself to ﬁnd the high-degree vertices. In their scheme, which they
call “acquaintance immunization,” they propose that one choose members of
the population at random and then get each of them to nominate an acquain614

16.4

|

P ERCOLATION IN REAL - WORLD NETWORKS

tance. Then that acquaintance receives a vaccination against the disease under
consideration. The acquaintance in this scenario is a “vertex at the end of an
edge,” so in the conﬁguration model it would have degree distributed according to the excess degree distribution, Eq. (13.46), rather than the original degree
distribution of the network. But the excess degree distribution, as discussed in
Section 13.3, is biased towards high-degree vertices since there are more edges
that end at a high-degree vertex than at a low-degree one. Thus the selection of
individuals in the scheme of Cohen et al. is also biased towards those with high
degree. The selected individuals are not guaranteed to be the highest-degree
vertices in the network, but we are a lot more likely to ﬁnd the hubs this way
than if we just choose vertices at random and in simulations the acquaintance
immunization scheme appears to work quite well.
The acquaintance immunization scheme does have some drawbacks. First,
contact networks in the real world are of course not conﬁguration models and
it is unclear how accurately the theoretical results describe real situations. Second, real contact networks mostly don’t have power-law degree distributions,
instead having somewhat shorter tails than the typical power law, which will
reduce the effectiveness of the scheme, or indeed of any scheme based on targeting the highly connected vertices. Another issue is that, in asking people to
name their acquaintances, the acquaintance immunization scheme necessarily probes the network of who is acquainted with whom, which is in general
not the same as the network of disease transmission, since people who are acquainted don’t necessarily have regular physical contact of the type necessary
to spread disease and because diseases can be and often are transmitted between people who don’t know one another. We can do our best to make the
networks similar, asking participants to name only acquaintances whom they
have seen recently and in person, rather than those they might not have seen
for a while or might only have to talked to on the phone. Still, the differences
between the two networks means that the scheme might end up focusing vaccination efforts on the wrong set of people.

16.4

P ERCOLATION IN REAL - WORLD NETWORKS

Having seen how percolation plays out in model networks, let us now take
a look at some real ones. If we have data on the structure of a network then
we can simulate the percolation process on a computer, removing vertices one
by one and examining the resulting clusters. Although this is straightforward
in theory, it requires some care to get good results in practice. The main issue is that the percolation process is normally a random one: the vertices are
removed in random order, which means that the cluster sizes can vary de615

P ERCOLATION AND NETWORK RESILIENCE

pending on the precise order we choose. Even in the case where vertices are
removed in decreasing order of their degree the process is still random to some
extent since there can be many vertices with a given degree, among which we
must choose somehow. To avoid possible biases, we usually choose among
them at random.
This randomness can easily be simulated on a computer using standard
random number generators, but the results of the simulation will then vary
from one run of our simulation to another depending on the output of the generator. To get a reliable picture of how percolation affects a network we must
perform the entire calculation many times, removing the vertices in different
random orders each time, so that we can see what the typical behavior is, as
well as the range of variation around that typical behavior. And this in turn
means that we need to be able to perform the percolation calculation quickly.
In a typical situation we might want to repeat the percolation calculation a
thousand times with different random orders of removal and even if each calculation took just one minute of computer time, all thousand runs would still
take a day.
If we are crafty, however, we can do much better than this and get an answer in just a few seconds for networks of the typical sizes we have been considering in this book.

16.5

C OMPUTER ALGORITHMS FOR PERCOLATION

The simplest way to simulate the percolation process on a computer is to make
use of the breadth-ﬁrst search algorithm of Section 10.3.4, which can ﬁnd all
components in a network in time O(m + n), where m is the total number of
edges in the network and n is the total number of vertices, or just O(n) for a
sparse network in which m ∝ n. If we remove a certain randomly chosen set
of vertices from a network, along with the edges attached to them, then the
resulting percolation clusters are by deﬁnition the components of the network
that remains, and hence we can use the component-ﬁnding algorithm to ﬁnd
the clusters. Then we can, for example, look through those clusters until we
ﬁnd the largest one.
In the case of uniformly random removal of vertices, for instance, we would
go through each vertex in turn, removing it (and its edges) from the network
with probability 1 − φ, ﬁnding the clusters, and (say) measuring the size of the
largest one. Then we repeat the entire calculation, starting with the complete
network again, removing a different set of vertices, and ﬁnding the clusters.
Repeating the calculation a large number of times, we can calculate a mean
value S(φ) for the size of the largest component when vertices are present or
616

16.5

|

C OMPUTER ALGORITHMS FOR PERCOLATION

functioning with probability φ.
If we are interested in only a single value of φ, this is, in fact, the best algorithm to use and the fastest known way of getting an answer. Usually, however, we are interested, as in previous sections, in the behavior of the system
over the whole range of φ from zero to one, or at least some portion of that
range. In that case, we would have to repeat the whole calculation above for
many values of φ in the range of interest and this process is time-consuming
and is not the best way to approach the problem.
Consider instead the following alternative approach, which appears at ﬁrst
to be only a slight variation on the previous one, but leads, as we will see, to
much more efﬁcient algorithms. Instead of making each vertex in the network
occupied with independent probability φ, let us make a ﬁxed number r of vertices occupied, repeating the calculation many times for a given value of r and
averaging to get a ﬁgure Sr for the size of the largest component (or any other
quantity of interest) as a function of r.
The calculation doesn’t directly give us the result we want: Sr is not the
same as S(φ) and it is the latter we are interested in. If, however, we know the
value of Sr for every allowed value of the integer r, i.e., from 0 to n, then we
can calculate S(φ) as follows. If each vertex in the network is occupied with
probability φ, then the probability that there are exactly r vertices occupied is
given by the binomial distribution
pr =

n r
φ (1 − φ ) n −r .
r

(16.42)

Averaging over this distribution, the average size of the largest component as
a function of φ is then
n

n

r =0

r =0

S ( φ ) = ∑ p r Sr = ∑

n r
φ ( 1 − φ ) n − r Sr .
r

(16.43)

At ﬁrst sight, this appears to be a less promising approach for calculating S(φ) than the previous approach. To make use of Eq. (16.43) we need to
know Sr for all r and it takes time O(m + n) to calculate Sr for one value of r
using breadth-ﬁrst search, so it is going to take O(n(m + n)) to calculate for all
n values, or O(n2 ) on a sparse network. Given that we also need to perform
each calculation of Sr many times to average over the randomness, the entire
process could take a very long time to complete.
There is however a faster way to calculate Sr for all r, inspired by the simple
observation that if we have already found all the clusters in a network with r
vertices present, then we can ﬁnd the clusters with r + 1 vertices simply by
adding one more vertex. Most of the clusters do not change very much when
617

P ERCOLATION AND NETWORK RESILIENCE

(a)

(b)

(c)

(d)

Figure 16.8: Percolation algorithm. In the percolation algorithm described in the text we add vertices to our network
one by one, rather than taking them away. Each addition consists of several steps. (a) We add the vertex itself but none
of its accompanying edges yet. At this stage the vertex constitutes a new cluster in its own right. (b) We start adding
the accompanying edges (if any) in any order we like. Only edges that connect to other vertices already present in the
network are added. The ﬁrst edge added (if any are added) will thus, by deﬁnition, always join the new vertex to one
of the previously existing clusters. Or to put it another way, it will join two clusters together, one of the old clusters
and the new cluster that consists of just the single added vertex. (c) In this example the next edge added also joins two
clusters together. (d) The ﬁnal edge added joins two vertices that are already members of the same cluster, so the cluster
structure of the network does not change.

we add just one vertex, and if we can ﬁnd only the clusters that change upon
adding a vertex, then we can save ourselves the work of performing an entire
new breadth-ﬁrst search, and hence save ourselves a lot of computer time. A
simple algorithm for doing this works as follows.
Rather than removing vertices from the complete network, our algorithm
works by building the network up from an initial state in which no vertices
are occupied and switching on vertices one by one until we recover the entire
network. As we add each vertex to the network we also add the accompanying
edges that join it to other vertices. Only connections to other vertices that are
already present need be added.
For the purposes of our algorithm, let us break down this process as shown
in Fig. 16.8. Each new vertex is ﬁrst added with, initially, no accompanying
edges (panel (a) in the ﬁgure). In this state it forms a cluster all on its own.
Then, one by one, we add its edges, those that connect it to other vertices already present. If there are no edges attached to the vertex or none connect to
vertices already present, then our new vertex remains a cluster on its own. If

618

16.5

(a)

1

|

C OMPUTER ALGORITHMS FOR PERCOLATION

2

3
1
1

(b)

2

2

1

2

1
1
1

(c)

2

2

1

1

1
1
1

1

1

Figure 16.9: Using labels to keep track of clusters. In the algorithm described in the text, each vertex is given a label, typically an integer, to denote which cluster it belongs to. In this
example there are initially two clusters, labeled 1 and 2. Then
a new vertex is added between them. (a) The new vertex is
added initially without its accompanying edges and is labeled
as a new cluster, cluster 3. (b) An edge is added that connects
cluster 3 to cluster 1, so we relabel one cluster to give it the
same label as the other. In the algorithm described in the text
we always relabel the smaller of the two clusters, which is cluster 3 in this case. (c) The next edge added joins clusters 1 and 2
and we relabel cluster 2 since it is smaller.

there are edges, however, then the ﬁrst edge we add joins our vertex to an adjacent cluster—see Fig. 16.8b. Subsequent edges are more complicated. They
can do one of two things. An edge can connect our vertex to another, different
cluster, in which case in the process it joins two clusters together making them
into a single cluster—see Fig. 16.8c. Alternatively, it could join our vertex to
another member of the same cluster that it already belongs to, as in Fig. 16.8d.
In this case, no clusters are joined together, and in terms of the size and identity
of the clusters the added edge has no effect.
To keep track of the clusters in the network, therefore, our algorithm needs
to do two things. First, when an edge is added it needs to identify the clusters
to which the vertices at either end belong. Second, if the clusters are different,
it needs to join them together into a single cluster. (If they are the same nothing
need be done.)
There are various ways of achieving this but a simple one is just to put
a label, such as an integer, on each vertex denoting the cluster to which it
belongs—see Fig. 16.9a. Then it is a simple matter to determine if two vertices

619

P ERCOLATION AND NETWORK RESILIENCE

belong to the same cluster (they do if their labels are the same), and joining
two clusters together is just a matter of relabeling all the vertices in one of the
clusters to match the label of the other cluster. This process is illustrated in
Fig. 16.9.
Then our algorithm is as follows:
1. Start with an empty network with no occupied vertices. Let c = 0 be the
number of clusters in the network initially. Choose at random an order
in which the vertices will be added to the network.
2. Add the next vertex in the chosen order, initially with no edges. This
vertex is a cluster in its own right, so increase c by one and label the
vertex with label c to indicate which cluster it belongs to. Also make a
note that cluster c has size 1.
3. Go through the edges attached to this vertex one by one. For each edge
determine whether the vertex at the other end has already been added to
the network. If it has, add the edge to the network.
4. As each edge is added, examine the cluster labels of the vertices at either
end. If they are the same, do nothing. If they are different, choose one of
the clusters and relabel all its vertices to have the same label as the other
cluster. Update the record of the size of the cluster to be equal to the sum
of the sizes of the two clusters from which it was formed.
5. Repeat from step 2 until all vertices have been added.
At the end of this process, we have gone from an entirely empty network to
the complete ﬁnal network with all vertices and edges present and in between
we have passed through a state with every possible intermediate number r of
vertices. Moreover, in each of those states we had a complete record of the
identities and sizes of all the clusters which we can use, for instance, to ﬁnd
the size Sr of the largest cluster. Then we can feed the results into Eq. (16.43)
to get S(φ) for any φ. As before, we will typically want to average the results
over many runs of the algorithm to allow for random variations from one run
to another, which arise from variations in the order in which the vertices are
added. This, however, is no longer a serious impediment to ﬁnishing the calculation because, if implemented appropriately, the algorithm can be made to
run very quickly.
The most time-consuming part of the algorithm is the relabeling of clusters
when they are joined together. Note however that when an edge joins two different clusters we are free to choose which of the two we relabel. It turns out
that the speed of the algorithm can be improved greatly if we choose always to
relabel the smaller one. (If the two clusters have the same size, it does not matter which we choose to relabel.) To see this, consider the following argument.

620

16.5

|

C OMPUTER ALGORITHMS FOR PERCOLATION

If we always relabel the smaller of two clusters, then the relabeled cluster
must have been joined with one at least as large as itself and hence it is now a
part of a cluster at least twice its size. Thus every time a vertex is relabeled the
cluster it belongs to at least doubles in size. Given that each vertex starts off
as a cluster in its own right of size 1, the size of the cluster to which it belongs
after k relabelings is thus at least 2k . Since no vertex can belong to a cluster
of size greater than the size n of the whole network, the maximum number
of relabelings a vertex can experience during the entire algorithm is given by
2k = n or k = log2 n, and the maximum number of relabeling operations on
all n vertices is thus n log2 n. Thus the total time to perform the relabeling part
of the algorithm is O(n log n).
The other parts of the algorithm are typically faster than this. The adding
of the vertices takes O(n) time and the adding of the edges takes O(m) time,
which is the same as O(n) on a sparse network with m ∝ n. So the overall
running time of the algorithm to leading order is O(m + n log n), or O(n log n)
on a sparse network, which is much better than our ﬁrst estimate of O(n(m +
n)) above.
Essentially the same algorithm can also be used when vertices are added or
removed with probabilities other than the uniformly random ones considered
here. For instance, if vertices are to be removed in decreasing order of their
degrees we simply reverse that process and add vertices to an initially empty
network in increasing order of degrees. The details of the algorithm itself are
unchanged—only the order of the vertices changes.
This algorithm works well in practice for almost all calculations. It is not,
however, the very fastest algorithm for the percolation problem. There exists
an even faster one, which runs in O(m + n) time (or O(n) for a sparse network)
and is also considerably simpler to program, although its outward simplicity
hides some subtleties. The reader interested in learning more about this approach is encouraged to look at Ref. [255].
16.5.1

R ESULTS

Figure 16.10 shows results for four different networks as a function of the fraction of occupied vertices. In this case, the occupied vertices are chosen uniformly at random. The ﬁgure shows in each case the size S of the largest
cluster as a fraction of system size, plotted as a function of φ. As described
in Section 16.2.1, the largest cluster acts as a proxy for the giant cluster in numerical calculations on ﬁxed networks for which the idea of a giant cluster, as
a cluster that scales with system size, is meaningless.
The top two networks in the ﬁgure, a power grid and a road network, are
621

P ERCOLATION AND NETWORK RESILIENCE

1

Power grid

Road network

Internet

Social network

Size of largest cluster S

0.5

0
1

0.5

0

0

0.5

1

0

0.5

1

Fraction of vertices present φ

Figure 16.10: Size of the largest percolation cluster as a function of occupation probability for four networks. The four frames of this ﬁgure show the size of the largest
cluster, measured as a fraction of network size, for random removal of vertices from
four real-world networks: the western United States power grid, the network formed
by the US Interstate highways, the Internet at the level of autonomous systems, and a
social network of professional collaborations between physicists. Each curve is averaged over 1000 random repetitions of the calculation, which is why the curves appear
smooth.

both networks with non-power-law degree distributions—the power grid has
a roughly exponential distribution while the road network has only vertices
of degree one to four and nothing else. For these cases, we expect to see behavior of the generic type described in Section 16.2.1: a continuous percolation
transition at a non-zero value of φ from a regime in which S ≃ 0 to a regime
of non-zero S. Because the networks are relatively small, however (4941 vertices for the power grid, 935 for the road network), we also expect to see some
rounding of the transition (see Section 16.2.1).
And this is in fact what we do see. In each of these two cases S is close to
zero below a certain value of φ, then grows rapidly but with a certain amount
622

16.5

|

C OMPUTER ALGORITHMS FOR PERCOLATION

of rounding near the transition. Overall, other than the rounding, the shape
of the curves is qualitatively similar to that of Fig. 16.4. One could even tentatively make an estimate of the percolation transition, which appears to fall
around φ = 0.6 or 0.7 in both networks.
The bottom two frames in the ﬁgure tell a different story. These show results for percolation on the Internet and a social network. Both of these networks have approximately power-law degree distributions and thus, based on
the insights of Section 16.2.1, might be expected to show no percolation transition (or a transition at φ = 0 if you prefer) and non-linear growth of the largest
cluster with growing φ. Again our expectations seem to be borne out, at least
qualitatively, by the numerical results. In both networks the value of S appears
to take non-zero values for all φ > 0 and the initial growth for small φ shows
some curvature, indicating non-linear behavior.
Thus our percolation theory for random graphs seems in this case to provide a good general guide to the robustness of networks. The power-law networks are robust against random removal of vertices, in the sense that a fraction of the vertices that haven’t been removed remain connected in a large
cluster even when most vertices have been removed. The non-power-law networks, by contrast, become essentially disconnected after relatively few vertices have been removed—just about 40% in this case.
Figure 16.11 shows results for the same four networks when vertices are removed in order of degree, highest degrees ﬁrst. As we can see, this “attack” on
the network is more effective at reducing the size of the largest component than
is random removal for all four networks. However, the difference between
Figs. 16.10 and 16.11 is not so great for the ﬁrst two networks, the power grid
and the road network. The giant component in both of these networks survives
nearly as long under the targeted attack as under random removal. This is as
we would expect, since neither has a signiﬁcant number of very high-degree
vertices (the road network, with maximum degree four, has none at all), so that
removal of the highest-degree vertices is not so very different from the removal
of vertices of average degree.
For the second two networks, however, the Internet and the collaboration
network, which both have roughly power-law degree distributions, the effect
is far larger. Where these networks were more resilient to random removal
than they others, they are clearly less resilient, at least by this measure, to targeted attack. The Internet in particular has a largest cluster size that falls essentially to zero when only about 5% of its highest-degree vertices have been
removed, a behavior similar again to our theoretical calculations (see Fig. 16.7
on page 613). Thus the real Internet appears to show the mix of robust and
fragile behavior that we saw in our calculations for the conﬁguration model,
623

P ERCOLATION AND NETWORK RESILIENCE

1

Power grid

Road network

Internet

Social network

Size of largest cluster S

0.5

0
1

0.5

0

0

0.5

1

0

0.5

1

Fraction of vertices present φ

Figure 16.11: Size of the largest percolation cluster as a function of occupation probability for targeted attacks on four networks. The four frames in this ﬁgure show the
size of the largest cluster, measured as a fraction of network size, for the same four
networks as Fig. 16.10, when vertices are removed in degree order, highest-degree vertices ﬁrst. Since this is mostly a deterministic process and not a random one (except for
random choices between vertices of the same degree) the curves cannot be averaged as
in Fig. 16.10 and so are relatively jagged.

being remarkably resilient to the random removal of vertices but far more susceptible to targeted attacks.
Overall, therefore, the percolation theory seems to be successful as a qualitative guide to the resilience of networks. Certainly it does not perfectly predict
the exact behavior of individual networks, but it gives a good feel for the behavior we expect of networks as vertices fail or are removed, as a function of
their degree distribution.
In the next chapter we will see another application of percolation, to the
spread of diseases in networks.

624

P ROBLEMS

P ROBLEMS
16.1 Consider the problem of bond percolation on a square lattice and consider the
following construction:

Here we have taken a bond percolation system (in black) and constructed another one
interlocking it (in gray), such that the bonds of the new system are occupied if and only
if the intersecting bond on the old system was not. Such an interlocking system is called
a dual lattice.
a) If the fraction of occupied bonds on the original lattice is φ, what is the fraction of
occupied bonds on the dual lattice?
b) Show that there is a path from top to bottom of the dual lattice if and only if there
is no path from side to side of the original lattice.
c) Hence show that the percolation transition for the square lattice occurs at φ = 12 .
16.2 Consider the site percolation problem with occupation probability φ on a Poisson
random graph with mean degree c. Let πs be the probability that a vertex belongs to
an non-giant percolation cluster of s vertices and deﬁne a generating function h(z) =
∞
∑ s =0 π s z s .
a) Show that h(z) = 1 − φ + φzec[h(z)−1] .
b) Hence show that the mean size of a small cluster in the non-percolating regime
(no giant cluster) is
φ
.
s =
1 − cφ
c) Deﬁne f (z) = [h(z) − 1 + φ]/φ. Using the Lagrange inversion formula, Eq. (12.49),
solve for the coefﬁcients in the series expansion of f (z) and hence show that

πs =

1−φ
φe−scφ (scφ)s−1/s!

if s = 0,
if s > 0.

16.3 Consider a conﬁguration model network that has vertices of degree 1, 2, and 3
only, in fractions p1 , p2 , and p3 , respectively.

625

P ERCOLATION AND NETWORK RESILIENCE

a) Find the value of the critical vertex occupation probability φc at which site percolation takes place on the network.
b) Show that there is no giant cluster for any value of the occupation probability φ if
p1 > 3p3 . Why does this result not depend on p2 ?
c) Find the size of the giant cluster as a function of φ. (Hint: you may ﬁnd it useful
to remember that u = 1 is always a solution of the equation u = 1 − φ + φg1 (u).)
16.4 In Section 16.3 we examined what happens when the highest-degree vertices are
removed from a conﬁguration model network with a power-law degree distribution
pk = k−α /ζ (α) for k ≥ 1 and p0 = 0.
a) Show that in this case the phase transition at which the giant cluster disappears
occurs when all vertices with degree k > k0 have been removed, where the cut-off
parameter k0 satisﬁes
k0

∑ ( k − α +2 − k − α +1 ) = ζ ( α − 1 ) .

k =1

− x = ζ ( x ), and making use of the trapezoidal
b) Using the fact that ∑1k0 k−x + ∑∞
k 0 +1 k
rule (Eq. (14.115) on page 524) for large values of k, show that
k0

∑ k−x ≃ ζ (x) − 21 (k0 + 1)−x −
1

( k 0 + 1 ) − x +1
.
x−1

c) Keeping leading-order terms in k0 only, show that the giant cluster disappears
approximately when

(k0 + 1)−α+3 = (α − 3) ζ (α − 2) − 2ζ (α − 1) .
d) Find the approximate value of k0 at the point where the giant cluster disappears
for α = 2.5.
16.5 Consider the computer algorithm for percolation described in Section 16.5, but
suppose that upon the addition of an edge between two clusters we relabel not the
smaller of the two clusters but one or the other chosen at random. Show by an argument
analogous to the one in Section 16.5 that the worst-case running time of this algorithm
is O(n2 ), which is substantially worse than the O(n log n) of the algorithm that always
relabels the smaller cluster.

626

C HAPTER 17

E PIDEMICS ON NETWORKS
An introduction to the theory of the epidemic processes
by which diseases spread over networks of contact
between humans, animals, plants, and even computers

O

NE OF the reasons for the large investment the scientiﬁc community has

made in the study of social networks is their connection with the spread
of disease. Diseases spread over networks of contacts between individuals:
airborne diseases like inﬂuenza or tuberculosis are communicated when two
people breathe the air in the same room; contagious diseases and parasites can
be communicated when people touch; HIV and other sexually transmitted diseases are communicated when people have sex. The patterns of such contacts
can be represented as networks and a good deal of effort has been devoted
to empirical studies of these networks’ structure. We have already discussed
some network aspects of epidemiology in the previous chapter when we considered site percolation as a model for the effects of vaccination. In this chapter
we look in more detail at the connections between network structure and disease dynamics and at mathematical theories that allow us to understand and
predict the outcomes of epidemics.
On a related topic, recent years have seen the emergence of a new type of infection, the computer virus, a self-reproducing computer program that spreads
from computer to computer in a manner similar to the spread of pathogenic infections between humans or animals. Many of the ideas described in this chapter can be applied not only to human diseases but also to computer viruses.

17.1

M ODELS OF THE SPREAD OF DISEASE

The biology of what happens when an individual (a “host” in the epidemiology jargon) catches an infection is complicated. The pathogen responsible
627

E PIDEMICS ON NETWORKS

for the infection typically multiplies in the body while the immune system
attempts to beat it back, often causing symptoms in the process. One or the
other usually wins in the end, though sometimes neither, with the ﬁnal result
being the individual’s recovery, their death, or a chronic disease state of permanent infection. In theory if we want to understand fully how diseases spread
through populations we need to take all of this biology into account, but in
practice that’s usually a dauntingly large job and it is rarely, if ever, attempted.
Luckily there are more tractable approaches based on simpliﬁed models of disease spread that give a good guide to disease behavior in many cases and it is
on these that we focus in this chapter.

17.2

T HE SI MODEL

In the typical mathematical representation of an epidemic the within-host dynamics of the disease is reduced to changes between a few basic disease states.
In the simplest version there are just two states, susceptible and infected. An
individual in the susceptible state is someone who does not have the disease
yet but could catch it if they come into contact with someone who does. An
individual in the infected state is someone who has the disease and can, potentially, pass it on if they come into contact with a susceptible individual.1
Although this two-state classiﬁcation sweeps a lot of biological details under
the rug, it captures some of the gross features of disease dynamics and is a
useful simpliﬁcation in the case where, as here, we are focused more on what’s
happening at the level of networks and populations than on what’s happening
within the bodies of the individual population members.
Mathematical modeling of epidemics predates the study of networks by
many years, stretching back at least as far as the pioneering work of Anderson
McKendrick, a doctor and amateur mathematician who made foundational
contributions to the ﬁeld early in the twentieth century. The theories that he
and others developed form the core of traditional mathematical epidemiology,
which is an extensive and heavily researched ﬁeld. Classic introductions to the
1
If you look at the epidemiology literature you will sometimes see the infected state referred
to as “infective.” There’s no difference between the two terms; they are synonymous. You may
also see the word “infectious” used, but this may mean something slightly different. As discussed
later in the chapter, more sophisticated models of disease distinguish between a state in which an
individual has a disease but it has not yet developed to the point where the individual can pass
it on, and a state where they can pass it on. This latter stage is sometimes called the “infectious”
stage, a name chosen to emphasize that the disease can be communicated. (The former state is
usually called the “exposed” state.) In the present simple two-state model, however, there is no
difference between infected and infectious; all individuals who are one are also the other.

628

17.2

subject include the highly theoretical 1975 book by Bailey [25] and the more
recent and practically oriented book by Anderson and May [17]. The review
article by Hethcote is also a good resource [156].
The traditional approach avoids discussing contact networks at all by making use of a fully mixed or mass-action approximation, in which it is assumed that
every individual has an equal chance, per unit time, of coming into contact
with every other—people mingle and meet completely at random in this approach. This is, of course, not a realistic representation of the way the world is.
In the real world, people have contact with only a small fraction of the population of the world, and that fraction is not chosen at random, which is precisely
why networks play an important role in the spread of disease. Nonetheless,
a familiarity with the traditional approaches will be useful to us in our study
of network epidemiology, so we will spend a little time looking at its basic
principles.
Consider a disease spreading through a population of individuals. Let S(t)
be the number of individuals who are susceptible at time t and let X (t) be the
number who are infected.2 Technically, since the disease-spreading process
is a random one, these numbers are not uniquely determined—if the disease
were to spread through the same population more than once, even under very
similar conditions, the numbers would probably be different each time. To get
around this problem let us deﬁne S and X more carefully to be the average
or expected numbers of susceptible and infected individuals, i.e., the numbers
we would get if we ran the process many times under identical conditions and
then averaged the results.3
The number of infected individuals goes up when susceptible individuals
contract the disease from infected ones. Suppose that people meet and make
contacts sufﬁcient to result in the spread of disease entirely at random with a
per-individual rate β, meaning that each individual has, on average, β contacts
with randomly chosen others per unit time.
The disease is transmitted only when an infected person has contact with a
susceptible one. If the total population consists of n people, then the average
probability of a person you meet at random being susceptible is S/n, and hence
an infected person has contact with an average of βS/n susceptible people per
unit time. Since there are on average X infected individuals in total that means
the overall average rate of new infections will be βSX/n and we can write a

|

T HE SI MODEL

S

I

The allowed transitions between states can be represented by ﬂow charts like
this simple one for the SI
model.

2
It might be more logical to use I (t) for the number infected, and many authors do so, but we
use X instead to avoid later confusion with the index i used to label vertices.
3
For convenience we will usually drop the explicit t-dependence of S(t) and X (t) and, as here,
just write S and X.

629

E PIDEMICS ON NETWORKS

differential equation for the rate of change of X thus:
SX
dX
.
(17.1)
=β
dt
n
At the same time the number of susceptible individuals goes down at the same
rate:
SX
dS
= −β
.
(17.2)
dt
n
This simple mathematical model for the spread of a disease is called the fully
mixed susceptible–infected model, or SI model for short.
It is often convenient to deﬁne variables representing the fractions of susceptible and infected individuals thus:
X
S
,
x= ,
n
n
in terms of which Eqs. (17.1) and (17.2) can be written
s=

ds
= − βsx,
dt
dx
= βsx.
dt

(17.3)

(17.4a)
(17.4b)

In fact, we don’t really need both of these equations, since it is also true that
S + X = n or equivalently s + x = 1 because every individual must be either
susceptible or infected. With this condition it is easy to show that Eqs. (17.1)
and (17.2) are really the same equation. Alternatively, we can eliminate s from
the equations altogether by writing s = 1 − x, which gives
dx
= β(1 − x ) x.
(17.5)
dt
This equation, which occurs in many places in biology, physics, and elsewhere,
is called the logistic growth equation. It can be solved using standard methods
to give
x0 eβt
(17.6)
x (t) =
1 − x0 + x0 eβt
where x0 is the value of x at t = 0. Generically this produces an S-shaped
“logistic growth curve” for the fraction of infected individuals, as shown in
Fig. 17.1. The curve increases exponentially for short time, corresponding to
the initial phase of the disease in which most of the population is susceptible,
and then saturates as the number of susceptibles dwindles and the disease has
a harder and harder time ﬁnding new victims.4
4

630

There aren’t many diseases that really saturate their population like this. Most real diseases

17.3

|

T HE SIR MODEL

Fraction infected x

1

0.5

0

0

2

4

6

8

10

Time t
Figure 17.1: The classic logistic growth curve of the SI epidemic model. A small
initial number of infected individuals in an SI model (1% in this example) will at ﬁrst
grow exponentially as they infect others, but growth eventually saturates as the supply
of susceptible individuals is exhausted, and the curve levels off at x = 1.

17.3

T HE SIR MODEL

The SI model is the simplest possible model of infection. There are many ways
in which it can be extended to make it more realistic or more appropriate as a
model of speciﬁc diseases. One common extension deals with recovery from
disease.
In the SI model individuals, once infected, are infected (and infectious) forever. For many real diseases, however, people recover from infection after a
certain time because their immune system ﬁghts off the agent causing the disease. Furthermore, people often retain their immunity to the disease after such
a recovery so that they cannot catch it again. To represent this behavior in our
that don’t kill their victims are eventually defeated by the immune system. In addition, for many
diseases some fraction of the population has a natural immunity that prevents them from being
infected (meaning that when exposed to the pathogen their immune system sees it off so quickly
that they never become infectious). And some diseases spread so slowly that a large fraction of the
population never catches them because they die of other causes ﬁrst. None of these phenomena is
represented in this model.

631

E PIDEMICS ON NETWORKS

S

I

R

The ﬂow chart for the SIR
model.

model we need a new third disease state, usually denoted R for recovered. The
corresponding three-state model is called the susceptible–infected–recovered or
SIR model.
With some other diseases people do not recover, but instead die after some
interval. Although this is the complete opposite of recovery in human terms,
it is essentially the same thing in epidemiological terms: it makes little difference to the disease whether a person is immune or dead—either way they
are effectively removed from the pool of potential hosts for the disease.5 Both
recovery and death can be represented by the R state in our model. Diseases
with mixed outcomes where people sometimes recover and sometimes die can
also be modeled in this way—from a mathematical point of view we don’t care
whether the individuals in the R state are recovered or dead. For this reason
some people say that the R stands for removed rather than recovered, so as to
encompass both possibilities, and they refer to the corresponding model as the
susceptible–infected–removed model.
The dynamics of the fully mixed SIR model has two stages. In the ﬁrst
stage, susceptible individuals become infected when they have contact with
infected individuals. Contacts between individuals are assumed to happen at
an average rate β per person as before. In the second stage, infected individuals recover (or die) at some constant average rate γ.
Given the value of γ we can calculate the length of time τ that an infected
individual is likely to remain infected before they recover. The probability of
recovering in any time interval δτ is γ δτ and the probability of not doing so
is 1 − γ δτ. Thus the probability that the individual is still infected after a total
time τ is given by
(17.7)
lim (1 − γ δτ )τ/δτ = e−γτ ,
δτ →0

and the probability p(τ ) dτ that the individual remains infected this long and
then recovers in the interval between τ and τ + dτ is this quantity times γ dτ:
p(τ ) dτ = γe−γτ dτ,

(17.8)

5
This is only approximately true. If people really do have a certain average number of contacts per unit time and assuming those contacts are with living people, then the presence of living
but recovered people in the population reduces the number of contacts between infected and susceptible individuals. If, on the other hand, people die rather than recover from the disease then
only susceptible and infected individuals are alive and the number of contacts between them will
be correspondingly greater. In effect, a person whose acquaintance dies from the disease will (on
average) gain one new acquaintance from among the living to replace them, and that new acquaintance might be infected, or might become infected, thereby increasing the chance of transmission
of the disease. This effect can easily be incorporated into the model, but we don’t do so here.

632

17.3

which is a standard exponential distribution. Thus an infected person is most
likely to recover just after becoming infected, but might in theory remain in
the infected state for quite a long time—many times the mean infectious time
(which is just 1/γ).
Neither of these behaviors is very realistic for most real diseases. With real
diseases, most victims remain infected for about the same length of time, such
as a week, say, or a month. Few stay in the infected state for much longer or
shorter than the average (see ﬁgure). Nonetheless, we will for the moment
stick with this model because it makes the mathematics simple. This is one
thing that will improve when we come to look at network models of epidemics.
In terms of the fractions s, x, and r of individuals in the three states, the
equations for the SIR model are
ds
= − βsx,
dt
dx
= βsx − γx,
dt
dr
= γx,
dt

(17.9a)
(17.9b)

|

T HE SIR MODEL

The distribution of times
for which an individual remains infected is typically
narrowly peaked around
some average value for
real diseases, quite unlike
the exponential distribution assumed by the SIR
model.

(17.9c)

and in addition the three variables necessarily satisfy
s + x + r = 1.

(17.10)

To solve these equations we eliminate x between Eqs. (17.9a) and (17.9c),
giving
1 ds
β dr
,
(17.11)
=−
s dt
γ dt
and then integrate both sides with respect to t to get:
s = s0 e− βr/γ ,

(17.12)

where s0 is the value of s at t = 0 and we have chosen the constant of integration so that there are no individuals in the recovered state at t = 0. (Other
choices are possible but we’ll use this one for now.)
Now we put x = 1 − s − r in Eq. (17.9c) and use Eq. (17.12) to get


dr
= γ 1 − r − s0 e− βr/γ .
dt

(17.13)

If we can solve this equation for r then we can ﬁnd s from Eq. (17.12) and x
from Eq. (17.10).
The solution is easy to write down in principle. It is given by
t=

1
γ

 r

du
.
− βu/γ
0 1 − u − s0 e

(17.14)
633

E PIDEMICS ON NETWORKS

1
Susceptible

Fraction of population

0.8
Recovered

0.6

0.4

Infected

0.2

0

0

5

10

15

20

Time t

Figure 17.2: Time evolution of the SIR model. The three curves in this ﬁgure show
the fractions of the population in the susceptible, infected, and recovered states as a
function of time. The parameters are β = 1, γ = 0.4, s0 = 0.99, x0 = 0.01, and r0 = 0.

Unfortunately, in practice we can’t evaluate the integral in closed form. We can
however evaluate it numerically. An example is shown in Fig. 17.2.
There are a number of notable things about this ﬁgure. The fraction of
susceptibles in the population decreases monotonically as susceptibles are infected and the fraction of recovered individuals increases monotonically. The
fraction infected, however, goes up at ﬁrst as people get infected, then down
again as they recover, and eventually goes to zero as t → ∞.
Note however that the number of susceptibles does not go to zero; a close
inspection shows that the curve for s(t) ends a little above the axis. This is because when x → 0 there are no infected individuals left to infect the remaining
susceptibles. Any individuals who survive to late enough times without being
infected will probably never get the disease at all. They are the lucky ones who
made it through the outbreak and out the other side. Similarly the fraction of
recovered individuals does not quite reach one as t → ∞.
The asymptotic value of r has an important practical interpretation: it is
the total number of individuals who ever catch the disease during the entire
course of the epidemic—the total size of the outbreak. It can be calculated from
Eq. (17.13) as the value at which dr/dt = 0, which gives r = 1 − s0 e− βr/γ .

634

17.3

|

T HE SIR MODEL

The initial conditions for the model can be chosen in a variety of ways,
but the most common is to assume that the disease starts with either a single
infected individual or a small number c of individuals and everyone else in
the susceptible state. In other words, the initial values of the variables are
s0 = 1 − c/n, x0 = c/n, and r0 = 0. In the limit of large population size
n → ∞, we can then write s0 ≃ 1, and our ﬁnal value of r satisﬁes
r = 1 − e− βr/γ .

(17.15)

Interestingly, this is the same as the equation we derived in Section 12.5 for the
size S of the giant component of a Poisson random graph, Eq. (12.15), provided
we equate β/γ with the mean degree of the random graph, and this correspondence allows us immediately to say several useful things. First, we know what
the size of the epidemic must look like (in the limit of large n) as a function
of the parameters β and γ: it will look like the plot of giant component size
shown in the right-hand panel of Fig. 12.1 on page 406, with c = β/γ. Second,
it tells us that the size of the epidemic goes continuously to zero as β/γ approaches one from above and for β/γ ≤ 1, or equivalently β ≤ γ, there is no
epidemic at all. The simple explanation for this result is that if β ≤ γ then infected individuals recover faster than susceptible individuals become infected,
so the disease cannot get a toehold in the population. The number of infected
individuals, which starts small, goes down, not up, and the disease dies out
instead of spreading.
The transition between the epidemic and non-epidemic regimes happens
at the point β = γ and is called the epidemic transition. Note that there was no
epidemic transition in the simpler SI model: in that model the disease always
spreads because individuals once infected never recover and hence the number
of infected individuals cannot decrease. (One can think of the SI model as the
special case of the SIR model in which γ = 0, so that β can never be less than γ.)
An important quantity in the study of epidemics is the basic reproduction
number, denoted R0 , which is deﬁned as follows. Consider the spread of a disease when it is just starting out, when there are only a few cases of the disease
and the rest of the population is susceptible—what is called a naive population in
the epidemiology jargon—and consider a susceptible who catches the disease
in this early stage of the outbreak. The basic reproduction number is deﬁned
to be the average number of additional people that such a person passes the
disease onto before they recover. For instance, if each person catching the disease passes it onto two others on average, then R0 = 2. If half of them pass it
on to just one person and the rest to none at all, then R0 = 12 , and so forth.
If we had R0 = 2 then each person catching the disease would pass it on
to two others on average, each of them would pass it on to two more, and so
635

E PIDEMICS ON NETWORKS

forth, so that the number of new cases of the disease would double at each
round, thus growing exponentially. Conversely if R0 = 12 the disease would
die out exponentially. The point R0 = 1 separates the growing and shrinking
behaviors and thus marks the epidemic threshold between regimes in which the
disease either multiplies or dies out.
We can calculate R0 straightforwardly for our model. If an individual remains infectious for a time τ then the expected number of others they will
have contact with during that time is βτ. The deﬁnition of R0 is speciﬁcally for
a naive population, and in a naive population all of the people with whom one
has contact will be susceptible, and hence βτ is also the total number of people
our infected individual will infect. Then we average over the distribution of τ,
Eq. (17.8), to get the average number R0 :
R0 = βγ

 ∞
0

τe−γτ dτ =

β
.
γ

(17.16)

This gives us an alternative way of deriving the epidemic threshold in the
SIR: the epidemic threshold falls at R0 = 1, which corresponds in this model
to the point β = γ, the same result as we found above by considering the
long-time behavior.6

17.4

S

I

Flow chart for the SIS
model.

T HE SIS MODEL

A different extension of the SI model is one that allows for reinfection, i.e., for
diseases that don’t confer immunity on their victims after recovery, or confer
only limited immunity, so that individuals can be infected more than once.
The simplest such model is the SIS model, in which there are just two states,
susceptible and infected, and infected individuals move back into the susceptible state upon recovery. The differential equations for this model are
ds
= γx − βsx,
dt
dx
= βsx − γx,
dt

(17.17a)
(17.17b)

with
s + x = 1.

(17.18)

Note that when γ = 0, as in the SI model, Eq. (17.16) implies that R0 → ∞. This is because an
infected individual remains infected indeﬁnitely in the SI model and hence can infect an arbitrary
number of others, so that R0 is formally inﬁnite. In any population of ﬁnite size, however, the
empirical value of R0 will be ﬁnite.
6

636

17.5

|

T HE SIRS MODEL

Putting s = 1 − x in Eq. (17.17b) gives
dx
= ( β − γ − βx ) x,
dt

(17.19)

which has the solution
x (t) = (1 − γ/β)

Ce( β−γ)t
,
1 + Ce( β−γ)t

(17.20)

where the integration constant C is ﬁxed by the initial value of x to be
C=

βx0
.
β − γ − βx0

(17.21)

In the case of a large population and a small number of initial carriers of the
disease we have x0 → 0 and C = βx0 /( β − γ), which gives us the simpler
solution
( β − γ )e( β − γ ) t
.
(17.22)
x ( t ) = x0
β − γ + βx0 e( β−γ)t
If β > γ this produces a logistic growth curve similar to that of the basic SI model—see Fig. 17.3—but differing in one important respect: we never
have the whole population infected with the disease. In the limit of long time
the system ﬁnds a stable state where the rates at which individuals are infected and recover from infection are exactly equal and a steady fraction of the
population—but not all of them—is always infected with the disease. (Which
particular individuals are infected changes over time, however, as some recover and others are infected.) The fraction of infected individuals can be
found from Eq. (17.22), or more directly from Eq. (17.19) by setting dx/dt = 0
to give x = ( β − γ)/β. In the epidemiology jargon the steady state is called an
endemic disease state.
Note that the fraction infected in the endemic state goes to zero as β approaches γ, and if β < γ then Eq. (17.22) predicts that the disease will die out
exponentially. Thus, as in the SIR model, the point β = γ marks an epidemic
transition between a state in which the disease spreads and one in which it
doesn’t. As before, we can calculate a basic reproduction number R0 , which
again takes the value R0 = β/γ, giving us an alternative derivation of the
position of the transition as the point at which R0 = 1.

17.5

T HE SIRS MODEL

We will look at one more epidemic model before we turn to the properties
of these models on networks. This is the SIRS model, another model incorporating reinfection. In this model individuals recover from infection and gain
637

E PIDEMICS ON NETWORKS

Fraction infected x

1

0.5

0

0

10

5

Time t
Figure 17.3: Fraction of infected individuals in the SIS model. The fraction of infected individuals in the SIS model grows with time following a logistic curve, as in
the SI model. Unlike the SI model, however, the fraction infected never reaches unity,
tending instead to an intermediate value at which the rates of infection and recovery
are balanced. (Compare this ﬁgure with Fig. 17.1 for the SI model.)

S

I

R

immunity as in the SIR model, but that immunity is only temporary, and after
a certain period of time individuals lose it and become susceptible again. We
introduce a new parameter δ to represent the average rate at which individuals
lose immunity. Then the equations for this model are

Flow chart for the SIRS
model

ds
= δr − βsx,
dt
dx
= βsx − γx,
dt
dr
= γx − δr,
dt

(17.23b)

s + x + r = 1.

(17.24)

(17.23a)

(17.23c)

and
The SIRS model cannot be solved analytically, although it can be treated
using linear stability analysis and other tricks from the non-linear dynamics
toolbox. A more straightforward approach is numerical integration of the dif638

17.6

|

E PIDEMIC MODELS ON NETWORKS

ferential equations, which reveals that the SIRS model has a rich palette of behaviors depending on the values of the three parameters, including behaviors
where the disease persists in an endemic state, where it dies out, and where it
oscillates between outbreaks and periods of remission. We will not delve into
the behavior of the SIRS model further in this chapter; the interested reader
can ﬁnd more details in Ref. [156].

Many other epidemic models have also been proposed to model the spread
of particular types of diseases. Extra states can be introduced such as an “exposed” state that represents people who have caught a disease but whose infection has not yet developed to the point where they can pass it on to others; or
an initial immune state coming before the susceptible state, often used to represent the maternally derived immunity that newborn babies possess. There
are also models that allow for new individuals to enter the population, by being born or immigrating, and models that distinguish between people who
recover fully from disease and those who recover but remain carriers who can
pass the disease to others. Those interested in pursuing the subject further are
encouraged to take a look at the references given at the beginning of the chapter. For our purposes, however, the models we have seen so far will be enough.
Let’s look at how these models behave when we include network structure in
our calculations.

17.6

E PIDEMIC MODELS ON NETWORKS

As discussed in Section 17.2, the standard approach to epidemic modeling described in the ﬁrst part of this chapter assumes “full mixing” of the population, meaning that each individual can potentially have contact with any other,
those contacts being realized, at a level sufﬁcient to transmit the disease, with
probability β per unit time.
In the real world, however, it is not a good assumption to say that any
two people could potentially have contact with one another. The chance of
a meeting between two people chosen at random from the population of the
entire world is probably small enough to be negligible. Most people have a set
of regular acquaintances, neighbors, coworkers, and so forth whom they meet
with some regularity and most other members of the world population can
safely be ignored. The set of a person’s potential contacts can be represented
as a network and the structure of that network can have a strong effect on the
way a disease spreads through the population.
Network models of disease typically work in the same way as the fully
639

E PIDEMICS ON NETWORKS

mixed models we have already seen but make use of this network of potential
contacts instead of assuming that contact is possible with the entire population. Let us deﬁne the transmission rate or infection rate for our network disease
process to be the probability per unit time that infection will be transmitted
between two individuals, one susceptible and one infected, who are connected
by an edge in the appropriate network. Alternatively it is the rate at which
contact sufﬁcient to spread the disease occurs between any two individuals
connected by an edge. The transmission rate is commonly denoted β by analogy with the quantity appearing in the fully mixed models, and we will adopt
that notation here, although you should note that the two parameters are not
exactly equivalent since β in the fully mixed case is the rate of contacts between
an infected individual and all others in the population, whereas in the network
case it is the rate of contacts with just one other.
The transmission rate is a property of the disease. Some diseases are transmitted more easily than others and so have higher transmission rates. But
transmission rate is also a property of the social and behavioral parameters of
the population. In some countries, for example, it is common etiquette for people with minor respiratory infections such as colds to wear surgical face masks
to prevent the spread of disease. Such conventions are absent in other countries, and the difference in conventions could produce a difference in transmission rate.

17.7

L ATE - TIME PROPERTIES OF EPIDEMICS ON NETWORKS

Given a value for the transmission rate one can deﬁne models for the spread
of disease over a network. Each of the models introduced in the ﬁrst part of
the chapter can be generalized to the network case. Consider the SI model,
for instance. In the network version of this model we have n individuals represented by the vertices of our network, with most of them in the susceptible
state at time t = 0 and just a small fraction x0 , or maybe even just a single
vertex, in the infected state. With probability β per unit time, infected nodes
spread the disease to their susceptible neighbors and over time the disease
spreads across the network.
It is difﬁcult to solve a model such as this for a general network, and in
many cases the best we can do is to simulate it on a computer. There is, however, one respect in which the model is straightforward, and that is its late-time
properties. It is clear that as t → ∞ in this model every individual who can be
infected by the disease is infected: since infected individuals remain infectious
forever, their susceptible neighbors will always, in the end, also become infected, no matter how small the transmission rate, so long as it is not zero. The
640

17.7

|

L ATE - TIME PROPERTIES OF EPIDEMICS ON NETWORKS

only condition for being infected therefore is that a vertex must be connected
to at least one infected individual by at least one path through the network, so
that the disease can reach them.
Thus in the limit of long times the disease will spread from every initial
carrier to infect all reachable vertices, meaning all vertices in the component
to which the carrier belongs. In the simplest case, where the disease starts out
with a single infected carrier, just one component will be infected.
As we have seen, however, most networks have a one large component that
contains a signiﬁcant fraction of all vertices in the network, plus, typically, a
selection of smaller components. If we have this kind of structure then an interesting behavior emerges. If we start with a single infected individual, and
if that individual turns out to belong to the large component, then the disease
will infect the large component and we will have a large outbreak. If the individual belongs to one of the small components, however, the disease will
only infect the few members of that small component and then die out. If
the initial carrier of the disease is chosen uniformly at random from the network, the probability that it will fall in the large component and we will have
a large outbreak is simply equal to S, the fraction of the network occupied by
the large component, and the size of the outbreak as a fraction of the network
will also be S. Conversely, with probability 1 − S the initial carrier will fall
in one of the small components and the outbreak will be small. In the latter
case the size of the outbreak will be given by the size of the appropriate small
component. If we can calculate the distribution of sizes of the small components, either analytically or numerically, for the network of interest, then we
also know the distribution of possible sizes of these small outbreaks, although
unless we know exactly which component the disease will start in we cannot
predict its size exactly.
This constitutes a new type of behavior not seen in fully mixed models. In
fully mixed models the possible behaviors are also either a run-away epidemic
that affects a large fraction of the population, or an outbreak that affects only a
few then dies out. But the choice between these outcomes was uniquely determined by the choice of model and the model parameters. For a given model
and parameter values the disease always either did one thing or the other. In
our network model, however, the behavior depends on the network structure
and on the position in the network of the ﬁrst infected individual. Thus there
is a new stochastic element in the process: with identical model parameters
and an identical network the disease sometimes takes off and sometimes dies
out.

An outbreak starting with
a single infected individual (circled) will eventually affect all those in the
same component of the network, but leave other components untouched.

641

E PIDEMICS ON NETWORKS

17.8

L ATE - TIME PROPERTIES OF THE SIR MODEL

The situation becomes more interesting still when we look at the SIR model.
In the SIR model individuals remain infectious for only a ﬁnite amount of time
and then they recover, so it is in general no longer true (as in the SI model) that
the susceptible neighbor of an infected individual will always get infected in
the end. If they are lucky, such neighbors may never catch the disease. The
probability of this happening can be calculated in a manner similar to the calculation of Eq. (17.7), and is equal to e− βτ , where β is again the transmission
rate and τ is the amount of time for which the infected individual remains
infected. Thus the probability that the disease is transmitted is
φ = 1 − e− βτ .

(17.25)

For simplicity, let us suppose that every infected individual remains infectious for the same length of time. This differs from the fully mixed version of
the model, where τ was distributed according to an exponential distribution
(see Eq. (17.8)), but in many cases is actually more realistic. As mentioned in
Section 17.3, observed values of τ for many diseases are narrowly concentrated
about a mean value, and their distribution is far from being exponential.
With this assumption, the probability of transmission φ is a constant across
the whole network. Every susceptible individual has equal probability φ of
catching the disease from their infected neighbor. (Of course, if they have more
than one infected neighbor the total probability is higher.)
Now here is a nice trick, developed originally by Mollison [223] and Grassberger [144]. Let us take our network and “color in” or “occupy” each edge
with probability φ, or not with probability 1 − φ. This is just the ordinary
bond percolation process introduced in Section 16.1, where a fraction φ of
edges are occupied uniformly at random. The occupied edges represent those
along which disease will be transmitted if it reaches either of the vertices at
the ends of the edge. That is, the occupied edges represent contacts sufﬁcient
to spread the disease, but not necessarily actual disease transmission: if the
disease doesn’t reach either end of an occupied edge then disease will not be
transmitted along that edge, so edge occupation only represents the potential
for transmission if the disease reaches an edge.
With this in mind consider now the spread of a disease that starts at a randomly chosen vertex. We can immediately see that the set of vertices to which
the disease will ultimately spread is precisely the set connected to the initial
vertex by any path of occupied edges—the disease simply passes from one
vertex to another by traversing occupied edges until all reachable vertices have
been infected. The end result is that the disease infects all members of the bond
642

17.8

(a) φ = 0.2

|

L ATE - TIME PROPERTIES OF THE SIR MODEL

(b) φ = 0.5

(c) φ = 1

Figure 17.4: Bond percolation. In bond percolation, a fraction φ of the edges in a network are ﬁlled in or “occupied” at
random to create connected clusters of vertices. (a) For small occupation probability φ the clusters are small. (b) Above
the percolation threshold a large cluster forms, though there are usually still some small clusters as well. (c) When φ = 1
all edges are occupied but the large cluster may still not ﬁll the whole network: at φ = 1 the largest cluster corresponds
to the largest component of the network, which is often just a subset of the whole network.

percolation cluster to which the initial carrier belongs.
It is important to appreciate that, as with our treatment of the network SI
model in the previous section, this process does not give us any information
about the temporal evolution of the disease outbreak. Individual infection
events are stochastic and a calculation of the curve of infections as a function of
time requires a more complicated analysis that takes their randomness into account. However, if we want to know only about long-time behavior, about the
overall total number of individuals infected by the disease, then all we need
do is count the vertices in the appropriate percolation cluster.
Bond percolation is in many ways similar to the site percolation processes
we studied in Chapter 16. Consider Fig. 17.4. For low edge occupation probability φ there are just a few occupied bonds which group into small disconnected clusters. But as φ increases there comes a point, the percolation transition, where the disconnected clusters grow large enough to join together and
form a giant cluster, although usually there exist other small clusters as well
that are not joined to the giant cluster. As φ increases still further, the giant
cluster grows, reaching its maximum size when φ = 1. Notice, however, that
this maximum size is not generally equal to the size of the whole network.
Even when every edge in the network is occupied, the size of the largest cluster is still limited to the size of the largest component on the network, which is
usually smaller than the whole network.
Translating these ideas into the language of epidemiology, we see that for

643

E PIDEMICS ON NETWORKS

small values of φ the cluster to which the initial carrier of a disease belongs
must be small, since all clusters are small. Thus in this regime we will have
only a small disease outbreak and most members of the population will be uninfected. Once we reach the percolation transition, however, and a giant cluster
forms, then a large outbreak of the disease—an epidemic—becomes possible,
although not guaranteed. If the giant cluster of the percolation process occupies a fraction S of the entire network, then our randomly chosen initial vertex
will fall within it with probability S, and if it does then the disease will spread
to infect the whole giant cluster, creating an epidemic reaching a fraction of
the population also equal to S. With probability 1 − S, on the other hand, the
initial vertex will fall in one of the small clusters and we will have only a small
outbreak of the disease. As φ increases, S also increases and hence both the
probability and the size of an epidemic increase with φ.
Thus the percolation transition for bond percolation on our network corresponds precisely to the epidemic threshold for a disease on the same network,
where the edge occupation probability φ is given in terms of the transmission
rate β and recovery time τ for the disease by Eq. (17.25), and the sizes of outbreaks are given by the sizes of the bond percolation clusters. This mapping
between percolation and epidemics is a powerful one that allows us to make a
whole range of calculations of the effects of network structure on the spread of
disease.
It is important to note that even when φ is above the epidemic threshold
we are not guaranteed that there will be an epidemic. This is similar to the
situation we saw in the simpler SI model, but different from the situation in the
fully mixed SIR model of Section 17.3, where an epidemic always takes place
if we are above the epidemic threshold. In many ways the behavior of our
network model is more realistic than that of the fully mixed model. For many
diseases it is true that outbreaks do not always result in epidemics. Sometimes
a disease dies out because, just by chance, its earliest victims happen not to
pass the disease on to others. Our theory tells us that the probability of this
happening is 1 − S, where S is the size of the giant cluster, which is also the
size of the epidemic if it does happen. The value of 1 − S is usually small
when we are well above the epidemic threshold, but can be quite large if we
are only a little above threshold, meaning that the probability of the disease
dying out can be quite large in this regime.
It is also important to bear in mind that percolation is a stochastic process.
We occupy edges at random on our network to represent the random nature of
the contacts that result in transmission of the disease. Two outbreaks happening under the same conditions on the same networks would not necessarily
travel along the same edges and the shapes of the percolation clusters would
644

17.8

|

L ATE - TIME PROPERTIES OF THE SIR MODEL

not necessarily be the same. Thus a vertex that happens to belong to the giant cluster on one occasion might not belong to it on another and our theory
cannot make exact predictions about disease outcomes. The best we can do is
calculate probabilities or average behaviors. We could for instance calculate
the expected number of people who would be affected by an outbreak, but we
cannot predict the exact number for any given outbreak.
17.8.1

SIR MODEL AND THE CONFIGURATION MODEL

In Section 16.2.1 we showed that it is possible to calculate exactly the average
behavior of a site percolation process on conﬁguration model networks. With
only slight modiﬁcation the same approach can also be used for bond percolation and hence we can make predictions about the size distribution of epidemics and the position of the epidemic threshold in such networks.
Consider an SIR epidemic process of the kind discussed in the previous
section, taking place on a conﬁguration model network with degree distribution pk . Let u be the average probability that a vertex is not connected to the
giant cluster via a speciﬁc one of its edges. There are two ways this can happen: either the edge in question can be unoccupied (with probability 1 − φ), or
it is occupied (probability φ) but the vertex at the other end of the edge is itself
not a member of the giant cluster. The latter happens only if that vertex is not
connected to the giant cluster via any of its other edges, which happens with
probability uk if there are k such edges. Thus the total probability is 1 − φ + φuk .
The value of k is distributed according to the excess degree distribution
qk =

( k + 1 ) p k +1
k

(17.26)

(see Eq. (16.3)). Averaging over k we then arrive at a self-consistent expression
for u thus:
∞

u = 1 − φ + φ ∑ qk uk = 1 − φ + φg1 (u),

(17.27)

k =0

where g1 is the probability generating function for the excess degree distribution, deﬁned in Eq. (13.49). Equation (17.27) is the same as the corresponding
equation for the site percolation case, Eq. (16.4), and has the same solutions.
The probability that a vertex of total degree k does not belong to the giant
cluster is now simply uk , and the average such probability over the whole network, which is equal to 1 − S, is calculated by averaging uk over the degree
distribution pk giving
∞

S = 1 − ∑ p k u k = 1 − g0 ( u ) .

(17.28)

k =0

645

E PIDEMICS ON NETWORKS

This equation differs from the corresponding equation in the site percolation
case, Eq. (16.2), by an overall factor of φ, but is otherwise the same. Thus the
shape of the curve for S as a function of φ will be different from the site percolation case, but the position φc of the percolation transition, which is dictated
by the solution of Eq. (17.27), will be the same. The solution of Eq. (17.27) was
shown graphically in Fig. 16.2 and the position of the transition is given by
Eq. (16.7) to be
1
k
.
(17.29)
= 2
φc = 
g1 ( 1 )
k − k
This equation thus also gives us the position of the epidemic threshold in terms
of the probability φ. If we prefer our solution in terms of the more fundamental
parameters β and τ we can rearrange Eq. (17.25) to give
βτ = − ln(1 − φc ) = ln

k2 − k
.
k2 − 2 k

(17.30)

If βτ exceeds this value then there is the possibility of an epidemic, though
not the certainty, since the initial carrier or carriers of the disease could by
chance fall outside the giant cluster. If βτ is smaller than this value then an
epidemic is impossible, no matter where the initial carrier falls. The probability
of the epidemic, if one is possible, is given by S, Eq. (17.28), as is the size of the
epidemic if and when one occurs.
Since the epidemic behavior of the model is controlled by the combination
of parameters βτ, the epidemic transition can be driven either by an increase in
the infectiousness time τ, which is a property of the particular disease under
study, or by an increase in the transmission rate β, which is a property both
of the disease and of the behavior of members of the population. At the same
time, the precise position of the transition in terms of these variables, as well as
the probability and size of any epidemic that occurs, depend on the structure
of the network via the moments k and k2 of the degree distribution. This
contrasts with the fully mixed model of Section 17.3, which incorporated no
network effects.
Because of the close similarity between the site and bond percolation problems, we can easily translate a number of the results of Section 16.2.1 into the
language of epidemics. For instance, a random graph with a Poisson degree
distribution with mean c, which has g0 (z) = g1 (z) = ec(z−1) , has an epidemic
threshold falls at φc = 1/c (Eq. (16.11)), or
βτ = ln

646

c
,
c−1

(17.31)

17.8

|

L ATE - TIME PROPERTIES OF THE SIR MODEL

and the size of the epidemic, when there is one, is given by the solution to the
equations
S = 1 − ec ( u −1) .
(17.32)
u = 1 − φ + φec(u−1) ,
The ﬁrst of these equations can be rearranged to read 1 − u = φ(1 − ec(u−1) ) =
φS and substituting into the second then gives
S = 1 − e−φcS ,

(17.33)

which has no simple closed-form solution,7 but can easily be solved numerically by making an initial guess at the solution (S = 12 seems to work well) and
then iterating the equation to convergence.
Note that this equation is similar to Eq. (17.15) for the fully mixed model,
but with different parameters. The similarity is not coincidental. In the fully
mixed model an infected individual infects others chosen uniformly at random
from the population, and in the Poisson random graph the network neighbors
of any individual are also chosen uniformly at random. It is possible to show
that there is a direct correspondence between the traditional fully mixed model
and the network model on a random graph [30].8
Another important case is the scale-free network with its power-law degree
distribution. As we saw in Section 16.2.1, if the exponent α of the power law
in such a network lies in the usual range 2 < α < 3 then φc = 0, because
k2 diverges while k remains constant and hence Eq. (17.29) goes to zero.
Thus in the power-law case there is always an epidemic, no matter how small
the probability of transmission of the disease, at least in the limit of inﬁnite
network size. (For ﬁnite networks, k2 is not inﬁnite, but very large, and φc is
correspondingly very small, but not precisely zero.)
7

The solution can be written in closed form using the Lambert W-function, which is deﬁned to
be the solution of the equation W (z)eW (z) = z. In terms of this function, the size of the epidemic is
given by


W −φce−φc
.
S = 1+
φc
Alternatively, we can rearrange Eq. (17.33) to give φ as a function of S rather than the other way
around:
ln(1 − S)
φ=−
.
cS
This expression can be useful for making plots of S.
8
The differences in parameters arise because we are considering a slightly different disease
process (one in which each individual is infectious for the same amount of time, rather than the
exponential distribution used in the fully mixed model), and also because in the network model β
is the transmission rate per edge, rather than the rate for the whole network—this is what gives us
the factor of c in the exponent of Eq. (17.33).

647

E PIDEMICS ON NETWORKS

This statement is, however, slightly misleading since, as we saw in the previous chapter, the size of the giant cluster in a scale-free network becomes very
small as we approach φ = 0; it generally decays faster than linearly with φ.
Thus although technically there may be an epidemic for all positive values of φ,
it can be very small in practice, affecting only the tiniest fraction of the population. (On the other hand, the difference between non-epidemic behavior and
epidemic behavior, even with a tiny value of S, will become very important
when we look at models such as the SIS model that incorporate reinfection. In
such models the epidemic threshold separates the regime in which the disease
persists and the regime in which it becomes extinct, an important distinction
even if the number of individuals infected is small.)

17.9

T IME - DEPENDENT PROPERTIES OF EPIDEMICS ON NETWORKS

The techniques of the previous section can tell us about the late-time properties of epidemics on networks, such as how many people will eventually be
affected in an outbreak of a disease. If we want to know about the detailed
progression of an outbreak as a function of time, however, then we need another approach that takes dynamics into account. Moreover, the techniques
we have used so far cannot tell us about even the late-time behavior of models
with reinfection, such as the SIS and SIRS models of Sections 17.4 and 17.5.
For these models the equivalence between epidemics and percolation that we
used above does not hold, and to understand their behavior, including at long
times, we need to address the dynamics of the epidemic.
A number of approaches have been proposed for tackling the dynamics of
epidemics on networks, some exact and some approximate. Of course, given a
speciﬁc network, one can always perform computer simulations of epidemics
and get numerical answers for typical disease outbreaks. Analytic approaches,
however, offer more insight and some results are known, as discussed below,
but they are mostly conﬁned to speciﬁc classes of model network, such as
random graphs and their generalizations. In the following sections we will
look at some of the most straightforward and general approaches to epidemic
dynamics on networks, starting with the simple SI model and progressing to
the more complex (and interesting) models in later sections.

17.10

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

The analytic treatment of the time-dependent properties of epidemic models
revolves around the time evolution of the probabilities for vertices to be in speciﬁc disease states. One can imagine having repeated outbreaks of the same
648

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

disease on the same network, starting from the same initial conditions, and
calculating for example the average probabilities si (t) and xi (t) that vertex i is
susceptible or infective at time t. Given the adjacency matrix of a network one
can write down equations for the evolution of such quantities in a straightforward manner. Consider for instance the SI model.
An SI outbreak starting with a single randomly chosen vertex somewhere
eventually spreads, as we have seen, to all members of the component containing that vertex. Our main interest is in epidemics occurring in the giant
component of the network, since all other outbreaks will only affect a small
component and then die out, so let us focus on the giant component case.
Consider a vertex i. If the vertex is not a member of the giant component
then by hypothesis si = 0 at all times, since we are assuming the epidemic
to take place in the giant component. For i in the giant component we can
write down a differential equation for si by considering the probability that i
becomes infected between times t and t + dt. To become infected an individual must catch the disease from a neighboring individual j, meaning j must
already be infected, which happens with probability x j = 1 − s j , and must
transmit the disease during the given time interval, which happens with probability β dt. In addition we also require that i be susceptible in the ﬁrst place,
which happens with probability si . Multiplying these probabilities and then
summing over all neighbors of i, the total probability of i becoming infected is
βsi ∑ j Aij x j , where Aij is an element of the adjacency matrix. Thus si obeys the
coupled set of n non-linear differential equations:
dsi
= − βsi ∑ Aij x j = − βsi ∑ Aij (1 − s j ).
dt
j
j

(17.34)

Note the leading minus sign on the right-hand side—the probability of being
susceptible goes down when vertices become infected.
Similarly we can write an equation for xi thus:
dxi
= βsi ∑ Aij x j = β(1 − xi ) ∑ Aij x j ,
dt
j
j

(17.35)

although the two equations are really the same equation, related to one another
by si + xi = 1.
We will use the same initial conditions as we did in the fully mixed case,
assuming that the disease starts with either a single infected vertex or a small
number c of vertices, chosen uniformly at random, so that xi = c/n and si =
1 − c/n for all i. In the limit of large system size n, these become xi = 0, si = 1,
and we will use this large-n limit to simplify some of the expression derived in
this and the following sections.
649

E PIDEMICS ON NETWORKS

Equation (17.34) is not solvable in closed form for general Aij but we can
calculate some features of its behavior by considering suitable limits. Consider
for example the behavior of the system at early times. For large n, and assuming initial conditions as above, xi will be small in this regime. Working with
Eq. (17.35) and ignoring terms of quadratic order in small quantities, we have
dxi
= β ∑ Aij x j ,
dt
j

(17.36)

or in matrix form

dx
= βAx,
(17.37)
dt
where x is the vector with elements xi .
Now let us write x as a linear combination of the eigenvectors of the adjacency matrix:
n

x ( t ) = ∑ ar ( t ) vr ,

(17.38)

r =1

where vr is the eigenvector with eigenvalue κr . Then
n
n
n
dar
dx
vr = βA ∑ ar (t)vr = β ∑ κr ar (t)vr .
=∑
dt
r =1 dt
r =1
r =1

(17.39)

Then, comparing terms in vr , we get

which has the solution

dar
= βκr ar ,
dt

(17.40)

ar (t) = ar (0) eβκr t .

(17.41)

Substituting this expression back into Eq. (17.38), we then have
n

x(t) = ∑ ar (0) eβκr t vr .

(17.42)

r =1

The fastest growing term in this expression is the term corresponding to the
largest eigenvalue κ1 . Assuming this term dominates over the others we will
get
(17.43)
x(t) ∼ eβκ1 t v1 .
So we expect the number of infected individuals to grow exponentially, just as
it does in the fully mixed version of the SI model, but now with an exponential
constant that depends not just on β but also on the leading eigenvalue of the
adjacency matrix.
650

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

Moreover, the probability of infection in this early period varies from vertex
to vertex roughly as the corresponding element of the leading eigenvector v1 .
The elements of the leading eigenvector of the adjacency matrix are the same
quantities that in other circumstances we called the eigenvector centrality—see
Section 7.2. Thus eigenvector centrality is a crude measure of the probability
of early infection of a vertex in an SI epidemic.
At long times in the SI model the probability of infection of a vertex in
the giant component tends to one (again assuming the epidemic takes place
in the giant component). Thus overall we expect the SI epidemic to have a
similar form to that seen in the fully mixed version of the model, producing
curves qualitatively like that in Fig. 17.1 but with vertices of higher eigenvector
centrality becoming infected faster than those of lower.
Reasonable though this approach appears to be, it is not precisely correct, as we can see by integrating Eq. (17.35) numerically. Figure 17.5a shows
the results of such a numerical integration (the curve labeled “ﬁrst-order”)
on a network generated using the conﬁguration model (Section 13.2), compared against an average over a large number of simulated epidemics with the
same β spreading on the same network (the circular dots). As the ﬁgure shows,
the agreement between the two is good, but deﬁnitely not perfect.
The reason for this disagreement is an interesting one. Equation (17.34)
may appear to be a straightforward generalization of the equivalent equation
for the fully mixed SI model, Eq. (17.4), but there are some subtleties involved.
The right-hand side of the equation contains two average quantities, si and x j ,
and in multiplying these quantities we are implicitly assuming that the product of the averages is equal to the average of their product. In the fully mixed
model this is true (for large n) because of the mixing itself, but in the present
case it is, in general, not, because the probabilities are not independent. The
quantity si measures a vertex’s probability of being susceptible and x j measures the probability of its neighbor being infected. It should come as no surprise that in general these quantities will be correlated between neighboring
vertices. Correlations of this type can be incorporated into our calculations, at
least approximately, by using a so-called pair approximation or moment closure method, as described in the following section.
17.10.1

PAIR APPROXIMATIONS

Correlations between the disease states of different vertices can be handled
by augmenting our theory to take account of the joint probabilities for pairs
of vertices to have given pairs of states. To handle such joint probabilities
we will need to make our notation a little more sophisticated. Let us denote
651

E PIDEMICS ON NETWORKS

1
First-order

Figure 17.5: Comparison of theory and simulation for the SI model on two different networks. (a) The fraction of infected individuals
as a function of time on the giant component
of a network with low transitivity (i.e., low
clustering coefﬁcient), calculated by numerical solution of the differential equations for the
ﬁrst- and second-order moment closure methods, and by direct simulation. (b) The same
comparison for a network with high transitivity. The networks have one million vertices
each and the transmission rate is β = 1 in all
cases. Simulation results were averaged over
500 runs.

Fraction infected

0.5

Theory
Simulation
Second-order

(a)
0

0

Low transitivity
1

2

3

4

1
First-order

Theory
Simulation

0.5

Second-order

(b)
0

High transitivity

0

5

10

Time t

by si the average probability that vertex i is susceptible. This is the same
quantity that we previously called si , but, as we will see, it will be useful to
indicate the average explicitly with the angle brackets . . . . If you like, you
can think of si (t) as now being a variable with value one if i is susceptible at
time t and zero otherwise and si as being the average of this quantity over
many different instances of disease outbreaks on the same network. Similarly
xi will be the average probability that i is infected. And si x j indicates the
average probability that i is susceptible and j is infected at the same time.
In this notation it is now straightforward to write down a truly exact version of Eq. (17.34), taking correlations into account. It is
d si
= − β ∑ Aij si x j .
dt
j

(17.44)

Equation (17.34) is an approximation to this true equation in which we assume
that si x j ≃ si x j .
652

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

The trouble with Eq. (17.44) is that we cannot solve it directly because it
contains the unknown quantity si x j on the right-hand side. To ﬁnd this quantity, we need another equation for si x j , which we can deduce as follows. To
reach the state in which i is susceptible and j is infected in an SI model it must
be the case that both i and j are susceptible to begin with and then j becomes
infected. Even though i and j are neighbors j cannot be infected by i, since i is
not infected, so j must be infected by some other neighboring vertex k, which
itself must therefore be infected. In our new notation, the probability for the
conﬁguration in which i and j are susceptible and k is infected is si s j xk . If we
have this conﬁguration, then j will become infected via k with rate β. Summing
over all neighbors k except for i, the total rate at which j becomes infected is
then β ∑k(=i) A jk si s j xk .
Unfortunately, this is not the end of the story because si x j can also decrease—it decreases if i becomes infected. This can happen in two different
ways. Either i can be infected by its infected neighbor j, which happens with
rate β si x j , or it can be infected by another neighbor l = j that happens to
be infected, which happens with rate β xl si x j . Summing the latter expression
over all neighbors l other than j gives a total rate of β ∑l (= j) Ail xl si x j .
Putting all of these terms together, with minus signs for those that decrease
the probability, we get a ﬁnal equation for si x j thus:
d si x j
= β ∑ A jk si s j xk − β ∑ Ail xl si x j − β si x j .
dt
k (=i )
l (= j)

(17.45)

In theory this equation will now allow us to calculate si x j . In practice, however, it involves yet more terms that we don’t know on the right-hand side,
the three-variable averages si s j xk and xl si x j . We can write down further
equations for these averages but, as you can no doubt guess, those equations
involve still higher-order (four-variable) terms, and so forth. The succession of
equations will never end—in the jargon of mathematics, it doesn’t close—and
so looks as though it will be of no use to us.9
In fact, however, we can still make progress by approximating our threevariable averages with appropriate combinations of one- and two-variable averages, which allows us to close the equations and get a set we can actually
solve. This process is called moment closure and the method described in this
section is called a moment closure method. The moment closure method at the
9
On a ﬁnite network with n vertices the equations will in fact close once we get all the way up
to combinations of n variables, but this limit is not useful in practice as the equations will become
unmanageably numerous and complicated long before we reach it.

653

E PIDEMICS ON NETWORKS

level of two-variable averages that we discuss here is also called a pair approximation method.
In fact, our ﬁrst attempt at writing equations for the SI model on a network,
Eq. (17.34), was itself a simple moment-closure method. We approximated the
true equation, Eq. (17.44), by writing si x j ≃ si x j , closing the equations at
the level of one-variable averages. By going a step further and closing at the
pair approximation level of two-variable averages, we can make our equations
more precise because we will be taking two-variable correlations into account.
In fact, as we will see, this “second-order” moment closure approach is exact
for some networks, although only approximate for others. Even in the latter
case, however, the method gives a remarkably good approximation. The approximation can be further improved by going to third order, but the equations
rapidly become complicated and researchers have rarely used moment closure
methods beyond the second-order, pair approximation level.
The pair approximation is relatively straightforward however. Starting
with Eq. (17.45) our goal is to approximate the three-variable averages on the
right-hand side with lower-order ones. We do this by making use of Bayes
theorem for probabilities thus:
si s j xk = P(i, j ∈ S, k ∈ I ) = P(i, j ∈ S) P(k ∈ I |i, j ∈ S),

(17.46)

where P(i ∈ S) means the probability that vertex i is in the set S of susceptible
vertices. We know that i and j are neighbors in the network and that j and k
are neighbors, and our approximation involves assuming that the disease state
of k doesn’t depend on the disease state of i. This is a good approximation—
indeed not an approximation at all—if the only path in the network from i to
k is through j. In that case, given that we know j to be susceptible, there is no
way that the disease state of i can affect that of k because there is no other path
by which the disease could spread from i to k. On the other hand, if there is
another path from i to k that avoids vertex j then the disease can spread along
that path, which will introduce correlations between i and k and in that case
our approximation is just that—an approximation—although as we will see it
may be a very good one.
Assuming the state of k to be independent of the state of i, we have
P(k ∈ I |i, j ∈ S) = P(k ∈ I | j ∈ S) =

s j xk
P( j ∈ S, k ∈ I )
,
=
P( j ∈ S)
sj

(17.47)

where we have used Bayes theorem again in the second equality. Putting
Eqs. (17.46) and (17.47) together, we then have
si s j xk =
654

si s j s j xk
.
sj

(17.48)

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

We can write a similar expression for the other three-variable average appearing in Eq. (17.45):
xl si si x j
xl si x j =
,
(17.49)
si
and, substituting both into Eq. (17.45), we then get the pair approximation
equation
d si x j
si s j
=β
dt
sj

∑ A jk s j xk − β

k (=i )

si x j
si

∑ Ail si xl − β si x j .

(17.50)

l (= j)

This equation now contains only averages over two variables at a time. It does
also contain a new average si s j that we have not encountered before, but
this can easily be rewritten as si s j = si (1 − x j ) = si − si x j and so our
equation becomes
si − si x j
si x j
d si x j
=β
A jk s j xk − β
Ail si xl − β si x j . (17.51)
∑
dt
sj
si l (∑
k (=i )
= j)
This equation is more complex than Eq. (17.34) but it can be simpliﬁed by
rewriting it as follows. We deﬁne pij to be the conditional probability that j is
infected given that i is not:
pij = P( j ∈ I |i ∈ S) =

si x j
P(i ∈ S, j ∈ I )
=
.
P (i ∈ S )
si

(17.52)

Then the time evolution of pij is given by
si x j
si
si x j d si
1 d si x j
=
−
si
dt
si 2 dt
s j xk
si x j
si x j
= β 1−
∑ A jk s j − β si
si
k (=i )

dpij
d
=
dt
dt

−β

si x j
si x j
+β
si
si

∑ Ail
l

∑ Ail

l (= j)

si xl
si

si xl
si

= β(1 − pij ) ∑ A jk p jk − βpij ∑ Ail pil − βpij + βpij ∑ Ail pil ,
k (=i )

l (= j)

(17.53)

l

where we have used Eqs. (17.44) and (17.51) in the third line. All but one of
the terms in the two sums over l now cancel out, leaving us with the relatively
simple equation


dpij
(17.54)
= β(1 − pij ) − pij + ∑ A jk p jk ,
dt
k (=i )
655

E PIDEMICS ON NETWORKS

where we have used the fact that Aij = 1 (since i and j are neighbors). We can
also rewrite Eq. (17.44) in terms of pij thus:
d si
= − β si ∑ Aij pij ,
dt
j

(17.55)

which has the solution
si (t) = si (0) exp − β ∑ Aij
j

 t
0

pij (t ) dt .

(17.56)

Between them, Eqs. (17.54) and (17.56) now give us our solution for the evolution of the epidemic. Note that there are two equations of the form (17.54) for
each edge in the network, since pij is not symmetric in i and j.
Figure 17.5a shows results from a numerical solution of these equations (the
curve marked “second-order”), again on a conﬁguration model network and,
as the ﬁgure shows, the calculation now agrees very well with the simulation
results represented by the dots in the ﬁgure. By accounting for correlations
between adjacent vertices we have created a much more accurate theory.
This near-perfect agreement, however, is something of a special case. Conﬁguration model networks are locally tree-like, meaning they have no short
loops, and, as discussed above, our second-order moment closure approximation is exact when non-adjacent vertices i and k have only a single path between them through some intermediate j. When there are no short loops in
our network this is true to an excellent approximation—the only other way to
get from i to k in such a network is by going around a long loop and the length
of such loops dilutes any resulting correlations between the states of i and k,
often to the point where they can be ignored. The network used in the simulations for Fig. 17.5a was sufﬁciently large (a million vertices) and the resulting
loops sufﬁciently long that the pair approximation equations are an excellent
approximation, which is why the agreement is so good in the ﬁgure.
Unfortunately, as we saw in Section 7.9, most real social networks have a
lot of short loops, which raises the question of how well our method does on
such networks. Figure 17.5b shows a comparison between the predictions of
our equations and direct simulations for a network with many short loops,10
for both the simple ﬁrst-order moment closure, Eq. (17.34), and for our more
sophisticated second-order approach. As the plot shows, the ﬁrst-order calculation agrees quite poorly with the simulations, its predictions being inaccurate
enough to be of little use in this case. The second-order equations, however,
10

656

The network was generated using the clustered network model of Ref. [240].

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

still do remarkably well. Their predictions are not in perfect agreement with
the simulations, but they are close.
Thus the pair approximation method offers a signiﬁcant improvement on
networks both with and without short loops, providing a usefully accurate
approximation in the former case and being essentially exact in the latter.
17.10.2

D EGREE - BASED APPROXIMATION FOR THE SI MODEL

The analysis of the previous section gives exact equations for the dynamics
of the SI model on a network with few short loops and an excellent approximation in other cases. Unfortunately those equations cannot in general be
solved analytically, even for simple networks such as those of the conﬁguration model. The solutions presented in Fig. 17.5 were derived by integrating
the equations numerically.
In this section we describe an alternative approximate approach that gives
good, though not perfect, results in practice and produces equations that can
be solved analytically. Moreover, the method can, as we will see, be generalized to other epidemic models such as the SIR model. The method was
pioneered by Pastor-Satorras and coworkers [32, 33, 263, 264], though it has
precursors in earlier work by May and others [199, 212]. It takes its simplest
form when applied to networks drawn from the conﬁguration model and so it
is on this model that we focus here, although in principle the method can be
extended to other networks.
Consider a disease propagating on a conﬁguration model network, i.e., a
random graph with a given degree distribution pk , as discussed in Chapter 13.
As before we focus on outbreaks taking place in the giant component of the
network, this being the case of most interest—outbreaks in small components
by deﬁnition die out quickly and do not give rise to epidemics.
An important point to notice is that the degree distribution of vertices in
the giant component of a conﬁguration model network is not the same as the
degree distribution of vertices in the network as a whole. As shown in Section 13.8, the probability of a vertex of degree k belonging to the giant component goes up with vertex degree. This means that the degree distribution of
vertices in the giant component is skewed towards higher degrees. (For a start,
notice that there are trivially no vertices of degree zero in the giant component,
since by deﬁnition such vertices are not attached to any others.) We will, as before, denote the degree distribution and the excess degree distribution in our
calculations by pk and qk , but bear in mind that these are for vertices in the
giant component, which means they are not the same as the distributions for
the network as a whole.
657

E PIDEMICS ON NETWORKS

The approximation introduced by Pastor-Satorras et al. was to assume that
all vertices of the same degree have the same probability of infection at any
given time. Certainly this is an approximation. The probability of infection of a
vertex of degree, say, ﬁve situated in the middle of the dense core of a network
will presumably be larger than the probability for a vertex of degree ﬁve that
is out on the periphery. Nonetheless, if the distribution of probabilities for
vertices of given degree is relatively narrow it may be a good approximation
to set them all equal to the same value. And in practice, as we have said, the
approximation appears to work very well.
Returning, for the sake of simplicity, to our earlier notation style, let us deﬁne sk (t) and xk (t) to be the probabilities that a vertex with degree k is susceptible or infected, respectively, at time t. Now consider a susceptible vertex A.
To become infected, A has to contract the infection from one of its network
neighbors. The probability that a particular neighbor B is infected depends
on the neighbor’s degree, but we must be careful. By hypothesis vertex A is
not infected and so B cannot have caught the disease from A. If B is infected
it must have caught the disease from one of its remaining neighbors. In effect
this reduces the degree of B by one—B will have the same probability of being
infected at the current time as the average vertex with degree one less. To put
that another way, B’s probability of infection depends upon its excess degree,
the number of edges it has other than the edge we followed from A to reach it.
B’s probability of infection is thus xk , but where k indicates the excess degree,
not the total degree.
The advantage of the degree-based approach now becomes clear: the probability of B being infected depends, in this approach, only on B’s excess degree
and not on A’s degree. By contrast, the conditional probability pij in our earlier
formalism was a function of two indices, making the equations more complicated. To derive the equations for the degree-based approximation, consider
the probability that vertex A becomes infected between times t and t + dt. To
become infected it must catch the disease from one of its neighbors, meaning
that neighbor must be infected. The probability of a neighbor being infected is
xk where k is the excess degree of the neighbor, and the excess degree is distributed according to the distribution qk of Eq. (13.46), which means that the
average probability that the neighbor is infected is
∞

v ( t ) = ∑ q k x k ( t ).

(17.57)

k =0

If the neighbor is infected then the probability that the disease will be transmitted to vertex A in the given time interval is β dt. Then the total probability
of transmission from a single neighbor during the time interval is βv(t) dt and
658

17.10

|

T IME - DEPENDENT PROPERTIES OF THE SI MODEL

the probability of transmission from any neighbor is βkv(t) dt, where k is now
the number of A’s neighbors. In addition we also require that A itself be susceptible, which happens with probability sk (t), so our ﬁnal probability that A
becomes infected is βkvsk dt. Thus the rate of change of sk is given by
dsk
= − βkvsk .
dt

(17.58)

This equation can be solved exactly. We can formally integrate it thus:
sk (t) = s0 exp − βk

 t
0

v(t ) dt ,

(17.59)

where we have ﬁxed the integration constant so that all vertices have probability s0 of being susceptible at t = 0. Although we don’t yet know the form of
the function v(t) this expression tells us that sk depends on k as a simple power
of some universal k-independent function u(t):
sk (t) = s0 [u(t)]k ,
where in this case
u(t) = exp − β

 t
0

v(t ) dt .

(17.60)

(17.61)

Writing xk = 1 − sk and substituting into Eq. (17.57) we then get
∞

∞

k =0

k =0

v ( t ) = ∑ q k ( 1 − s k ) = ∑ q k ( 1 − s 0 u k ) = 1 − s 0 g1 ( u ) ,

(17.62)

where g1 (u) is the generating function for qk and we have made use of ∑k qk =
1. Substituting Eq. (17.60) into Eq. (17.58) then gives us
du
= − βuv = − βu 1 − s0 g1 (u) .
dt

(17.63)

This is a straightforward linear differential equation for u that, given the degree
distribution, can be solved by direct integration.
Finally, to calculate the total fraction x (t) of infected individuals in the network we average over k thus:
∞

∞

k =1

k =1

x ( t ) = ∑ p k x k ( t ) = ∑ p k ( 1 − s 0 u k ) = 1 − s 0 g0 ( u ) .

(17.64)

Notice that the sums here start at k = 1 because there are no vertices of degree
zero in the giant component.
659

E PIDEMICS ON NETWORKS

Equations (17.63) and (17.64) between them give us an approximate solution for the SI model on the giant component of a conﬁguration model network
with any degree distribution.
Although the solution is elegant in principle, in most practical cases we
cannot integrate Eq. (17.63) in closed form. Even without completing the integral, however, we can already see the basic form of the solution. First of all,
at time t = 0 we have u = 1 by Eq. (17.61). Since v(t) is, by deﬁnition, positive and non-decreasing with time, the same equation also implies that u(t)
always decreases and tends to zero as t → ∞. This implies that at long times
Eq. (17.63) becomes
du
= − βu 1 − s0 g1 (0) = − βu(1 − s0 p1 / k ),
dt

(17.65)

and hence u(t) decays exponentially as e− β(1−s0 p1 / k )t . Assuming the infection
starts with only one or a handful of cases, so that s0 = 1 − c/n for some constant c, we have s0 → 1 in the limit of large n and
u ( t ) ∼ e− β (1− p1 / k ) t .

(17.66)

Note that the long-time behavior is dictated by the fraction p1 of vertices with
total degree one. This is because these are the last vertices to be infected—
individuals with only one contact are best protected from infection, although
even they are guaranteed to become infected in the end. In networks where
the fraction p1 is zero or very small we have u(t) ∼ e− βt and the functional
form of the long-time behavior depends only on the infection rate and not on
the network structure.
At short times we can write u = 1 −  and to leading order in  Eq. (17.63)
becomes
d
= β x0 + ( g1 (1) − 1) ,
(17.67)
dt
where x0 = 1 − s0 is the initial value of xk . This has solution
(t) =

βx0

g1 ( 1 ) − 1



eβ( g1 (1)−1)t − 1 ,

(17.68)

where we have made use of the initial condition  = 0. Equivalently we can
write11
βx0

eβ( g1 (1)−1)t − 1 .
u(t) = 1 −  = 1 − 
(17.69)
g1 ( 1 ) − 1
11
This equation will diverge if g1 (1) = 1. However, since we are performing the calculation on
the giant component of the network, and since the giant component only exists if g1 (1) > 1—see
Section 13.8—we can safely rule out this possibility.

660

17.11

|

T IME - DEPENDENT PROPERTIES OF THE SIR MODEL

Given the short- and long-time behavior and the
fact that u(t) is monotonically decreasing, we can now
guess that u(t) has a form something like Fig. 17.6.
Then, since g0 is a monotonically increasing function of
its argument, x (t) in Eq. (17.64) has a similar shape but
turned upside down, so that it looks qualitatively similar to the curve for the fully mixed version of the model
shown in Fig. 17.1, although quantitatively it may be
different.
The initial growth of x (t) can be calculated by
putting u = 1 −  in Eq. (17.64) to give g0 (1 − ) ≃
1 − g0 (1) and
x (t) = 1 − s0 + s0 g0 (1)


βg (1)

eβ( g1 (1)−1)t − 1 ,
= x0 1 +  0
g1 ( 1 ) − 1

(17.70)

1

u(t)
0.5

0

Time t
Figure 17.6: The function u(t) in the solution of the
SI model. Generically we expect u(t) to have the form
sketched here: it is monotonically decreasing from an
initial value of 1 and has an exponential tail at long
times.

where we have again set s0 = 1. Thus, as we would
expect, the initial growth of infection is roughly exponential.
The appearance of g1 (1) in Eq. (17.70) is of interest.
As we saw in Eq. (13.68), g1 (1) is equal to the ratio c2 /c1 of the average number of second neighbors to ﬁrst neighbors of a vertex and hence is a measure
of how fast the network branches as we move away from the vertex where the
disease ﬁrst starts. It should be not surprising therefore (though it’s still satisfying) to see that this same quantity—along with the transmission rate β—
controls the rate at which the disease spreads in our SI model.
Another interesting feature of the model is the behavior of the quantities
sk (t) that measure the probability that a vertex of a given degree is susceptible.
Since these quantities are all proportional to powers of u(t)—see Eq. (17.60)—
they form a family of curves as shown in Fig. 17.7. Thus, as we might expect,
the vertices with highest degree are the ones that become infected ﬁrst, on
average, while those with low degree hold out longer.

17.11

T IME - DEPENDENT PROPERTIES OF THE SIR MODEL

It is relatively straightforward to extend the techniques of Section 17.10 to the
more complex (and interesting) SIR model. Again we concentrate on outbreaks
taking place in the giant component of the network and we deﬁne si , xi , and ri
to be the probabilities that vertex i is susceptible, infected, or recovered respectively. The evolution of si is (approximately) governed by the same equation
661

E PIDEMICS ON NETWORKS

Fraction of population

1

0.5

0

Time t

Figure 17.7: Fractions of susceptible and infected vertices of various degrees in the SI
model. The various curves show the fraction of vertices of degree k that are susceptible
(gray) and infected (black) as a function of time for k = 1, 2, 4, 8, and 16. The highest
values of k give the fastest changing (leftmost) curves and the lowest values the slowest
changing. The curves were calculated by integrating Eq. (17.63) numerically with β = 1
and a Poisson degree distribution with mean degree four.

as before:

dsi
= − βsi ∑ Aij x j ,
dt
j

(17.71)

dxi
= βsi ∑ Aij x j − γxi ,
dt
j

(17.72)

dri
= γxi ,
dt

(17.73)

while xi and ri obey

where, as previously, γ is the recovery rate, i.e., the probability per unit time
that an infected individual will recover.12
12

This contrasts with the approach we took in Section 17.8 where all vertices remained infected
for the same amount of time and then recovered. Thus the model studied in this section is not
exactly the same as that of Section 17.8, being more similar to the traditional SIR model of Section 17.3. We will see some minor consequences of this difference shortly.

662

17.11

|

T IME - DEPENDENT PROPERTIES OF THE SIR MODEL

We can choose the initial conditions in various ways, but let us here make
the same assumption as we did for the SI model, that at t = 0 we have a
small number c of infected individuals and everyone else is susceptible, so
that si (0) = 1 − c/n, xi (0) = c/n, and ri (0) = 0.
As with the SI model we cannot solve these equations exactly, but we can
extract some useful results by examining their behavior at early times. In the
limit t → 0, xi is small and si = 1 − c/n, which tends to 1 as n becomes large,
so Eq. (17.72) can be approximated as
dxi
= β ∑ Aij x j − γxi = ∑( βAij − γδij ) x j ,
dt
j
j

(17.74)

where δij is the Kronecker delta. This can be written in matrix form as
dx
= βMx,
dt

(17.75)

where M is the n × n symmetric matrix
M = A−

γ
I.
β

(17.76)

As before we can write x as a linear combination of eigenvectors, though they
are now eigenvectors of M rather than of the simple adjacency matrix as in the
case of the SI model. But now we notice a useful thing: since M differs from
the adjacency matrix only by a multiple of the identity matrix, it has the same
eigenvectors vr as the adjacency matrix:
Mvr = Avr −

γ
Ivr =
β

κ−

γ
vr .
β

(17.77)

Only the eigenvalue has been shifted downward by γ/β.
The equivalent of Eq. (17.42) is now
n

x(t) = ∑ ar (0)vr e( βκr −γ)t .

(17.78)

r =1

Note that the exponential constant now depends on βκr − γ and so is a function
not only of the adjacency matrix and the infection rate but also of the recovery
rate, as we would expect—the faster people recover from infection the less
chance they have to spread the disease and the slower it will spread.
Again the fastest growing term is that corresponding to the most positive eigenvalue κ1 of the adjacency matrix and individuals having the highest
eigenvector centrality get infected ﬁrst. Note, however, that it is now possible for γ to be sufﬁciently large that the exponential constant in the leading
663

E PIDEMICS ON NETWORKS

term becomes negative, meaning that the term decays exponentially rather
than grows. And if the leading term decays, so necessarily do all other terms,
and so the total number of infected individuals will decay over time and the
disease will die out without causing an epidemic.
The point at which this happens is the epidemic threshold for our model
and it occurs at βκ1 − γ = 0, or equivalently
1
β
= .
κ1
γ

(17.79)

Thus the position of the epidemic threshold depends on the leading eigenvalue
of the adjacency matrix. If the leading eigenvalue is small, then the probability
of infection β must be large, or the recovery rate γ small, for the disease to
spread. In other words a small value of κ1 makes it harder for the disease to
spread and a large value easier. This makes intuitive sense, since large values
of κ1 correspond to denser adjacency matrices and smaller values to sparser
ones.
As in the case of the SI model, Eqs. (17.71–17.73) are only approximate,
because they neglect correlations between the states of adjacent vertices. And
as before we can allow for these correlations by using a pair approximation,
but here we take a different approach and consider instead the equivalent of
the methods of Section 17.10.2 for the SIR model.13
17.11.1

D EGREE - BASED APPROXIMATION FOR THE SIR MODEL

As with the SI model, let us make the approximation that all vertices with the
same degree behave in the same way. Again we concentrate on the example of
the conﬁguration model [229] and on outbreaks taking place in the giant component of the network. We deﬁne sk (t), xk (t), and rk (t) to be the probabilities
that a vertex with degree k is susceptible, infected, or recovered, respectively,
at time t. Then we consider the state of a vertex B that is the neighbor of a
susceptible vertex A. For such a vertex to be infected it must have contracted
the disease from one of its neighbors other than A, since A is susceptible. That
means, as before, that B’s probability of being infected is given by xk , but with
k equal to the excess degree, which is one less than the total degree. And the
13

We can see that the approach of this section cannot be exactly correct from the behavior of
Eq. (17.79) on very sparse networks. On a vanishingly sparse network, with only a very few
edges and no giant component, κ1 becomes very small, though still non-zero. On such a network
Eq. (17.79) implies that we could, nonetheless, have an epidemic if β is very large or γ very small.
Clearly this is nonsense—there can be no epidemic in a network with no giant component. Thus
the equation cannot be exactly correct.

664

17.11

|

T IME - DEPENDENT PROPERTIES OF THE SIR MODEL

probability that B is recovered depends only on the probability that it was previously infected, which is given by rk where k is the excess degree, and the
probability sk of being susceptible can be derived from sk + xk + rk = 1.
Armed with these observations, we can now write down an appropriate
set of equations for the epidemic. The rate at which the probability of being
susceptible decreases is given by the same equation as before, Eq. (17.58):
dsk
= − βkvsk ,
dt

(17.80)

where v(t) is the average probability that a neighbor is infected:
∞

v ( t ) = ∑ q k x k ( t ),

(17.81)

k =0

and the equations for xk and rk are
dxk
= βkvsk − γxk ,
dt
drk
= γxk .
dt

(17.82)
(17.83)

We can solve these equations exactly by a combination of the methods of Sections 17.3 and 17.10. We deﬁne the average probability that a neighbor is recovered thus:
∞

w ( t ) = ∑ q k r k ( t ).

(17.84)

k =0

Then, using Eqs. (17.81) and (17.83), we ﬁnd
∞
∞
dw
dr
= ∑ qk k = γ ∑ qk xk = γv,
dt
dt
k =0
k =0

(17.85)

which we use to eliminate v from Eq. (17.80), giving
dsk
β dw
sk .
=− k
dt
γ dt

(17.86)

This equation can be integrated to give
β
sk = s0 exp − kw ,
γ

(17.87)

where we have ﬁxed the constant of integration so that at t = 0 all vertices
have the same probability s0 of being susceptible and there are no recovered
vertices (w = 0).
665

E PIDEMICS ON NETWORKS

Equation (17.87) implies that sk is again proportional to a power of a universal function:
k
(17.88)
s k ( t ) = s0 u ( t ) ,
where in this case

u(t) = e− βw/γ .

(17.89)

Then, using Eq. (17.87), we ﬁnd
v ( t ) = ∑ q k x k = ∑ q k (1 − r k − s k ) = 1 − w ( t ) − s0 ∑ q k u k
k

k

k

γ
= 1 + ln u − s0 g1 (u),
β

(17.90)

and Eq. (17.85) becomes


du
γ
= − βu 1 + ln u − s0 g1 (u) .
dt
β

(17.91)

This is the equivalent for the SIR model of Eq. (17.63), and indeed differs from
that equation only by the new term in ln u on the right-hand side.
As before, Eq. (17.91) is a ﬁrst-order linear differential equation in u and
hence can, in principle, be solved by direct integration, although for any given
degree distribution the integral may not have a closed-form solution. Once we
have u(t) the probability sk of a vertex being susceptible is given by Eq. (17.88),
or we can write the total fraction of susceptibles as
s ( t ) = ∑ p k s k = s 0 ∑ p k u k = s 0 g0 ( u ) .
k

(17.92)

k

Solving for xk and rk requires a little further work but with perseverance it
can be achieved.14 Figure 17.8 shows the equivalent of Fig. 17.7 for vertices of
a range of degrees. As we can see, the solution has the expected form, with the
number of infected individuals rising, peaking, then dropping off as the system evolves to a ﬁnal state in which some fraction of the population is recovered from the disease and some fraction has never caught it (and never will).
Among vertices of different degrees the number infected goes up sharply with
degree, as we would expect.
Even in cases where the integral in Eq. (17.91) cannot be performed, our
solution can still shed light on features of the epidemic. Consider for example
14

We observe that

dxk
d  γt 
+ γxk = eγt βkvsk ,
e xk = eγt
dt
dt
where we’ve used Eq. (17.82) in the second equality. Integrating and using Eqs. (17.81) and (17.88),

666

17.11

|

T IME - DEPENDENT PROPERTIES OF THE SIR MODEL

Probability

1

0.5

0

0

2

4

6

Time t

Figure 17.8: Fractions of susceptible, infected, and recovered vertices of various degrees in the SI model. The fraction of vertices of degree k that are susceptible (light
gray), infected (darker gray), and recovered (black) as a function of time for k = 1, 2,
4 and β = γ = 1 on a network with an exponential degree distribution (Eq. (13.129))
with λ = 0.2. The highest values of k give the fastest growing numbers of infected and
recovered vertices and the lowest values the slowest growing.

the long-time behavior. In the limit of long time we expect that the number
of infected individuals will vanish leaving some individuals recovered and
some who have never caught the disease. At t = ∞ the total fraction r (t) of
recovered individuals measures the overall size of the outbreak of the disease
and is given by
(17.93)
r (∞) = 1 − s(∞) = 1 − g0 (u(∞)).
where we have set s0 = 1 as before on the assumption that the system is large
and the number of initially infected individuals small.
We can ﬁnd the stationary value of u by setting du/dt = 0 in Eq. (17.91) to
we then have



 t
γ

eγt [u(t )]k 1 + ln u(t ) − s0 g1 (u(t )) dt ,
xk (t) = e−γt x0 + βks0
β
0

and rk = 1 − sk − xk .

667

E PIDEMICS ON NETWORKS

give
1+

γ
ln u − g1 (u) = 0.
β

(17.94)

In the special case where the outbreak is small, so that the ﬁnal value of u
is close to 1, we can expand ln u = ln[1 + (u − 1)] ≃ u − 1 and Eq. (17.94)
becomes
β
β
u ≃ 1 − + g1 ( u ) .
(17.95)
γ γ
Equations (17.93) and (17.95) are similar in form to Eqs. (17.27) and (17.28)
which give the ﬁnal size of the outbreak in our treatment of the SIR model
using percolation theory. The reason why Eq. (17.95) is only approximate in
the present case where Eq. (17.28) was exact is that the model treated in this
section is slightly different from the one treated earlier, having (as discussed
in footnote 12 on page 662) a constant probability γ per unit time of recovery
from disease for each infected individual as opposed to a ﬁxed infection time
for the model of Section 17.8.1.
We can also examine the early-time behavior of the outbreak by looking at
the behavior of Eq. (17.91) close to u = 1. Writing u = 1 −  and keeping terms
to leading order in  we get
d
= βg1 (1) − γ ,
dt

(17.96)

assuming s0 = 1 again, which means that


u(t) = 1 − (t) = 1 − e( βg1 (1)−γ)t .

(17.97)

This is similar to Eq. (17.69) for the SI model, except for the inclusion of the
term in γ. The fraction of susceptible degree-k vertices is given by


sk (t) = uk = 1 − e( βg1 (1)−γ)t

k



≃ 1 − ek( βg1 (1)−γ)t ,

(17.98)

and total cases of the disease, infected and recovered, which is just 1 − sk ,

grows exponentially as ek[ βg1 (1)−γ]t .
The epidemic threshold for the model is the line that separates an initially
growing number of cases of the disease from an initially decreasing one and is
given in this case by the point at which the exponential constant in Eq. (17.98)
equals zero, which gives
1
β
= 
.
(17.99)
g1 ( 1 )
γ

668

17.12

|

T IME - DEPENDENT PROPERTIES OF THE SIS MODEL

This result is similar in form to Eq. (17.79) for the epidemic threshold on a general network,15 but with the leading eigenvalue of the adjacency matrix κ1 replaced with g1 (1). It also looks similar to Eq. (17.29) for the percolation threshold for bond percolation, but this similarity is somewhat deceptive. In fact,
the result most nearly corresponding to this one in the percolation treatment
is Eq. (17.30). If we equate our recovery rate γ with the reciprocal of the infectiousness time τ in that previous treatment, then the two are roughly equivalent when the epidemic threshold is low, meaning either that β is small or that
γ is large. If the threshold is higher then the match between the two models is
poorer, which is again a result of the fact that the models are deﬁned in slightly
different ways.

17.12

T IME - DEPENDENT PROPERTIES OF THE SIS MODEL

It is straightforward to extend our methods to the SIS model also. By analogy
with Eqs. (17.71–17.73) we have
dsi
= − βsi ∑ Aij x j + γxi ,
dt
j

(17.100a)

dxi
= βsi ∑ Aij x j − γxi
dt
j

(17.100b)

for the SIS model. Caveats similar to those for previous models apply here:
these equations ignore correlations between the states of adjacent vertices and
hence are only an approximation.
Equations (17.100a) and (17.100b) are not independent since si + xi = 1, so
only one is needed to form a solution. Taking the second and eliminating si we
get
dxi
= β(1 − xi ) ∑ Aij x j − γxi .
(17.101)
dt
j
At early times, assuming as before that xi (0) = x0 = 1 − c/n for all i and
constant c, we can drop terms at quadratic order in small quantities to get
dxi
= β ∑ Aij x j − γxi ,
dt
j

(17.102)

which is identical to Eq. (17.74) for the SIR model at early times. Hence we can
immediately conclude that the early-time behavior of the model is the same,
15
And like Eq. (17.79) it is also clearly wrong on sparse networks for the same reasons—see
footnote 13 on page 664.

669

E PIDEMICS ON NETWORKS

with initially exponential growth and an epidemic threshold given by
β
1
= .
γ
κ1

(17.103)

(See Eq. (17.79).) Also as in the SIR model the probability of infection of a given
vertex at early times will be proportional to the vertex’s eigenvector centrality.
At late times we expect the probability of infection to settle to a constant
endemic level, which we can calculate by setting dxi /dt = 0 in Eq. (17.101)
and rearranging, to give
xi =

∑ j Aij x j
.
γ/β + ∑ j Aij x j

(17.104)

Typically we cannot derive a closed-form solution for xi from this expression,
but we can solve it numerically by iteration starting from a random initial
guess. We can also see the general form the solution will take by considering
limiting cases. If β/γ is large, meaning that we are well above the epidemic
threshold given in Eq. (17.103), then we can ignore the term γ/β in the denominator and xi ≃ 1 for all i, meaning that essentially all vertices will be
infected all the time. This makes good sense since if β/γ is large then the rate
of infection is very high while the rate of recovery is negligible.
Conversely, if β/γ is only just above the epidemic threshold level set by
Eq. (17.103) then xi will be small—the disease only just manages to stay alive—
and we can ignore the sum in the denominator of Eq. (17.104) so that
β
Aij x j ,
γ∑
j

(17.105)

κ1 xi ≃ ∑ Aij x j ,

(17.106)

xi ≃
or

j

where we have used Eq. (17.103). This implies that xi is proportional to the
leading eigenvector of the adjacency matrix or, equivalently, proportional to
the eigenvector centrality. (Note that this is at late times so this result is distinct
from the ﬁnding above that xi is proportional to eigenvector centrality at early
times.)
Thus the long-time endemic disease behavior of the SIS model varies from
a regime just above the epidemic threshold in which the probability of a vertex
being infected is proportional to its eigenvector centrality, to a regime well
above the threshold in which essentially every vertex is infected at all times.

670

17.12

17.12.1

|

T IME - DEPENDENT PROPERTIES OF THE SIS MODEL

D EGREE - BASED APPROXIMATION FOR THE SIS MODEL

We can also write down approximate equations for the evolution of the SIS
model in which, as in Sections 17.10.2 and 17.11.1, we assume that the probability of infection is the same for all vertices with a given degree. Focusing once
again on conﬁguration model networks, the equivalent of Eqs. (17.80–17.82) is
dsk
= − βkvsk + γxk ,
dt
dxk
= βkvsk − γxk ,
dt

(17.107a)
(17.107b)

where the variables sk and xk are as before, and again
∞

v ( t ) = ∑ q k x k ( t ).

(17.108)

k =0

As before Eqs. (17.107a) and (17.107b) are not independent and only one is
need to form a solution. Let us take the second and rewrite it using sk = 1 − xk
to give
dxk
= βkv(1 − xk ) − γxk .
(17.109)
dt
Unfortunately, there is no known complete solution to this equation but we
can once again ﬁnd its behavior at early and late times.
Assuming, as previously, that our epidemic starts off with only a single case
or a small number of cases, the probability xk of being infected at early times
is c/n for constant c and hence small in the limit of large n. Dropping terms of
second order in small quantities then gives us the linear equation
dxk
= βkv − γxk ,
dt

(17.110)

which can be rewritten using an integrating factor to read
d  γt 
dxk
e xk = eγt
+ γeγt xk = βkeγt v,
dt
dt

(17.111)

and hence integrated to give
xk (y) = βke−γt

 t
0



eγt v(t ) dt .

(17.112)

Thus xk (t) for short times takes the form
xk = ku(t),

(17.113)
671

E PIDEMICS ON NETWORKS

where u(t) is some universal, k-independent function. Substituting into Eqs.
(17.108) and (17.110), we then have
v(t) = u(t) ∑ kqk = g1 (1)u(t),

(17.114)

k =0

and

du
= βg1 (1) − γ u(t).
(17.115)
dt
Thus we have exponential growth or decay of the epidemic at early times, with
the epidemic threshold separating the two falling at the point where βg1 (1) −
γ = 0, or
1
β
= 
,
(17.116)
γ
g1 ( 1 )
just as for the SIR model (see Eq. (17.99)).
At late times the disease to settles down into an endemic state in which
some constant fraction of the population is infected. We can solve for this
endemic state by setting dxk /dt = 0 for all k in Eq. (17.109) to give
xk =

kv
.
kv + γ/β

(17.117)

Substituting this expression into Eq. (17.108), we then ﬁnd that
∞

kqk

∑ kv + γ/β = 1.

(17.118)

k =0

In general there is no closed-form solution to this implicit equation for v, although it can typically be solved numerically for any given qk , and given the
value we can then get xk from Eq. (17.117).
What we can tell from Eq. (17.118) is that, given the degree distribution,
v at late times is a function solely of β/γ (or γ/β if you prefer) and hence xk is
solely a function of β/γ and k. Moreover, in order for Eq. (17.118) to be satisﬁed
v must be an increasing function of β/γ—as β gets larger or γ smaller, v must
increase in order to keep the sum in the equation equal to one. This means that
xk will also be an increasing function of β/γ. (Equation (17.117) implies that it
is an increasing function of k as well.) Thus the equations give us a qualitative
picture of the behavior of the SIS model, although quantitative details require
a numerical solution.

We have in this chapter only brushed the surface of what is possible in the
modeling of epidemics spreading across networks. We can extend our studies
672

P ROBLEMS

to more complicated network structures, such as networks with degree correlations, networks with transitivity, networks with community structure, and
even epidemics on empirically observed networks. More complicated models of the spread of infection are also possible, such as the SIRS model mentioned in Section 17.5, as well as models that incorporate birth, death, or geographic movement of individuals [17, 156]. In recent years, scientists have
developed extremely sophisticated computer models of disease spread using
complex simulations of the behavior patterns of human populations, including
models of entire cities down to the level of individual people, cars, and buildings [110], and models of the international spread of disease that incorporate
detailed data on the ﬂight patterns and timetables of international airlines [79].
These developments, however, are beyond the scope of our necessarily brief
treatment in this chapter.

P ROBLEMS
17.1 Consider an SIR epidemic on a conﬁguration model network with exponential
degree distribution pk = (1 − e−λ )e−λk .
a) Using the results of Section 16.2.1 write down an expression for the probability u
appearing in Eq. (17.27) in terms of φ and λ.
b) Hence ﬁnd an expression for the probability that a vertex is infected by the disease
if it has degree k.
c) Evaluate this probability for the case λ = 1 and φ = 0.9, for k = 0, 1, and 10.
17.2 Consider the spread of an SIR-type disease on a network in which some fraction
of the individuals have been vaccinated against the disease. We can model this situation
using a joint site/bond percolation model in which a fraction φs of the vertices are
occupied, to represent the vertices not vaccinated, and a fraction φb of the edges are
occupied to represent the edges along which contact takes place.
a) Show that the fraction S of individuals infected in the limit of long time is given
by the solution of the equations
S = φs [1 − g0 (u)],

u = 1 − φs φb + φs φb g1 (u),

where g0 (z) and g1 (z) are the generating functions for the degree distribution and
excess degree distribution, as usual.
b) Show that for a given probability of contact φb the fraction of individuals that
need to be vaccinated to prevent spread of the disease is 1 − 1/[φb g1 (1)].

673

E PIDEMICS ON NETWORKS

17.3 We have been concerned in this chapter primarily with epidemic disease outbreaks, meaning outbreaks that affect a ﬁnite fraction of all individuals in a network.
Consider, by contrast, a small SIR outbreak—an outbreak that corresponds to one of
the non-giant percolation clusters in the bond percolation approach of Section 17.8—
occurring on a conﬁguration model network with degree distribution pk .
a) What is the probability of such an outbreak occurring if the disease starts at a
vertex chosen uniformly at random from the whole network (including vertices
both within and outside the giant component)?
b) Show that if the probability of transmission along an edge is φ then the generating
function h0 (z) for the probability πs that the outbreak has size s is given by the
equations
h0 (z) = zg0 (h1 (z)),

h1 (z) = 1 − φ + φzg1 (h1 (z)),

where g0 (z) and g1 (z) are the generating functions for the degree distribution and
excess degree distribution respectively.
c) What is the mean size of such an outbreak?
17.4 Consider an SI-type epidemic spreading on the giant component of a k-regular
random graph, i.e., a conﬁguration model network in which all vertices have the same
degree k. Assume that some number c of vertices, chosen at random, are infected at
time t = 0.
a) Show using the results of Section 17.10 that the probability of infection of every
vertex increases at short times as eβkt .
b) Show that within the ﬁrst-order moment closure approximation of Eq. (17.35) the
average probability of infection x of every vertex is the same and give the differential equation it satisﬁes.
c) Hence show that

ceβkt
.
n − c + ceβkt
d) Find the time at which the “inﬂection point” of the epidemic occurs, the point
at which the rate of appearance of new disease cases stops increasing and starts
decreasing.
x (t) =

17.5 Consider a conﬁguration model network containing vertices of degrees 1, 2, and 3
only, such that the fractions of vertices of each degree in the giant component are p1 =
0.3, p2 = 0.3, and p3 = 0.4.
a) Find an expression for the excess-degree generating function g1 (z) appearing in
Eq. (17.63).
b) Hence, by solving Eq. (17.63), ﬁnd an expression for t as a function of u for an SI
epidemic on the giant component of the network, assuming that s0 ≃ 1, and with
initial condition u(0) = 1 − , where  is small.
c) Show that in the limit of long times the number of susceptibles falls off in proportion to e−21βt/2 .

674

P ROBLEMS

17.6 Consider the spread of an SIR-type disease in a network in which some fraction of
the individuals have been vaccinated against the disease. We can model this situation
using a joint site/bond percolation model in which a fraction φs of the vertices are
occupied, to represent the vertices not vaccinated, and a fraction φb of the edges are
occupied to represent the edges along which contact takes place.’
a) Show that the fraction S of individuals infected in the limit of long time is given
by the solution of the equations
S = φs [1 − g0 (u)],

u = 1 − φs φb + φs φb g1 (u),

where g0 (z) and g1 (z) are the generating functions for the degree distribution and
excess degree distribution, as usual.
b) Show that for a given probability of contact φb the fraction of individuals that
need to be vaccinated to prevent spread of the disease is 1 − 1/[φb g1 (1)].

675

C HAPTER 18

D YNAMICAL SYSTEMS ON NETWORKS
A discussion of dynamical systems on networks, a
subject area that is in its infancy but about which we
nonetheless have some interesting results

T

HE epidemic models of Chapter 17 are a particular example of the more

general concept of dynamical systems on networks. A dynamical system
is any system whose state, as represented by some set of quantitative variables, changes over time according to some given rules or equations. Dynamical systems come in continuous- and discrete-time varieties and can be either
deterministic or stochastic. The epidemic models we looked at, for instance,
were continuous-time dynamical systems because their equations described
the continuous-time variation of the variables. They were also deterministic
because the equations we wrote down exactly determine the values of all variables for all time: there was no random or external element affecting the evolution whose value was not known in advance. On the other hand, an explicit
computer simulation of, say, an SI epidemic model on a network would be
a stochastic dynamical system and might use either continuous- or discretetime. The stochastic element in this case corresponds to the chance infection of
a susceptible individual by an infectious neighbor. And time might be represented in discrete time-steps, although it might not, depending on the decision
of the researcher.
Many other real-world processes—or simpliﬁed models of real-world processes—can be represented as dynamical systems on networks. The spread
of news or information between friends, the movement of money through an
economy, the ﬂow of trafﬁc on roads, data over the Internet, or electricity over
the grid, the evolution of populations in an ecosystem, the changing concentrations of metabolites in a cell, and many other systems of scientiﬁc interest

676

18.1

|

D YNAMICAL SYSTEMS

are best thought of as dynamical processes of one kind or another taking place
on an appropriate network.
In other, non-network contexts, the theory of dynamical systems is a welldeveloped branch of mathematics and physics. (See, for example, the book by
Strogatz [307].) In this chapter we delve into some of this theory and show
how it can be applied to dynamical systems on networks. Necessarily our
introduction only skims the surface of what could be said; dynamical systems
is a topic of entire books in its own right. But the material covered here gives a
ﬂavor of the kinds of calculation that are possible.

18.1

D YNAMICAL SYSTEMS

Our discussion in this chapter will concentrate principally on deterministic
systems of continuous real-valued variables evolving in continuous time t. We
begin by introducing some of the basic ideas in a non-network context, then
we extend these ideas to networks.
A simple (non-network) example of a continuous dynamical system is a
system described by a single real variable x (t) that evolves according to a ﬁrstorder differential equation
dx
= f ( x ),
(18.1)
dt
where f ( x ) is some speciﬁed function of x. Typically we will also give an initial
condition that speciﬁes the value x0 taken by x at some initial time t0 .
The fully-mixed SI model of Section 17.2 is an example of a dynamical system of this kind, having a single variable x representing the fraction of infected
individuals in the system, obeying the equation
dx
= βx (1 − x ).
dt

(18.2)

(See Eq. (17.5).) Thus in this case we have f ( x ) = βx (1 − x ).
One can also have dynamical systems of two variables:
dx
= f ( x, y),
dt

dy
= g( x, y),
dt

(18.3)

and the approach can be extended to larger numbers of variables as well.
When we come to consider systems on networks we will put separate variables on each vertex of the network.
One could also imagine making the functions on the right-hand sides of
our equations depend explicitly on time t:
dx
= f ( x, t).
dt

(18.4)
677

D YNAMICAL SYSTEMS ON NETWORKS

This, however, can be regarded as merely a special case of Eq. (18.3). If we
write
dx
dy
= f ( x, y),
= 1,
(18.5)
dt
dt
with initial condition y(0) = 0, then we have y = t for all times and dx/dt =
f ( x, t) as required. By this trick it is always possible to turn equations with
explicit dependence on t into equations without explicit dependence on t but
with one extra variable. For this reason we will conﬁne ourselves in this chapter to systems with no explicit dependence on t.
Another possible generalization would be to consider systems governed
by equations containing higher derivatives, such as second derivatives. But
these can also be reduced to simpler cases by introducing extra variables. For
instance the equation
d2 x
+
dt2

dx
dt

2

−

dx
= f ( x ),
dt

(18.6)

can be transformed by introducing a new variable y = dx/dt so that we have
dy
= f ( x ) − y2 + y,
dt

dx
= y,
dt

(18.7)

which is a special case of Eq. (18.3) again.
Thus the study of systems of equations like (18.1) and (18.3) covers a broad
range of situations of scientiﬁc interest. Let us look at some of the techniques
used to analyze such equations.
18.1.1

F IXED POINTS AND LINEARIZATION

Equation (18.1), which involves only the one variable x, can, at least in principle, always be solved by simply rearranging and integrating:
 x

dx 
= t − t0 ,

x0 f ( x )

(18.8)

although in practice the integral may not be known in closed form. For cases
with two or more variables, on the other hand, it is not in general possible to
ﬁnd a solution. And for the network examples that we will be studying shortly
the number of variables is typically very large, so that, unless we are lucky (as
we were with some of the epidemiological models of the previous chapter),
full analytic solutions are unlikely to be forthcoming.
We can of course integrate the equations numerically and in some cases this
can give useful insight. But let’s not give up on analytic approaches yet. There
678

18.1

|

D YNAMICAL SYSTEMS

is in fact a well-developed set of techniques for understanding how dynamical systems work without ﬁrst solving their equations exactly. Most of those
techniques focus on the properties of ﬁxed points.
A ﬁxed point is a steady state of the system—any value of the variable or
variables for which the system is stationary and doesn’t change over time. In
the one-variable system, Eq. (18.1), for example, a ﬁxed point is any point x =
x ∗ for which the function on the right-hand side of the equation is zero
f ( x ∗ ) = 0,

(18.9)

so that dx/dt = 0 and x doesn’t move. If, in the evolution of the system,
x ever reaches a ﬁxed point then it will remain there forever. The ﬁxed points
of a one-variable system can be found simply by solving Eq. (18.9) for x.
In a two-variable system like Eq. (18.3) a ﬁxed point is a pair of values
( x∗ , y∗ ) such that f ( x∗ , y∗ ) = 0 and g( x∗ , y∗ ) = 0, making dx/dt = dy/dt = 0
so that both variables stand still at this point.
Consider the SI model of Eq. (18.2). Putting f ( x ) = 0 in this model gives us
βx (1 − x ) = 0, which has solutions x = 1 and x = 0 for the ﬁxed points. We
can see immediately what these ﬁxed points mean in epidemiological terms.
The ﬁrst at x = 1 represents the steady state in which everyone in the system
is infected. Clearly once everyone is infected the system doesn’t change any
more, because there is no one else to infect and because in the SI model no one
recovers either. The second ﬁxed point x = 0 corresponds to the state of the
system where no one is infected. In this state no one will ever become infected,
since there is no one to catch the disease from, so again we have a steady state.
The importance of ﬁxed points in the study of dynamical systems derives
from two key features of these points: ﬁrst, they are relatively easy to ﬁnd, and
second, it is straightforward to determine the dynamics of the system when it
is close to, but not exactly at, a ﬁxed point. The dynamics close to a ﬁxed point
is found by expanding about the point as follows.
Consider ﬁrst a simple one-variable system obeying Eq. (18.1). We represent the value of x close to a ﬁxed point at x ∗ by writing x = x ∗ +  where ,
which represents our distance from the ﬁxed point, is small. Then
d
dx
=
= f ( x ∗ +  ).
(18.10)
dt
dt
Now we perform a Taylor expansion of the right-hand side about the point
x = x ∗ to get
d
= f ( x ∗ ) +  f  ( x ∗ ) + O( 2 ),
(18.11)
dt
where f  represents the derivative of f with respect to its argument. Neglecting
terms of order 2 and smaller and noting that f ( x ∗ ) = 0 (see Eq. (18.9)), we then
679

D YNAMICAL SYSTEMS ON NETWORKS

have

d
=  f  ( x ∗ ).
dt
This is a linear ﬁrst-order differential equation with solution

where

(18.12)

(t) = (0) eλt ,

(18.13)

λ = f  ( x ∗ ).

(18.14)

Note that λ is just a simple number, which we can calculate provided we know
the position x ∗ of the ﬁxed point and the function f ( x ). Depending on the sign
of λ, Eq. (18.13) tells us that our distance  from the ﬁxed point will either
grow or decay exponentially in time. Thus this analysis allows us to classify
our ﬁxed points into two types. An attracting ﬁxed point is one with λ < 0, for
which points close by are attracted towards the ﬁxed point and eventually ﬂow
into it. A repelling ﬁxed point is one with λ > 0, for which points close by are
repelled away. In between these two types there is a special case when λ = 0
exactly. Fixed points with λ = 0 are usually still either attracting or repelling,1
but one cannot tell which is which from the analysis here; one must retain
some of the higher-order terms that we dropped in Eq. (18.11) to determine
what happens.
Analysis of the kind represented by Eq. (18.12) is known as linear stability
analysis. It can be applied to systems with two or more variables as well. Consider, for instance, a dynamical system governed by equations of the form of
Eq. (18.3), with a ﬁxed point at ( x ∗ , y∗ ), meaning that
f ( x ∗ , y∗ ) = 0,

g( x ∗ , y∗ ) = 0.

(18.15)

We represent a point close to the ﬁxed point in the two-dimensional x, y space
by x = x ∗ + x and y = y∗ + y , where x and y are both assumed small.
As before we expand about the ﬁxed point, performing now a double Taylor
expansion:
dx
dx
=
= f ( x ∗ +  x , y ∗ + y )
dt
dt
= f ( x ∗ , y ∗ ) +  x f ( x ) ( x ∗ , y ∗ ) + y f ( y ) ( x ∗ , y ∗ ) + . . . ,

(18.16)

There are also a couple of other rarer possibilities. A ﬁxed point with λ = 0 can be neutral,
meaning it neither attracts nor repels. Points near a neutral ﬁxed point stay exactly where they
are, meaning that they are ﬁxed points too. For example, the choice f ( x ) = 0 for all x has a neutral
ﬁxed point at every value of x. Another less trivial possibility is that a ﬁxed point with λ = 0
may be of mixed type, meaning that it attracts on one side and repels on the other. An example is
f ( x ) = x2 which has a ﬁxed point at x = 0 that is attracting for x < 0 and repelling for x > 0.
1

680

18.1

|

D YNAMICAL SYSTEMS

where f (x) and f (y) indicate the derivatives of f with respect to x and y. Making
use of Eq. (18.15) and neglecting all higher-order terms in the expansion, we
can simplify this expression to
dx
=  x f ( x ) ( x ∗ , y ∗ ) + y f ( y ) ( x ∗ , y ∗ ).
dt

(18.17)

Similarly
dy
=  x g ( x ) ( x ∗ , y ∗ ) + y g ( y ) ( x ∗ , y ∗ ).
(18.18)
dt
We can combine Eqs. (18.17) and (18.18) and write them in matrix form as
d
= J,
dt

(18.19)

where  is the two-component vector (x , y ) and J is the Jacobian matrix
⎞
⎛
∂f ∂f
⎜ ∂x ∂y ⎟
⎟
⎜
J=⎜
(18.20)
⎟,
⎝ ∂g ∂g ⎠
∂x ∂y
where the derivatives are all evaluated at the ﬁxed point.
For systems of three or more variables we an employ the same approach
and again arrive at Eq. (18.19), but with the rank of the vectors and matrices
increasing with increasing number of variables.
Equation (18.19) is again a linear ﬁrst-order differential equation but its solution is more complicated than for the one-variable equivalent. Let us begin
with a particular simple case, the case where the Jacobian matrix is diagonal:
⎞
⎛
dx
⎜ dt ⎟
λ1 0
x
⎟
⎜
,
(18.21)
⎝ dy ⎠ = 0 λ2
y
dt
where λ1 and λ2 are real numbers. In this case, the equations for x and y
separate from one another thus:
dx
= λ1  x ,
dt

dy
= λ2 y ,
dt

(18.22)

 y ( t ) =  y (0 ) eλ2 t ,

(18.23)

and we can solve them separately to get
 x ( t ) =  x (0 ) eλ1 t ,

681

D YNAMICAL SYSTEMS ON NETWORKS

or equivalently
x ( t ) = x ∗ +  x (0 ) eλ1 t ,

y ( t ) = y ∗ +  y (0 ) eλ2 t ,

(18.24)

so that x and y are independently either attracted or repelled from the ﬁxed
point over time, depending on the signs of the two quantities
λ1 =

∂f
∂x

x=x∗
y=y∗

,

λ2 =

∂g
∂y

x=x∗
y=y∗

.

(18.25)

These results give rise to a variety of possible behaviors of the system near
the ﬁxed point, as shown in Fig. 18.1. If λ1 and λ2 are both negative, for instance, then the ﬁxed point will be attracting, while if they are both positive it
will be repelling. If they are of opposite signs then we have a new type of point
called a saddle point that attracts along one axis and repels along the other. In
some respects a saddle point is perhaps best thought of as a form of repelling
ﬁxed point, since a system that starts near a saddle point will not stay near it,
the dynamics being repelled along the unstable direction.
Unless we are very lucky, however, the Jacobian matrix is unlikely to be
diagonal. In the general case it will have off-diagonal as well as diagonal elements and the solution above will not be correct. With a little more work,
however, we can make progress in this case too. The trick is to ﬁnd combinations of the variables x and y that move independently as x and y alone do
above.
Consider the combinations of variables
ξ 1 = ax + by ,

ξ 2 = cx + dy .

(18.26)

x
,
y

(18.27)

In matrix form we can write these as
ξ1
ξ2

=

a b
c d

or simply
ξ = Q,

(18.28)

where Q is the matrix of the coefﬁcients a, b, c, d.
The time evolution of ξ close to the ﬁxed point is given by
d
dξ
=Q
= Q J = Q J Q−1 ξ
dt
dt

(18.29)

where we have used Eqs. (18.19) and (18.28). If ξ 1 and ξ 2 are to evolve independently, then we require that the matrix Q J Q−1 be diagonal, just as J itself
682

18.1

(a) λ1 , λ2 < 0,
λ1 < λ2

(b) λ1 , λ2 < 0,
λ1 = λ2

(c) λ1 , λ2 < 0,
λ1 > λ2

(d) λ1 , λ2 > 0,
λ1 < λ2

(e) λ1 , λ2 > 0,
λ1 = λ2

(f) λ1 , λ2 > 0,
λ1 > λ2

(g) λ1 < 0 < λ2

|

D YNAMICAL SYSTEMS

(h) λ2 < 0 < λ1

Figure 18.1: Flows in the vicinity of different types of ﬁxed points. The ﬂows around
a ﬁxed point in a two-variable dynamical system with a diagonal Jacobian matrix, as
described in the text, can take a variety of different forms as shown. (a), (b), and (c)
are all attracting ﬁxed points, (d), (e), and (f) are repelling, and (g) and (h) are saddle
points.

683

D YNAMICAL SYSTEMS ON NETWORKS

was in the simple case we studied above. Linear algebra then tells us that Q
must be the matrix of eigenvectors of J. More speciﬁcally, since J is in general
asymmetric, Q is the matrix whose rows are the left eigenvectors of J and Q−1
is the inverse of that matrix, which is the matrix whose columns are the right
eigenvectors of J (since the left and right eigenvectors of a matrix are mutually
orthogonal).
Thus, provided we can ﬁnd the eigenvectors of J we can also ﬁnd the combinations ξ 1 and ξ 2 that move independently of one another near the ﬁxed
point. These combinations satisfy the equations
dξ 1
= λ1 ξ 1 ,
dt

dξ 2
= λ2 ξ 2 ,
dt

(18.30)

where λ1 and λ2 are the elements of our diagonal matrix, which are also the
eigenvalues of J corresponding to the two eigenvectors. Equation (18.30) has
the obvious solution
ξ 1 ( t ) = ξ 1 (0 ) eλ1 t ,

ξ 2 ( t ) = ξ 2 (0 ) eλ2 t .

(18.31)

The lines ξ 1 = 0 and ξ 2 = 0 play the role of the axes in Fig. 18.1—they
are lines along which we move either directly away from or directly towards
the ﬁxed point—and Eq. (18.31) indicates that our distance from the ﬁxed point
along these lines will either grow or decay exponentially according to the signs
of the two eigenvalues. Since the eigenvectors of an asymmetric matrix are not
in general orthogonal to one another, these lines are not in general at right angles, so the ﬂows around the ﬁxed point will look similar to those of Fig. 18.1
but squashed, as shown in Fig. 18.2. Nonetheless, we can still classify our ﬁxed
points as attracting, repelling, or saddle points as shown in the ﬁgure. Similar
analyses can be performed for systems with larger numbers of variables and
the basic results are the same: by ﬁnding the eigenvectors of the Jacobian matrix we can determine the combinations of variables that move independently
and hence solve the evolution of the system in the vicinity of the ﬁxed point.
There is another subtlety that arises for systems of two or more variables
that is not found in the one-variable case. The eigenvalues of an asymmetric
matrix need not be real. Even if the elements of the matrix itself are real, the
eigenvalues can be imaginary or complex. What does it mean if the eigenvalues of the Jacobian matrix in our derivation are complex? Putting such
eigenvalues into Eq. (18.31) gives us a solution that oscillates around the ﬁxed
point, rather than simply growing or decaying. Indeed, the substitution actually gives us a value for ξ 1 and ξ 2 that itself is complex, which looks like it
might be a problem, since the coordinates are supposed to be real. However,

684

18.1

(a) Attracting

(b) Repelling

|

D YNAMICAL SYSTEMS

(c) Saddle point

Figure 18.2: Examples of ﬂows around general ﬁxed points. When the Jacobian matrix
is not diagonal the ﬂows around a ﬁxed point look like squashed or stretched versions
of those in Fig. 18.1.

our equations are linear, so the real part of that solution is also a solution, as is
the imaginary part, or any combination of the two.
If λ1 = α + iω, for example, where α and ω are real numbers, then the
general real solution for ξ 1 is


ξ 1 (t) = Re C e(α+iω )t = eαt A cos ωt + B sin ωt ,

(18.32)

where A and B are real constants and C is a complex constant. Thus the solution is the product of a part that oscillates and a part that either grows or
decays exponentially. For the case of two variables, it turns out that the eigenvalues are always either both real or both complex, and if both are complex
then they are complex conjugates of one another. In the latter case, both ξ 1 and
ξ 2 then have this combined behavior of oscillation with exponential growth or
decay, with the same frequency ω of oscillation and the same rate of growth
or decay. The net result is a trajectory that describes a spiral around the ﬁxed
point. Depending on whether α is positive or negative the spiral either moves
outward from the ﬁxed point or inward. If it moves inward, i.e., if α < 0. then
the ﬁxed point is a stable one; otherwise, of α > 0, it is unstable. Thus stability
is in this case determined solely by the real part of the eigenvalues. (In the
special case where α = 0 we must, as before, look at higher-order terms in the
expansion around the ﬁxed point to determine the nature of the point.)
When there are more than two variables, the eigenvalues must either be real
or they appear in complex conjugate pairs. Thus again we have eigendirections
that simply grow or decay, or that spiral in or out.
We are, however, not done yet. There is a further interesting behavior aris-

The ﬂows around a ﬁxed
point whose Jacobian matrix has complex eigenvalues describe a spiral.

685

D YNAMICAL SYSTEMS ON NETWORKS

ing in systems with two or more variables that will be important when we
come to study networked systems. In addition to ﬁxed points, one also ﬁnds
in some systems limit cycles. A limit cycle is a closed loop in the dynamics
such that a system ﬁnding itself on such a loop remains there indeﬁnitely, circulating around and returning repeatedly to its starting point. Limit cycles can
be treated in many ways rather like ﬁxed points: we can study the dynamics
close to the limit cycle by expanding in a small displacement coordinate. Like
ﬁxed points, limit cycles tend to be either attracting or repelling, meaning that
points close to them either spiral inwards toward the limit cycle or outwards
away from it.
Physically, limit cycles represent stable oscillatory behaviors in systems.
We mentioned one such behavior in Section 17.5 in our brief discussion of the
SIRS model. In certain parameter regimes, the SIRS model can show “waves”
of infection—oscillatory behaviors under which a disease infects a large fraction of the population, who then recover and gain immunity, reducing substantially the number of victims available to the disease and therefore causing
the number of cases to drop dramatically. When the ﬁrst wave of individuals
later loses their immunity they move back into the susceptible state, become
infected again, and another wave starts. Another example of oscillation in
a dynamical system is the oscillation of the numbers of predators and prey
in a two-species ecosystem represented, for example, by the Lotka–Volterra
predator-prey equations [307]. Such oscillations have been famously implicated in the mysterious periodic variation in the populations of hares and lynx
recorded by the Hudson Bay Company in Canada during the nineteenth century. A further discussion of this and other aspects of limit cycles can be found
in Ref. [307].

18.2

D YNAMICS ON NETWORKS

Let us now apply some of the ideas of the previous section to dynamical systems on networks. First, we need to be clear what we mean by such systems.
Typically, we mean that we have independent dynamical variables xi , yi , . . . on
each vertex i of our network and that they are coupled together only along the
edges of the network. That is, when we write our equation for the time evolution of a variable xi , the individual terms appearing in that equation each
involve only xi , other variables on vertex i, or one or more variables on a vertex adjacent to i in the network. There are no terms involving variables on
non-adjacent vertices and no terms involving variables on more than one adjacent vertex.
An example of a dynamical system of this type is our equation (17.35) for
686

18.2

|

D YNAMICS ON NETWORKS

the probability of infection of a vertex in the network version of the SI epidemic
model:
dxi
= β(1 − xi ) ∑ Aij x j .
(18.33)
dt
j
This equation only has terms involving pairs of variables that are connected
by edges since these are the only pairs for which Aij is non-zero.
For a system with a single variable on each vertex we can write a general
ﬁrst-order equation
dxi
= f i ( xi ) + ∑ Aij gij ( xi , x j ),
dt
j

(18.34)

where we have separated terms that involve variables on adjacent vertices
from those that do not. You can think of f i as specifying the intrinsic dynamics
of a vertex—it speciﬁes how the variable xi would evolve in the absence of any
connections between vertices, i.e., if Aij = 0 for all i, j. Conversely, gij describes
the contribution from the connections themselves; it represents the coupling
between variables on different vertices.
Notice that we have speciﬁed different functions f i and gij for each vertex
or pair of vertices, so the dynamics obeyed by each vertex can be different. In
many cases, however, when each of the vertices represents a similar thing—
such as a person in the case of an epidemic model—the dynamics for each
vertex may be the same, or at least similar enough that we can ignore any differences. In such cases, the functions in Eq. (18.34) are the same for all vertices
and the equation becomes
dxi
= f ( xi ) + ∑ Aij g( xi , x j ).
dt
j

(18.35)

In the examples in this chapter we will assume that this is the case. We will
also assume that the network is undirected so that Aij is symmetric—if xi is
affected by x j then x j is similarly affected by xi . (Note, however, that we do not
assume that the function g is symmetric in its arguments: g(u, v) = g(v, u).)
Again, the SI model of Eq. (18.33) is an example of a system of this kind, one
in which f ( x ) = 0 and g( xi , x j ) = β(1 − xi ) x j .
18.2.1

L INEAR STABILITY ANALYSIS

Let us try applying the tools of linear stability analysis to Eq. (18.35). Suppose
we are able to ﬁnd a ﬁxed point { xi∗ } of Eq. (18.35) by solving the simultaneous
equations
(18.36)
f ( xi∗ ) + ∑ Aij g( xi∗ , x ∗j ) = 0
j

687

D YNAMICAL SYSTEMS ON NETWORKS

for all i. Note that ﬁnding a ﬁxed point in this case means ﬁnding a value
xi = xi∗ for every vertex i—the ﬁxed point is the complete set { xi∗ }. Note also
that in general the position of the ﬁxed point depends both on the particular
dynamical process taking place on the network (via the functions f and g) and
on the structure of the network (via the adjacency matrix). If either is changed
then the position of the ﬁxed point will also change.
Now we can linearize about this ﬁxed point in the usual way by writing
xi = xi∗ + i , performing a multiple Taylor expansion in all variables simultaneously, and dropping terms at second order in small quantities and higher:
dxi
di
=
= f ( xi∗ + i ) + ∑ Aij g( xi∗ + i , x ∗j +  j )
dt
dt
j
"
df "
= f ( xi∗ ) + i ""
+ Aij g( xi∗ , x ∗j )
dx x=x∗ ∑
j
i
"
"
∂g(u, v) ""
∂g(u, v) ""
+ Aij  j
+...
+ i ∑ Aij
∂u "u=x∗ ,v=x∗ ∑
∂v "u=x∗ ,v=x∗
j
j
i
j
i
j
"
"
"
d f ""
∂g(u, v) ""
∂g(u, v) ""
= i "
+ i ∑ Aij
+ Aij  j
+...,
dx x=x∗
∂u "u=x∗ ,v=x∗ ∑
∂v "u=x∗ ,v=x∗
j
j
i

i

j

i

j

(18.37)
where we have used Eq. (18.36).
If we know the position of the ﬁxed point, then the derivatives in these
expressions are simply numbers. For convenience, let us write
"
∂ f ""
,
(18.38a)
αi =
∂x " x=x∗
i
"
∂g(u, v) ""
β ij =
,
(18.38b)
∂u "u=x∗ ,v=x∗
i
j
"
∂g(u, v) ""
.
(18.38c)
γij =
∂v "u=x∗ ,v=x∗
i

Then

j



di
= αi + ∑ β ij Aij i + ∑ γij Aij  j ,
dt
j
j

(18.39)

which we can write in matrix form as
d
= M,
dt

688

(18.40)

18.2

where M is the matrix with elements


Mij = δij αi + ∑ β ik Aik + γij Aij ,

|

D YNAMICS ON NETWORKS

(18.41)

k

and δij is the Kronecker delta.
We can solve Eq. (18.40) by writing  as a linear combination of the eigenvectors of M, speciﬁcally the right eigenvectors, since M is in general not symmetric:
(18.42)
( t ) = ∑ c r ( t ) vr ,
r

so that Eq. (18.40) becomes
dcr

∑ dt vr = M ∑ cr (t)vr = ∑ μr cr (t)vr ,
r

r

(18.43)

r

where μr is the eigenvalue corresponding to the eigenvector vr . Comparing
terms in each eigenvector we then have

which implies that

dcr
= μr c r ( t ),
dt

(18.44)

c r ( t ) = c r (0 ) eμr t .

(18.45)

Immediately we see that if the real parts of all of the eigenvalues μr are
negative, then cr (t)—and hence —is decaying in time for all r and our ﬁxed
point will be attracting. If the real parts are all positive the ﬁxed point will
be repelling. And if some are positive and some are negative then the ﬁxed
point is a saddle, although, as before, this is perhaps best looked at as a form
of repelling ﬁxed point: the ﬂows near a saddle have at least one repelling
direction, which means that a system starting in the vicinity of such a point
will not in general stay near it, regardless of whether the other directions are
attracting or not.
18.2.2

S PECIAL CASES

Let us look at some common special cases of the general formalism above.
A particularly simple case is when the ﬁxed point is symmetric, meaning that
xi∗ has the same value for every i: xi∗ = x ∗ . This occurs in the SI model for
instance—there is a ﬁxed point at xi∗ = 1 for all i.
For a symmetric ﬁxed point, the ﬁxed point equation, Eq. (18.36), becomes
f ( x ∗ ) + ∑ Aij g( x ∗ , x ∗ ) = f ( x ∗ ) + k i g( x ∗ , x ∗ ) = 0,

(18.46)

j

689

D YNAMICAL SYSTEMS ON NETWORKS

where k i is the degree of vertex i and we have made use of k i = ∑ j Aij (see
Eq. (6.19)). Given the appearance of k i here, there are only two ways this equation can be satisﬁed for all i: either all vertices must have the same degree or
g( x ∗ , x ∗ ) = 0. Since the former is not really realistic—few networks of interest
have all degrees the same—let us concentrate on the latter and assume that
g( x ∗ , x ∗ ) = 0.

(18.47)

Again the SI model provides an example of this type of behavior. The coupling
function g is of the form βx (1 − x ) in that model, which is zero at the two ﬁxed
points at x = 0, 1.
Equations (18.46) and (18.47) together imply also that f ( x ∗ ) = 0 and hence
the ﬁxed point x ∗ is the same in this case as the ﬁxed point for the “intrinsic” dynamics of a vertex: it falls at the same place as it would if there were
no connections between vertices at all. The position of the ﬁxed point is also
independent of the network structure in this case, a point that will shortly be
important.
For a symmetric ﬁxed point, the quantities αi , β ij , and γij deﬁned in Eq.
(18.38) become
"
∂ f ""
,
(18.48a)
αi = α =
∂x " x=x∗
"
∂g(u, v) ""
β ij = β =
,
(18.48b)
∂u "u,v=x∗
"
∂g(u, v) ""
γij = γ =
.
(18.48c)
∂v "u,v=x∗
Then Eq. (18.39) becomes
di
= (α + βk i )i + γ ∑ Aij  j .
dt
j

(18.49)

The situation simpliﬁes further if the coupling function g( xi , x j ) depends
only on x j and not on xi , i.e., if xi obeys an equation of the form dxi /dt =
f ( xi ) + ∑ j Aij g( x j ). Then β = 0 and
di
= αi + γ ∑ Aij  j ,
dt
j

(18.50)

which we can write in matrix form as
d
= (αI + γA).
dt
690

(18.51)

18.2

|

D YNAMICS ON NETWORKS

As in the general case, the ﬁxed point will be stable if and only if all of the
eigenvalues of the matrix αI + γA are negative. Let vr be the eigenvector of
the adjacency matrix with eigenvalue κr . Then

(αI + γA)vr = αIvr + γAvr = αvr + γκr vr = (α + γκr )vr .

(18.52)

Hence vr is also an eigenvector of αI + γA, but with eigenvalue α + γκr . Now
if all eigenvalues are to be negative, we require that
α + γκr < 0

(18.53)

for all r and from this we can deduce a number of things. First of all it implies that α < −γκr for all r. The adjacency matrix always has both positive
and negative eigenvalues (a result that we will prove in Section 18.3.2), which
means that for this inequality to be satisﬁed for all r we must have α < 0. If
α > 0 then the ﬁxed point is never stable.
Second, we can rearrange Eq. (18.53) to give
κr < −α/γ

if γ > 0,

(18.54a)

κr > −α/γ

if γ < 0,

(18.54b)

for all r. Note, however, that if Eq. (18.54a) is satisﬁed for the largest (most
positive) eigenvalue κ1 of the adjacency matrix, then it is necessarily satisﬁed
by all the other eigenvalues as well. Similarly if Eq. (18.54b) is satisﬁed for
the most negative eigenvalue κn then it is satisﬁed by all others. Thus the
conditions above can be simpliﬁed to a single condition each:
κ1 < −α/γ

if γ > 0,

(18.55a)

κn > −α/γ

if γ < 0.

(18.55b)

Alternatively, we can take reciprocals of these conditions and combine them
into a single statement:
γ
1
1
<− < .
(18.56)
α
κ1
κn
If we want we can ﬁll in the explicit values of α and γ thus:
 , 
dg d f
1
1
<−
< ,
dx dx x=x∗
κn
κ1

(18.57)

where we have written g as a function of a single variable since, by hypothesis,
it only depends on one argument in this case.
Equation (18.57) is sometimes called a master stability condition. It has a
special form: note that κ1 and κn depend only on the structure of the network
691

D YNAMICAL SYSTEMS ON NETWORKS

and not on anything about the dynamics, while α and γ depend only the nature
of the dynamics and not on the network structure. Thus Eq. (18.57) effectively
gives us a single condition that must be satisﬁed by any type of dynamics and
its associated ﬁxed point if that dynamics is to be stable on our network. Or
conversely, it gives a condition on the network structure, via the largest and
smallest eigenvalues, that guarantees stability of a given ﬁxed point for a given
type of dynamics.
Another case where we can derive a master stability condition is the case
in which the coupling function g depends on its two arguments according to
g( xi , x j ) = g( xi ) − g( x j ). A physicist might think of this as a “spring-like”
interaction—if g( x ) were a simple linear function of its argument then xi and
x j would act upon one another like two masses coupled by a spring, exerting
forces that depend on the difference of their positions. More generally, g( x ) is
non-linear and we have a non-linear spring.
For this choice of coupling, and still assuming a symmetric ﬁxed point, we
have g( x ∗ , x ∗ ) = 0 as before and hence also f ( x ∗ ) = 0, and the quantities
deﬁned in Eq. (18.38) become
"
d f ""
,
(18.58a)
αi = α =
dx " x=x∗
"
dg ""
β ij = β =
,
(18.58b)
dx " x=x∗
γij = − β.

(18.58c)

Then Eq. (18.39) becomes
di
= (α + βk i )i − β ∑ Aij  j
dt
j

= αi + β ∑(k i δij − Aij ) j ,

(18.59)

j

or in matrix form

d
= (αI + βL),
dt
where L is the matrix with elements
Lij = k i δij − Aij .

(18.60)

(18.61)

We have encountered this matrix before. It is the graph Laplacian—see Eq. (6.43).
Equation (18.60) is of the same form as Eq. (18.51), with the adjacency matrix replaced by the graph Laplacian. Thus we can immediately see that the
692

18.2

|

D YNAMICS ON NETWORKS

ﬁxed point will be stable if and only if the eigenvalues λr of the Laplacian
satisfy
(18.62)
α + βλr < 0
for all r.
As shown in Section 6.13.2, the smallest eigenvalue of the Laplacian matrix
is always zero, and hence Eq. (18.62), when applied to the smallest eigenvalue,
implies again that α < 0 is a necessary (but not sufﬁcient) condition for the
ﬁxed point to be stable, or equivalently
"
d f ""
< 0.
(18.63)
dx " x=x∗
Assuming this condition is satisﬁed then, since all eigenvalues of the Laplacian
are non-negative it follows that 1/λr > − β/α for stability, regardless of the
sign of β. Furthermore, if this condition is true for the largest eigenvalue, traditionally denoted λn , then it is true for all smaller eigenvalues as well, so the
requirement for stability can be reduced to the requirement that 1/λn > − β/α,
or
 , 
dg d f
1
>−
,
(18.64)
λn
dx dx x=x∗
along with the condition in Eq. (18.63).
Again, Eq. (18.64) neatly separates questions of dynamics from questions
of network structure. The structure appears only on the left of the inequality,
via the eigenvalues of the graph Laplacian, and the dynamics appears only on
the right, via derivatives of the functions f and g.
Apart from establishing a condition for the stability of a ﬁxed point, the
master stability condition is of particular interest in the study of bifurcations—
situations in which a ﬁxed point loses stability as the parameters of a system
change. If we vary parameters appearing in the deﬁnitions of f and g, for
example, then we can cause a ﬁxed point that initially satisﬁes a condition
like (18.64) to stop satisfying it and so become unstable. In practice, this means
that the system will suddenly change its behavior as it passes through the point
where 1/λn = − β/α. At one moment it will be sitting happily at its stable
ﬁxed point, going nowhere, and at the next, as that point becomes unstable,
it will start moving, gathering speed exponentially, and quite likely wind up
in some completely different state far from where it started, as it falls into the
basin of attraction of a different stable ﬁxed point or limit cycle. We will see
some examples of behavior of this kind shortly.

693

D YNAMICAL SYSTEMS ON NETWORKS

18.2.3

A N EXAMPLE

As an example, consider the following simple model of “gossip,” or diffusion
of an idea or fad across a social network. Suppose some new idea is circulating
through a community and xi represents the amount person i is talking about
it, which will be governed by an equation of the form (18.35). We will put
f ( x ) = a (1 − x )

(18.65)

with a > 0, which means that the intrinsic dynamics of a single vertex has a
stable ﬁxed point at x ∗ = 1—each person has an intrinsic tendency to talk this
much about the latest craze, regardless of whether their friends want to hear
about it or not. For the interaction term we will assume that people tend to
copy their friends: they increase the amount they are talking about whatever
it is if their friends are talking about it more than they are, and decrease if
their friends are talking about it less. We represent this by putting g( xi , x j ) =
g( x j ) − g( xi ) with
bx
(18.66)
g( x ) =
1+x
and b > 0. This is an increasing function of its argument, as it should be, but
saturates when x  1—beyond some point, it makes no difference if your
friends shout louder.
Now we can apply the general formalism developed above. The symmetric
ﬁxed point for the model is at xi = 1 for all i. At this point everyone is talking
about the topic du jour with equal enthusiasm. This ﬁxed point, however, is
stable only provided Eqs. (18.63) and (18.64) are satisﬁed. Equation (18.63) is
always satisﬁed, given that a > 0. Equation 18.64 implies that 1/λn > b/4a, or
equivalently
4a
.
(18.67)
λn <
b
Thus we can make the ﬁxed point unstable, for example, by increasing b to
the point where the right-hand side of this inequality falls below the largest
eigenvalue λn of the Laplacian for the particular network we are looking at.
Increasing b in this case corresponds to increasing the amount of inﬂuence
your friends have on you.
And what happens when the ﬁxed point becomes unstable? There are no
other symmetric ﬁxed points for this particular system, since there are no other
values that give f ( x ) = 0 (which is a requirement for our symmetric ﬁxed
point). So the system cannot switch to another symmetric ﬁxed point. One
possibility is that the variables might diverge to ±∞, and this happens in some
systems, but not in this one, where the form of f ( x ) prevents it. Another possibility is that the system might begin to oscillate, or even enter a chaotic regime
694

18.3

|

D YNAMICS WITH MORE THAN ONE VARIABLE PER VERTEX

in which it meanders around in pseudorandom fashion indeﬁnitely. In the
present case, however, it does something simpler. It moves to a non-symmetric
ﬁxed point, one in which the ﬁxed-point values of the variables xi are not all
equal. This is an interesting and perhaps unexpected behavior. Our calculations are telling us when the inﬂuence between neighboring individuals in the
network becomes very strong that instead of driving everyone to behave in the
same way, as one might expect, it actually causes behaviors to differ. People
spontaneously develop idiosyncrasies and start doing things their own way.

18.3

D YNAMICS WITH MORE THAN ONE VARIABLE PER VERTEX

Our developments so far have assumed that there is only a single variable xi
on each vertex i of the network. Many systems, however, have more than one
variable per vertex. The epidemiological examples of Chapter 17, mostly have
several—s, x, r, and so forth.
Consider a system with an arbitrary number of variables x1i , x2i , . . . on each
vertex i, but let us assume that we have the same number of variables on
each vertex and that, as before, they obey equations of the same form. For
convenience let us write the set of variables on a single vertex as a vector
xi = ( x1i , x2i , . . .) and then write the equations governing their time evolution as
dxi
= f(xi ) + ∑ Aij g(xi , x j ).
dt
j

(18.68)

Note that the functions f and g, representing the intrinsic dynamics and the
coupling, have now become vector functions f and g of vector arguments, with
the same rank as x.
Following the same line of reasoning as before, we can study the stability
of a symmetric ﬁxed point xi = x∗ by writing xi = x∗ + i and performing a
Taylor expansion. The resulting linearized equation for the evolution of the
μth component of i is then


dμi
i ∂ f μ (x)
i ∂ f μ (x)
= 1
+ 2
+...
dt
∂x1
∂x2
x=x∗


∂g
(
u,
v
)
∂g
μ
μ ( u, v )
j ∂gμ ( u, v )
j ∂gμ ( u, v )
+ ∑ Aij 1i
+ 2i
+ . . . + 1
+ 2
+...
∂u1
∂u2
∂v1
∂v2
u,v=x∗
j


"
"
"
"
∂ f μ (x) ""
j ∂gμ ( u, v ) ""
i ∂gμ ( u, v ) "
,
(18.69)
= ∑ νi
+
k

+
A

i ν
ij ν
∂xν "x=x∗
∂uν "u,v=x∗ ∑
∂vν "u,v=x∗
ν
j
where f μ and gμ represent the μth components of f and g.
695

D YNAMICAL SYSTEMS ON NETWORKS

As before, the derivatives in this expression are simply constants, and for
convenience let us deﬁne
"
∂ f μ (x) ""
αμν =
,
(18.70a)
∂xν "x=x∗
"
∂gμ (u, v) ""
,
(18.70b)
β μν =
∂uν "u,v=x∗
"
∂gμ (u, v) ""
,
(18.70c)
γμν =
∂vν "u,v=x∗
so that
dμi
dt



j
= ∑ αμν + k i β μν νi + ∑ Aij γμν ν
ν





j

= ∑ δij αμν + k i β μν + Aij γμν ν
j

(18.71)

jν

where δij is the Kronecker delta again.
We can write this equation in the matrix form
d
= M,
dt

(18.72)

where M is a matrix whose rows (and columns) are labeled by a double pair
of indices (i, μ) and whose elements are
Miμ,jν = δij αμν + δij k i β μν + Aij γμν .

(18.73)

In principle, we can now determine whether the ﬁxed point is stable by examining the eigenvalues of this new matrix. If the real parts of the eigenvalues are
all negative then the ﬁxed point is stable, otherwise it is not. In practice this
can be a difﬁcult thing to do in general but, as before, there are some common special cases where the calculation simpliﬁes, yielding a master stability
condition.
18.3.1

S PECIAL CASES

As before we consider the case where g(xi , x j ) depends only on its second argument and not on its ﬁrst. In this case β μν = 0 for all μ, ν and Eq. (18.71)
becomes
dμi
j
= ∑ δij αμν + Aij γμν ν .
(18.74)
dt
jν
696

18.3

|

D YNAMICS WITH MORE THAN ONE VARIABLE PER VERTEX

Now let vri be the ith component of the eigenvector vr of the adjacency matrix
corresponding to eigenvalue κr . Let us write
μi (t) = ∑ crμ (t)vri .

(18.75)

r

This equation expresses the vector of elements μi as a linear combination of
eigenvectors in the usual way, but with a separate set of coefﬁcients crμ for each
dynamical variable μ. Substituting into Eq. (18.74), we get
dcrμ

∑ dt vri = ∑ ∑ δij αμν + Aij γμν crν (t)vr
j

r

r

jν

= ∑ αμν + κr γμν crν (t)vri .

(18.76)

rν

Equating terms in the individual eigenvectors on both sides of the equation,
we thus conclude that
dcrμ
dt

= ∑ αμν + κr γμν crν (t).

(18.77)

ν

We can think of this as itself a matrix equation for a vector cr = (c1r , c2r , . . .)
thus:
dcr
= [α + κ r γ ] cr ( t ),
(18.78)
dt
where α and γ are matrices with elements αμν and γμν , respectively.
This equation expresses the dynamics of the system close to the ﬁxed point
as a decoupled set of n separate systems, one for each eigenvalue κr of the
adjacency matrix. If the ﬁxed point of the system as a whole is to be stable,
then each of these individual systems also needs to be stable, meaning that
their eigenvalues need to be negative, or, more simply, the largest (i.e., most
positive) eigenvalue of α + κr γ needs to be negative for every r.
Let us deﬁne the function σ (κ ) to be equal to the most positive eigenvalue
of the matrix α + κγ, or the most positive real part in the case where the eigenvalues are complex. Typically this is an easy function to evaluate numerically.
Notice that α + κγ has only as many rows and columns as there are variables
on each vertex of the network. If we have three variables on each vertex, for
instance, the matrix has size 3 × 3, which is easily diagonalized.
The function σ (κ ) is called a master stability function. If our system is to be
stable, the master stability function evaluated at the eigenvalue κr should be
negative for all r:
(18.79)
σ (κr ) < 0.

697

D YNAMICAL SYSTEMS ON NETWORKS

κ min

κ max
σ

κ

Figure 18.3: A sketch of a master stability function. One possible form for the master stability function σ(κ ) might be as shown here (solid curve), with
positive values for large and small κ but negative values in the intermediate range between κmin and κmax .
If all the eigenvalues of the adjacency matrix (represented by the dots) fall in this intermediate range,
then the system is stable.

One possible form for the master stability function
is shown in Fig. 18.3—it becomes large and positive for
κ sufﬁciently small or sufﬁciently big, but is negative
in some intermediate range κmin < κ < κmax . In that
case, the system is stable provided all eigenvalues κr
of the adjacency matrix fall in this range. Again this
gives us a master stability condition that separates network structure from dynamics. The eigenvalues κr are
properties solely of the structure, being derived from
the adjacency matrix alone, while the limits κmin and
κmax are properties solely of the dynamics, being derived from the matrices α and γ, which are determined
by the derivatives of the functions f and g.
We can similarly write down the generalization
of Eq. (18.58) to the case of many variables per vertex. If the interaction between vertices takes the form
g(xi , x j ) = g(xi ) − g(x j ), then γμν = − β μν and
dμi
dt

= ∑ δij αμν + Lij β μν ν ,
j

(18.80)

jν

where Lij = δij − Aij is an element of the Laplacian.
Then the equivalent of Eq. (18.78) is
dcr
= [α + λ r β ] cr ( t ),
dt

(18.81)

where λr is an eigenvalue of the Laplacian and β is the matrix with elements β μν . Again we can deﬁne a master stability function σ (λ) equal to the
most positive eigenvalue of α + λβ (or the most positive real part for complex eigenvalues) and for overall stability of the system this function must be
negative when λ = λr for all r:
σ (λr ) < 0.

(18.82)

And once again, for suitable forms of the master stability function, this allows
us to develop a stability criterion that separates structure from dynamics.
18.3.2

S PECTRA OF COMPLEX NETWORKS

The formalism of the previous section turns questions about the stability of
dynamical systems on networks into questions about the eigenvalue spectra
698

|

18.3

D YNAMICS WITH MORE THAN ONE VARIABLE PER VERTEX

of matrices. Given the deﬁnition of the dynamics taking place on the vertices
of a network we calculate the master stability function and then the stability or
not of the system depends on whether the master stability function is negative
when evaluated at each of the eigenvalues of the appropriate matrix, such as
the adjacency matrix or graph Laplacian. In particular, when the master stability function takes a relatively simple form like that sketched in Fig. 18.3, so
that stability requires only that the eigenvalues fall in some speciﬁed range,
then it is enough to know the smallest (most negative) and largest (most positive) eigenvalues of the matrix to insure stability—if the smallest and largest
fall in the given range then necessarily all the others do too.
A number of results are known about the spectra of networks, and in particular about the smallest and largest eigenvalues, which allow us to make
quite general theoretical statements about stability. For the adjacency matrix,
for example, we can derive limits on the eigenvalues as follows.
Let x be an arbitrary real vector of n elements, which we will write as a
linear combination of the eigenvectors vr of the adjacency matrix A thus:
x = ∑ cr vr .

(18.83)

r

Then
x T Ax
∑ cs vsT A ∑r cr vr
∑ cs cr κr vsT vr
∑ c2 κ r
∑ c2 κ 1
= s
= rs
= r r 2 ≤ r r 2 = κ1 ,
T
T
T
x x
∑ s c s v s ∑r cr vr
∑rs cs cr vs vr
∑r cr
∑r cr
(18.84)
where, as before, κ1 is the largest eigenvalue and we have made use of the fact
that vsT vr = δrs . This inequality is correct for any choice of x. Thus, for instance,
if x = 1 = (1, 1, 1, . . .) then
κ1 ≥

1 T A1
2m
=
= k .
T
1 1
n

(18.85)

So the largest eigenvalue of the adjacency matrix is never less than the average
degree of the network.
Alternatively, suppose that vertex v is the highest-degree vertex in the network, with degree kmax , and let us choose the elements of x thus:
⎧√
if i = v,
⎨ kmax
xi = 1
(18.86)
if Aiv = 1,
⎩
0
otherwise.
Then

⎧
kmax
⎨√
∑ Aij x j ≥ ⎩ kmax
j
0

⎫
if i = v ⎬ (
= kmax xi .
if Aiv = 1
⎭
otherwise

(18.87)

699

D YNAMICAL SYSTEMS ON NETWORKS

(This result is non-trivial and you may ﬁnd it helpful to work through each of
the three cases to convince yourself that it is indeed correct.)
Multiplying both sides of Eq. (18.87) by xi and summing over i we now get
√
x T Ax ≥ kmax x T x or, using Eq. (18.84),
κ1 ≥

(
x T Ax
≥
kmax .
xT x

(18.88)

Thus the largest eigenvalue of the adjacency matrix is never less than the square
root of the largest degree.
Equations (18.85) and (18.88) imply that if we increase either the average
or the maximum degree in our network, we will eventually increase the maximum eigenvalue also. In a system with a master stability function like that
depicted in Fig. 18.3, this will in the end cause the system to become unstable.
We can also derive similar results for the lowest (most negative) eigenvalue κn of the adjacency matrix. We have
x T Ax
∑r c2r κr
∑r c2r κn
=
≥
= κn
xT x
∑r c2r
∑r c2r

(18.89)

for any real vector x. So, for instance, if vertex v is again the highest-degree
vertex in the network and we make the choice
⎧√
if i = v,
⎨ kmax
x i = −1
(18.90)
if Aiv = 1,
⎩
0
otherwise,
then, following the same approach as before, we ﬁnd that
(
κn ≤ − kmax .

(18.91)

Thus increasing the highest degree in the network can also make the system
unstable by the alternative route of decreasing the lowest eigenvalue. Whichever eigenvalue passes out of the region of stability ﬁrst will be the one that
makes the system unstable.
(We note in passing that Eqs. (18.88) and (18.91) together also tell us that
the adjacency matrix of an undirected network always has both positive and
negative eigenvalues, unless the network has no edges in it at all, in which case
all eigenvalues are zero. We used this result previously in Section 18.2.2.)
Other results for the eigenvalues of the adjacency matrix can be derived for
speciﬁc models of networks. For example, Chung et al. [68] have shown for the
conﬁguration model that the expected value of the largest eigenvalue in the
limit of large network size is
k2
.
(18.92)
κ1 =
k
700

18.4

|

S YNCHRONIZATION

In many cases this gives values of κ1 considerably above the limits set by
Eqs. (18.85) and (18.88). On conﬁguration model networks with power-law
degree distributions, for instance, where k2 formally diverges in the limit of
large n, we expect that κ1 will similarly diverge.
One can also derive results for eigenvalues of the Laplacian. The smallest
eigenvalue of the Laplacian is simple—it is always zero. For large networks
the largest eigenvalue λn can be shown to lie in the range [18]
kmax ≤ λn ≤ 2kmax ,

(18.93)

which appears to be a relatively large range but in fact tells us a lot, ensuring
again that the largest eigenvalue is guaranteed to increase if the highest degree
in the network increases sufﬁciently.

18.4

S YNCHRONIZATION

A topic closely related to the study of dynamical stability is the study of synchronization. Many systems of scientiﬁc interest can be modeled as oscillators
of one sort or another. The ﬂashing of ﬁreﬂies, the ticking of clocks, the synchronized clapping of a large audience, and the pathologically synchronized
ﬁring of brain cells during an epileptic attack can all be modeled as networks
of oscillators coupled in such a way that the coupling causes the oscillators to
synchronize.
The periodic, synchronized oscillations of such an oscillator network correspond, in dynamical systems terms, to a limit cycle of the overall dynamics
(see Section 18.1.1). Like ﬁxed points, limit cycles can be stable or unstable,
attracting or repelling, depending on whether small perturbations away from
the periodic behavior tend to grow or decay over time. The mathematics of
whether synchronized states are stable is very similar to that for ﬁxed points.
Again one starts with a system of equations of the form of Eq. (18.68) but now
assumes a periodic limit-cycle solution, xi (t) = s(t) for all i. Perturbing around
this solution one can linearize the equations and, depending on the particular
form of the interaction between vertices, expand the linearized solution as a
combination of the eigenvectors of an appropriate matrix, such as the adjacency matrix or Laplacian. The result is a set of n decoupled systems, each
oscillating independently and each of which must be stable if the system as a
whole is to be stable. One can deﬁne a master stability function σ (λ) again,
corresponding to the growth rate of perturbations away from the periodic solution, which in this context is known as a Lyapunov exponent, although it plays
exactly the same role as the leading eigenvector in our earlier analysis. Once
again this master stability function must be negative when evaluated at each
701

D YNAMICAL SYSTEMS ON NETWORKS

of the eigenvalues λ of the appropriate matrix and this gives us a condition for
stability of the synchronized state.
Many details of the network synchronization process and many special
cases have been studied. For a comprehensive discussion, the interested reader
is encouraged to consult the review by Arenas et al. [23].

P ROBLEMS
18.1 Consider a dynamical system on a k-regular network (i.e., one in which every
vertex has the same degree k) satisfying
dxi
= f ( xi ) + ∑ Aij g( xi , x j ),
dt
j
and in which the initial condition is uniform over vertices, so that xi (0) = x0 for all i.
a) Show that xi (t) = x (t) for all i where
dx
= f ( x ) + kg( x, x ),
dt
and hence that one has to solve only one equation to solve the dynamics.
b) Show that for stability around a ﬁxed point at xi = x ∗ for all i we require that


1
∂
∂
g(u, v)
k<−  ∗
+
.
f (x )
∂v
∂u
u=v= x∗
18.2 Consider a dynamical system on an undirected network, with one variable per
vertex obeying
dxi
= f ( xi ) + ∑ Aij [ g( xi ) − g( x j )],
dt
j
as in Section 18.2.2. Suppose that the system has a symmetric ﬁxed point at xi = x ∗ for
all i.
a) Show, using results given in this chapter, that the ﬁxed point is always stable if
the largest degree kmax in the network satisﬁes
 , 
1
dg d f
> −2
.
dx dx x=x∗
kmax
b) Suppose that f ( x ) = rx (1 − x ) and g( x ) = ax2 . Show that there are two symmetric ﬁxed points for this system, but that one if them is always unstable.
c) Give a condition on the maximum degree in the network that will ensure the
stability of the other ﬁxed point.

702

P ROBLEMS

18.3 The dynamical systems we have considered in this chapter have all been on undirected networks, but systems on directed networks are possible too. Consider a dynamical system on a directed network in which the sign of the interaction along an edge
attached to a vertex depends on the direction of the edge, ingoing edges having positive sign and outgoing edges having negative sign. An example of such a system is a
food web of predator–prey interactions, in which an ingoing edge indicates in-ﬂow of
energy to a predator from its prey and an outgoing edge indicates out-ﬂow from a prey
to its predator. Such a system can be represented by a dynamics of the form
dxi
= f ( xi ) + ∑( Aij − A ji ) g( xi , x j ),
dt
j
where g is a symmetric function of its arguments: g(u, v) = g(v, u).
a) Consider a system of this form in which the in- and out-degrees of every vertex
are equal to the same constant k. Show that such a system has a symmetric ﬁxed
point xi∗ = x ∗ for all i satisfying f ( x ∗ ) = 0.
b) Writing xi = x ∗ + i linearize around this ﬁxed point to show that in the vicinity
of the ﬁxed point the vector  = (1 , 2 , . . .) satisﬁes
d
= (αI + βM),
dt
where M = A − A T . Determine the values of the constants α and β.
c) Show that the matrix M has the property M T = −M. Matrices with this property
are called skew-symmetric matrices.
d) If v is a right eigenvector of a skew-symmetric matrix M with eigenvalue μ, show
that v T is a left eigenvector with eigenvalue −μ. Hence by considering the equality
v∗ T μv
v∗ T Mv
μ = ∗T =
v∗ T v
v v
show that the complex conjugate of the eigenvalue is μ∗ = −μ and hence that all
eigenvalues of a skew-symmetric matrix are imaginary.
e) Show that the dynamical system is stable if Re(α + βμr ) < 0 for all eigenvalues μr
of the matrix M, and hence that the condition for stability is simply α < 0.
The last result means that if the individual vertices are stable in the absence of interaction with other vertices, then the coupled dynamical system is also stable at the symmetric ﬁxed point.
18.4 Following the arguments of Section 18.2.2 the stability of a ﬁxed point in certain
dynamical systems on networks depends on the spectrum of eigenvalues of the adjacency matrix. Suppose we have a dynamical system on a network that takes the form
of an L × L square lattice with periodic (toroidal) boundary conditions along its edges,
and suppose we label each vertex of the lattice by its position vector r = (i, j) where
i, j = 1 . . . L are the row and column indices of the vertex.

703

D YNAMICAL SYSTEMS ON NETWORKS

a) Consider the vector v with one element for each vertex such that vr = exp(ik T r).
Show that this vector is an eigenvector of the adjacency matrix provided
k=

2π
L

n1
,
n2

where n1 and n2 are integers.
b) What range of values is permitted for the integers n1 and n2 ? Hence ﬁnd the
largest and smallest eigenvalues.
18.5 Consider a network with an oscillator on every vertex. The state of the oscillator
on vertex i is represented by a phase angle θi and the system is governed by dynamical
equations of the form
dθi
= ω + ∑ Aij g(θi − θ j ),
dt
j
where ω is a constant and the function g( x ) respects the rotational symmetry of the
phases, meaning that g( x + 2π ) = g( x ) for all x.
a) Show that the synchronized state θi = θ ∗ = ωt for all i is a solution of the dynamics.
b) Consider a small perturbation away from the synchronized state θi = θ ∗ + i and
show that the vector  = (1 , 2 , . . .) satisﬁes
d
= g (0) L,
dt
where L is the graph Laplacian.
c) Hence show that the synchronized state is stable against small perturbations if
and only if g (0) < 0.

704

C HAPTER 19

N ETWORK SEARCH
A discussion of methods for searching networks for
particular vertices or items, a process important for web
search and peer-to-peer networks, and for our
understanding of the workings of social networks

I

N CHAPTER 4 we saw a number of examples of networks that have infor-

mation stored at their vertices: the World Wide Web, citation networks,
peer-to-peer networks, and so forth. These networks can store large amounts
of data but those data would be virtually useless without some way of searching through them for particular items. So important is it to be able to perform
fast and accurate searches that the companies that provide the most popular
search services are now some of the largest in their respective industries—
Google, Thomson Reuters, LexisNexis—and constitute multibillion dollar international operations. In this chapter we examine some of the network issues
involved in efﬁcient searching and some implications of search ideas for the
structure and behavior of networks.

19.1

W EB SEARCH

We have already discussed brieﬂy some aspects of how web search engines
work in Sections 4.1, 7.4, and 7.5. In this section we discuss the issue in more
detail.
Traditional, or ofﬂine, web search is a multistage process. It involves ﬁrst
“crawling” the Web to ﬁnd web pages and recording their contents, then creating an annotated index of those contents, including lists of words and estimates of the importance of pages based on a variety of criteria. And then there
is the search process itself, in which a user submits a text query to a search

705

N ETWORK SEARCH

engine and the search engine extracts a list of pages matching that query from
the index.
The process of web crawling by which web pages are discovered is interesting in itself and exploits the network structure of the Web directly. The crawler
follows hyperlinks between web pages in a manner similar to the breadth-ﬁrst
search algorithm for ﬁnding components described in Section 10.3. The basic process is described in Section 4.1. Practical web crawlers for big search
operations employ many elaborations of this process, including:
• Searching in parallel at many locations on the Web simultaneously using
many different computers,
• Placing the computers at distributed locations around the world to speed
access times to pages coming from different places,
• Repeatedly crawling the same web pages at intervals of a few days or
weeks to check for changes in page contents or pages that appear or disappear,
• Checking on pages more often if their contents have historically changed
more often,
• Checking on pages more often if they are popular with users of the search
engine,
• Heuristics to spot dynamically generated pages that can lead a crawler
into an inﬁnite loop or tree of pages and waste time,
• Targeted crawling that probes more promising avenues in the network
ﬁrst, and
• Altered behavior depending on requests from owners of speciﬁc sites,
who often allow only certain crawlers to crawl their pages, or allow
crawlers to crawl only certain pages, in order to reduce the load on their
servers.
At their heart, however, most web crawlers are still dumb animals, following
links and recording what they see for later processing.
The processing of the raw crawler output also has interesting networkrelated elements. Early search engines simply compiled indexes of words or
phrases occurring in web pages, so one could look up a word and get a list
of pages containing it. Pages containing combinations of words could also be
found by taking the sets of pages containing each individual word in the combination of interest and forming the intersection of those sets. Indexes can be
extended by adding annotations indicating, for example, how often a word appears on a page or whether it appears in the page title or in a section heading,
which might indicate a stronger connection between that word and the subject
matter of the page. Such annotations allow the search engine to make choices

706

19.1

|

W EB SEARCH

about which are the pages most relevant to a given query. Even so, search engines based solely on indexes and textual criteria of this sort do not return very
good results and have been superseded by more sophisticated technology.
Modern search engines do still use indexes in their search process, but only
as a ﬁrst step. A typical modern search engine will use an index to ﬁnd a set
of candidate pages that might be relevant to the given query and then narrow
that set down using other criteria, some of which may be network-based. The
initial set is usually chosen deliberately to be quite broad. It will typically
include pages on which the words of the query appear, but also pages on which
they don’t appear but that link to, or are linked to by, pages that do contain
the query words. The net result is a set of pages that probably includes most
of those that might be of interest to the user submitting the query, but also
many irrelevant pages as well. The strength of the search engine, its ability to
produce useful results, therefore rests primarily on the criteria it uses to narrow
the search within this broad set.
The classic example of a criterion for narrowing web searches comes from
the Google search engine, which makes use of the eigenvector centrality measure known as PageRank, discussed in Section 7.4. PageRank accords pages a
high score if they receive hyperlinks from many other pages, but does so in a
way such that the credit received for a link is higher if it comes from a page that
is itself highly ranked. PageRank, however, is only one of many elements that
go into the formula Google uses to rank web pages. Others include traditional
measures such as frequency of occurrence of query words in the page text and
position of occurrence (near the top or bottom, in titles and headings, etc.), as
well as occurrence of query words in “anchor text” (the highlighted text that
denotes a hyperlink in a referring page) and previous user interest in a particular page (whether people selected this page from the list of search results on
other occasions when the same text query, or a similar one, was entered).
Google gives each web page in the initial set a score that is a weighted
combination of these elements and others. The particular formula used is a
closely guarded secret and is moreover constantly changing, partly just to try
and improve results, but also to confound the efforts of web page creators, who
try to increase their pages’ ranking by working out what particular elements
carry high weight in Google’s formula and incorporating those elements into
their pages.
An important point to appreciate is that some parts of the score a page
receives depend on the particular search query entered by the user—frequency
of occurrence of query words, for instance—but others, such as PageRank, do
not. This allows Google’s computers (or their counterparts in other search
companies) to calculate the latter parts “ofﬂine,” meaning they are calculated
707

N ETWORK SEARCH

ahead of time and not at the time of the query itself. This has some advantages.
PageRank, for instance, is computationally intensive to calculate and it saves
a lot of time if you only have to calculate it once. But there are disadvantages
too. PageRank measures the extent to which people link to a given web page,
but people may link to a page for many reasons. Thus a page may have a
high PageRank for a reason unrelated to the current search query. A page
whose text makes mention of two or more different topics (and many do) may
be a crucial authority on one topic but essentially irrelevant on another, and
PageRank cannot distinguish between the two.
One could imagine a version of PageRank that was speciﬁc to each individual query. One could calculate a PageRank score within just the subnetwork
formed by the set of pages initially selected from the index to match the query.
But this would be computationally expensive and it’s not what Google does.
As a result it is not uncommon for a page to be ranked highly in a particular search even though a casual human observer could quickly see that it was
irrelevant to the search topic. In fact, a large fraction of “bad” search results
returned by search engines probably fall in this category: they are pages that
are important in some context, but not in the context of the speciﬁc search conducted.
The overall process behind searches on Google and similar large search engines is thus as follows [55]. First the Web is crawled to ﬁnd web pages. The
text of those web pages is processed to created an annotated index, and the link
structure of the hyperlinks between them is used to calculate a centrality score
or scores for each page, such as PageRank in Google’s case or (presumably)
some similar measure for other search engines. When a user enters a query
the search engine extracts a deliberately broad set of matching pages from the
index, scores them according to various query-speciﬁc measures such as frequency of occurrence of the query words, then combines those scores with the
pre-computed centrality measure and possibly other pre-computed quantities,
to give each page in the set an overall score. Then the pages are sorted in order
of their scores and the ones with the highest scores are transmitted to the user.
Typically only a small number of the highest-scoring pages are transmitted—
say the ﬁrst ten—but with an option to see lower-scoring pages if necessary.
Despite the reservations mentioned above, this system works well in practice, far better than early web search engines based on textual content alone,
and provides useful search results for millions of computer users every day.

708

19.2

19.2

|

S EARCHING DISTRIBUTED DATABASES

S EARCHING DISTRIBUTED DATABASES

Some information networks form distributed databases. A typical example
is a peer-to-peer ﬁle-sharing network, in which individual computers in the
network each store a subset of the data stored in the network as a whole. The
form and function of peer-to-peer networks were described in Section 4.3.1.
The “network” in a peer-to-peer network is typically a virtual one, in which
individual computers maintain contacts with a subset of others, which are not
necessarily those with which they have direct physical data connections. In
this respect peer-to-peer networks are somewhat similar to the World Wide
Web, in which the hyperlinks between websites are virtual links chosen by a
page’s creator and their topology need have nothing to do with the topology
of the underlying physical Internet. Indeed, the World Wide Web is itself, in a
sense, a distributed database, storing information in the pages at its vertices,
but web search works in a fundamentally different way from search in other
distributed databases, so we treat the two separately.
Search is a fundamental problem in peer-to-peer networks and similar systems: how do we ﬁnd speciﬁc items among those stored at the many vertices
of the network? One way would be to copy the web search approach of Section 19.1 and construct a comprehensive index of all items at some central location and then search that index for items of interest. For a variety of reasons,
however, most peer-to-peer networks don’t go this route, but instead make use
of distributed search techniques in which the search task is shared among the
computers in the network via messages passed along network edges. Indeed
the performance of such distributed searches is the primary reason for linking the vertices into a network in the ﬁrst place and there are some interesting
principles relating the structure of the network to the efﬁciency with which
searches can be performed.
Suppose that we have a peer-to-peer network composed of n individual
computers and each computer is linked by virtual connections to a selection
of the others, where “linked” in this context merely means that these others
are the ones with which a computer has agreed to communicate directly in
the course of performing searches. There is no reason in principle why a computer could not communicate with all others if it wanted to, but in practice
this would demand too much effort or data bandwidth, and limiting the number of network neighbors a computer has brings the resources required within
reasonable bounds.
The simplest form of distributed search, used in some of the earliest peerto-peer networks, is a version of the breadth-ﬁrst search algorithm described in
Section 10.3 (where it was used for ﬁnding network components and shortest

709

N ETWORK SEARCH

paths). Under this approach, a user gives the computer a search term, such
as the name of a computer ﬁle, and the computer sends a query to each of its
neighbors in the peer-to-peer network, asking if they have the ﬁle in question.
If they do, they send the ﬁle to the ﬁrst computer and the search is complete.
If they don’t, then they send a further query to each of their neighbors asking
for the ﬁle. Any neighbor that has seen the query before, such as the computer
that originated it in the ﬁrst place, ignores it. All others check to see if the have
the requested ﬁle and send it back to the originating computer if they do. If
not, they pass the query on to their neighbors, and so on.
This simple strategy certainly works and it has some advantages. For instance, assuming that the network displays the small-world effect (Section 8.2),
the number of steps we will have to take in our breadth-ﬁrst search will be
small even when the network is large (typically increasing only logarithmically with n—see Section 12.7). This means that most searches will take only a
short amount of time to ﬁnd the desired ﬁle.
But there are some serious disadvantages with the approach as well. First,
as we have described it the search doesn’t actually stop when the target ﬁle
is found. There is no mechanism to inform computers that the ﬁle has been
found and that they don’t need to pass the query on to anyone further. This
problem can be ﬁxed relatively easily, however, for example by requiring each
computer receiving the query to check with the originating computer to see if
the ﬁle has been found before they do anything else.
A more serious problem is that the messages transmitted in the process of
spreading a query across the network quickly add up to a huge amount of data
and can easily overwhelm the capacity of the computers involved. Assuming
a worst-case scenario in which a desired ﬁle exists on only a single computer
in the network, we will, on average, have to pass our query to half of all computers before we ﬁnd the ﬁle. That means the number of messages sent in the
course of one query is O(n). Suppose that users perform queries at some constant average rate r, so that the overall rate of queries is rn = O(n). Then the
total number of messages sent per unit time is O(n) × O(n) = O(n2 ) and the
number of messages per computer per unit time is, on average, O(n2 )/n =
O(n), which goes up linearly with the size of the network. This means that, no
matter how much bandwidth our computers have to send and receive data, it
will in the end always become swamped if the network becomes large enough.
And peer-to-peer networks can become extremely large. Some of the largest
have millions of users.
Luckily this worst-case scenario is not usually realized. It is in fact rarely
the case that an item of interest exists on only one computer in a network. Most
items in typical peer-to-peer networks exist in many places. Indeed, assuming
710

19.2

|

S EARCHING DISTRIBUTED DATABASES

that some fraction of the user population likes or needs each item, it is more
reasonable that any given item appears on some ﬁxed fraction c of the vertices
in the network, so that the total number of copies cn goes up as the size of the
network increases. If this is the case, and assuming for the moment that the
value of c is the same for every item, then one will have to search on average
only 1/c vertices before ﬁnding a copy of an item. This means that the total
number of query messages sent over the network per unit time is O(n/c) and
the number per computer per unit time is O(1/c), which is just a constant and
does not increase with increasing network size.
A more realistic calculation allows for the fact that some items are more
popular than others. Suppose that the factors c, which are proportional to
popularity, have a distribution p(c), meaning that the probability of falling in
the interval c to c + dc is p(c) dc. Also important to note is that not all items
are searched for with equal frequency. Indeed a more reasonable assumption
is that they are searched for with frequency proportional to their popularity,
i.e., that the probability of a search query asking for an item with popularity

in the interval c to c + dc is cp(c) dc/ c , where the factor of c = cp(c) dc
insures that the distribution is properly normalized. Then the average number
of vertices we have to examine before we ﬁnd the item corresponding to a
typical query is
 1
1 cp(c) dc
1
=
,
(19.1)
c
c
0 c
and hence the number of query messages sent or received per computer per
unit time is O(1/ c ), which is again a constant as network size becomes large.
In principle, therefore, if a node can handle messages at the rate given by
Eq. (19.1) then the network should go on functioning just ﬁne as its size becomes large. In practice, however, there are still problems. The main difﬁculty
is that vertices in the network vary enormously in their bandwidth capabilities. Most vertices have relatively slow communications with the network,
i.e., low bandwidth, while a few have much better, higher-bandwidth connections. This means that even if bandwidth requirements per vertex are reduced
to a constant as above, the network will still run at a speed dictated by the
majority slow vertices, making queries slow and possibly overwhelming the
capacity of some vertices.
To get around this problem, most modern peer-to-peer networks make use
of supernodes (also called superpeers). Supernodes are high-bandwidth nodes
chosen from the larger population in the network and connected to one another to form a supernode network over which searches can be performed
quickly—see Fig. 19.1.

711

N ETWORK SEARCH

Figure 19.1: The structure of a peer-to-peer network with supernodes. Client nodes
(ﬁlled circles) are connected to a network of supernodes (open circles) that have aboveaverage network bandwidth and hence can conduct searches quickly.

A supernode acts a little like a local exchange in a telephone network (see
Section 2.2). Each normal user, or client, in the network attaches to a supernode (or sometimes to more than one) that acts as their link to the rest of the
network. Each supernode has a number of such clients and the clients communicate to the supernode a list of the ﬁles or other data items they possess
so that the supernode can respond appropriately to search queries from other
supernodes. An individual client wanting to perform a search then sends their
search query to the local supernode, which conducts a breadth-ﬁrst search interrogation of the network of supernodes to ﬁnd the desired item. Since the
supernodes possess records of all the items that the clients have, the entire
search can be performed on the network of supernodes alone and no client
resources are used at all. And since the supernodes are deliberately selected
to have fast network connections, the search runs at the speed of the quickest
vertices in the network.
In practice schemes like this work quite well—well enough to be in wide
use in peer-to-peer networks of millions of users. More sophisticated schemes
have been devised that in theory could work better still—an example is the
“Chord” system proposed by Stoica et al. [305]—but such systems have yet
to ﬁnd widespread adoption since the more traditional supernode approach
appears to work well enough for practical purposes.

712

19.3

19.3

|

M ESSAGE PASSING

M ESSAGE PASSING

A different variation of the distributed search problem is the problem of getting
a message to a particular node in a network. The classic example of this problem is Stanley Milgram’s “small-world” experiment, described in Section 3.6.
In this experiment participants were asked to get a message to a speciﬁc target
individual by passing it from acquaintance to acquaintance through the social
network. Milgram famously found that messages that arrived at the destination passed through only about six people on their way, which is the origin of
the popular concept of the “six degrees of separation.” As discussed in Section 3.6, however, there is another perhaps more surprising implication of the
experiment, ﬁrst pointed out by Kleinberg [177], which is that short paths not
only exist in the network but that people are remarkably good at ﬁnding them.
Of course if one knows the structure of an entire network then one can ﬁnd
short paths directly using, for example, the breadth-ﬁrst search method of Section 10.3.5. Participants in Milgram’s experiment, however, did not know the
whole network and probably only knew a very small part of it, and yet they
were still able to get a message rapidly to the desired target.
This observation raises a number of interesting questions. How, in practice, did people ﬁnd these short paths to the target? Can we come up with an
algorithm that will do the job efﬁciently? How does the performance of that
algorithm depend on the structure of the network? In the following sections
we consider two different models of the message passing process that address
these questions. As we will see, these models suggest that social (or other) networks must have a very particular type of structure if one wants to be able to
ﬁnd short paths easily without a global knowledge of the network.
19.3.1

K LEINBERG ’ S MODEL

The instructions to the participants in Milgram’s experiment were that upon
receiving the message (actually a small booklet or “passport” sent through
the mail), they were to forward it to an acquaintance who they believed to be
closer to the target than they were. The deﬁnition of “closer” was left vague,
however, and one of the ﬁrst things we need to do if we want to model the
mechanics of the experiment is decide on a practical deﬁnition.
An illuminating attempt at modeling Milgram’s experiment was made by
Kleinberg [177, 178], who employed a variant of the small-world model of Section 15.1, as shown in Fig. 19.2. As in the standard small-world model, it has
a ring of vertices around the edge plus a number of “shortcut” edges that connect vertex pairs at random points around the ring. In Kleinberg’s model all

713

N ETWORK SEARCH

Target

2

1

0

3

1

2

3

4

Figure 19.2: The variant small-world model used to model message passing. In the
variant of the small-world model used here, vertices are connected around a ring and
shortcuts added between them as in the normal small-world model. However, the
shortcuts are now biased so that there are more of them connecting nearby vertices
than distant vertices. The strength of the bias is controlled by the parameter α. In the
proof given in the text, the vertices are divided into numbered classes, class 0 consisting
of just the target vertex and higher classes radiating out from the target, each successive
class containing twice as many vertices as the previous one.

vertices are connected to their two immediate neighbors around the ring—
c = 2 in the notation of Chapter 15—and Kleinberg made use of the connections in the ring to deﬁne the “closeness” of vertices for the purposes of the
message-passing experiment. He proposed that individuals in the network,
represented by vertices, are aware of the distance around the ring to other individuals, and hence can say when one of their acquaintances is “closer” to the
target vertex than they are in this sense.
In his calculations Kleinberg considered a greedy algorithm for message passing in which each individual receiving a message passes it on to the one of
their neighbors who is closest to the target in the sense above. This algorithm
is guaranteed always to get the message to the target eventually. Every individual has at least one neighbor who is closer to the target in the Kleinberg

714

19.3

|

M ESSAGE PASSING

sense than they are—their neighbor around the ring in the direction towards
the target. Thus on each step of the message passing process the message is
guaranteed to get at least one step closer to the target around the ring and
hence it must eventually get to the target. In the worst case individuals simply
pass the message around the ring until it reaches its destination but generally
we can expect to do better than this because of the shortcuts. The question
is how much better. Kleinberg showed that it is possible for the greedy algorithm to ﬁnd the target vertex in O(log2 n) steps, but that it can do so only for
particular choices of the arrangement of the shortcuts.
Kleinberg considered a one-parameter family of models that generalizes
the standard small-world model by allowing for different arrangements of the
shortcuts.1 Instead of assuming that shortcuts are placed uniformly at random,
we assume (not unreasonably) that people have more acquaintances among
those close to them (in the sense deﬁned above) than among those far away.
By analogy with the standard small-world model let us place shortcuts around
the ring equal in number to p times the number of edges in the ring itself,
which in this case is just n. Since each shortcut has two ends this means that
the average number of shortcuts attached to each vertex will be 2p (and the actual number will be Poisson distributed with mean 2p). Where we differ from
the standard small-world model is in how these shortcuts are placed. Shortcuts are still placed at random, but they are chosen so that the probability of
a particular shortcut covering a distance r around the ring is Kr −α , where α
is a non-negative constant and K is a normalizing constant. That is, for each
shortcut we choose ﬁrst its length r from this distribution, then we place the
shortcut, spanning exactly r vertices, at a position around the ring chosen uniformly at random. If α = 0 then we recover the standard small-world model
of Section 15.1, but more generally, for α > 0, the model has a preference for
connections between nearby vertices.
Note that the probability that a particular shortcut connects a speciﬁc pair
of vertices a distance r apart is equal to Kr −α /n, which is the probability Kr −α
that the shortcut has length r multiplied by the probability 1/n that out of the
n possible choices it falls in the speciﬁc position around the ring that connects
the two vertices in question. Given that there are np shortcuts in the whole
network, this means that the total probability of having a shortcut between
1
The model we use is a somewhat simpliﬁed version of Kleinberg’s. His model, for instance,
used a two-dimensional lattice instead of a one-dimensional ring as the underlying structure on
which the model was built. The calculations, however, work just as well in either case. Our model
also places shortcuts at random, where Kleinberg’s ﬁxed the number attached to each vertex to be
constant and also made them directed rather than undirected.

715

N ETWORK SEARCH

a given pair of vertices is np × Kr −α /n = pKr −α . (More correctly, this is the
expected number of such shortcuts, but so long as the number is small, the
difference is negligible.)
The normalizing constant K is ﬁxed by the condition that every shortcut
must have some length, and that all lengths lie between 1 and 12 (n − 1), so that2
1
2 ( n −1)

K

∑ r−α = 1.

(19.2)

r =1

We can approximate the sum by an integral using the trapezoidal rule of Eq.
(14.115) thus:
 1 ( n −1)

1
2 ( n −1)

∑ r −α ≃ 1

r =1

=
which gives

2

r −α dr + 12 + 12 12 (n − 1)

1− α
1
−1
2 ( n − 1)

1−α

⎧
1
α −1
⎨ (1 − α)( 2 n)
1
K ≃ 1/ ln 2 n
⎩
2( α − 1) / ( α + 1)

−α

+ 12 + 12 12 (n − 1)
for α < 1,
for α = 1,
for α > 1,

−α

,

(19.3)

(19.4)

as n becomes large.3
We can now show that, for suitable choice of α, the greedy algorithm on this
network can indeed ﬁnd a given target vertex quickly. The proof is as follows.
Suppose, without loss of generality, that the target vertex is at the top of the
ring, as depicted in Fig. 19.2, and let us divide up the other vertices into classes
according to their distance from the target. Class 0 consists of just the target
itself. Class 1 consists of all vertices distance d = 1 from the target around the
ring, of which there are two. Class 2 consists of vertices with distances in the
range 2 ≤ d < 4, class 3 of vertices 4 ≤ d < 8, and so forth. Each class is double
the size of the previous one. In general, class k consists of vertices at distances
2k−1 ≤ d < 2k and contains nk = 2k vertices. (For simplicity, let us assume that
the total number n of vertices is a power of two, minus one, so that everything
works out neatly.)
Now consider a message being passed through the network according to
the greedy algorithm described above and suppose that at a particular step of
2
The maximum length of a shortcut is 12 (n − 1) if n is odd and 12 n if n is even. We will assume
that n is odd in this case, which avoids some small annoyances in the derivations.
3
Note that both the numerator and denominator of the fraction in Eq. (19.3) vanish at α = 1,
so one must use l’Hopital’s rule to extract the limiting value. The same goes for Eq. (19.8).

716

19.3

|

M ESSAGE PASSING

the process the message is at a vertex of class k. How many more steps will it
take before the message leaves class k and passes into a lower class? The total
number of vertices in lower classes is
k −1

k −1

m =0

m =0

∑ n m = ∑ 2m = 2k − 1 > 2k −1 ,

(19.5)

and from Fig. 19.2 we can see that all of these are, at most, a distance 3 × 2k −
2 < 2k+2 from the vertex in class k that currently holds the message. Thus the
probability of the vertex with the message having a shortcut to a particular one
of these vertices in lower classes is at least pK 2−(k+2)α , and the probability of
having a shortcut to any of them is at least pK 2k−1−(k+2)α .
If our vertex has no shortcut that takes the message out of class k then, in
the worst case, it simply passes the message to another vertex in class k that is
closer to the target, either via a shortcut or by passing around the ring. Using
the probability above, the expected number of such moves made before we
ﬁnd a shortcut that takes us out of class k is at most
1 2α+1 (α−1)k
1
2
=
2
.
pK
pK 2k−1−(k+2)α

(19.6)

Finally, again in the worst case, the message will pass through each of the
classes before reaching the target. There are log2 (n + 1) classes in total and
summing over them we ﬁnd that an upper bound on the expected number of
steps  needed to reach the target is

≤
=

1 2α+1
2
pK

log2 (n+1)

∑

k =0

2( α −1) k =

1 2α+1 2(α−1)[1+log2 (n+1)] − 1
2
pK
2α −1 − 1

1 2α+1 [2(n + 1)]α−1 − 1
2
.
2α −1 − 1
pK

(19.7)

Making use of Eq. (19.4) for the constant K and taking the limit of large n we
ﬁnd that asymptotically
⎧
1− α
⎨ An
 ≤ B log2 n
⎩
C n α −1

if α < 1,
if α = 1,
if α > 1,

(19.8)

where A, B, and C are constants depending on α and p, but not n, whose rather
complicated values we can work out from Eqs. (19.4) and (19.7) if we want.
Since Eq. (19.8) gives an upper bound on , this result guarantees that for
the particular case α = 1 we will be able to ﬁnd the target vertex in a time
717

N ETWORK SEARCH

that increases as log2 n with the size of the network. This is not quite as good
as log n, which is the actual length of the shortest path in a typical network,
but it is still a slowly growing function of n and it would be fair to claim that
the small-world experiment would succeed in ﬁnding short paths in a network
that had α = 1. Thus it is possible, provided the network has the correct structure, for a simple strategy like the greedy algorithm, in which vertices have
knowledge only of their immediate network neighborhood, to produce results
similar to those observed by Milgram in his experiment.
On the other hand, if α = 1 then Eq. (19.8) increases as a power of n, suggesting that it would take much longer in such networks to ﬁnd the target
vertex. In particular, for the original small-world model of Section 15.1, which
corresponds to α = 0, Eq. (19.8) grows linearly with n, suggesting that the
Milgram experiment could take millions of steps to ﬁnd a target in a social network of millions of people. Equation (19.8) is only an upper bound on the time
taken, so if one is lucky one may be able to ﬁnd the target faster. For instance,
if the message starts at a vertex that happens to have a shortcut directly to the
target vertex then one can ﬁnd the target in a single step. However, Kleinberg [178] was also able to prove that the average time it takes to ﬁnd the target
increases at least as fast as a power of n except in the special case α = 1, so in
general the greedy algorithm for α = 1 will not work well.4
These results tell us two things. First, they tell us that it is indeed possible
for the small-world experiment to work as observed even if the participants
don’t know the details of the whole network. Second, they tell us that, at
least within the context of the admittedly non-realistic model used here, the
experiment only works for certain very special values of the parameters of the
network. Thus the success of Milgram’s experiment suggests not only that, as
Milgram concluded, there are short paths in social networks, but also that they
have a particular structure that makes path ﬁnding possible.
19.3.2

A HIERARCHICAL MODEL OF MESSAGE PASSING

While interesting, the results of the previous section are not wholly convincing
because the model is clearly not a realistic one. People don’t live around a
circle with just a few shortcuts to others, and message passing doesn’t work
because people know where others live on the circle.
4

In fact, since Kleinberg was studying a two-dimensional version of the small-world model,
his result was for α = 2, not α = 1. In general, on a small-world network built on a d-dimensional
lattice, the greedy algorithm succeeds in ﬁnding the target in time O(log2 n) only when α = d and
for all other values takes time increasing at least as a power of n.

718

19.3

|

M ESSAGE PASSING

So can we derive similar results for a more realistic network model? To
answer this question let us ﬁrst ask how message passing does work. We
can get a hint from the “reverse small-world” experiments of Killworth and
Bernard [39, 174] discussed in Section 3.6. Recall that in these experiments researchers asked subjects to imagine that they were participating in Milgram’s
small-world experiment and then asked them what information they would
want to know about the target in order to make a decision about who to pass
their message on to. Killworth and Bernard found that three pieces of information were sought more often than any others, and by almost all subjects: the
name, occupation, and geographic location of the target.
The target’s name is an obvious requirement in the small-world experiment, since it’s needed to recognize the target when you ﬁnd him or her. Beyond that, however, it probably doesn’t play much role in the message passing, except perhaps in cultures where names can give a clue as to the location
or social status of an individual. Occupation and geographic location, on the
other hand, are of great use in deciding how to forward a message, and these
appear to be the primary pieces of information participants in the experiment
use.
Take geographic location as an example. How would one use information
on geography to route a message? Presumably, one would attempt to pass the
message to someone closer geographically to the target than oneself. Suppose
for instance that the target lives, as Milgram’s did, in a suburb of the city of
Boston, Massachusetts, in the United States. A participant in, say, England,
attempting to get a message to this target, would perhaps ﬁrst forward it to
someone they knew in the US. That person might forward it in turn to someone
they knew in the state of Massachusetts, who would forward it to someone in
Boston, who would forward it to the target’s speciﬁc suburb, and so forth. At
each step in the process, the participants narrow down the search to a smaller
and smaller geographic area until, with luck, the area is so small that someone
there knows the target individual directly.
In a sense, this is what happens in Kleinberg’s model. In Section 19.3.1 we
divided Kleinberg’s circle into zones or classes that get ever smaller as they
close in on the target and showed that under suitable circumstances it takes
only a small number of steps of the message-passing process to ﬁnd a connection from one class to the next smaller one. Since the number of classes is
logarithmic in the size of the network, this means that it also takes only a small
number of steps overall to home in on the target. Kleinberg’s network structure was unrealistic, but the basic idea of progressively narrowing the ﬁeld is
a good one and we would like to ﬁnd a more realistic network model to which
the same type of argument can be applied.
719

N ETWORK SEARCH

4
3

5

2
1

A

B

C

D

E

X

Figure 19.3: The hierarchical model of Watts et al. Small groups of individuals (boxes) are divided up in a hierarchical
structure represented by a binary tree, which might, for instance, correspond to the hierarchical division of geographic
space into countries, regions, towns, and so forth. The hierarchy dictates which social connections (indicated by curves)
are most likely. A vertex in group A, for instance, is most likely to be connected to others close to it in the tree (B, C)
and less likely to be connected to those further away (D, E).

Such a model is the hierarchical model of Watts et al. [322], in which the interplay of social structure and geographic or other dimensions is represented
by a tree or dendrogram.5 In the context of geography, for example, the world
would be divided into countries, the countries into regions, states, or provinces,
the regions into cities and towns, and so forth. The division ends when we
reach units so small that it can reasonably be assumed that everyone knows
everyone else—a single family, for instance.
The divisions can be represented by a tree structure like that shown in
Fig. 19.3. The tree depicted is a binary tree in this case. Each branch splits
in two, then in two again, and so forth. In the real world branches might easily
split into more than two parts. There are more than two countries in the world
after all. However, the binary tree is the simplest case to study (and the one
studied by Watts et al.), and the analysis given here for the binary case can be
generalized to other cases quite easily.
Let us also assume that the groups at the bottom of the tree all have the
5

720

A similar model was also proposed independently by Kleinberg [179].

19.3

|

M ESSAGE PASSING

same size g. Again this is a simpliﬁcation, but a useful one that does not have
a major effect on the results. If the total number of individuals in the network
is n then the number of groups is n/g, and the number of levels in the tree is
log2 (n/g).
The model of Watts et al. makes two other important assumptions. First,
it assumes that people measure distance to a target individual in terms of the
tree, and more speciﬁcally in terms of the lowest common ancestor in the tree
that they share with the target. That is, people are able to tell when someone
lives in the same country as themselves, or the same region or town, but do
not have any detailed information beyond that. This is a more conservative
assumption than is made by Kleinberg’s model. In Kleinberg’s model it is assumed that people know their exact geometric distance to the target, no matter
where in the network the target falls. In the present model people have a much
more coarse-grained impression of how close they are to the target.
The second assumption in the model of Watts et al. is that the social network
itself is correlated with the hierarchical tree structure so that people who are
closer together in the tree, in the sense of sharing a lower common ancestor, are
also more likely to be acquainted. Thus people are more likely to know others
in their own country than in other countries, more likely to know others in
their own town than in other towns, and so forth. A few sample acquaintances
are represented by the curves at the bottom of the ﬁgure.
Thus there are really two networks present in this model. There is the “real”
network of actual acquaintances represented by the curves, and a “shadow”
network, the hierarchical tree, which is not a network of actual acquaintances
but which inﬂuences the acquaintance network and of which individuals are
somewhat aware, in the sense that they know how close they are to others in
the tree.
An important point to note about this model is that although an individual
is less likely to know others far away in the tree, there are also more such faraway individuals than there are ones close by, and the two effects cancel out
to some extent so that it is quite possible for a given individual to know others
who are both near and far. The people who live on your street, for instance,
are close by, so you are likely to know some of them, but they are also few in
number. By contrast, India may be far away for you (depending on where you
live) but there are a lot of people there, so even though you are not very likely
to know any particular inhabitant, it is nonetheless quite likely that you know
at least one out of the whole population. This behavior is crucial to making the
message-passing experiment work on this network.
Consider an individual in group A in Fig. 19.3. Let us suppose that, because of the effect above, this individual has at least one acquaintance at every
721

N ETWORK SEARCH

“distance” in the tree, i.e., one acquaintance in every subtree of the hierarchy
with which they share a common ancestor. That is, they know one of the individuals in group B, the one group with which they share ancestor 1, and they
also know (say) someone in group C, one of the two with whom they share
ancestor 2, and so on through groups D and E as shown. And suppose that
a similar pattern of acquaintances holds for every individual in the network:
everyone knows at least one person in every subtree with whom they share a
common ancestor.
Now consider a greedy algorithm for message passing on this network.
Suppose the message starts at a vertex in group A and, as before, the holder of
the message at each step passes it to an acquaintance closer to the target than
they are, distance now being measured in the sense of the hierarchical tree as
described above.
Suppose the target vertex is in group X, which shares a common ancestor
with A only at the highest and coarsest level marked 4 in the ﬁgure. That
is, the target is in the opposite subtree of ancestor 4 from A. By hypothesis,
the individual holding the message knows this and hence knows that in order
to get the message closer to the target they must pass it to someone in that
opposite subtree. Luckily, under the assumption above they always have such
an acquaintance, in this case in group E. So they pass the message to their
friend in group E. The friend now notes that the target X is in the subtree with
whom they share the common ancestor marked 5 and hence knows that they
must pass the message to a neighbor in that subtree to get it closer to the target.
Again, by deﬁnition, they have at least one such neighbor, to whom they pass
the message. And so the process proceeds. At each step we narrow down our
search to a smaller subtree of the overall network, or equivalently we move to
a lower level in the hierarchy, pivoting about a lower common ancestor. But
the total number of levels in the hierarchy is log2 (n/g) and hence this is the
maximum number of steps that the process will take to reach the target. In
this model, therefore, the message always reaches its target in a logarithmic
number of steps.
It’s not, however, very realistic to assume that each individual in the network knows at least one person at each distance. Watts et al. considered a more
realistic probabilistic model in which there is a probability pm of two individuals knowing one another when their lowest common ancestor is at level m
in the tree. The level is deﬁned to be m = 0 for groups that are immediately
adjacent, as A and B are in Fig. 19.3, and to increase by one for each higher
level up to a maximum of m = log2 (n/g) − 1 at the top of the tree.

722

19.3

|

M ESSAGE PASSING

Watts et al. considered the particular choice
pm = C 2− βm ,

(19.9)

where C and β are constants.6 So long as β is positive this choice gives, as
desired, a lower probability of acquaintance with more distant individuals,
the exact rate of variation being controlled by the value of β. The parameter C
controls the overall number of acquaintances that each individual has.
The number of vertices with which any given vertex shares its ancestor at
level m is just 2m g and hence the expected number of such vertices that it will
be connected to is
(19.10)
2m gpm = Cg 2(1− β)m
with the choice above for pm . Summing over all levels the total expected number of acquaintances an individual has, their average degree in the network,
is
k = Cg

log2 (n/g)−1

∑

m =0

2(1− β)m = Cg

2(1− β) log2 (n/g) − 1
(n/g)1− β − 1
=
Cg
. (19.11)
21− β − 1
21− β − 1

Thus the constant C is given by
C=

k
21 − β − 1
.
g (n/g)1− β − 1

(19.12)

In the limit of large n this simpliﬁes to
⎧
1− β
− 1)(n/g)1− β
⎨ ( k /g)(2
C = ( k /g)/ log2 (n/g)
⎩
( k /g)(1 − 21− β )

for β < 1,
for β = 1,
for β > 1.

(19.13)

Now if a particular vertex receives a message and wants to pass it to a
member of the opposite subtree at level m, it can do so provided it has a suitable acquaintance. If (19.10) is small, however, then most likely it will not, in
which case the best it can do is to pass the message to someone else in the subtree it is already in, who can then repeat the process. The expected number of
times this will happen before one person does have a neighbor in the opposite
subtree is given by the reciprocal of (19.10), which is 2( β−1)m /Cg. Then, summing this over all levels, the total expected number of steps to reach the target
6
Watts et al. actually wrote the expression as Ce− βm , but the difference is only in the value of β
and we ﬁnd the deﬁnition (19.9) more convenient.

723

N ETWORK SEARCH

is

=
=

1
Cg

log2 (n/g)−1

∑

m =0
β −1

2( β −1) m =

1 2( β−1) log2 (n/g) − 1
Cg
2 β −1 − 1

1 (n/g)
−1
.
Cg 2β−1 − 1

(19.14)

It is also possible that the vertex holding the message will not have a neighbor
either in the opposite subtree or in its own subtree. If this happens then the
vertex has only neighbors further from the target than it is and none nearer. In
this case the Milgram experiment fails—recall that participants were asked to
pass the message to someone closer to the target. This, however, is not necessarily unrealistic. As Watts et al. pointed out, this presumably does happen in
the real experiment sometimes, and moreover it is well documented that many
messages, a majority in fact, get lost and never reach their target. For messages
that do get through, however, Eq. (19.14) gives an estimate of the number of
steps they take to arrive.
Equation (19.14) is rather similar to the corresponding expression for the
model of Kleinberg, Eq. (19.7), which is not a coincidence since the mechanisms
by which the message-passing process proceeds are similar in the two cases.
Taking the limit of large n and making use of Eq. (19.13), we ﬁnd that
⎧
1− β
⎨ D (n/g)
2
 = E log (n/g)
⎩
F (n/g) β−1

for β < 1,
for β = 1,
for β > 1,

(19.15)

where D, E, and F are constants.
These results have the same functional form as those of Eq. (19.8) for Kleinberg’s model and tell us that it is indeed possible for Milgram’s experiment
to succeed in networks of this type, but only for the special parameter value
β = 1. For all other values, the number of steps  taken to reach the target
increases as a power of n.
Thus the model of Watts et al. conﬁrms Kleinberg’s results in the context
of a more realistic network. The results are, however, somewhat mysterious
in a way. The idea that the network must be tuned to a special point in order
for the Milgram experiment to succeed is surprising. The Milgram experiment
does appear to succeed when conducted on real-world social networks, but
on the face of it there is no clear reason why real-world networks should fall
at this special point. Is it really true that if the world happened to be a little
different from the way it is, Milgram’s experiment would fail? This is a point
that is not yet fully understood. It is possible that our model misses some
724

P ROBLEMS

important feature of the network structure that makes message passing more
robust in the real world and less dependent on the precise tuning of the network, or that people are using a different scheme for passing messages that
works substantially better than our greedy algorithm. On the other hand, it
is also possible that our model is basically correct but that the world is in fact
only rather loosely tuned to the special point β = 1 at which message passing
succeeds in ﬁnding short paths. For values of β close to 1 the power of n in
Eq. (19.14) is small and hence  still grows quite slowly. Indeed it is in general
difﬁcult to distinguish experimentally between low powers and logarithms, so
any value of β in the rough vicinity of β = 1 could result in good apparent
performance in the message passing experiment.

P ROBLEMS
19.1 Suppose that we use a web crawler to crawl a small portion of the Web, starting
from a randomly chosen web page somewhere in the large in-component. Let us model
the crawl as a breadth-ﬁrst search starting from the given vertex and proceeding for r
“waves” of search, i.e., until it reaches vertices that are r steps away from the start. Let
Si be the size of the large in-component.
a) What is the probability that a given web page has been crawled at the “zeroth”
wave of the algorithm, i.e., when only the one starting page has been crawled?
b) Argue that the probability pi that a page is ﬁrst reached by the crawl on the rth
wave is given approximately by p(r ) = Ap(r − 1), where p = ( p1 , p2 , . . .). Why
is this relation only approximate in general?
c) Hence argue that the probability of a page being found in a small crawl is roughly
proportional to the eigenvector centrality of the page. Recall that the eigenvector
centrality is zero for vertices in the in-component that don’t also belong to the
strongly connected component (see Section 7.2). Explain why this makes sense in
the present context.
19.2 Suppose that a search is performed on a peer-to-peer network using the following
algorithm. Each vertex on the network maintains a record of the items held by each
of its neighbors. The vertex originating a search queries one of its neighbors, chosen
uniformly at random, for a desired item and the neighbor responds either that it or one
of its neighbors has the item, in which case the search ends, or that they do not. In
the latter case, the neighboring vertex then passes the query on to one of its neighbors,
chosen at random, and the process repeats until the item is found. Effectively, therefore,
the search query makes a random walk on the network.

725

N ETWORK SEARCH

a) Argue that, in the limit of a large number of steps, the probability that the query
encounters a vertex i on any particular step is k i /2m, where k i is the degree as
usual and m is the total number of edges in the network.
b) Upon arriving at a vertex of degree k, the search learns (at most) about the items
held by all of that vertex’s k neighbors except for the one the query is coming
from, for a total of k − 1 vertices. Show that on average at each step the search
learns about the contents of approximately k2 / k − 1 vertices and hence that,
for a target item that can be found at a fraction c of the vertices in the network, the
expected number of copies of the item found on a given step is c( k2 / k − 1).
c) Argue that the probability of not ﬁnding the target item on any particular step is
approximately q = exp[c(1 − k2 / k )] and that average number of steps it takes
to ﬁnd a copy of the item is 1/(1 − q).
d) On a network with a power-law degree distribution with exponent less than 3, so
that k2 → ∞, this last result implies that in the limit of large network size the
search should end after only one step. Is this really true? If not, explain why not.
Although the random walk is not a realistic model for actual network search it is nonetheless useful: presumably more intelligent search strategies will ﬁnd results quicker
than a mindless random walk and hence the random walk provides an upper bound
on the length of search needed to ﬁnd an item. In particular, if the random walk works
well, as in the example above, then it suggests that more intelligent forms of search will
also work well.
19.3 The network navigation model of Kleinberg described in Section 19.3.1 is a onedimensional version of what was, originally, a two-dimensional model. In Kleinberg’s
original version, the model was built on a two-dimensional square lattice with vertices
connected by shortcuts with probability proportional to r −α where r is the “Manhattan”
distance between the vertices, i.e., the geodesic network distance in terms of number
of edges traversed (rather than the Euclidean distance). Following the outline of Section 19.3.1, sketch an argument to show for this variant of the model that it is possible
to ﬁnd a target vertex in O(log2 n) steps, but only if α = 2.
19.4 Show that the ability to ﬁnd short paths (of order log2 n) in the hierarchical model
of Section 19.3.2 coincides with the state of the network in which a vertex has equal
numbers of neighbors on average at each possible distance, where “distance” is deﬁned
by the lowest common ancestor two vertices share.

726

R EFERENCES
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

Abello, J., Buchsbaum, A., and Westbrook, J., A
functional approach to external graph algorithms,
in Proceedings of the 6th European Symposium on Algorithms, Springer, Berlin (1998).
Abramowitz, M. and Stegun, I. A., eds., Handbook
of Mathematical Functions, Dover Publishing, New
York (1974).
Achlioptas, D., Clauset, A., Kempe, D., and Moore,
C., On the bias of traceroute sampling: or, Powerlaw degree distributions in regular graphs, J. ACM
56(4), 21 (2009).
Adamic, L. A. and Glance, N., The political blogosphere and the 2004 US election, in Proceedings of
the WWW-2005 Workshop on the Weblogging Ecosystem (2005).
Adamic, L. A. and Huberman, B. A., The nature
of markets in the World Wide Web, Q. J. Electronic
Commerce 1, 512 (2000).
Adamic, L. A., Lukose, R. M., Puniyani, A. R., and
Huberman, B. A., Search in power-law networks,
Phys. Rev. E 64, 046135 (2001).
Adleman, L. M., Molecular computation of solutions to combinatorial problems, Science 266, 1021–
1024 (1994).
Ahuja, R. K., Magnanti, T. L., and Orlin, J. B., Network Flows: Theory, Algorithms, and Applications,
Prentice Hall, Upper Saddle River, NJ (1993).
Aiello, W., Chung, F., and Lu, L., A random graph
model for massive graphs, in Proceedings of the 32nd
Annual ACM Symposium on Theory of Computing,
pp. 171–180, Association of Computing Machinery,
New York (2000).
Aiello, W., Chung, F., and Lu, L., Random evolution of massive graphs, in J. Abello, P. M. Pardalos,
and M. G. C. Resende, eds., Handbook of Massive
Data Sets, pp. 97–122, Kluwer, Dordrecht (2002).

727

[11]

Albert, R. and Barabási, A.-L., Topology of evolving networks: Local events and universality, Phys.
Rev. Lett. 85, 5234–5237 (2000).

[12]

Albert, R. and Barabási, A.-L., Statistical mechanics of complex networks, Rev. Mod. Phys. 74, 47–97
(2002).

[13]

Albert, R., Jeong, H., and Barabási, A.-L., Diameter
of the world-wide web, Nature 401, 130–131 (1999).

[14]

Albert, R., Jeong, H., and Barabási, A.-L., Attack
and error tolerance of complex networks, Nature
406, 378–382 (2000).

[15]

Aldous, D., Spatial transportation networks with
transfer costs: Asymptotic optimality of hub and
spoke models, Mathematical Proceedings of the Cambridge Philosophical Society 145, 471–487 (2008).

[16]

Amaral, L. A. N., Scala, A., Barthélémy, M., and
Stanley, H. E., Classes of small-world networks,
Proc. Natl. Acad. Sci. USA 97, 11149–11152 (2000).

[17]

Anderson, R. M. and May, R. M., Infectious Diseases
of Humans, Oxford University Press, Oxford (1991).

[18]

Anderson, W. N. and Morley, T. D., Eigenvalues of
the Laplacian of a graph, Linear and Multilinear Algebra 18, 141–145 (1985).

[19]

Anthonisse, J. M., The rush in a directed graph,
Technical Report BN 9/71, Stichting Mathematisch
Centrum, Amsterdam (1971).

[20]

Appel, K. and Haken, W., Every planar map is four
colorable. II: Reducibility, Illinois J. Math. 21, 491–
567 (1977).

[21]

Appel, K. and Haken, W., The solution of the fourcolor map problem, Sci. Am. 237, 108–121 (1977).

[22]

Appel, K., Haken, W., and Koch, J., Every planar map is four colorable. I: Discharging, Illinois J.
Math. 21, 429–490 (1977).

R EFERENCES

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

728

Arenas, A., Dı́az-Guilera, A., Kurths, J., Moreno,
Y., and Zhou, C., Synchronization in complex networks, Phys. Rep. 469, 93–153 (2008).
Auerbach, F., Das Gesetz der Bevölkerungskonzentration, Petermanns Geographische Mitteilungen 59, 74–76 (1913).
Bailey, N. T. J., The Mathematical Theory of Infectious
Diseases and Its Applications, Hafner Press, New
York (1975).
Banavar, J. R., Maritan, A., and Rinaldo, A., Size
and form in efﬁcient transportation networks, Nature 399, 130–132 (1999).
Barabási, A.-L. and Albert, R., Emergence of scaling in random networks, Science 286, 509–512
(1999).
Barabási, A.-L., Albert, R., and Jeong, H., Scale-free
characteristics of random networks: The topology of the World Wide Web, Physica A 281, 69–77
(2000).
Barabási, A.-L., Jeong, H., Ravasz, E., Néda, Z.,
Schuberts, A., and Vicsek, T., Evolution of the
social network of scientiﬁc collaborations, Physica
A 311, 590–614 (2002).
Barbour, A. and Mollison, D., Epidemics and
random graphs, in J. P. Gabriel, C. Lefevre, and
P. Picard, eds., Stochastic Processes in Epidemic Theory, pp. 86–89, Springer, New York (1990).
Barthélémy, M. and Amaral, L. A. N., Small-world
networks: Evidence for a crossover picture, Phys.
Rev. Lett. 82, 3180–3183 (1999).
Barthélémy, M., Barrat, A., Pastor-Satorras, R., and
Vespignani, A., Velocity and hierarchical spread of
epidemic outbreaks in scale-free networks, Phys.
Rev. Lett. 92, 178701 (2004).
Barthélémy, M., Barrat, A., Pastor-Satorras, R., and
Vespignani, A., Dynamical patterns of epidemic
outbreaks in complex heterogeneous networks, J.
Theor. Bio. 235, 275–288 (2005).
Bearman, P. S., Moody, J., and Stovel, K., Chains of
affection: The structure of adolescent romantic and
sexual networks, Am. J. Sociol. 110, 44–91 (2004).
Bern, M., Eppstein, D., and Gilbert, J., Provably
good mesh generation, in Proceedings of the 31st
Annual IEEE Symposium on the Foundations of Computer Science, pp. 231–241, Institute of Electrical
and Electronics Engineers, New York (1990).

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

[46]

[47]

Bernard, H. R., Johnsen, E. C., Killworth, P. D.,
and Robinson, S., Estimating the size of an average
personal network and of an event population, in
M. Kochen, ed., The Small World, pp. 159–175,
Ablex Publishing, Norwood, NJ (1989).
Bernard, H. R., Johnsen, E. C., Killworth, P. D., and
Robinson, S., Estimating the size of an average personal network and of an event population: Some
empirical results, Social Science Research 20, 109–121
(1991).
Bernard, H. R. and Killworth, P. D., Informant accuracy in social network data II, Hum. Commun.
Res. 4, 3–18 (1977).
Bernard, H. R., Killworth, P. D., Evans, M. J., McCarty, C., and Shelley, G. A., Studying social relations cross-culturally, Ethnology 2, 155–179 (1988).
Bernard, H. R., Killworth, P. D., and Sailer, L.,
Informant accuracy in social network data IV: A
comparison of clique-level structure in behavioral
and cognitive network data, Soc. Networks 2, 191–
218 (1980).
Bernard, H. R., Killworth, P. D., and Sailer, L., Informant accuracy in social network data V: An experimental attempt to predict actual communication from recall data, Soc. Sci. Res. 11, 30–66 (1982).
Bianconi, G. and Barabási, A.-L., Bose–Einstein
condensation in complex networks, Phys. Rev. Lett.
86, 5632–5635 (2001).
Bianconi, G. and Barabási, A.-L., Competition and
multiscaling in evolving networks, Europhys. Lett.
54, 436–442 (2001).
Bianconi, G. and Capocci, A., Number of loops of
size h in growing scale-free networks, Phys. Rev.
Lett. 90, 078701 (2003).
Blondel, V. D., Gajardo, A., Heymans, M., Senellart, P., and Dooren, P. V., A measure of similarity between graph vertices: Applications to synonym extraction and web searching, SIAM Review
46, 647–666 (2004).
Boccaletti, S., Latora, V., Moreno, Y., Chavez, M.,
and Hwang, D.-U., Complex networks: Structure
and dynamics, Phys. Rep. 424, 175–308 (2006).
Boguñá, M., Pastor-Satorras, R., Dı́az-Guilera, A.,
and Arenas, A., Models of social networks based
on social distance attachment, Phys. Rev. E 70,
056122 (2004).

R EFERENCES

[48]

[49]
[50]

[51]
[52]

[53]

[54]

[55]

[56]

[57]

[58]
[59]

Bollobás, B., Riordan, O., Spencer, J., and Tusnády,
G., The degree sequence of a scale-free random
graph process, Random Struct. Alg. 18, 279–290
(2001).
Bonacich, P. F., Power and centrality: A family of
measures, Am. J. Sociol. 92, 1170–1182 (1987).
Borgatti, S. P., Structural holes: Unpacking Burt’s
redundancy measures, Connections 20(1), 35–38
(1997).
Borgatti, S. P., Centrality and network ﬂow, Soc.
Networks 27, 55–71 (2005).
Borodin, A., Roberts, G. O., Rosenthal, J. S., and
Tsaparas, P., Finding authorities and hubs from
link structures on the World Wide Web, in V. Y.
Shen, N. Saito, M. R. Lyu, and M. E. Zurko, eds.,
Proceedings of the 10th International World Wide Web
Conference, pp. 415–429, Association of Computing
Machinery, New York (2001).
Boyd, D. M. and Ellison, N. B., Social network
sites: Deﬁnition, history, and scholarship, Journal
of Computer-Mediated Communication 13, 210–230
(2008).
Brandes, U., Delling, D., Gaertler, M., Görke, R.,
Hoefer, M., Nikoloski, Z., and Wagner, D., On
ﬁnding graph clusterings with maximum modularity, in Proceedings of the 33rd International Workshop on Graph-Theoretic Concepts in Computer Science, no. 4769 in Lecture Notes in Computer Science, Springer, Berlin (2007).
Brin, S. and Page, L., The anatomy of a large-scale
hypertextual Web search engine, Comput. Netw. 30,
107–117 (1998).
Broder, A., Kumar, R., Maghoul, F., Raghavan, P.,
Rajagopalan, S., Stata, R., Tomkins, A., and Wiener,
J., Graph structure in the web, Comput. Netw. 33,
309–320 (2000).
Broido, A. and Claffy, K. C., Internet topology: Connectivity of IP graphs, in S. Fahmy and
K. Park, eds., Scalability and Trafﬁc Control in IP Networks, no. 4526 in Proc. SPIE, pp. 172–187, International Society for Optical Engineering, Bellingham,
WA (2001).
Burlando, B., The fractal dimension of taxonomic
systems, J. Theor. Bio. 146, 99–114 (1990).
Burt, R. S., Network items and the General Social
Survey, Soc. Networks 6, 293–339 (1984).

[60]

[61]

[62]

[63]

[64]

[65]

[66]

[67]

[68]

[69]

[70]

[71]

Burt, R. S., Structural Holes: The Social Structure
of Competition, Harvard University Press, Cambridge, MA (1992).
Caldarelli, G., Pastor-Satorras, R., and Vespignani,
A., Structure of cycles and local ordering in complex networks, Eur. Phys. J. B 38, 183–186 (2004).
Callaway, D. S., Newman, M. E. J., Strogatz, S. H.,
and Watts, D. J., Network robustness and fragility:
Percolation on random graphs, Phys. Rev. Lett. 85,
5468–5471 (2000).
Cano, P., Celma, O., Koppenberger, M., and Buldú,
J. M., Topology of music recommendation networks, Chaos 16, 013107 (2006).
Carvalho, R., Buzna, L., Bono, F., Gutierrez, E.,
Just, W., and Arrowsmith, D., Robustness of transEuropean gas networks, Phys. Rev. E 80, 016106
(2009).
Catania, J. A., Coates, T. J., Kegels, S., and
Fullilove, M. T., The population-based AMEN
(AIDS in Multi-Ethnic Neighborhoods) study, Am.
J. Public Health 82, 284–287 (1992).
Chen, Q., Chang, H., Govindan, R., Jamin, S.,
Shenker, S. J., and Willinger, W., The origin of
power laws in Internet topologies revisited, in Proceedings of the 21st Annual Joint Conference of the
IEEE Computer and Communications Societies, IEEE
Computer Society, New York (2002).
Chung, F. and Lu, L., The average distances in
random graphs with given expected degrees, Proc.
Natl. Acad. Sci. USA 99, 15879–15882 (2002).
Chung, F., Lu, L., and Vu, V., Spectra of random
graphs with given expected degrees, Proc. Natl.
Acad. Sci. USA 100, 6313–6318 (2003).
Clarkson, G. and DeKorte, D., The problem of
patent thickets in convergent technologies, in W. S.
Bainbridge and M. C. Roco, eds., Progress in Convergence: Technologies for Human Wellbeing, no. 1093
in Annals of the New York Academy of Science,
pp. 180–200, New York Academy of Sciences, New
York (2006).
Clauset, A., Moore, C., and Newman, M. E. J., Hierarchical structure and the prediction of missing
links in networks, Nature 453, 98–101 (2008).
Clauset, A., Newman, M. E. J., and Moore, C.,
Finding community structure in very large networks, Phys. Rev. E 70, 066111 (2004).

729

R EFERENCES

[72]

Clauset, A., Shalizi, C. R., and Newman, M. E. J.,
Power-law distributions in empirical data, SIAM
Review 51, 661–703 (2009).

[85]

Danon, L., Duch, J., Diaz-Guilera, A., and Arenas, A., Comparing community structure identiﬁcation, J. Stat. Mech. P09008 (2005).

[73]

Cohen, J. E., Ecologists’ Co-operative Web Bank, Version 1.0: Machine-Readable Data Base of Food Webs,
Rockefeller University, New York (1989).

[86]

Davis, A., Gardner, B. B., and Gardner, M. R., Deep
South, University of Chicago Press, Chicago (1941).

[87]

[74]

Cohen, R., Erez, K., ben-Avraham, D., and Havlin,
S., Resilience of the Internet to random breakdowns, Phys. Rev. Lett. 85, 4626–4628 (2000).

Davis, G. F. and Greve, H. R., Corporate elite networks and governance changes in the 1980s, Am. J.
Sociol. 103, 1–37 (1997).

[88]

[75]

Cohen, R. and Havlin, S., Scale-free networks are
ultrasmall, Phys. Rev. Lett. 90, 058701 (2003).

Davis, G. F., Yoo, M., and Baker, W. E., The small
world of the American corporate elite, 1982–2001,
Strateg. Organ. 1, 301–326 (2003).

[76]

Cohen, R., Havlin, S., and ben-Avraham, D., Efﬁcient immunization strategies for computer networks and populations, Phys. Rev. Lett. 91, 247901
(2003).

[89]

de Castro, R. and Grossman, J. W., Famous trails to
Paul Erdős, Math. Intell. 21, 51–63 (1999).

[90]

De Vries, H., Finding a dominance order most consistent with a linear hierarchy: A new procedure
and review, Anim. Behav. 55, 827–843 (1998).

[77]

Cole, B. J., Dominance hierarchies in Leptothorax
ants, Science 212, 83–84 (1981).

[91]

[78]

Coleman, J. S., Katz, E., and Menzel, H., The diffusion of an innovation among physicians, Sociometry 20, 253–270 (1957).

De Vries, H., Stevens, J. M. G., and Vervaecke, H.,
Measuring and testing the steepness of dominance
hierarchies, Anim. Behav. 71, 585–592 (2006).

[92]

Dobson, I., Carreras, B. A., Lynch, V. E., and Newman, D., Complex systems analysis of series of
blackouts: Cascading failure, critical points, and
self-organization, Chaos 17, 026103 (2007).

[93]

Connor, R. C., Heithaus, M. R., and Barre, L. M.,
Superalliance of bottlenose dolphins, Nature 397,
571–572 (1999).

Dodds, P. S., Muhamad, R., and Watts, D. J., An
experimental study of search in global social networks, Science 301, 827–829 (2003).

[94]

Cormen, T. H., Leiserson, C. E., Rivest, R. L., and
Stein, C., Introduction to Algorithms, MIT Press,
Cambridge, MA, 2nd ed. (2001).

Dodds, P. S. and Rothman, D. H., Geometry of
river networks, Phys. Rev. E 63, 016115, 016116, &
016117 (2001).

[95]

Dorogovtsev, S. N., Goltsev, A. V., and Mendes, J.
F. F., Ising model on networks with an arbitrary
distribution of connections, Phys. Rev. E 66, 016104
(2002).

[96]

Dorogovtsev, S. N. and Mendes, J. F. F., Scaling behaviour of developing and decaying networks, Europhys. Lett. 52, 33–39 (2000).

[97]

Dorogovtsev, S. N. and Mendes, J. F. F., Language
as an evolving word web, Proc. R. Soc. London B
268, 2603–2606 (2001).

[98]

Dorogovtsev, S. N. and Mendes, J. F. F., Evolution
of networks, Adv. Phys. 51, 1079–1187 (2002).

[99]

Dorogovtsev, S. N., Mendes, J. F. F., and Samukhin,
A. N., Structure of growing networks with preferential linking, Phys. Rev. Lett. 85, 4633–4636 (2000).

[79]

[80]

[81]

Colizza, V., Barrat, A., Barthélemy, M., and Vespignani, A., The role of the airline transportation network in the prediction and predictability of global
epidemics, Proc. Natl. Acad. Sci. USA 103, 2015–
2020 (2006).

[82]

Cover, T. M. and Thomas, J. A., Elements of Information Theory, John Wiley, New York (1991).

[83]

Cox, R. A. K., Felton, J. M., and Chung, K. C.,
The concentration of commercial success in popular music: an analysis of the distribution of gold
records, J. Cult. Econ. 19, 333–340 (1995).

[84]

730

Crovella, M. E. and Bestavros, A., Self-similarity
in World Wide Web trafﬁc: Evidence and possible
causes, in B. E. Gaither and D. A. Reed, eds., Proceedings of the 1996 ACM SIGMETRICS Conference
on Measurement and Modeling of Computer Systems,
pp. 148–159, Association of Computing Machinery,
New York (1996).

R EFERENCES

[100] Dorogovtsev, S. N., Mendes, J. F. F., and Samukhin,
A. N., Giant strongly connected component of directed networks, Phys. Rev. E 64, 025101 (2001).
[101] Drews, C., The concept and deﬁnition of dominance in animal behaviour, Behaviour 125, 283–313
(1993).
[102] Dunne, J. A., Williams, R. J., and Martinez, N. D.,
Food-web structure and network theory: The role
of connectance and size, Proc. Natl. Acad. Sci. USA
99, 12917–12922 (2002).
[103] Ebel, H., Mielsch, L.-I., and Bornholdt, S., Scalefree topology of e-mail networks, Phys. Rev. E 66,
035103 (2002).
[104] Eckmann, J.-P. and Moses, E., Curvature of colinks uncovers hidden thematic layers in the world
wide web, Proc. Natl. Acad. Sci. USA 99, 5825–5829
(2002).
[105] Erdős, P. and Rényi, A., On random graphs, Publicationes Mathematicae 6, 290–297 (1959).
[106] Erdős, P. and Rényi, A., On the evolution of
random graphs, Publications of the Mathematical Institute of the Hungarian Academy of Sciences 5, 17–61
(1960).
[107] Erdős, P. and Rényi, A., On the strength of connectedness of a random graph, Acta Mathematica Scientia Hungary 12, 261–267 (1961).
[108] Erickson, B., Some problems of inference from
chain data, in K. F. Schuessler, ed., Sociological
Methodology 1979, pp. 276–302, Jossey-Bass, San
Francisco (1978).
[109] Estoup, J. B., Gammes Stenographiques, Institut
Stenographique de France, Paris (1916).
[110] Eubank, S., Guclu, H., Kumar, V. S. A., Marathe,
M. V., Srinivasan, A., Toroczkai, Z., and Wang,
N., Modelling disease outbreaks in realistic urban
social networks, Nature 429, 180–184 (2004).
[111] Faloutsos, M., Faloutsos, P., and Faloutsos, C., On
power-law relationships of the internet topology,
Comput. Commun. Rev. 29, 251–262 (1999).
[112] Fararo, T. J. and Sunshine, M., A Study of a Biased Friendship Network, Syracuse University Press,
Syracuse (1964).
[113] Feld, S., Why your friends have more friends than
you do, Am. J. Sociol. 96, 1464–1477 (1991).

[114] Fernholz, D. and Ramachandran, V., The diameter
of sparse random graphs, Random Struct. Alg. 31,
482–516 (2007).
[115] Ferrer i Cancho, R., Janssen, C., and Solé, R. V.,
Topology of technology graphs: Small world patterns in electronic circuits, Phys. Rev. E 64, 046119
(2001).
[116] Ferrer i Cancho, R. and Solé, R. V., The small world
of human language, Proc. R. Soc. London B 268,
2261–2265 (2001).
[117] Ferrer i Cancho, R. and Solé, R. V., Optimization in
complex networks, in R. Pastor-Satorras, J. Rubi,
and A. Dı́az-Guilera, eds., Statistical Mechanics of
Complex Networks, no. 625 in Lecture Notes in
Physics, pp. 114–125, Springer, Berlin (2003).
[118] Fiedler, M., Algebraic connectivity of graphs,
Czech. Math. J. 23, 298–305 (1973).
[119] Fields, S. and Song, O., A novel genetic system
to detect protein–protein interactions, Nature 340,
245–246 (1989).
[120] Fisher, M. E. and Essam, J. W., Some cluster size
and percolation problems, J. Math. Phys. 2, 609–619
(1961).
[121] Flack, J. C., Girvan, M., de Waal, F. B. M., and
Krakauer, D. C., Policing stabilizes construction
of social niches in primates, Nature 439, 426–429
(2006).
[122] Flake, G. W., Lawrence, S. R., Giles, C. L., and Coetzee, F. M., Self-organization and identiﬁcation of
Web communities, IEEE Computer 35, 66–71 (2002).
[123] Flory, P. J., Molecular size distribution in three dimensional polymers. I: Gelation, J. Am. Chem. Soc.
63, 3083–3090 (1941).
[124] Fortunato, S., Community detection in graphs,
Phys. Rep. 486, 75–174 (2010).
[125] Fowler, J. H. and Jeon, S., The authority of Supreme
Court precedent, Soc. Networks 30, 16–30 (2008).
[126] Fowler, J. H., Johnson, T. R., Spriggs II, J. F., Jeon, S.,
and Wahlbeck, P. J., Network analysis and the law:
Measuring the legal importance of Supreme Court
precedents, Political Analysis 15, 324–346 (2007).
[127] Frank, O., Estimation of population totals by use
of snowball samples, in P. W. Holland and S. Leinhardt, eds., Perspectives on Social Network Research,
pp. 319–348, Academic Press, New York (1979).

731

R EFERENCES

[128] Freeman, L. C., A set of measures of centrality based upon betweenness, Sociometry 40, 35–41
(1977).
[129] Freeman, L. C., The Development of Social Network
Analysis, Empirical Press, Vancouver (2004).
[130] Freeman, L. C., Borgatti, S. P., and White, D. R.,
Centrality in valued graphs: A measure of betweenness based on network ﬂow, Soc. Networks
13, 141–154 (1991).
[131] Freeman, L. C., Freeman, S. C., and Michaelson,
A. G., On human social intelligence, J. Soc. Biol.
Struct. 11, 415–425 (1988).
[132] Freeman, L. C., Freeman, S. C., and Michaelson,
A. G., How humans see social groups: A test of the
Sailer–Gaulin models, J. Quant. Anthropol. 1, 229–
238 (1989).
[133] Fronczak, A., Hołyst, J. A., Jedynak, M., and
Sienkiewicz, J., Higher order clustering coefﬁcients
in Barabasi–Albert networks, Physica A 316, 688–
694 (2002).
[134] Galaskiewicz, J., Social Organization of an Urban
Grants Economy, Academic Press, New York (1985).
[135] Gastner, M. T., Spatial Distributions: DensityEqualizing Map Projections, Facility Location, and
Two-Dimensional Networks, Ph.D. thesis, University
of Michigan (2005).
[136] Gastner, M. T. and Newman, M. E. J., Diffusionbased method for producing density equalizing
maps, Proc. Natl. Acad. Sci. USA 101, 7499–7504
(2004).
[137] Gastner, M. T. and Newman, M. E. J., Optimal design of spatial distribution networks, Phys. Rev. E
74, 016117 (2006).
[138] Girvan, M. and Newman, M. E. J., Community
structure in social and biological networks, Proc.
Natl. Acad. Sci. USA 99, 7821–7826 (2002).
[139] Gleiser, P. and Danon, L., Community structure in
jazz, Adv. Complex Syst. 6, 565–573 (2003).
[140] Gleiss, P. M., Stadler, P. F., Wagner, A., and Fell,
D. A., Relevant cycles in chemical reaction networks, Adv. Complex Syst. 4, 207–226 (2001).
[141] Goldstein, M. L., Morris, S. A., and Yen, G. G.,
Problems with ﬁtting to the power-law distribution, Eur. Phys. J. B 41, 255–258 (2004).
[142] Grandy, Jr., W. T., Foundations of Statistical Mechanics: Equilibrium Theory, Reidel, Dordrecht (1987).

732

[143] Grant, T. R., Dominance and association among
members of a captive and a free-ranging group of
grey kangaroos (Macropus giganthus), Anim. Behav.
21, 449–456 (1973).
[144] Grassberger, P., On the critical behavior of the general epidemic process and dynamical percolation,
Math. Biosci. 63, 157–172 (1982).
[145] Grossman, J. W., The evolution of the mathematical research collaboration graph, Congressus Numerantium 158, 202–212 (2002).
[146] Grossman, J. W. and Ion, P. D. F., On a portion
of the well-known collaboration graph, Congressus
Numerantium 108, 129–131 (1995).
[147] Grujić, J., Movies recommendation networks as bipartite graphs, in M. Bubak, G. D. Albada, J. Dongarra, and P. M. A. Sloot, eds., Proceedings of the
8th International Conference on Computational Science, no. 5102 in Lecture Notes in Computer Science, pp. 576–583, Springer, Berlin (2008).
[148] Guardiola, X., Guimerà, R., Arenas, A., DiazGuilera, A., Streib, D., and Amaral, L. A. N.,
Macro- and micro-structure of trust networks,
Preprint cond-mat/0206240 (2002).
[149] Guare, J., Six Degrees of Separation: A Play, Vintage,
New York (1990).
[150] Guimerà, R. and Amaral, L. A. N., Functional cartography of complex metabolic networks, Nature
433, 895–900 (2005).
[151] Guimerà, R., Sales-Pardo, M., and Amaral, L.
A. N., Modularity from ﬂuctuations in random
graphs and complex networks, Phys. Rev. E 70,
025101 (2004).
[152] Gupta, S., Anderson, R. M., and May, R. M., Networks of sexual contacts: Implications for the pattern of spread of HIV, AIDS 3, 807–817 (1989).
[153] Gutenberg, B. and Richter, R. F., Frequency of
earthquakes in california, B. Seismol. Soc. Am. 34,
185–188 (1944).
[154] Harary, F., On the notion of balance of a signed
graph, Mich. Math. J. 2, 143–146 (1953).
[155] Harary, F., Graph Theory, Perseus, Cambridge, MA
(1995).
[156] Hethcote, H. W., The mathematics of infectious
diseases, SIAM Rev. 42, 599–653 (2000).

R EFERENCES

[157] Holland, P. W. and Leinhardt, S., An exponential family of probability distributions for directed
graphs, J. Amer. Stat. Assoc. 76, 33–50 (1981).
[158] Holme, P., Edling, C. R., and Liljeros, F., Structure
and time-evolution of an Internet dating community, Soc. Networks 26, 155–174 (2004).
[159] Huberman, B. A., The Laws of the Web, MIT Press,
Cambridge, MA (2001).
[160] Huxham, M., Beaney, S., and Raffaelli, D., Do parasites reduce the chances of triangulation in a real
food web?, Oikos 76, 284–300 (1996).
[161] Jaffe, A. and Trajtenberg, M., Patents, Citations and
Innovations: A Window on the Knowledge Economy,
MIT Press, Cambridge, MA (2002).
[162] Jeh, G. and Widom, J., SimRank: A measure
of structural-context similarity, in Proceedings of
the 8th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pp. 538–543,
Association of Computing Machinery, New York
(2002).
[163] Jenks, S. M. and Ginsburg, B. E., Socio-sexual dynamics in a captive wolf pack, in H. Frank, ed.,
Man and Wolf, pp. 375–399, Junk Publishers, Dordrecht (1987).
[164] Jeong, H., Mason, S., Barabási, A.-L., and Oltvai,
Z. N., Lethality and centrality in protein networks,
Nature 411, 41–42 (2001).
[165] Jeong, H., Néda, Z., and Barabási, A.-L., Measuring preferential attachment in evolving networks,
Europhys. Lett. 61, 567–572 (2003).
[166] Jeong, H., Tombor, B., Albert, R., Oltvai, Z. N.,
and Barabási, A.-L., The large-scale organization of
metabolic networks, Nature 407, 651–654 (2000).
[167] Jones, J. H. and Handcock, M. S., Sexual contacts and epidemic thresholds, Nature 423, 605–606
(2003).
[168] Kansky, K. J., Structure of Transportation Networks: Relationships Between Network Geometry
and Regional Characteristics, University of Chicago,
Chicago (1963).
[169] Katz, L., A new status index derived from sociometric analysis, Psychometrika 18, 39–43 (1953).
[170] Kennedy, J. W., Quintas, L. V., and Syslo, M. M.,
The theorem on planar graphs, Historia Math. 12,
356–368 (1985).

[171] Kernighan, B. W. and Lin, S., An efﬁcient heuristic procedure for partitioning graphs, Bell System
Technical Journal 49, 291–307 (1970).
[172] Kernighan, B. W. and Ritchie, D. M., The C Programming Language, Prentice Hall, Upper Saddle
River, NJ, 2nd ed. (1988).
[173] Killworth, P. D. and Bernard, H. R., Informant accuracy in social network data, Hum. Organ. 35,
269–286 (1976).
[174] Killworth, P. D. and Bernard, H. R., The reverse
small world experiment, Soc. Networks 1, 159–192
(1978).
[175] Killworth, P. D., Johnsen, E. C., Bernard, H. R.,
Shelley, G. A., and McCarty, C., Estimating the size
of personal networks, Soc. Networks 12, 289–312
(1990).
[176] Kleinberg, J. M., Authoritative sources in a hyperlinked environment, J. ACM 46, 604–632 (1999).
[177] Kleinberg, J. M., Navigation in a small world, Nature 406, 845 (2000).
[178] Kleinberg, J. M., The small-world phenomenon:
An algorithmic perspective, in Proceedings of the
32nd Annual ACM Symposium on Theory of Computing, pp. 163–170, Association of Computing Machinery, New York (2000).
[179] Kleinberg, J. M., Small world phenomena and
the dynamics of information, in T. G. Dietterich,
S. Becker, and Z. Ghahramani, eds., Proceedings of
the 2001 Neural Information Processing Systems Conference, MIT Press, Cambridge, MA (2002).
[180] Kleinberg, J. M., Kumar, S. R., Raghavan, P., Rajagopalan, S., and Tomkins, A., The Web as a
graph: Measurements, models and methods, in
T. Asano, H. Imai, D. T. Lee, S.-I. Nakano, and
T. Tokuyama, eds., Proceedings of the 5th Annual International Conference on Combinatorics and Computing, no. 1627 in Lecture Notes in Computer Science,
pp. 1–18, Springer, Berlin (1999).
[181] Kleinfeld, J., The small world problem, Society
39(2), 61 (2002).
[182] Klovdahl, A. S., Urban social networks: Some
methodological problems and possibilities, in
M. Kochen, ed., The Small World, Ablex Publishing,
Norwood, NJ (1989).
[183] Klovdahl, A. S., Potterat, J. J., Woodhouse, D. E.,
Muth, J. B., Muth, S. Q., and Darrow, W. W., Social

733

R EFERENCES

networks and infectious disease: The Colorado
Springs study, Soc. Sci. Med. 38, 79–88 (1994).
[184] Knuth, D. E., The Stanford GraphBase: A Platform for
Combinatorial Computing, Addison-Wesley, Reading, MA (1993).
[185] Kohli, R. and Sah, R., Market shares: Some
power law results and observations, Working paper 04.01, Harris School of Public Policy, University of Chicago (2003).
[186] Korte, C. and Milgram, S., Acquaintance links between White and Negro populations: Application
of the small world method, J. Pers. Soc. Psychol. 15,
101–108 (1970).
[187] Krapivsky, P. L. and Redner, S., Organization of
growing random networks, Phys. Rev. E 63, 066123
(2001).
[188] Krapivsky, P. L. and Redner, S., A statistical
physics perspective on Web growth, Comput. Netw.
39, 261–276 (2002).
[189] Krapivsky, P. L., Redner, S., and Leyvraz, F., Connectivity of growing random networks, Phys. Rev.
Lett. 85, 4629–4632 (2000).
[190] Krapivsky, P. L., Rodgers, G. J., and Redner, S., Degree distributions of growing networks, Phys. Rev.
Lett. 86, 5401–5404 (2001).
[191] Krebs, V. E., Mapping networks of terrorist cells,
Connections 24, 43–52 (2002).
[192] Lakhina, A., Byers, J., Crovella, M., and Xie, P.,
Sampling biases in IP topology measurements, in
Proceedings of the 22nd Annual Joint Conference of the
IEEE Computer and Communications Societies, Institute of Electrical and Electronics Engineers, New
York (2003).
[193] Landauer, T. K., Foltz, P. W., and Laham, D., An
introduction to latent semantic analysis, Discourse
Processes 25, 259–284 (1998).
[194] Leicht, E. A., Clarkson, G., Shedden, K., and Newman, M. E. J., Large-scale structure of time evolving citation networks, Eur. Phys. J. B 59, 75–83
(2007).
[195] Leicht, E. A., Holme, P., and Newman, M. E. J., Vertex similarity in networks, Phys. Rev. E 73, 026120
(2006).
[196] Lewis, K., Kaufman, J., Gonzalez, M., Wimmer, A.,
and Christakis, N., Tastes, ties, and time: A new

734

social network dataset using Facebook.com, Soc.
Networks 30, 330–342 (2008).
[197] Liljeros, F., Edling, C. R., and Amaral, L. A. N.,
Sexual networks: Implication for the transmission
of sexually transmitted infection, Microbes Infec. 5,
189–196 (2003).
[198] Liljeros, F., Edling, C. R., Amaral, L. A. N., Stanley, H. E., and Åberg, Y., The web of human sexual
contacts, Nature 411, 907–908 (2001).
[199] Lloyd, A. L. and May, R. M., How viruses spread
among computers and people, Science 292, 1316–
1317 (2001).
[200] Lorenz, M. O., Methods of measuring the concentration of wealth, Pub. Am. Stat. Assoc. 9, 209–219
(1905).
[201] Lotka, A. J., The frequency distribution of scientiﬁc
production, J. Wash. Acad. Sci. 16, 317–323 (1926).
[202] Lowry, O. H., Rosebrough, N. J., Farr, A. L., and
Randall, R. J., Protein measurement with the Folin
phenol reagent, J. Biol. Chem. 193, 265–275 (1951).
[203] Lu, E. T. and Hamilton, R. J., Avalanches of the
distribution of solar ﬂares, Astrophys. J. 380, 89–92
(1991).
[204] Lueg, C. and Fisher, D., eds., From Usenet to
CoWebs: Interacting with Social Information Spaces,
Springer, New York (2003).
[205] Lusseau, D., The emergent properties of a dolphin
social network, Proc. R. Soc. London B (suppl.) 270,
S186–S188 (2003).
[206] MacKinnon, I. and Warren, R., Age and geographic
inferences of the LiveJournal social network, in
E. Airoldi, D. M. Blei, S. E. Fienberg, A. Goldenberg, E. P. Xing, and A. X. Zheng, eds., Statistical Network Analysis: Models, Issues, and New Directions, vol. 4503 of Lecture Notes in Computer Science,
pp. 176–178, Springer-Verlag, Berlin (2007).
[207] Mariolis, P., Interlocking directorates and control
of corporations: The theory of bank control, Soc.
Sci. Quart. 56, 425–439 (1975).
[208] Maritan, A., Rinaldo, A., Rigon, R., Giacometti, A.,
and Rodrı́guez-Iturbe, I., Scaling laws for river networks, Phys. Rev. E 53, 1510–1515 (1996).
[209] Martinez, N. D., Artifacts or attributes? Effects of
resolution on the Little Rock Lake food web, Ecol.
Monographs 61, 367–392 (1991).

R EFERENCES

[210] Martinez, N. D., Constant connectance in community food webs, Am. Nat. 139, 1208–1218 (1992).
[211] Maslov, S., Sneppen, K., and Zaliznyak, A., Detection of topological patterns in complex networks:
Correlation proﬁle of the internet, Physica A 333,
529–540 (2004).
[212] May, R. M. and Anderson, R. M., The transmission dynamics of human immunodeﬁciency virus
(HIV), Philos. Trans. R. Soc. London B 321, 565–607
(1988).
[213] McCarty, C., Killworth, P. D., Bernard, H. R.,
Johnsen, E. C., and Shelley, G. A., Comparing two
methods for estimating network size, Hum. Organ.
60, 28–39 (2001).
[214] McMahan, C. A. and Morris, M. D., Application
of maximum likelihood paired comparison ranking to estimation of a linear dominance hierarchy
in animal societies, Anim. Behav. 32, 374–378 (1984).
[215] Medus, A., Acuña, G., and Dorso, C. O., Detection
of community structures in networks via global
optimization, Physica A 358, 593–604 (2005).
[216] Menger, K., Zur allgemeinen Kurventheorie, Fundamenta Mathematicae 10, 96–115 (1927).
[217] Meyer, C. D., Matrix Analysis and Applied Linear Algebra, Society for Industrial and Applied Mathematics, Philadelphia (2000).
[218] Mézard, M. and Montanari, A., Information,
Physics, and Computation, Oxford University Press,
Oxford (2009).
[219] Milgram, S., The small world problem, Psychol. Today 2, 60–67 (1967).
[220] Milo, R., Kashtan, N., Itzkovitz, S., Newman, M.
E. J., and Alon, U., Subgraphs in networks, Phys.
Rev. E 70, 058102 (2004).
[221] Milo, R., Shen-Orr, S., Itzkovitz, S., Kashtan, N.,
Chklovskii, D., and Alon, U., Network motifs:
Simple building blocks of complex networks, Science 298, 824–827 (2002).
[222] Mitzenmacher, M., A brief history of generative
models for power law and lognormal distributions, Internet Mathematics 1, 226–251 (2004).
[223] Mollison, D., Spatial contact models for ecological
and epidemic spread, J. Roy. Stat. Soc. B 39, 283–326
(1977).

[224] Molloy, M. and Reed, B., A critical point for
random graphs with a given degree sequence,
Random Struct. Alg. 6, 161–179 (1995).
[225] Moody, J., Race, school integration, and friendship
segregation in America, Am. J. Sociol. 107, 679–716
(2001).
[226] Moore, C., Ghoshal, G., and Newman, M. E. J.,
Exact solutions for models of evolving networks
with addition and deletion of nodes, Phys. Rev. E
74, 036121 (2006).
[227] Moore, C. and Mertens, S., The Nature of Computation, Oxford University Press, Oxford (2010).
[228] Moreno, J. L., Who Shall Survive?, Beacon House,
Beacon, NY (1934).
[229] Moreno, Y., Pastor-Satorras, R., and Vespignani,
A., Epidemic outbreaks in complex heterogeneous
networks, Eur. Phys. J. B 26, 521–529 (2002).
[230] Neukum, G. and Ivanov, B. A., Crater size distributions and impact probabilities on Earth from lunar, terrestial-planet, and asteroid cratering data,
in T. Gehrels, ed., Hazards Due to Comets and Asteroids, pp. 359–416, University of Arizona Press,
Tucson, AZ (1994).
[231] Newman, E. I., A method of estimating the total
length of root in a sample, J. Appl. Ecol. 3, 139–145
(1966).
[232] Newman, M. E. J., Models of the small world, J.
Stat. Phys. 101, 819–841 (2000).
[233] Newman, M. E. J., Clustering and preferential attachment in growing networks, Phys. Rev. E 64,
025102 (2001).
[234] Newman, M. E. J., Scientiﬁc collaboration networks: I. Network construction and fundamental
results, Phys. Rev. E 64, 016131 (2001).
[235] Newman, M. E. J., Scientiﬁc collaboration networks: II. Shortest paths, weighted networks, and
centrality, Phys. Rev. E 64, 016132 (2001).
[236] Newman, M. E. J., The structure of scientiﬁc collaboration networks, Proc. Natl. Acad. Sci. USA 98,
404–409 (2001).
[237] Newman, M. E. J., Assortative mixing in networks,
Phys. Rev. Lett. 89, 208701 (2002).
[238] Newman, M. E. J., Ego-centered networks and the
ripple effect, Soc. Networks 25, 83–95 (2003).
[239] Newman, M. E. J., Mixing patterns in networks,
Phys. Rev. E 67, 026126 (2003).

735

R EFERENCES

[240] Newman, M. E. J., Properties of highly clustered
networks, Phys. Rev. E 68, 026121 (2003).
[241] Newman, M. E. J., The structure and function of
complex networks, SIAM Rev. 45, 167–256 (2003).
[242] Newman, M. E. J., Analysis of weighted networks,
Phys. Rev. E 70, 056131 (2004).
[243] Newman, M. E. J., A measure of betweenness centrality based on random walks, Soc. Networks 27,
39–54 (2005).
[244] Newman, M. E. J., Power laws, Pareto distributions and Zipf’s law, Contemp. Phys. 46, 323–351
(2005).
[245] Newman, M. E. J., Finding community structure in
networks using the eigenvectors of matrices, Phys.
Rev. E 74, 036104 (2006).
[246] Newman, M. E. J., Modularity and community
structure in networks, Proc. Natl. Acad. Sci. USA
103, 8577–8582 (2006).
[247] Newman, M. E. J., Random graphs with clustering,
Phys. Rev. Lett. 103, 058701 (2009).
[248] Newman, M. E. J., Forrest, S., and Balthrop,
J., Email networks and the spread of computer
viruses, Phys. Rev. E 66, 035101 (2002).
[249] Newman, M. E. J. and Girvan, M., Mixing patterns and community structure in networks, in
R. Pastor-Satorras, J. Rubi, and A. Dı́az-Guilera,
eds., Statistical Mechanics of Complex Networks,
no. 625 in Lecture Notes in Physics, pp. 66–87,
Springer, Berlin (2003).
[250] Newman, M. E. J. and Girvan, M., Finding
and evaluating community structure in networks,
Phys. Rev. E 69, 026113 (2004).
[251] Newman, M. E. J., Moore, C., and Watts, D. J.,
Mean-ﬁeld solution of the small-world network
model, Phys. Rev. Lett. 84, 3201–3204 (2000).
[252] Newman, M. E. J. and Park, J., Why social networks are different from other types of networks,
Phys. Rev. E 68, 036122 (2003).
[253] Newman, M. E. J., Strogatz, S. H., and Watts, D. J.,
Random graphs with arbitrary degree distributions and their applications, Phys. Rev. E 64, 026118
(2001).
[254] Newman, M. E. J. and Watts, D. J., Scaling and percolation in the small-world network model, Phys.
Rev. E 60, 7332–7342 (1999).

736

[255] Newman, M. E. J. and Ziff, R. M., Fast Monte Carlo
algorithm for site or bond percolation, Phys. Rev. E
64, 016706 (2001).
[256] Ng, A. Y., Zheng, A. X., and Jordan, M. I., Stable
algorithms for link analysis, in D. H. Kraft, W. B.
Croft, D. J. Harper, and J. Zobel, eds., Proceedings of
the 24th Annual International ACM SIGIR Conference
on Research and Development in Information Retrieval,
pp. 258–266, Association of Computing Machinery,
New York (2001).
[257] Ogielski, A. T., Integer optimization and zerotemperature ﬁxed point in Ising random-ﬁeld systems, Phys. Rev. Lett. 57, 1251–1254 (1986).
[258] Onnela, J.-P., Saramäki, J., Hyvönen, J., Szabó, G.,
Lazer, D., Kaski, K., Kertész, J., and Barabási, A.L., Structure and tie strengths in mobile communication networks, Proc. Natl. Acad. Sci. USA 104,
7332–7336 (2007).
[259] Padgett, J. F. and Ansell, C. K., Robust action and
the rise of the Medici, 1400–1434, Am. J. Sociol. 98,
1259–1319 (1993).
[260] Park, J. and Newman, M. E. J., Solution of the 2-star
model of a network, Phys. Rev. E 70, 066146 (2004).
[261] Park, J. and Newman, M. E. J., Solution for the
properties of a clustered network, Phys. Rev. E 72,
026136 (2005).
[262] Pastor-Satorras, R., Vázquez, A., and Vespignani,
A., Dynamical and correlation properties of the Internet, Phys. Rev. Lett. 87, 258701 (2001).
[263] Pastor-Satorras, R. and Vespignani, A., Epidemic
dynamics and endemic states in complex networks, Phys. Rev. E 63, 066117 (2001).
[264] Pastor-Satorras, R. and Vespignani, A., Epidemic
spreading in scale-free networks, Phys. Rev. Lett.
86, 3200–3203 (2001).
[265] Pastor-Satorras, R. and Vespignani, A., Evolution
and Structure of the Internet, Cambridge University
Press, Cambridge (2004).
[266] Pelletier, J. D., Self-organization and scaling relationships of evolving river networks, Journal of
Geophysical Research 104, 7359–7375 (1999).
[267] Perlman, R., An overview of PKI trust models,
IEEE Network 13, 38–43 (1999).
[268] Pitts, F. R., A graph theoretic approach to historical geography, The Professional Geographer 17, 15–20
(1965).

R EFERENCES

[269] Plischke, M. and Bergersen, B., Equilibrium Statistical Physics, World Scientiﬁc, Singapore, 3rd ed.
(2006).
[270] Pool, I. de S. and Kochen, M., Contacts and inﬂuence, Soc. Networks 1, 1–48 (1978).
[271] Pothen, A., Simon, H., and Liou, K.-P., Partitioning
sparse matrices with eigenvectors of graphs, SIAM
J. Matrix Anal. Appl. 11, 430–452 (1990).
[272] Potterat, J. J., Phillips-Plummer, L., Muth, S. Q.,
Rothenberg, R. B., Woodhouse, D. E., MaldonadoLong, T. S., Zimmerman, H. P., and Muth, J. B.,
Risk network structure in the early epidemic phase
of HIV transmission in Colorado Springs, Sex.
Transm. Infect. 78, i159–i163 (2002).
[273] Press, W. H., Teukolsky, S. A., Vetterling, W. T., and
Flannery, B. P., Numerical Recipes in C, Cambridge
University Press, Cambridge (1992).
[274] Price, D. J. de S., Networks of scientiﬁc papers, Science 149, 510–515 (1965).
[275] Price, D. J. de S., A general theory of bibliometric and other cumulative advantage processes, J.
Amer. Soc. Inform. Sci. 27, 292–306 (1976).
[276] Radicchi, F., Castellano, C., Cecconi, F., Loreto, V.,
and Parisi, D., Deﬁning and identifying communities in networks, Proc. Natl. Acad. Sci. USA 101,
2658–2663 (2004).
[277] Rapoport, A. and Horvath, W. J., A study of a large
sociogram, Behavioral Science 6, 279–291 (1961).
[278] Ravasz, E. and Barabási, A.-L., Hierarchical organization in complex networks, Phys. Rev. E 67,
026112 (2003).
[279] Rea, L. M. and Parker, R. A., Designing and Conducting Survey Research: A Comprehensive Guide, JosseyBass, San Francisco, CA, 2nd ed. (1997).
[280] Redner, S., How popular is your paper? An empirical study of the citation distribution, Eur. Phys. J.
B 4, 131–134 (1998).
[281] Reichardt, J. and Bornholdt, S., Statistical mechanics of community detection, Phys. Rev. E 74, 016110
(2006).
[282] Ripeanu, M., Foster, I., and Iamnitchi, A., Mapping
the Gnutella network: Properties of large-scale
peer-to-peer systems and implications for system
design, IEEE Internet Computing 6, 50–57 (2002).

[283] Roberts, D. C. and Turcotte, D. L., Fractality and
self-organized criticality of wars, Fractals 6, 351–
357 (1998).
[284] Rodrı́guez-Iturbe, I. and Rinaldo, A., Fractal River
Basins: Chance and Self-Organization, Cambridge
University Press, Cambridge (1997).
[285] Rothenberg, R., Baldwin, J., Trotter, R., and Muth,
S., The risk environment for HIV transmission: Results from the Atlanta and Flagstaff network studies, J. Urban Health 78, 419–431 (2001).
[286] Sade, D. S., Sociometrics of Macaca mulatta: I.
Linkages and cliques in grooming matrices, Folia
Primatologica 18, 196–223 (1972).
[287] Sailer, L. D. and Gaulin, S. J. C., Proximity, sociality
and observation: The deﬁnition of social groups,
Am. Anthropol. 86, 91–98 (1984).
[288] Salganik, M. J., Dodds, P. S., and Watts, D. J., Experimental study of inequality and unpredictability in an artiﬁcial cultural market, Science 311, 854–
856 (2006).
[289] Salganik, M. J. and Heckathorn, D. D., Sampling and estimation in hidden populations using
respondent-driven sampling, Sociol. Methodol. 34,
193–239 (2004).
[290] Salton, G., Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, Addison-Wesley, Reading, MA (1989).
[291] Schaeffer, S. E., Graph clustering, Comp. Sci. Rev. 1,
27–64 (2007).
[292] Schank, T. and Wagner, D., Approximating clustering coefﬁcient and transitivity, J. Graph Algorithms
Appl. 9, 265–275 (2005).
[293] Scott, J., Social Network Analysis: A Handbook, Sage,
London, 2nd ed. (2000).
[294] Sen, P., Dasgupta, S., Chatterjee, A., Sreeram, P. A.,
Mukherjee, G., and Manna, S. S., Small-world
properties of the Indian railway network, Phys.
Rev. E 67, 036106 (2003).
[295] Shuzhuo, L., Yinghui, C., Haifeng, D., and Feldman, M. W., A genetic algorithm with local search
strategy for improved detection of community
structure, Complexity 15 (2010).
[296] Sibani, P. and Littlewood, P. B., Slow dynamics
from noise adaptation, Phys. Rev. Lett. 71, 1482–
1485 (1993).

737

R EFERENCES

[297] Simkin, M. V. and Roychowdhury, V. P., Read before you cite, Complex Systems 14, 269–274 (2003).
[298] Simkin, M. V. and Roychowdhury, V. P., Stochastic
modeling of citation slips, Scientometrics 62, 367–
384 (2005).
[299] Simon, H. A., On a class of skew distribution functions, Biometrika 42, 425–440 (1955).
[300] Smith, M., Invisible crowds in cyberspace: Measuring and mapping the social structure of
USENET, in M. Smith and P. Kollock, eds., Communities in Cyberspace, Routledge Press, London
(1999).
[301] Smith, R. D., Instant messaging as a scale-free network, Preprint cond-mat/0206378 (2002).
[302] Solé, R. V., Pastor-Satorras, R., Smith, E., and Kepler, T. B., A model of large-scale proteome evolution, Adv. Complex Syst. 5, 43–54 (2002).
[303] Solomonoff, R. and Rapoport, A., Connectivity of
random nets, B. Math. Biophys. 13, 107–117 (1951).
[304] Stauffer, D. and Aharony, A., Introduction to Percolation Theory, Taylor and Francis, London, 2nd ed.
(1992).
[305] Stoica, I., Morris, R., Karger, D., Kaashoek, M. F.,
and Balakrishnan, H., Chord: A scalable peer-topeer lookup service for Internet applications, in
Proceedings of the 2001 ACM Conference on Applications, Technologies, Architectures, and Protocols for
Computer Communications (SIGCOMM), pp. 149–
160, Association of Computing Machinery, New
York (2001).
[306] Strauss, D., On a general class of models for interaction, SIAM Rev. 28, 513–527 (1986).
[307] Strogatz, S. H., Nonlinear Dynamics and Chaos,
Addison-Wesley, Reading, MA (1994).
[308] Stutzbach, D. and Rejaie, R., Characterizing today’s Gnutella topology, Technical Report CIS-TR04-02, Department of Computer Science, University of Oregon (2004).
[309] Szabó, G., Alava, M., and Kertész, J., Structural
transitions in scale-free networks, Phys. Rev. E 67,
056102 (2002).
[310] Thompson, S. K. and Frank, O., Model-based estimation with link-tracing sampling designs, Surv.
Methodol. 26, 87–98 (2000).

738

[311] Travers, J. and Milgram, S., An experimental study
of the small world problem, Sociometry 32, 425–443
(1969).
[312] Turner, T. C., Smith, M. A., Fisher, D., and Welser,
H. T., Picturing Usenet: Mapping computermediated collective action, J. Comput.-Mediat. Commun. 10(4), 7 (2005).
[313] Tyler, J. R., Wilkinson, D. M., and Huberman,
B. A., Email as spectroscopy: Automated discovery of community structure within organizations,
in M. Huysman, E. Wenger, and V. Wulf, eds.,
Proceedings of the First International Conference on
Communities and Technologies, Kluwer, Dordrecht
(2003).
[314] Udry, J. R., Bearman, P. S., and Harris, K. M., National Longitudinal Study of Adolescent Health.
This work uses data from Add Health, a program
project designed by J. Richard Udry, Peter S. Bearman, and Kathleen Mullan Harris, and funded by
a grant P01–HD31921 from the Eunice Kennedy
Shriver National Institute of Child Health and Human Development, with cooperative funding from
23 other federal agencies and foundations. Special acknowledgment is due Ronald R. Rindfuss
and Barbara Entwisle for assistance in the original design. Persons interested in obtaining data
ﬁles from Add Health should contact Add Health,
Carolina Population Center, 123 W. Franklin Street,
Chapel Hill, NC 27516–2524 (addhealth@unc.edu).
No direct support was received from grant P01–
HD31921 for this analysis.
[315] Valverde, S., Cancho, R. F., and Solé, R. V., Scalefree networks from optimal design, Europhys. Lett.
60, 512–517 (2002).
[316] van Hooff, J. A. R. A. M. and Wensing, J. A. B.,
Dominance and its behavioral measures in a captive wolf pack, in H. Frank, ed., Man and Wolf, pp.
219–252, Kluwer, Dordrecht (1987).
[317] Vázquez, A., Flammini, A., Maritan, A., and
Vespignani, A., Modeling of protein interaction
networks, Complexus 1, 38–44 (2003).
[318] Vázquez, A., Pastor-Satorras, R., and Vespignani,
A., Large-scale topological and dynamical properties of the Internet, Phys. Rev. E 65, 066130 (2002).
[319] Wakita, K. and Tsurumi, T., Finding community structure in mega-scale social networks, in

R EFERENCES

P. Isaı́as, M. B. Nunes, and J. Barroso, eds.,
Proceedings of the IADIS International Conference,
WWW/Internet 2007, pp. 153–162, IADIS Press, Lisbon (2007).
[320] Wasserman, S. and Faust, K., Social Network
Analysis, Cambridge University Press, Cambridge
(1994).
[321] Watts, D. J., Small Worlds, Princeton University
Press, Princeton (1999).
[322] Watts, D. J., Dodds, P. S., and Newman, M. E. J.,
Identity and search in social networks, Science 296,
1302–1305 (2002).
[323] Watts, D. J. and Strogatz, S. H., Collective dynamics of ‘small-world’ networks, Nature 393, 440–442
(1998).
[324] West, D. B., Introduction to Graph Theory, Prentice
Hall, Upper Saddle River, NJ (1996).
[325] West, G. B., Brown, J. H., and Enquist, B. J., A general model for the origin of allometric scaling laws
in biology, Science 276, 122–126 (1997).
[326] West, G. B., Brown, J. H., and Enquist, B. J., A general model for the structure and allometry of plant
vascular systems, Nature 400, 664–667 (1999).
[327] White, D. R. and Reitz, K. P., Measuring role distance: Structural, regular and relational equivalence, Technical report, University of California,
Irvine (1985).

[328] White, J. G., Southgate, E., Thompson, J. N., and
Brenner, S., The structure of the nervous system of
the nematode Caenorhabditis Elegans, Phil. Trans. R.
Soc. London 314, 1–340 (1986).
[329] Wilf, H., Generatingfunctionology, Academic Press,
London, 2nd ed. (1994).
[330] Willis, J. C. and Yule, G. U., Some statistics of evolution and geographical distribution in plants and
animals, and their signiﬁcance, Nature 109, 177–
179 (1922).
[331] Yeomans, J. M., Statistical Mechanics of Phase Transitions, Oxford University Press, Oxford (1992).
[332] Yook, S. H., Jeong, H., and Barabási, A.-L., Modeling the Internet’s large-scale topology, Proc. Natl.
Acad. Sci. USA 99, 13382–13386 (2001).
[333] Yule, G. U., A mathematical theory of evolution
based on the conclusions of Dr. J. C. Willis, Philos.
Trans. R. Soc. London B 213, 21–87 (1925).
[334] Zachary, W. W., An information ﬂow model for
conﬂict and ﬁssion in small groups, J. Anthropol.
Res. 33, 452–473 (1977).
[335] Zanette, D. H. and Manrubia, S. C., Vertical transmission of culture and the distribution of family
names, Physica A 295, 1–8 (2001).
[336] Zipf, G. K., Human Behaviour and the Principle of
Least Effort, Addison-Wesley, Reading, MA (1949).

739

I NDEX
Page numbers in bold denote deﬁnitions or principal references.

absorbing random walk 158, 192
acquaintance immunization
614–615
actor 36, 109–110
actor database 183
acyclic network 69, 101, 118–122
absence of loops in 69, 71, 118,
490
academic citation network 69,
118–119
adjacency matrix for 120–122
cascade model 426
citation network 69, 71, 72,
118–119
eigenvector centrality 172
food web 101
legal citation network 72
patent citation network 71
Price model 490
scientiﬁc citation network 69,
118–119
self-edges in 118, 121
strongly connected
components 144, 172,
240–241
test for 120
vertex ordering 119–121
visualization 120
AddHealth study 43, 221
adjacency list 286–290, 298
adding an edge to 289
computational complexity of
operations 289–290, 298,
343
directed network 287–289

enumerating edges 290
ﬁnding an edge 289–290
hybrid matrix/list
representation 298–299,
314
multiedges 287
removing an edge 290
self-edges 287
undirected network 286–287
adjacency matrix 110–115, 283–286
acyclic network 120–122
adding an edge to 283–284
asymmetric 114, 138–139, 171,
284
block diagonal 142–143
computational complexity of
operations 283–285, 290,
298, 299, 309, 349–350
correlation coefﬁcient for rows
214–215, 387
covariance of rows 215
dense network 286
diagonal elements 112, 113,
115, 121, 133
directed network 112, 114–115,
120–122, 135, 138–139,
171, 284
eigenvalues 121–122, 137–139,
170, 173, 345–350,
691–692, 698–701,
703–704
eigenvectors 137–139, 170–171,
345–350, 691, 703–704
hybrid matrix/list
representation 298–299,

740

314
largest eigenvalue 173, 219,
345–348, 650, 663–664,
699–701
leading eigenvector 173, 219,
345–348, 650–651, 663
left eigenvectors 171, 172
lowest eigenvalue 700
memory space 285–286, 287,
298–299
multiedges 112, 113, 115, 438
multigraph 112, 113, 115, 283
negative elements 113, 206
nilpotent 122
Pearson coefﬁcient for rows
214–215, 387
powers of 136–138, 218, 346
reduced 158
removing an edge from
283–284
right eigenvectors 138, 171
Schur decomposition 138
self-edges 112, 115, 121, 133,
284
smallest eigenvalue 700
sparse network 134, 286
spectrum 121–122, 137–139,
170, 173, 345–350,
691–692, 698–701,
703–704
storing on a computer
283–286, 287, 298–299
strictly upper triangular 121
undirected network 110–112,
114–115, 137–138, 284

I NDEX

upper triangular 120–121
weighted network 112–113,
283
adjacency tree 290–291, 297–298
afﬁliation network 38, 53–54, 123
boards of directors 53–54, 123,
237
CEOs of companies 53
coauthorship 54, 123, 237
ﬁlm actors 54, 123, 124, 237
picture of 39
Southern Women Study 38, 39,
53
afﬁnity puriﬁcation 88
age
assortative mixing by 221, 222,
226–227, 229
effect on vertex degree 509–510
of vertices 509–510
agglomerative clustering 387
airline network 32, 541–548
edge lengths 113, 546–547
hub-and-spoke structure 541,
543–544, 548
models of 541–548
optimization 541–548
role in disease spread 673
algebraic connectivity 157, 370
algorithm for 350–353
connected networks 157
spectral partitioning 368, 370
algorithm 275ff, 308ff, 345ff
acyclic network test 120
algebraic connectivity 350–353
Arnoldi algorithm 353
augmenting path algorithm
149–150, 333–343
average-linkage clustering
388–390
average shortest path 322
Barabási–Albert model 502
betweenness centrality
324–329, 333
breadth-ﬁrst search 65–66, 143,
279–280, 315–329,
334–335, 337, 616–617,
709–710

burning algorithm 315
closeness centrality 322
clustering coefﬁcient 310–314
community detection 371–391
complete-linkage clustering
388–389
components 143, 317, 322
computational complexity
278–282
connectivity 149–150, 333–343
correlation coefﬁcient 267, 310
degree 308–309
Dijkstra’s algorithm 301,
330–333
edge cut set 340–341
Edmonds–Karp algorithm 334
eigenvalues 348, 350–354
eigenvector centrality 345–350
eigenvectors 345–354
Ford–Fulkerson algorithm
333–343
genetic algorithm 381
geodesic distance 315–322
geodesic path 315, 322–324
giant cluster 616–621
greedy algorithm 381, 387, 545,
714–715, 716, 722
heuristic 360
hierarchical clustering 386–391
HITS algorithm 118, 179–181
Householder algorithm 353
hubs and authorities 118,
179–181
independent paths 339–340,
341–343
Katz centrality 174
k-cores 195
Kernighan–Lin algorithm
360–364, 369–370, 373,
374–375
Lanczos algorithm 353–354,
370
maximum ﬂow 333–343
minimum cut 149–150,
333–341
modularity maximization
372–382, 385

node-disjoint paths 341–343
node-independent paths
341–343
percolation 616–621
preﬂow-push algorithm 334
proof of correctness 315
QL algorithm 353–354
REGE algorithm 217
running time 278–282
shortest augmenting path
algorithm 334
shortest distance 315–322,
330–333
shortest path 315, 322–324, 333
single-linkage clustering
388–390
sparse graphs 135, 280,
284–286, 306, 310, 321,
353–354
vertex-disjoint paths 341–343
vertex-independent paths
341–343
weighted shortest path 333
allometric scaling 35
AltaVista 237, 238
alter 44
Amazon.com 75
anabolic metabolism 78
anchor text 707
animal social network 47
animosity 113, 206
Antarctica, food web 99–102
ants, social network 47
archival records 38, 47–53
Arnoldi algorithm 353
Arts and Humanities Citation Index
68
AS numbers 26
assortative mixing 45, 220–231,
266–268, 310, 372
and community structure
267–268
biological networks 237, 267
by age 221, 222, 226–227, 229
by degree 230–231, 266–268,
310, 313
by educational level 221

741

I NDEX

by enumerative characteristics
222–226, 372
by race 221, 357
by scalar characteristics
228–229
by vector characteristics 229
citation networks 222
correlation coefﬁcient 229
disassortative mixing 222, 224,
228–229, 230–231,
266–268, 473
ego-centered networks 45
friendship networks 220–222,
226–227
information networks 237, 267
measures of 222–231, 266–268,
310
Pearson coefﬁcient 229
random graphs 423, 473–474
social networks 45, 220–222,
226–227, 237, 267–268
statistics 237
stratiﬁed network 226
technological networks 237,
267
World Wide Web 222, 237
assortativity coefﬁcient 225, 229,
230–231, 237, 267–268,
310, 313
attachment kernel 521–523, 528–529
attracting ﬁxed point 680, 682, 684,
689
augmenting path 337–339
augmenting path algorithm
149–150, 333–343
breadth-ﬁrst search 334
computational complexity 337
directed networks 334
implementation 336–337
minimum cut set 340–341
proof of correctness 337–339
running time 337
authority centrality 179–181
autonomous system 24, 25–27
AS numbers 26
geographical location 28

742

Internet representation 25–27,
200, 243, 245, 259,
265–266, 424, 448, 622, 624
average degree 134, 135–136
and generating function 433,
450
Bianconi–Barabási model
530–532
collaboration networks 237,
448
conﬁguration model 446–448,
450, 456
directed networks 135–136
directed random graphs 476
friendship networks 45–46
G (n, m) 399
G (n, p) 401
in-degree 135–136
Internet 237, 448
neighbors 446–448
out-degree 135–136
planar networks 166
Poisson random graph 399,
401
Price model 491, 508
random graphs 399, 401
social networks 45–46, 237, 422
statistics 237
undirected networks 134
average geodesic distance 181–185,
237, 241–243
algorithm 322
logarithmic scaling 10, 242,
564, 710, 718
scale-free network 242–243
small-world model 560–565
statistics 237
average-linkage clustering 388–390
average neighbor degree 446–448
coauthorship network 448
conﬁguration model 446–448
Internet 448
average shortest distance, see
average geodesic distance
AVL tree 128, 297
baboons, social network 47
backbone, Internet 19–20, 197

Bacon, Kevin 54
bait protein 87
balance 208–211
balanced network 208–211
balanced tree 293–294, 295–297
Barabási–Albert model 500–502
addition of extra edges
514–516
algorithm 502
degree distribution 501–502,
526
exponent 502
extensions 514–534
master equation 501
non-linear 521–527
power-law degree distribution
502, 526
preferential attachment
500–501
relation to Price model 501,
502
removal of edges 516–521
simulation 502
basic reproduction number 635–636
SIR model 635–636
SIS model 637
Bianconi–Barabási model 527–534
average degree 530–532
condensation 531–533
degree distribution 529–532
hubs 531–533
master equation 528
mean degree 530
Bell numbers 455
Bernoulli random graph 400
beta function 493–494
integral form 499, 530
power-law tail 494, 507, 513,
516, 529
Stirling’s approximation 494
Bethe lattice 128, 268–269
percolation on 598
betweenness centrality 185–193
algorithm 324–329, 333
community detection 382–385
computational complexity
326–327, 329

I NDEX

cumulative distribution
function 261–262
directed networks 188
distribution 261–262
dynamic range 189–190, 261
edge betweenness 382–383
ﬁlm actor network 189–190
ﬂow betweenness 191–192
Internet 261–262
normalization 190
power-law distribution 261
random-walk betweenness
192–193
star graph 189, 190
structural holes 202–203
trees 182, 233
variants 190–193
weighted networks 333
BGP 20–21, 25–26, 73
BGP table 25–26
bibliographic coupling 70, 116–118
difference from cocitation
117–118
legal citation networks 72
matrix 117, 180–181
network 70, 117, 181
patent citation networks 72
scientiﬁc citation networks 70
bibliographic coupling matrix 117,
180–181
bibliographic coupling network 70,
117, 181
bibliometrics 68
bicomponent 196, 426
bifurcation 693
big-O notation 279
big-Θ notation 279
binary heap 301–305, 332, 389
and Dijkstra’s algorithm 301,
332
and epidemic simulation 302
and hierarchical clustering
389–390
binary tree 291
binary heap 302
data structure 291
dendrogram 128, 383–384

hierarchical network model
720
partially ordered 302–303
binomial degree distribution
401–402
binomial distribution 401–402, 483,
617
biochemical network 7–8, 78ff
biological network 6–8, 33–35, 78ff
assortative 237, 267
disassortative 267
empirical measurement 78ff
food webs 6–7, 99–103
genetic regulatory networks 7,
89–94
metabolic networks 7, 78–84,
539
models of 426, 439–541
neural networks 6, 94–98
protein–protein interaction
networks 7, 85–89,
539–541
vertex copying in 539–541
biologist coauthorship network 237,
448
bipartite network 33, 38, 53–54,
74–77, 80–81, 123–126
boards of directors 53–54, 123,
237
CEOs of companies 53
coauthorship 54, 123, 237
directed 80, 126
examples 33, 38, 53–54, 74–77,
80, 104, 123
ﬁlm actors 54, 123–125, 237
incidence matrix 124, 126
index 75–77
keyword index 75–77
metabolic network 80–81
mutualistic network 104
pictures of 39, 81, 122, 164
protein–protein interaction
network 85
rail network 33
recommender network 74–75
singular value decomposition
76

social network 38, 53–54, 123
Southern Women Study 38, 39,
53
weighted 126
bisection 359–360
community detection 371–380
graph partitioning 359–360,
362, 364–365
Kernighan–Lin algorithm
360–364
modularity maximization
372–382
problems with 379–380
repeated bisection 359, 362,
364–365, 378–380
spectral algorithm 364–370,
375–380
block diagonal matrix
adjacency matrix 142–143
Laplacian 156–157
blog network 50
blood vessel network 33–35
boards of directors network 53–54,
123, 237
bond 109
bond percolation 593–594, 642–648
and epidemiology 642–645,
646, 669
and SIR model 642–648
giant cluster 643–644, 645–648
percolation threshold 643–644,
646
square lattice 625
bootstrap percolation 195
Bose–Einstein condensation 531
bow tie diagram 240, 479
World Wide Web 240
brain cell 94–98
branching polymers 456
breadth-ﬁrst search 315–329
augmenting path algorithm
334
betweenness centrality
324–329
burning algorithm 315
closeness centrality 322

743

I NDEX

computational complexity
279–280, 320–321
dense networks 321
Edmonds–Karp algorithm 334
ﬁnding components 143, 317,
322
ﬁnding shortest paths 322–324
implementation 317–321
peer-to-peer networks 709–710
percolation 616
proof of correctness 316–317
running time 279–280, 320–321
shortest augmenting path
algorithm 334
shortest path tree 322–324
sparse networks 280, 321
variants 321–329
web crawling 65–66
web search 65, 706
bridge problem 140–141
broker 189
burning algorithm, see breadth-ﬁrst
search
business relationships 6, 10–11,
37–38, 39–40, 53–54,
109–110
Caenorhabditis elegans
metabolic network 539
neural network 98
call graph
software 28
telephone 49, 237
cargo network 32, 33
cascade model 426
cascading failure 31–32
catabolic metabolism 78
cavity method 411
Cayley tree 128, 268–269
percolation on 598
C. elegans
metabolic network 539
neural network 98
centrality 9, 168ff
authority centrality 179–181
betweenness centrality
185–193, 202, 261–262,
324–329, 333

744

closeness centrality 181–184,
261, 263, 322
degree centrality 168–169, 178
distribution 261–262
eigenvector centrality 59,
169–172, 178, 261–262,
345–350, 651, 663, 670
ﬂow betweenness 191–192
hub centrality 179–181
Katz centrality 172–175, 178,
219, 232
PageRank 175–178, 707–708
random-walk betweenness
192–193
regular graphs 231–232
CEO network 53
CERN 64
chromatic number 130–131
circle model 553–555, 557
circuit
electronic 28
resistor networks 161–164
statistics 237
circuit switched network 18, 29, 31
citation data 68–72
Arts and Humanities Citation
Index 68
Citebase 68
Citeseer 68
Google Scholar 68
legal opinions 72
patents 71
Science Citation Index 68, 69
Scopus 68
Social Science Citation Index
68
web crawlers 68–69
citation network 67–72, 487–499
academic 67–70
acyclic 69, 71, 72, 118–119
assortative mixing 222
bibliographic coupling
networks 70, 117, 181
cocitation networks 70, 116,
180
cumulative degree
distribution 252–253

data for 68–72
degree centrality 169
degree distribution 68, 69, 248,
252–253, 430, 487, 494
eigenvector centrality 261
indirect citations 511
legal citations 71–72
loops in 69, 71,
models of 487–499, 534–539
multiedges 489–490, 491
patent citations 70–71
power-law degree distribution
68, 69, 248, 252–253, 430,
487, 494
Price model 487–499
scale-free network 68, 69
Science Citation Index 68, 69
scientiﬁc 67–70
statistics 69, 237, 260
strongly connected
components 172, 241
time ordering 69, 118
vertex copying model 534–539
Citebase 68
Citeseer 68
class A subnet 24
class B subnet 24
class C subnet 4, 24
Internet representation 4, 24,
26
clique 193–194
in one-mode projection
124–125
k-clique 195–196
transitivity 198
closeness centrality 181–184
algorithm 322
distribution 261, 263
dynamic range 182–183
ﬁlm actor network 183
problems with 182–184
variants 184
clusterability theorem 208–211
clusterable network 208, 210–211
clustering 198–204, 262–266, 354,
386–391
agglomerative 387

I NDEX

average-linkage 388–390
clusterable network 208,
210–211
clustering coefﬁcient 199–204,
262–266, 310–314
community detection 354
complete-linkage 388–389
directed network 201
ego-centered networks 45
hierarchical 386–391
local 201–204
partial 198–199
perfect 198
random graph 402–403, 423,
426–427, 474, 552
single-linkage 388–390
small-world model 555–565
social networks 200–201
Strauss model 583–585
transitivity 198–204, 262–266
clustering coefﬁcient 199–204,
262–266
algorithm 310–314
alternative deﬁnition 203–204
and community structure 265
calculation of 199–200,
201–202, 203–204,
310–314
coauthorship networks
200–201, 237, 263
conﬁguration model 262–263,
449–450
directed networks 201, 311
email networks 200–201, 237
ﬁlm actor network 200–201,
237
food webs 237, 264
Internet 200, 237, 264
local clustering coefﬁcient
201–204, 265–266
observed values 237, 262–266
Poisson random graph
402–403, 423, 450, 552
power-law degree distribution
264, 450
random graphs 200–201,
262–263, 402–403, 423,

425, 449–450, 552
scale-free networks 264, 450
small-world model 558–560,
564–565
social networks 45, 200–201,
237, 262–263
statistics 237
trees 199
triangular lattice 552–553
World Wide Web 237, 264
clusters 10–11, 193ff, 208–211, 354ff,
595ff, 643ff
cliques 193ff
clusterability 208–211
community detection 10–11,
371ff
graph partitioning 354ff
percolation 595ff, 643ff
coauthorship network 54, 354–355
afﬁliation network 54, 123, 237
average degree 237, 448
average neighbor degree 448
biologists 237, 448
bipartite network 54, 123, 237
clustering coefﬁcient 200–201,
237, 263
funneling effect 56, 57, 243
mathematicians 237, 448
mean degree 237, 448
neighbor degree 448
percolation 622
physicists 263–264
picture of 355
statistics 237
triadic closure 263–264
cocitation 70, 115–116
and cosine similarity 212–213
differences from bibliographic
coupling 117–118
legal citation network 72
matrix 115–116, 180
network 70, 116, 180
patent citation network 72
scientiﬁc citation network 70
cocitation matrix 115–116, 180
cocitation network 70, 116, 180
self-edges 116

weighted 70, 116
coexistence region
Strauss model 585
two-star model 581, 582–583
co-immunoprecipitation 85–86, 87,
88
co-link 205
collaboration network 54, 354–355
afﬁliation network 54, 123, 237
average degree 237, 448
average neighbor degree 448
biologists 237, 448
bipartite network 54, 123, 237
clustering coefﬁcient 200–201,
237, 263
funneling effect 56, 57, 243
mathematicians 237, 448
mean degree 237, 448
neighbor degree 448
percolation 622
physicists 263–264
picture of 355
statistics 237
triadic closure 263–264
collaborative ﬁltering 75
coloring
chromatic number 130–131
four-color theorem 130–131
structural balance 208–210
community detection 354–355,
357–358, 371–391
agglomerative clustering 387
algorithms 371–391
average-linkage clustering
388–390
betweenness algorithm
382–385
bisection 371–380
clustering 354, 386–391
complete-linkage clustering
388–389
genetic algorithm 381
greedy algorithm 381–382, 387
hierarchical clustering 386–391
loop counting algorithm
385–386

745

I NDEX

modularity maximization
372–382
more than two groups 378–380
simulated annealing 381–382
single-linkage clustering
388–390
spectral algorithm 375–379
two communities 371–380
using cosine similarity 387,
390, 392
vertex moving algorithm
373–375
community food web 102
community structure 10–11, 193,
354–355
and assortativity 267–268
and clustering coefﬁcient 265
detection 354–355, 357–358,
371–391
friendship networks 10, 357,
373–374, 390
karate club network 373–374,
377
metabolic networks 357
social networks 10, 357,
373–374, 390
World Wide Web 357
company director network 53–54
afﬁliation network 53–54, 123
bipartite network 53–54, 123
statistics 237
compartmental model 628–639
complete-linkage clustering
388–389
complexity, computational 278–282
component 142–145, 196–198,
235–241
algorithm for 143, 317, 322
bicomponents 196, 426
conﬁguration model 456–470
directed networks 66–67,
143–145, 239–241,
477–483
disease spread 641, 649, 657,
674
ﬁlm actor network 236
giant 235–239, 403–409, 456,

746

460–465, 466, 471–473,
477–482, 657
in-components 145, 239–240,
478–479, 510–513
k-components 196–198, 426
large 235–239
out-components 144–145, 172,
239–240, 478–479
Poisson random graph
403–419
Price model 510–513
random graphs 403–419,
456–473, 477–483
real-world networks 235–241
sizes 412–419, 456–470, 483,
512
small 128, 235, 238–241,
408–419, 456–460,
465–470, 482–483
strongly connected 144–145,
239–241, 477–479,
481–483, 485
tricomponents 196, 197
undirected networks 142–143,
235–239
weakly connected 143, 236,
239, 479–480, 482
World Wide Web 66–67,
143–145, 238, 239–240
computational complexity 278–282
adjacency list operations
289–290, 298, 343
adjacency matrix operations
283–285, 290, 298, 299,
309, 349–350
augmenting path algorithm
337
betweenness centrality
algorithm 326–327, 329
breadth-ﬁrst search 279–280,
320–321
Dijkstra’s algorithm 332–333
hierarchical clustering 389–390
Kernighan–Lin algorithm
362–364
modularity maximization
374–375, 377–378, 382

on sparse networks 280, 284,
306, 321
power method 348–350
spectral partitioning 370
worst-case 278–282
computer algorithm, see algorithm
computer virus 48–49, 627
condensation, in Bianconi–Barabási
model 531–533
conﬁguration model 434ff
average component size
465–467, 485
average degree 446–448, 450,
456
average neighbor degree
446–448
bond percolation on 645–648
clustering coefﬁcient 262–263,
449–450
component sizes 456–470
condition for giant component
456, 462–463, 464–465,
471–473, 484, 604
continuous phase transition
466
deﬁnition 435
degree sequence 435, 439
density of multiedges 436,
438–439, 440
density of self-edges 436, 441
directed networks 473–483
edge probability 439–442
ensemble 435, 439, 484
epidemics on 645–648, 651,
656, 657–661, 664–669,
671–672
epidemic threshold 646–647,
668–669, 672
examples 462, 470–473, 484,
600–601, 602–604,
611–614
exponential degree
distribution 469, 484,
602–604, 611
giant component 456, 460–465,
466, 471–473, 484, 604

I NDEX

giant percolation cluster
596–614, 645–648
graphical solution 463–465
largest eigenvalue 700–701
mean component size 465–467,
485
multiedges 436, 437–438, 440
neighbor degree 446–447
neighbors at a given distance
451–456
number of common neighbors
441–442
numerical solution 473–474
pair approximation 656
percolation on 596–615
phase transition 466
power-law degree distribution
470–473
scale-free network 470–473
second moment of degree
distribution 447, 450, 472
second neighbors 451–456
self-edges 436–438, 441
SI model on 656, 657–661
SIR model on 645–648, 664–669
site percolation on 596–615
small components 456–460,
465–470
third neighbors 454
connectance 134
connected network 142, 157
connectivity 145–150, 333–343
algebraic connectivity 157,
350–353, 368, 370
algorithm 149–150, 333–343
and network robustness 197,
333
augmenting path algorithm
149–150, 333–343
directed networks 147, 149,
334
edge connectivity 146–147,
148, 149, 333–341
vertex connectivity 146–147,
148, 196–197, 333,
341–343
consumer ISP 19, 20

contact tracing 60
continuous phase transition 582,
604–606
conﬁguration model 466
epidemic transition 644
exponential random graph
582, 585
percolation 595, 604
random graph 404, 582
second-order 606, 607
Strauss model 585
two-star model 582
core/periphery structure 230–231
correlation coefﬁcient
algorithm for 267, 310
and assortative mixing 229,
230–231
and community detection 387
calculation of 267, 310
for degree 230–231, 237,
267–268, 310, 313
for rows of adjacency matrix
214–215, 387
cosine similarity 212–214, 216
and cocitation 212–213
and community detection 387,
390, 392
and hierarchical clustering
387, 390, 392
covariance
assortative mixing 228–229
degrees 230, 485
rows of adjacency matrix 215
crawler, see web crawler
critical point, see phase transition
cryptography 50–53
asymmetric 51–52
public key 50–53
trust networks 53
cumulative advantage 487
cumulative degree distribution
251–254
calculation of 253–254, 309–310
citation network 252–253
disadvantages 254
Internet 252

power-law distribution
251–252, 257
preferential attachment model
498–500
Price model 498–500
scale-free network 251–252,
257, 498–500
World Wide Web 252–253
cumulative distribution function
251–254
betweenness centrality
261–262
calculation of 253–254, 309–310
degree 251–254, 257, 309–310
eigenvector centrality 261–262
power-law distribution
251–252, 257
rank/frequency plot 253–254
current law 162
cut set 147–150, 333–334
algorithm for 340–341
and network robustness 197,
333
edge cut set 147–150, 196–197,
333–334, 340–341
vertex cut set 147–150, 196, 333
cut size 359, 361–370
and community detection
371–372
and graph partitioning 359,
361–370
and Laplacian 365–370
cycle 118–121, 137–139
acyclic networks 69, 118–121
limit cycles 686, 701
number of a given length 121,
137–139
strongly connected
components 144, 241
cyclic network 118, 120, 121–122
cypher 50–52
asymmetric 51–52
databases
actors 183
citations 68, 69, 72
distributed 709–712
ﬁlms 183

747

I NDEX

food webs 103
genetic regulatory networks 94
legal citations 72
metabolic pathways 84
movies 183
protein interactions 88
data structures 282ff
adjacency list 286–290, 298
adjacency matrix 283–286, 287,
298–299
AVL tree 128, 297
balanced tree 293–294, 295–297
binary heap 301–305, 332, 389
binary tree 291
forest 291
tree 290–298
dating network 49, 237
degree 9, 133–136, 168–169
algorithm 308–309
and adjacency list 309
and adjacency matrix 133–136,
309
and vertex age 509–510
assortative mixing by 230–231,
266–268, 310, 313
average 45–46, 134, 135–136,
237, 446–448
calculation 133, 135, 309
correlations 230–231, 237,
266–268, 310, 313, 423
covariance 230, 485
cumulative distribution
function 251–254, 257,
309–310
degree centrality 168–169, 178
degree distribution 42, 68,
243–260, 309–310,
424–425, 434ff
degree sequence 244–245, 435,
439, 475
directed networks 9, 135–136
disassortative mixing by
230–231, 266–268
friendship networks 9, 41–42,
45–46, 135, 446
out-degree 9, 135, 169

748

Pearson correlation coefﬁcient
230–231, 237, 267–268,
310, 313
sequence 244–245, 435, 439,
475
social networks 9, 41–42,
45–46, 135, 446
undirected networks 9, 133
variance 447
degree centrality 168–169, 178
degree distribution 243–260
Barabási–Albert model
501–502
Bianconi–Barabási model
529–532
binomial 401–402
calculation of 309–310
citation networks 68, 69, 248,
252–253, 430, 487, 494
conﬁguration model 435, 439,
445–449, 450–451,
470–472
cumulative 251–254
deﬁnition 243–244
directed networks 246–247,
252–253, 475–477
excess degree distribution
445–449, 459, 597, 645
exponential 430, 469, 484,
602–604, 611–613, 622
exponential random graphs
573–575
generating functions 450–451,
462, 469, 472, 597–600, 607
histograms 245–253, 309, 424,
498–500, 539, 558
in giant component 657
Internet 24, 245–246, 247–248,
250–251, 252, 255, 424, 601
metabolic networks 539
non-power-law 249, 424–425,
557–558
plots of 245, 246, 248, 251, 252,
253, 424, 500, 527, 539, 558
Poisson 401–402, 450–451
Poisson random graph
401–402, 424, 428

power law 24, 68, 69, 74, 242,
247–260, 312, 314,
397–398, 430, 470–473,
487, 494–495, 502, 516,
520, 537–538, 601,
613–614, 647–648
random graphs 401–402, 424,
428, 434–435, 442–445,
445–446, 450–451,
475–477
right skewed 246, 264, 314, 424
second moment 257–259,
312–314, 433, 440, 450,
472, 483, 601, 646, 647
small-world model 557
social networks 42, 45–46
statistics 237
tail of 245–246, 249–250,
256–257, 258, 487, 494, 502
undirected networks 243–246
variance 447
World Wide Web 246, 252–253,
259
degree sequence 244–245
conﬁguration model 435, 439
directed networks 475
delivery networks 33–35
dendrogram 128, 383–384
community detection 383–385,
390
hierarchical clustering 390, 392
hierarchical network model
720
dense network 134–135, 286, 321
adjacency matrix 286
breadth-ﬁrst search on 321
food webs 135
density 134–135
deoxyribonuclease footprinting
assay 92–93
diameter 140, 242–243
Poisson random graph
420–422
power-law degree
distributions 242–243
random graphs 399, 419–422
scale-free networks 242–243

I NDEX

scaling with network size
242–243, 420–422
diffusion 152–154
equation 153–154, 156
of diseases 152
of ideas 694
digital signature 52–53
digraph, see directed network
Dijkstra’s algorithm 330–333
binary heap 301, 332
proof of correctness 331–332
running time 332–333
shortest path tree 333
DIMES project 22
directed edge 5, 114–115, 204–205
directed network 5, 114–122
adjacency list 287–289
adjacency matrix 112, 114–115,
120–122, 135, 138–139,
171, 284
augmenting path algorithm
334
average degree 135–136
betweenness centrality 188
bipartite 80, 126
citation networks 67
clustering coefﬁcient 201, 311
components 66–67, 143–145,
239–241, 477–483
connectivity 147, 149, 334
correlation of in- and
out-degree 475
cycles in 118–121, 138–139, 204
degree 9, 135–136
degree distribution 246–247,
252–253, 475–477
degree sequence 475
dynamical system on 703
eigenvector centrality 171–172
excess degree distribution 477
exponential random graphs
575–577
food webs 99–101
friendship networks 41, 50
geodesic distance 242
giant components 477–482
in-components 145, 239–240

in-degree 9, 135–136, 169
in-degree distribution 246–247,
475–477
independent paths 334
joint degree distribution
246–247, 475–477
Katz centrality 174
Laplacian 152
loops 118–121, 138–139, 204
mapping to undirected
network 115–118
maximum ﬂow 334
mean degree 135–136
metabolic networks 80–82
multiedges 115
out-components 144–145, 172,
239–240, 478–479
out-degree 9, 135–136, 169
out-degree distribution
246–247, 475–477
path lengths 242
paths 136, 188, 242
random graph model 473–483
reciprocity 204–205, 576–577
self-edges 115
shortest distance 242
social networks 41, 48–49, 50,
53
transitivity 201
World Wide Web 5, 63–64,
66–67, 143
directed random graph 473–483
average degree 476
edge probability 475
ensemble 475
excess degree distribution 477
generating functions 474–477
giant components 477–482
giant in-component 478–482
giant out-component 478–482
in-components 478–479
mean degree 476
out-components 478–479
phase transition 480–482
small components 482–483
strongly connected
components 477–479, 485

weakly connected components
477, 479–480, 482
disassortative mixing 222, 224,
230–231, 266–268
and modularity 224, 228–229
biological networks 267
by degree 230–231, 266–268
by gender 222, 224
by scalar characteristics
228–229
by vector characteristics 229
information networks 267
random graphs 473
simple graphs 267
social networks 267–268
technological networks 267
disconnected network 142
disease spread 627ff
and bond percolation 642–648,
669
and components 641, 649, 657,
674
and diffusion 152
and eigenvector centrality 651,
663, 670
and percolation threshold
643–644
compartmental models
628–639
computer simulation 302
contact tracing 60
fully mixed approximation
629–639
herd immunity 592, 601
immunity 592, 601, 631–632,
636, 638, 639, 686
immunization 592, 601
infected state 628
infection rate 640
infective state 628
models 152, 627–639
naive population 635
on networks 639ff
recovered state 631–632
reinfection 636
removed state 632

749

I NDEX

SI model 628–631, 640–641,
648–661, 677, 689
SIR model 631–636, 642–648,
661–669
SIRS model 637–639
SIS model 636–637, 669–672
small outbreaks 641, 644, 674
susceptible state 628
disjoint paths 145–150, 196–198,
333, 339–343
distributed database 709–712
peer-to-peer network 709–712
World Wide Web 709
distribution network 33–35
gas pipelines 32, 33
optimization of 541
package delivery 33
rivers 33, 35
sewerage 33
water supply 33
divisive clustering 387
DNA 79, 87, 89–94, 539–540
gene 91–94, 539–540
repeat 539–540
DNA computer 142
DNA microarray 94
dolphins, social network 47
domain, Internet 24–25
dominance hierarchy 47
drug users 58–59
dynamical system 676ff
and Laplacian 152–154,
692–693, 698
bifurcations 693
continuous 676, 677
deterministic 676, 677
diffusion 152–154
directed networks 703
discrete 676
explicit time dependence
677–678
ﬁxed points 678–686, 687–690
gossip model 694–695
Jacobian matrix 681–685
limit cycles 686, 701
linearization 678–686, 688–689

750

linear stability analysis
680–686, 687–689
Lyapunov exponent 701
more than one variable per
vertex 695–698
on a network 686ff
one variable 677, 679–680,
687–689
oscillation 684–686, 701–702,
704
oscillator networks 701, 704
regular graphs 702
second order 678
SI model 677, 679, 687, 689, 690
SIRS model 686
stochastic 676
synchronization 701–702, 704
two variables 677–678, 679,
680–686
dynamic web pages 65, 66, 706
E. coli 539
ecological network 6–7, 99–104
food web 6–7, 99–103
host–parasite network 103
mutualistic network 103–104
ecosystem 99
edge betweenness 382–383
edge connectivity 146–147, 148, 149,
333–341
algorithm 333–341
edge cut set 147–150, 196–197,
333–334, 340–341
algorithm 340–341
edge-disjoint paths, see
edge-independent paths
edge incidence matrix 155
edge-independent paths 145–150,
196–197, 333–341
algorithm 339–340
edge lengths 34, 113, 329
airline networks 113, 546–547
and network optimization
546–548
and shortest paths 329–333
formula for 34–35
Internet 329
road networks 34, 113, 329

social networks 329
edge list 111, 300–301
edge percolation, see bond
percolation
edge probability
conﬁguration model 439–442
directed random graphs 475
exponential random graphs
572–573, 574–575,
578–583
random graphs 400
two-star model 578–583
edges 1, 109–110
citation network 67
directed 5, 114–115, 204–205
examples of 110
food webs 6–7, 99, 100–101
friendship networks 6, 37,
41–42, 50
hyperedges 122
Internet 19ff
lengths 34, 113, 329
metabolic networks 80–81
multiedges 110, 111, 113, 115
negative weights 113, 206
percolation on 593–594,
642–648
protein–protein interaction
network 85
reciprocated 204–205, 576–577
self-edges 110, 111, 112, 115
signed 206
social networks 6, 37–38, 41,
42, 48–49, 50, 53
valued 43, 112–113, 299–300,
329
variables on 112–114, 299–300
weighted 43, 112–113, 299–300,
329
World Wide Web 5, 63–64, 143
Edmonds–Karp algorithm 334
ego 44
ego-centered network 44–46
assortative mixing 45
clustering 45
eigenvalues

I NDEX

adjacency matrix 121–122,
137–139, 170, 173,
345–350, 691–692,
698–701, 703–704
algorithms for 348, 350–354
Jacobian matrix 684
Laplacian 154–156, 350–353,
368, 370, 693, 698, 701
largest 173, 219, 346–347, 348,
650–651, 664, 693,
699–701
Perron–Frobenius theorem
177, 232, 346–347
power method 348
eigenvector centrality 169–172, 178
acyclic networks 172
algorithm 345–350
and probability of infection
651, 663, 670
and SIR model 663–664
and SIS model 670
and snowball sampling 59
citation networks 261
cumulative distribution
function 261–262
directed networks 171–172
distribution 261–262
Internet 261–262
normalization 171
PageRank 175–178, 707–708
power-law distribution of 261
problems with 171–172
regular graphs 231–232
undirected networks 171
eigenvectors
adjacency matrix 137–139,
170–171, 345–350,
650–651, 663, 691,
703–704
algorithms 345–354
eigenvector centrality 59,
169–172, 178, 261–262,
345–350, 651, 663, 670
Laplacian 154–156, 157,
158–159, 161, 163,
350–351, 367–370, 701

leading 170, 171, 345–353, 651,
663
modularity matrix 377
Perron–Frobenius theorem
177, 232, 346–347
power method 346–353
sparse networks 353–354
electric circuit 28, 161–164
resistor network 161–164
statistics 237
electricity grid, see power grid
electronic circuit 28
resistor network 161–164
statistics 237
electrophoresis 92, 93
electrophoretic mobility shift assay
92
email 48–49
addresses 48–49
logs 48
messages 48
networks 48–49
small-world experiment 57
viruses 48–49
email network 48–49
address book network 49, 205,
237
clustering coefﬁcient 200–201,
237
message network 48–49, 200,
237
reciprocity 205
endemic disease 637
SIRS model 639
SIS model 637, 670, 672
ensemble 399, 400, 566–569
conﬁguration model 435, 439,
484
directed random graph 475
exponential random graph
566–569
Poisson random graph 399,
400, 401
random graph 399, 400, 401,
435, 439, 475, 484, 566
entropy 568
maximum 568, 585

enzyme 79–80, 84
enzyme inhibitor 84
epidemic models 627ff
epidemic threshold 636, 644
and percolation threshold
643–644
conﬁguration model 646–647,
668–669, 672
Poisson random graph 646
SIR model 636, 644, 646, 664,
668–669
SIS model 637, 670, 672
epidemics 627ff
and diffusion 152
and eigenvector centrality 651,
663, 670
and percolation 642–648, 669
compartmental models
628–639
computer simulation 302
contact tracing 60
fully mixed approximation
629–639
herd immunity 592, 601
immunity 592, 601, 631–632,
636, 638, 639, 686
immunization 592, 601
infected state 628
infection rate 640
infective state 628
models of 152, 627–639
naive population 635
on networks 639ff
recovered state 631–632
reinfection 636
removed state 632
SI model 628–631, 640–641,
648–661, 677, 689
SIR model 631–636, 642–648,
661–669
SIRS model 637–639
SIS model 636–637, 669–672
small outbreaks 641, 644, 674
susceptible state 628
equivalence, regular 211–212,
217–220
Erdős, Paul 400

751

I NDEX

Erdős–Rényi model, see Poisson
random graph
Escherichia coli 539
Euclidean distance 216, 387
Euler beta function 493–494
integral form 499, 530
power-law tail 494, 507, 513,
516, 529
Stirling’s approximation 494
Euler, Leonard 140
Königsberg bridge problem
140–141
Euler tour 297
Eulerian path 140–142
applications 141–142
excess degree 448–449
excess degree distribution 445–449,
459, 597, 645
directed network 477
directed random graph 477
generating function 450–451,
477, 597–598, 602
undirected network 445–449,
459, 597, 645
expansion of a network 132–133
exponent 248, 254–255
Barabási–Albert model 502
biases 254
citation networks 495, 237
formula for 255
Hill estimator 255
Internet 237, 255, 601
Lyapunov exponent 701
maximum likelihood estimate
255
measurement 254–255
preferential attachment
models 494–495, 502, 516,
520
Price model 494–495
statistical error on 255
values 237
vertex copying model 537–538
World Wide Web 237, 259
exponential degree distribution 469,
602

752

and robustness 602–604,
611–613
conﬁguration model 469, 484,
602–604, 611
generating functions 430, 469,
602
network optimization 545
percolation threshold 603
power grid 622
site percolation 602–604,
611–613
exponential distribution 430, 469
generating function 430, 469,
602
Lorenz curve 269
normalization 269, 430
recovery times 632–633, 642
stretched exponential 525–526
exponential generating function 429
exponential random graph 565ff
continuous phase transition
582, 585
degree distribution 573–575
directed networks 575–577
edge probability 572–573,
574–575, 578–583
ensemble 566–569
expectation values 569–571
ﬁxed degrees 573–575
free energy 570, 572, 576–577
graphical solution 579–580
Hamiltonian 569, 571, 573, 575,
577–578, 585
mean-ﬁeld theory 578, 585
partition function 569, 570,
572, 574, 575, 576
phase transition 582, 585
reciprocity model 576–577
simple graphs 567
sparse networks 574, 575
Strauss model 583–585
transitivity 583–585
Facebook 6, 36, 49, 63
Fibonacci heap 332
ﬁlesharing network, see
peer-to-peer network
ﬁlm actor database 183

ﬁlm actor network 54
afﬁliation network 54, 123, 124
betweenness centrality
189–190
bipartite representation 54,
123–125
closeness centrality 183
clustering coefﬁcient 200–201,
237
components 236
largest component 236
small-world effect in 54
statistics 237
ﬁnite size effect 607
ﬁrst-in/ﬁrst-out buffer 319
ﬁrst mover advantage 508–509
ﬁrst-order phase transition 604
ﬁrst passage time 159–161
ﬁxed choice survey 41–42
ﬁxed point 678–686, 687–690
attracting 680, 682, 684, 689
expansion around 679–686,
687–688, 695–696
ﬂows near 682–685
linearization 678–686, 687–688,
695–696
mixed 680
neutral 680
non-symmetric 695
repelling 680, 682, 684, 689
saddle point 682, 684, 689
SI model 679, 689, 690
symmetric 689–690, 694–695
Florentine families network 48
ﬂow betweenness 191–192
food chain 99, 101
food web 6–7, 99–103
acyclic 101
Antarctic species 99–102
cascade model 426
clustering coefﬁcient 237, 264
community food webs 102
connectance 135
databases 103
density 135
edges 6–7, 99, 100–101
empirical measurements 102

I NDEX

freshwater species 237
Little Rock Lake 7
marine species 237
model of 426
nodes 6, 99–100
pictures of 7, 100
sink food webs 102
source food webs 102
statistics 237
transitivity 264
trophic levels 101–102, 166–167
vertices 6, 99–100
weighted networks 102–103,
112–113
Ford–Fulkerson algorithm 333–343
forest, data structure 127, 291
four-color theorem 130–131
free choice survey 41, 45
free energy 570, 572, 576–577
freshwater food web 237
friendship network 6, 36, 37, 39–46
AddHealth study 43, 221
animosity in 113, 206
average degree 45–46
community structure in 10,
357, 373–374, 390
degree 9, 41–42, 45–46, 135, 446
directed networks 41, 50
edges 6, 37, 41–42, 50
geodesic distance 10, 54–58
groups in 193–194, 221, 357,
373–374
in-degree 41–42
karate club network 6, 47,
373–374
out-degree 41–42
schoolchildren 37, 40–42,
220–222, 226–227, 357
sparse networks 135
frustration 207
FTP (File Transfer Protocol) 18
fully mixed approximation 629–639
SI model 630, 641, 651, 677
SIR model 633, 642, 644, 646,
647
SIS model 636–637
funneling effect 56, 243

coauthorship networks 56, 57,
243
Internet 243
gamma function 493
integral form 493, 499
Stirling’s approximation 494
gas pipeline network 31, 33–34
picture of 34
gel electrophoresis 92, 93
gender, disassortative mixing by
222, 224
gene duplication 539–540
General Social Survey 45
generating function 412–419,
429–434
and average degree 432–433,
450, 455, 476
average of distribution
432–433
component sizes 412–419,
457–462, 465–470, 483
degree distribution 450–451,
462, 469, 472, 597–600, 607
derivatives of 413–414,
432–433, 600
directed networks 474–483
directed random graphs
474–477
divergence 430
examples 429–432
excess degree distribution
450–451, 597–598, 602
exponential distribution 430,
469, 484, 602
exponential generating
functions 429
moments of distribution
432–433
normalization 432, 460
Poisson distribution 430,
450–451, 455
Poisson random graph
412–419, 432, 450–451
power-law distribution
430–432, 451, 472
powers of 433–434, 453, 459

preferential attachment model
519
properties of 432–434
generative network models 486ff
genes 91–94, 539–540
duplication 539–540
expression 91–92
regulatory networks 7, 89–94
transcription 91–92
translation 91
genetic algorithm 381
genetic regulatory network 7, 89–94
databases 94
geodesic distance 9–10, 54–56,
139–140, 241–243
algorithm 315–322
and closeness centrality
181–185, 322
average 181–185, 237, 241–243,
322
diameter 140
directed networks 242
friendship networks 10, 54–58
inﬁnite 139, 183–185
Internet 241–242
longest 140
random graphs 420
scale-free networks 242–243
small-world model 560–565
social networks 10, 54–58, 183,
241–243
geodesic path 139–140, 241–243
absence of loops in 139
algorithm 315, 322–324
and betweenness centrality
185–189
diameter of network 140
inﬁnite 139, 183–185
longest 140
overlapping 187–188
self-avoiding 136, 139
uniqueness 140
weighted networks 301, 329,
333
geography 27–28, 32
autonomous systems 28
Internet 27–28

753

I NDEX

network search 719–721
power grid 31
river network 33
social networks 28, 229,
719–721
telephone network 31
transportation networks 32,
546–548
giant cluster 595ff, 643–648
algorithm 616–621
and epidemics 643–644,
645–648
bond percolation 643–644,
645–648
conﬁguration model 596–614,
645–648
deﬁnition 595, 606
near percolation threshold
604–608
non-uniform percolation
609–613
real-world networks 621–624
scale-free networks 607–608,
613–614, 648
scaling with network size 606
site percolation 595–608
size 597–599, 603–614, 645–648
giant component 235–239, 403–408,
460–465
condition for 407–408, 456,
462–463, 464–465,
471–473, 484, 604
conﬁguration model 456,
460–465, 466, 471–473,
484, 604
degree distribution in 657
directed networks 477–482
directed random graphs
477–482
exponential degree
distribution 484, 604
ﬁlm actor network 236
in-component 478–482
more than one 238, 409
numerical calculation 473
out-component 67, 478–479

754

Poisson random graph
404–408, 409, 635
power-law degree distribution
471–473
random graphs 404–408, 409,
456, 460–465, 471–473,
477–482, 635
scale-free networks 471–473
strongly connected 477–479
uniqueness 238, 409
weakly connected 477,
479–480, 482
giant in-component 478–482
giant out-component 478–482
directed random graphs
478–482
World Wide Web 67
giant strongly connected
component 477–479
giant weakly connected component
479–480, 482
Gibbs entropy 568
Gibbs, Willard 568
G (n, m) 399
G (n, p) 400
Gnutella 73–74
Google 5, 66, 67, 176–177, 707–708
Google Scholar 68
gossip 10
model 694–695
Gram–Schmidt orthogonalization
352–353
graph 109–110
graph bisection 359–360
community detection 371–380
graph partitioning 359–360,
362, 364–365
Kernighan–Lin algorithm
360–364
modularity maximization
372–382
problems with 379–380
repeated bisection 359, 362,
364–365, 378–380
spectral algorithm 364–370,
375–380

graph Hamiltonian, see
Hamiltonian
graph Laplacian, see Laplacian
graph partitioning 354–370
and Laplacian 350–351,
364–370
applications 356–357
bisection 359–360, 362, 364–365
exhaustive search 359–360
in parallel computing 356–357
Kernighan–Lin algorithm
360–364, 369–370, 373,
374–375
more than two groups 359, 362
ratio cut partitioning 371–372
repeated bisection 359, 362,
364–365
spectral partitioning 364–370
two groups 359–360, 362,
364–365
graph theory 109
Graphviz (software package) 277
greedy algorithm 381, 387, 545,
714–715, 716, 722
community detection 381–382,
387
message passing 714–715, 716,
722
modularity maximization 381,
387
network optimization 545
small-world experiment
714–715, 716, 722
GTL (software library) 277
Guare, John 56
Hamiltonian 569
directed random graph 575
random graph 571, 573, 578
reciprocity model 576
Strauss model 585
two-star model 577–578
Hamiltonian path 140–142
applications 141–142
self-avoiding 136, 140
Hamming distance 216, 387
Harary, Frank 208

I NDEX

Harary’s clusterability theorem
208–211
heap data structure 301–305
adding an element to 304–305
binary heap 301–302
Dijkstra’s algorithm 301, 332
epidemic simulation 302
Fibonacci heap 332
ﬁnding smallest value 305
hierarchical clustering 389
modiﬁed 389
reducing a value in 305
removing an element from
305, 389
root element 305
sifting 304–305, 389
herd immunity 592, 601
heuristic algorithm 360
hidden population 58
hierarchical clustering 386–391
algorithm 388–390
and cosine similarity 387, 390,
392
average-linkage clustering
388–390
complete-linkage clustering
388–389
computational complexity
389–390
example 390
implementation 389
karate club network 390
problems with 390–391
running time 389–390
single-linkage clustering
388–390
hierarchical decomposition 385,
386–391
hierarchical structure 265–266, 385,
386–391, 718, 720–725
high-throughput method 86
Hill estimator 255
histogram
degree distribution 245–253,
309, 424, 498–500, 539, 558
power-law distribution
247–251

HITS algorithm 118, 179–181
homophily, see assortative mixing
host–parasite network 103
Householder algorithm 353
HTML (Hypertext Markup
Language) 64
HTTP (Hypertext Transfer Protocol)
18, 64
hub 9, 245–246
airline networks 541
and degree distribution
245–246, 424
Bianconi–Barabási model
531–533
hub-and-spoke networks 541,
543–544, 548
hub centrality 178–181
hubs and authorities 178–181
Internet 245–246, 424
removal 614–615
superhub 531–533
hub-and-spoke network 541,
543–544, 548
hub centrality 178–181
hubs and authorities algorithm 118,
179–181
hyperedge 122
hypergraph 122–123
hyperlinks 5, 63–64
anchor text 707
crawling 706–708
distribution of 259–260
igraph (software library) 277
immune system 85–86, 628, 631
immunity 592, 601, 631–632, 636
epidemic models 631–632,
637–638
herd immunity 592, 601
infants 639
SIR model 631–632
SIRS model 637–638, 686
SIS model 636
temporary 638
immunization 592, 601–602,
614–615
acquaintance immunization
614–615

percolation theory 592,
601–602, 609, 613,
614–615, 673
scale-free network 602, 614
targeted 609, 613, 614–615
non-uniform 609, 613
immunoprecipitation 85
incidence matrix 124, 155
bipartite network 124, 126
edge incidence matrix 155
in-component 145, 239–240
directed random graph
478–479
giant 478–482
overlapping 240
Price model 510–513
tree-like 511
World Wide Web 240
in-degree 9, 135–136
average 135–136
citation network 68, 69, 169,
248, 252–253
correlation with out-degree
475
degree centrality 169
distribution 246–247, 248,
252–253, 259, 475–477
social networks 41–42
World Wide Web 9, 246, 248,
252–253, 259
independent paths 145–150,
339–343
algorithm 339–343
and robustness 197, 333
directed networks 334
edge-independent 145–150,
196–197, 333–341
Menger’s theorem 148–149
vertex-independent 146–150,
196–198, 333, 341–343
INDEX experiment 57–58, 719
infected state 628
infection rate 640
infective state 628
InFlow (software package) 277
information network 63ff
assortative mixing 237, 267

755

I NDEX

citation networks 67–72
disassortative mixing 267
empirical measurements 63ff
keyword indexes 75–77
peer-to-peer networks 72–74
recommender networks 74–75
statistics 237
World Wide Web 63–67
information science 68
instant messaging 6, 49
intermarriage network 48
Internet 3, 18–28
autonomous system
representation 25–27, 200,
243, 245, 259, 265–266,
424, 448, 622, 624
average degree 237, 448
average neighbor degree 448
backbone 19, 20, 197
betweenness centrality
261–262
class C subnet representation
4, 24, 26–27
clustering coefﬁcient 200, 237,
264
cumulative degree
distribution 252
degree distribution 24,
245–246, 247–248,
250–251, 252, 255, 424, 601
DIMES project 22
domain 24–25
domain representation 24–25
edges 19, 22–23, 24, 25, 26
eigenvector centrality 261–262
exponent 237, 601
failure of routers 197, 592, 594
funneling effect 243
geodesic distances 241–242
geography 27–28
highest degree vertex 245
Internet service providers 19,
20
IP addresses 18, 21–24
largest component 238
mean degree 237, 448
neighbor degree 448

756

network backbone providers
19
nodes 19, 20, 23–25, 26–27
packet loss 18
packets 3, 10, 18, 21, 25–26,
243, 329
percolation on 621–624
pictures of 4, 20, 27
power-law degree distribution
24, 247–249, 250–251, 252,
255, 264, 601
protocols 3–5, 18–19
robustness 197, 600, 623–624
router representation 23–24
routers 19, 23–24
Routeviews project 26
scale-free network 24, 247–249,
264
schematic picture of 20
shortest paths 241–242
site percolation on 600–601
small-world effect 10
sparse network 134–135
statistics 237
subnet representation 4, 24,
26–27
subnets 24
transitivity 200, 264
vertices 19, 20, 23–25, 26–27
Internet Movie Database 183
Internet Protocol (IP) 18
interviews 38, 39–44
inversion formula 417–419, 468
IP address 18, 21–24
ISP (Internet Service Provider) 19,
20
local 19, 20
regional 19, 20
Jacobian matrix 681–684
diagonal 681–682
dynamical system 681–685
eigenvalues 684
JAVA libraries 277
JUNG (software library) 277
kangaroos, social network 47
karate club network 6, 373–374

community structure 373–374,
377, 390
hierarchical clustering 390
pictures of 6, 374
split in 373–374
Katz centrality 172–175, 178
calculation 174
directed networks 174
extensions 174–175
parameter value 173–174
regular graphs 232
undirected networks 174
Katz similarity 219
k-clan 196
k-clique 195–196
k-club 196
k-component 196–198
and robustness 197
bicomponent 196, 426
contiguous 197–198
non-contiguous 197–198
random graph 426
tricomponent 196, 197
k-connected component, see
k-component
k-core 195
Kernighan, Brian 360
Kernighan–Lin algorithm 360–364
community detection 373
comparison with spectral
partitioning 369–370
computational complexity
362–364, 374–375
example 362–363
implementation 363–364
key-signing network 53
keyword index 75–77
Kirchhoff current law 162
Kleinberg small-world model
713–718
Königsberg Bridge Problem
140–141
k-plex 194
k-regular graph 135
circle model 554, 557
dynamical system 702
eigenvector centrality 231–232

I NDEX

Katz centrality 232
SI model 674
Krichhoff’s current law 162
Kuratowski, Kazimierz 132
Kuratowski’s theorem 132–133
Lagrange inversion formula
417–419, 468
Lambert W-function 405, 422, 647
Lanczos algorithm 353–354, 370
landline telephone network 29–30
LAPACK (software library) 354
Laplacian 152ff
and algebraic connectivity 157,
350–353, 368, 370
and cut size 365–370
block diagonal 156–157
directed networks 152
dynamical systems 692–693,
698
eigenvalues 154–156, 350–353,
368, 370, 693, 698, 701
eigenvectors 154–156, 157,
158–159, 161, 163,
350–351, 367–370, 701
graph partitioning 350–351,
364–370
largest eigenvalue 693, 701
random walks 157–161
reduced 161, 163–164
resistor networks 163–164
second eigenvalue 157,
350–353, 368, 370
singular 156
smallest eigenvalue 156, 693,
701
spectral gap 157
spectral partitioning 364–370
spectrum 154–156, 370, 701
zero eigenvalue 156, 693, 701
large component
absence of 238–239, 403–404
directed networks 239–241
more than one 238, 409
World Wide Web 237, 239–240
largest component 235–239, 403–404
ﬁlm actor network 236

giant component 235–236,
403–408, 460–465
Internet 238
random graph 403–404
statistics 237
strongly connected 239–241
weakly connected 236, 239
World Wide Web 239–240
latent semantic indexing 76
LEDA/AGD (software library) 277
Lee, Christopher 183, 190
left eigenvector 171, 172
legal citation network 71–72
Lerch transcendent 432
letter-passing experiment, see
small-world experiment
LexisNexis 72
library science 68
LimeWire 73
limit cycle 686, 701
linearization 678–686, 687–688,
695–696
linear stability analysis 680–686,
687–689
link 109
LinkedIn 49
Little Rock Lake food web 7
LiveJournal 50
local clustering coefﬁcient 201–204,
265–266
and global clustering
coefﬁcient 203
and redundancy 203
dependence on degree 265–266
local ISP 19, 20
logarithmic binning 250
logistic growth 630, 637
SI model 630–631
SIS model 637
long-distance telephone network
30–31
longitudinal network studies 49–50
loops 137–139
absence in acyclic networks 69,
71, 118, 490
absence in citation networks
69, 71,

absence in geodesic paths 139
absence in small components
410, 457, 482
absence in trees 127–129, 410,
457, 482
in directed networks 118–121,
138–139, 204
length three 199–200, 204, 262,
263, 584
length two 204
number of given length
137–139, 199
self-loops 110
structural balance 207–209
Lorenz curve 259–260
exponential distribution 269
power law 259–260
scale-free network 259–260
Lorenz, Max 259
Lotka–Volterra equations 686
Lyapunov exponent 701
Maple (software package) 277
marine food web 237
marriage network 48
mass-action approximation 629
master equation 491–492
Barabási–Albert model 501
Bianconi–Barabási model 528
for component sizes 512
generalized preferential
attachment 515, 517–518
non-linear preferential
attachment 522
preferential attachment
491–492, 501, 503–505,
512–513, 528
Price model 491–492, 503–505,
512–513
vertex copying model 537
master stability condition 691–693,
698
master stability function 697–698,
699, 700, 701
Mathematica (software package)
277, 354
mathematics coauthorship network
237, 448

757

I NDEX

Matlab (software package) 277, 354
matrix
adjacency matrix 110–115,
283–286
bibliographic coupling matrix
117, 180–181
cocitation matrix 115–116, 180
edge incidence matrix 155
incidence matrix 124, 155
Jacobian 681–685
Laplacian 152ff, 350–351,
364–370, 692–695, 698,
701
modularity matrix 224,
376–377
nilpotent 122
Schur decomposition 138
skew symmetric 703
triangular 120–121
max-ﬂow/min-cut theorem
149–151, 333, 336, 341
weighted network 150–151
maximum entropy 568, 585
maximum ﬂow 148–151, 333–343
algorithm 333–343
and connectivity 149–150, 333
and minimum cut 147–151
augmenting path algorithm
149–150, 333–343
directed networks 149, 334
ﬂow betweenness 191–192
max-ﬂow/min-cut theorem
149–151, 333, 336, 341
preﬂow-push algorithm 334
weighted networks 150–151
maximum likelihood 255
McKendrick, Anderson 628
mean degree, see average degree
mean-ﬁeld theory
exponential random graph
578, 585
small-world model 563–564
Strauss model 585
two-star model 578–583
medical doctor network 42
Medici family 48
Menger, Karl 148

758

Menger’s theorem 148–149
message passing 54–58, 241, 243,
713
greedy algorithm 714–715, 716,
722
hierarchical model 718,
720–725
Kleinberg model 713–718
reverse small-world
experiment 57–58, 719
small-world experiment 54–58,
241–243, 713, 718, 719,
724–725
messenger RNA 91, 94
metabolic network 7, 78–84
bipartite representation 80–81
C. elegans 539
community structure 357
databases 84
degree distribution 539
E. coli 539
edges 80–81
empirical measurements 82
nodes 79
picture of 83
power-law degree distribution
539
scale-free network 539
statistics 237
tripartite representation 80
vertex copying 539
vertices 79
metabolic pathway 78–79, 82–84
databases 84
metabolic reaction 78–84
databases 84
enzymes 79–80
inhibition of 84
products 79, 80
substrates 79, 80
metabolism 78–80
anabolic 78
catabolic 78
metabolite 7, 79
microarray 94
Milgram small-world experiment,
see small-world

experiment
Milgram, Stanley 54, 241, 713
minimum cut 147–151, 333, 340–341
algorithm 149–150, 333–341
and connectivity 149–150, 333
and maximum ﬂow 147–151
augmenting path algorithm
149–150, 340–341
directed networks 149, 334
max-ﬂow/min-cut theorem
149–151, 333, 336, 341
preﬂow-push algorithm 334
weighted networks 150
minimum spanning tree 128
mixed ﬁxed point 680
model 397–398
airline network 541–548
biological networks 426,
439–541
cascade model 426
circle model 553–555, 557
citation network 487–499,
534–539
compartmental 628–639
disease spread 152, 627–639
epidemics 152, 627–639
food web 426
generative 486ff
gossip 694–695
growing network 487ff
hierarchical model 718,
720–725
message passing 713–718,
720–725
network formation 486ff
network optimization 541–548
of Barabási and Albert 500–502
of Bianconi and Barabási
527–534
of Erdős and Rényi 398ff
of Ferrer i Cancho and Solé
542–546, 547
of Gastner and Newman
546–548
of Kleinberg 713–718
of Price 487–500, 501, 503–513,
537–538

I NDEX

of Strauss 583–585
of Watts and Strogatz 555–565
preferential attachment 487ff
protein–protein interaction
network 539–541
p-star models 566
reciprocity model 576–577
road network 547–548
SI model 628–631, 640–641,
648–661, 677, 689
SIR model 631–636, 642–648,
661–669
SIRS model 637–639
SIS model 636–637, 669–672
small-world effect 554ff,
713–718, 719–725
small-world model 555–565
two-star model 577–583, 584,
586
vertex copying 534–541
World Wide Web 514–521
modularity 224–226, 372–382
alternative forms 225–226,
375–376
community detection 372–382
matrix form 375–376
maximization 372–382, 385
normalization 225
values of 224
modularity matrix 224, 376–377
eigenvectors 377
generalized 379
leading eigenvector 377
sparseness 377
modularity maximization 372–382,
385
algorithms 372–382, 385
bisection 372–382
computational complexity
374–375, 377–378, 382
genetic algorithm 381
greedy algorithm 381, 387
simulated annealing 381
spectral algorithm 375–379
vertex moving algorithm
373–375

Molloy–Reed criterion 456, 464–465,
471
moment closure 653–657
conﬁguration model 656
SI model 653–657
moments
and generating function
432–433
divergence 257–258, 312, 314,
440, 472, 601, 647
ﬁrst 257, 312, 314, 472
power-law distribution
257–259, 312, 314, 440,
472, 601, 647
second 257–259, 312–314, 433,
440, 450, 472, 483, 601,
646, 647
monkeys, social network 47
Moreno, Jacob 36, 44
motifs 264–265
movie database 183
multiedges 110, 111, 113
and adjacency list 287
and adjacency matrix 112, 113,
115, 438
citation networks 489–490, 491
conﬁguration model 436,
437–438, 440
directed networks 115
preferential attachment model
489–490, 491
Price model 489–490, 491
scale-free networks 440
small-world model 555
multigraph 110, 113
adjacency matrix for 112, 113,
115, 283
connection to weighted
networks 113
mutualistic network 103–104
MySpace 36
naive population 635
name generator 40–42, 220
Napster 73
National Longitudinal Study of
Adolescent Health 43, 221
neighbor degree 446–448

average 446–448
coauthorship network 448
conﬁguration model 446–447
Internet 448
neighbors
at given distance 451–456
average degree of 446–448
second neighbors 451–456
Netminer (software package) 277
network 1ff
network backbone provider 19
network optimization 541–548
airline networks 541–548
distribution networks 541
greedy algorithm 545
model of Ferrer i Cancho and
Solé 542–546, 547
model of Gastner and
Newman 546–548
road networks 547–548
simulated annealing 547
transportation networks 541
network visualization 8
Network Workbench (software
package) 277
NetworkX (software package) 277
neural network 6, 94–98
C. elegans 98
empirical measurements 97
picture of 98
statistics 237
neuron 94–98
neutral ﬁxed point 680
news spreading 10
nilpotent matrix 122
node 1, 109
average degree 134, 135–136
centrality 9, 168ff
citation network 67
degree 9, 133–136, 168–169
examples of 110, 123
food web 6, 99–100
groups of 193–198, 354ff
high degree 9, 245–246, 424,
614–615
highest degree 245, 253,
259–260, 278–279,

759

I NDEX

306–307, 609, 611–614,
623–624, 626, 699–701
importance 9, 168ff
Internet 19, 20, 23–25, 26–27
metabolic network 79
power grid 31
removal 514, 592ff
social network 36
values on 113–114, 282–283
World Wide Web 5, 63
node-disjoint paths, see
node-independent paths
node-independent paths 146–150,
196–198, 333, 341–343
algorithm for 341–343
non-linear preferential attachment
514, 521–527
degree distribution 522–527
empirical measurements 521
non-symmetric ﬁxed point 695
NP (complexity class) 360
occupation probability 594–595
oil pipeline network 33
one-mode projection 33, 124–126
ﬁlm actor network 124
rail networks 33
weighted networks 125–126
online network 6, 48–50
blogs 50
Facebook 6, 36, 49, 63
instant messaging 6, 49
LinkedIn 49
LiveJournal 50
MySpace 36
social networks 6, 36, 49–50
Usenet 39, 50
weblogs 50
O notation 279
Opte project 4
optimization
airline networks 541–548
distribution networks 541
genetic algorithms 381
greedy algorithms 381, 387,
545
model of Ferrer i Cancho and
Solé 542–546, 547

760

model of Gastner and
Newman 546–548
modularity 372–382, 385
relaxation method 366–369,
376–377
road networks 547–548
simulated annealing 381–382,
547
transportation networks 541
orthogonalization 352–353
Gram–Schmidt 352–353
spectral partitioning 370
oscillation 684–686, 701
dynamical systems 684–686,
701, 704
predator–prey dynamics 686
SIRS model 638, 686
synchronization 701–702, 704
oscillator network 701, 704
out-component 144–145, 239–240
and eigenvector centrality 172,
174, 178
directed random graphs
478–479
giant 67, 478–479
overlapping 240
World Wide Web 67
out-degree 9, 135
average 135–136
correlation with in-degree 475
degree centrality 169
distribution 246–247, 475–477
friendship network 41–42
social network 41–42
World Wide Web 9, 246, 248,
252–253
package delivery network 33, 541
packet, Internet 3, 10, 18, 21, 25–26,
243, 329
packet switched network 18
Internet 18
telephone network 31
PageRank 175–178, 707–708
extensions of 177–178
Google 176–177, 707–708
ofﬂine calculation 708
parameter value 176–177

pair approximation 651–657
Pajek (software package) 277
papers 67–70
citation 67–70
coauthorship 54
partition function 569, 570, 572, 574,
575, 576
patent citation network 70–71, 72
path lengths 136–140, 181–185,
241–243
algorithms 315–322, 330–333
diameter 140, 242–243, 420–422
directed networks 242
random graphs 419–423, 555
shortest 139–140, 181–185,
241–243, 315–322,
330–333
paths 136–142
augmenting 337–339
directed networks 136, 188,
242
disjoint 145–150, 196–198, 333,
339–343
edge-disjoint 145–150,
196–197, 333–341
edge-independent 145–150,
196–197, 333–341
Eulerian 140–142
geodesic 136, 139–140,
181–189, 241, 322–324
Hamiltonian 136, 140–142
independent paths 145–150,
339–343
in trees 128
lengths 136–140, 181–185,
241–243, 315–333
loops 137–139
number of given length
136–139
random walks 61, 157–161,
192, 725–726
self-avoiding 136
shortest 136, 139–140, 181–189,
241, 322–324, 330–333
vertex-disjoint 146–150,
196–198, 333, 341–343

I NDEX

vertex-independent 146–150,
196–198, 333, 341–343
weighted networks 301, 329,
333
P (complexity class) 360
Pearson coefﬁcient
algorithm for 267, 310
and assortative mixing 229,
230–231
and community detection 387
for degree 230–231, 237,
267–268, 310, 313
for rows of adjacency matrix
214–215, 387
calculation of 267, 310
peer-to-peer network 72–74,
709–712
bandwidth usage 74, 710–712
breadth-ﬁrst search 709–710
client nodes 712
Gnutella 73–74
LimeWire 73
Napster 73
search 73–74, 709–712
statistics 237
supernodes 74, 711–712
percolation 592ff
algorithm 616–621
and epidemics 642–648
and robustness 592, 601–602,
606, 608, 611–614,
623–624
Bethe lattice 598
bootstrap percolation 195
breadth-ﬁrst search 616
by degree 594, 609, 611–615,
623–624
clusters 595ff, 643ff
coauthorship network 621–624
conﬁguration model 596–615
continuous phase transition
595, 604
giant cluster 595ff, 643–648
immunization 592, 601–602,
609, 613, 673
Internet 621–624
joint site/bond percolation 673

non-uniform 594, 609–615,
623–624
occupation probability
594–595
phase transition 595, 604
Poisson random graph
600–601
power grid 621–624
power-law degree distribution
601, 602, 614, 623
random graphs 596–615
random removal of vertices
594–608, 621–623
real-world networks 615–624
relabeling algorithm 618–621
road networks 621–624
scale-free networks 601, 602,
614, 623
social network 621–624
spanning cluster 595–596
targeted attacks 594, 609–615,
623–624
threshold 595–596, 600–607,
614, 621–623, 643–644,
646
uniform removal of vertices
594–608, 621–623
vaccination 592, 601–602, 609,
613, 673
percolation threshold 595–596
and epidemics 643–644
bond percolation 643–644, 646
conﬁguration model 600–606,
614
Poisson random graph
600–601
real-world networks 621–623
sharpness 606–607, 622–623
site percolation 595–596,
600–606, 614
periphery 230–231
Perron–Frobenius theorem 177, 232,
346–347
personal network 44–46
PGP (software package) 53
phase diagram 583
phase transition 404

conﬁguration model 466
continuous 582, 604–606, 607
directed random graph
480–482
exponential random graphs
582, 585
ﬁrst-order 604
percolation 595, 604
Poisson random graph 404,
406, 414
random graphs 404, 406–407,
414, 466–467, 481, 582
second-order 606, 607
Strauss model 585
third-order 607
two-star model 582
physicist coauthorship network
263–264
percolation on 622
statistics 237
pipeline network 31, 33–34
planar network 129–133
approximately planar 130
average degree 166
countries 130–131
detection 131–133
Kuratowski’s theorem 132–133
measures of planarity 133
river networks 129
road networks 129–130, 547
trees 129
plant root network 33
point mutation 540
Poisson degree distribution
401–402, 450–451
generating functions 450–451,
455
random graph 402, 424, 428,
450–451
small-world model 557
Poisson distribution 402
generating function 430,
450–451, 455
Poisson random graph 400, 402
and exponential random
graph 573, 578

761

I NDEX

average component size
413–416
average degree 399, 401
clustering coefﬁcient 402–403,
423, 450, 552
community structure 424
components 403–419
degree distribution 401–402,
424, 428
diameter 399, 419–422
divergence of component sizes
414–415, 416
ensemble 399, 400
epidemic transition on 646
extensive components
403–404, 408–409
ﬁxed number of edges 398–399
generating functions 412–419,
450–451
giant component 404–408, 409,
635
G (n, m) 399
G (n, p) 400
graphical solution 405–407
large size limit 399, 402, 403,
405, 409, 422, 423
largest component 403–404
number of edges 398–399,
400–401
path lengths 419–423, 555
percolation on 600–601
phase transition 404, 406, 414
problems with 423–425
robustness 601
simple graph 398–399, 400
SIR model 635, 646–647
small components 128, 408ff
small-world effect 419–420,
422–423, 555
transitivity 402–403, 423, 552
tree-like components 128, 410
Pólya’s urn 533
polylogarithm function 431, 451
polymers 456
power failures 31–32
power grid 31–32
degree distribution 622

762

percolation on 621–624
power failures 31–32
statistics 237
power-law degree distribution 24,
68, 247–260
and giant component 471–473
and multiedges 440
and percolation 601, 602, 614,
623
and robustness 601, 608,
613–614
Barabási–Albert model 502,
526
citation networks 68, 69, 248,
252–253, 430, 487, 494
clustering coefﬁcient 264, 450
conﬁguration model 470–473
cumulative distribution
251–252, 257
detection 249–255
diverging second moment 312,
314
exponent 237, 248, 252,
254–255, 259, 472,
494–495, 502, 516, 520,
537–538, 601, 613–614,
647
generating functions 451
immunization 602
Internet 24, 247–249, 250–251,
252, 255, 264, 601
Lorenz curves 259–260
metabolic networks 539
non-power-law distributions
249, 424–425, 557–558
peer-to-peer network 74
preferential attachment
models 494–495, 500, 502,
520, 526
Price model 494–495, 498–499,
507–508
robustness of networks 601,
613–614
site percolation 601–602,
607–608, 613–614, 623
vaccination 602
vertex copying model 537–538

visualization 245–254
World Wide Web 248, 252–253,
259, 430, 487, 490, 503,
514, 516
power-law distribution 247–260,
430–432
beta function 494, 507, 513,
516, 529
betweenness centrality 261
centrality measures 261
cumulative distribution
251–252, 257
cut off 258
degrees 24, 68, 247–260,
494–495, 500, 502
detection 249–255
diverging second moment 258,
312, 314, 440, 472, 601, 647
eigenvector centrality 261
exponent 237, 248, 252,
254–255, 259, 472,
494–495, 502, 513, 516,
520, 537–538, 601,
613–614, 647
ﬁrst moment 257, 312, 314, 472
generating functions 430–432,
451, 472
Hill estimator 255
histograms 247–251
Lorenz curves 259–260
maximum likelihood
estimator 255
mean 257
moments 257–259
normalization 248, 256–257,
430–431
power failures 31
properties 255–260
pure form 256, 470–473
second moment 257–258, 312,
314, 440, 472, 601, 647
simple graph 258
tail 249, 250, 256–257, 258, 472,
487, 494, 498–499, 502
visualization 249–255
power method 346–353

I NDEX

computational complexity
348–350
convergence 348
for second eigenvalue 351–353
spectral partitioning 370
predator–prey interactions 6, 99,
686
preferential attachment 487ff
addition of extra edges
514–516
and vertex copying 537–538
average degree 491, 508
Barabási–Albert model
500–502, 510, 514, 526
Bianconi–Barabási model
527–534
citation networks 487–499
computer simulation 495–500,
502
cumulative degree
distribution 498–500
degree as a function of time
503–510
empirical evidence for 521
exponent 494–495, 502, 516,
520
extensions 514ff
models 487ff
multiedges 489–490, 491
non-linear 514, 521–527
power-law degree distribution
494–495, 502, 520, 526
Price model 487–500, 501,
503–513, 537–538
removal of edges 514, 516–521
removal of vertices 514
sublinear 521–526
superlinear 526–527
vertex ﬁtness 527–534
Yule process 487
preﬂow-push algorithm 334
prey protein 87
Price, Derek de Solla 68, 487
Price model 487–500, 501, 503–513,
537–538
acyclic networks 490
average degree 491, 508

citation networks 487–499
components 510–513
computer simulation 495–500
cumulative degree
distribution 498–500
degree distribution 493–495,
498–499, 507–508
degrees as a function of time
503–510
drawbacks 488, 495, 514
exponent 494–495
extensions 514ff
in-components 510–513
master equation 491–492,
503–505, 512–513
multiedges 489–490
power-law degree distribution
494–495, 498–499,
507–508
relation to Barabási–Albert
model 501, 502
relation to vertex copying
model 537–538
World Wide Web 490, 514
probability generating function, see
generating function
projection, one-mode, see one-mode
projection
protein 79
bait protein 87
complexes 85
interaction networks 7, 85–89
prey protein 87
protein–protein interaction network
7, 85–89
afﬁnity puriﬁcation 88
bipartite representation 85
co-immunoprecipitation
85–86, 87, 88
databases 88
models of 539–541
mutations 540
picture of 89
S. cerevisiae 89
statistics 237
tandem afﬁnity puriﬁcation 88
two-hybrid screen 86–88

vertex copying 539–540
yeast 88–89
yeast two-hybrid screen 86–88
protocols, Internet 3–5, 18–19
p-star model 566
public-key cryptography 50–53
QL algorithm 353–354
questionnaires 38, 39–44
queue 319, 327
race, assortative mixing by 221, 357
radix sort 310
rail network 32–33, 237
bipartite representation 33
one-mode projection 33
random-ﬁeld Ising model 151–152
random graph 398ff
assortative 423, 473–474
average component size
413–416, 465–467
average degree 399, 401
average number of edges
400–401
binomial degree distribution
401–402
bipartite 473–474
clustering 402–403, 423,
426–427, 474, 552
clustering coefﬁcient 262–263,
402–403, 423, 425,
449–450, 552
community structure 424
components 403–419, 456–473,
477–483
condition for giant component
407–408, 456, 463–465,
471–472
continuous phase transition
404, 582
degree correlations 423,
473–474
degree distribution 401–402,
424, 428, 434–435, 439,
445–446, 450–451,
475–477
diameter 399, 419–422
disassortative 473

763

I NDEX

divergence of component size
414–415, 416, 466, 467
edge probability 400
ensemble 399, 400, 401, 435,
439, 475, 484, 566
extensive components
403–404, 408–409
ﬁxed degree distribution 435,
439
ﬁxed degree sequence 434–439
ﬁxed expected degrees
442–445
ﬁxed number of edges 398–399
geodesic distances 420
giant component 404–408, 409,
456, 460–465, 471–473,
477–482, 635
G (n, m) 399
G (n, p) 400
graphical solution 405–407,
464
Hamiltonian for 571, 573, 578
large size limit 399, 402, 403,
405, 409, 422, 423, 428,
436, 441, 457, 474
largest component 403–404
number of edges 400–401
path lengths 419–423
percolation on 596–615
phase transition 404, 406–407,
414, 466–467, 481, 582
Poisson degree distribution
402, 424, 428, 450–451
Poisson random graph 400,
402
self-edges 398, 399, 436–438,
441
shortest paths 420
simple graph 398–399, 400
small components 128, 408ff,
456–460, 465–470
small-world effect 419–420,
422–423, 555
transitivity 402–403, 423,
426–427, 474, 552
tree-like components 128, 410,
457

764

triangles in 425, 426–427
randomized tree 296
random walk 157–161, 192
absorbing 158, 192
and Laplacian 157–161
and vertex degree 61, 159
search strategy 725–726
self-avoiding 158
random-walk betweenness 192–193
random-walk sampling 60–62, 158
random-walk search 725–726
rank/frequency plot 253–254
ratio cut partitioning 371–372
reciprocated edges 204–205,
576–577
reciprocity 204–205, 233
calculation of 343
email network 205
exponential random graph
model 576–577
model of 576–577
World Wide Web 205
reciprocity model 576–577
recommender network 74–75
bipartite representation 74–75
collaborative ﬁltering 75
weighted network 75
recommender system 75
record dynamics 534
recovered state 631–632
recovery from disease 631–632
exponential distribution of
632–633, 642
reduced adjacency matrix 158
reduced Laplacian 161, 163–164
redundancy 203
REGE algorithm 217
regional ISP 19, 20
regular equivalence 211–212,
217–220
and community detection 387
Katz similarity 219
measures of 217–220
REGE algorithm 217
regular graph 135
circle model 554, 557
dynamical system on 702

eigenvector centrality 231–232
Katz centrality 232
SI model on 674
regulatory network, genetic 7,
89–94
reinfection 636
relaxation method 366–369, 376–377
removed state 632
Rényi, Alfred 400
reorthogonalization 353
Gram–Schmidt
orthogonalization
352–353
spectral partitioning 370
repeated bisection 359, 362,
364–365, 378–380
community detection 378–380
graph partitioning 359, 362,
364–365
problems with 379–380
repelling ﬁxed point 680, 682, 684,
689
residual graph 336–339
resilience, see robustness
resistor network 161–164
and Laplacian 163–164
respondent-driven sampling 61–62
reverse small-world experiment
57–58, 719
Rey, Fernando 189
rich-get-richer effect 487
Riemann zeta function 256, 431,
471, 472
generalized 256
incomplete 256
right eigenvector 138, 171
river network 32, 33, 35, 128
picture of 35
planarity 129
tree-like 33, 35, 128
RNA 79, 91
messenger RNA 91, 94
transfer RNA 91
RNA polymerase 91–92
road network 32, 113
edge lengths 113, 329
model of 547–548

I NDEX

optimization model 547–548
percolation on 621–624
planarity 129–130, 133, 547
robots.txt 66
robustness 197, 592ff
and connectivity 197, 333
and cut sets 197, 333
and epidemics 601–602,
613–615
and k-components 197
conﬁguration model 601–602,
606, 608, 611–614
exponential degree
distribution 602–604,
611–613
independent paths 197, 333
Internet 197, 600, 623–624
percolation 592, 601–602, 606,
608, 611–614, 623–624
Poisson random graph 601
power-law degree distribution
601, 608, 613–614
real-world networks 621–624
scale-free networks 601, 608,
613–614
social networks 601–602,
613–615
targeted attacks 594, 609–615,
623–624
vertex removal 592, 601–602,
606, 608, 611–614,
623–624
Roget’s Thesaurus 237
rooted tree 127
root node 127–128, 291
roots 33
formula for lengths 34
router 19, 23–24
failure 197, 592, 594
routing tables 25–26
router table 25–26
Routeviews project 26
routing table 25–26
rumor spreading 10, 694
running time 278–282
adjacency list operations
289–290, 298, 343

adjacency matrix operations
283–285, 290, 298, 299,
309, 349–350
augmenting path algorithm
337
betweenness centrality
algorithm 326–327, 329
breadth-ﬁrst search 279–280,
320–321
Dijkstra’s algorithm 332–333
hierarchical clustering 389–390
Kernighan–Lin algorithm
362–364
modularity maximization
374–375, 377–378, 382
on sparse networks 280, 284,
306, 321
power method 348–350
spectral partitioning 370
worst-case 278–282
Saccharomyces cerevisiae 89
saddle point 682, 684, 689
Salton cosine similarity, see cosine
similarity
scale-free network 247–260
average geodesic distances
242–243
Barabási–Albert model 502,
526
citation networks 68, 69, 248,
252–253, 430, 487, 494
clustering coefﬁcient 264, 450
conﬁguration model 470–473
core 242
cumulative degree
distribution 251–252, 257
diameter 242–243
exponent 237, 248, 252,
254–255, 259, 472,
494–495, 502, 516, 520,
537–538, 601, 613–614,
647
geodesic distances 242–243
giant component 471–473
giant percolation cluster
607–608, 648
immunization 602

Internet 24, 247–249, 264
Lorenz curves 259–260
metabolic networks 539
multiedges 440
non-uniform percolation
613–614
peer-to-peer networks 74
percolation 601, 602, 614, 623
preferential attachment
models 494–495, 502, 520,
526
Price model 494–495, 498–499
robustness 601, 608, 613–614
shortest paths 242–243
SIR model on 647
site percolation 601–602,
607–608, 613–614, 623
vaccination 602, 613–614
vertex copying model 537–538
World Wide Web 248, 514
scaling
allometric scaling 35
in biology 35
small-world model 560–565
scaling parameter, see exponent
S. cerevisiae 89
Schur decomposition 138
Science Citation Index 68, 69
scientiﬁc citation network 67–70
scientiﬁc coauthorship network 54,
123, 263–264, 354–355
average neighbor degree 448
biologists 448
clustering coefﬁcient 200–201,
237, 263
funneling effect 56, 57, 243
mathematicians 448
percolation on 621–624
physicists 263–264
statistics 237
triadic closure in 263–264
scientiﬁc papers 67–70
citation 67–70
coauthorship 54
Scopus 68
search 705ff
engine 176–177, 705–708

765

I NDEX

ﬁlesharing network 709
peer-to-peer network 73–74,
709–712
random-walk search 725–726
small-world experiment 56–57,
713–724
web search 5, 67, 176–177,
705–708
search engine 705–708
AltaVista 237, 238
Ask.com 181
Google 176–177, 707–708
Teoma 181
second neighbors 451–456
second-order phase transition 606,
607
self-avoiding path 136
geodesic path 139
Hamiltonian path 140
random walk 158
shortest path 139
self-avoiding walk 158
self-edge 110, 111, 115
acyclic network 118, 121
and adjacency list 287
and adjacency matrix 112, 115,
121, 133, 284
cocitation networks 116
computer representation 287
conﬁguration model 436–438,
441
directed networks 115
random graphs 398, 399,
436–438, 441
self-loop, see self-edge
sewerage network 33
sexual contact network 42, 237
sexually transmitted disease 42
shortcut 555–556, 713–715
shortest augmenting path
algorithm 334
shortest distance, see geodesic
distance
shortest path 136, 139–140, 181–189,
241–243
absence of loops in 139
algorithm 315, 322–324, 333

766

diameter of network 140
Dijkstra’s algorithm 301, 329,
333
inﬁnite 139, 183–185
longest 140
overlapping 187–188
self-avoiding 139
small-world effect 241–243
uniqueness 140
weighted networks 301,
329–333
shortest path tree 322–324, 333
betweenness centrality
325–329
breadth-ﬁrst search 322–324
Dijkstra’s algorithm 333
weighted networks 333
signed edges 206
signed network 206–211
similarity 211–220
and community detection
387–389, 390
between groups of vertices 388
cosine similarity 212–214, 216,
387, 390, 392
Euclidean distance 216, 387
Katz similarity 219
non-network measures 211
Pearson coefﬁcient 214–215,
387
regular equivalence 211–212,
217–220
structural equivalence 211–216
similarity transformation 138
SI model 628–631, 640–641, 648–661,
677, 689
and conﬁguration model 656,
657–661
as a dynamical system 677,
679, 687, 689, 690
degree-based approximation
657–661
early-time behavior 650–651,
660–661
equations 630
ﬁxed points 679, 689, 690
fully mixed 630, 641, 651, 677

initial conditions 630, 641, 649
late-time behavior 640–641,
651, 660–661
logistic growth 630–631
moment closure method
653–657
on a regular graph 674
short-time behavior 650–651,
660–661
solution 630–631, 640–641, 650,
658–661
symmetric ﬁxed point 689
time-dependent properties
630–631, 648–661
Simon, Herbert 487
simple graph 110
disassortative mixing 267
exponential random graph
model 567
maximum number of edges
134
Poisson random graph
398–399, 400
random graph 398–399, 400
with power-law degree
distribution 258
simple network, see simple graph
simulated annealing 381–382
community detection 381–382
modularity maximization 381
network optimization 547
single-linkage clustering 388–390
implementation 390
singular value decomposition 76
sink food web 102
SIR model 631–636, 642–648,
661–669
and bond percolation 642–648
and conﬁguration model
645–648, 664–669
and eigenvector centrality
663–664
basic reproduction number
635–636
degree-based approximation
664–669

I NDEX

early-time behavior 663–664,
668
epidemic outbreaks 635–636,
644, 647, 664
epidemic threshold 636, 644,
646, 664, 668–669
fully mixed 633–634, 642, 644,
646, 647
initial conditions 635, 663
late-time behavior 642–648,
667–668
Poisson random graph 635,
646–647
power-law networks 647
random graphs 635, 645–648,
664–669
scale-free networks 647
short-time behavior 663–664,
668
size of outbreaks 634–635,
643–645, 645–648, 667
small outbreaks 674
time-dependent properties
633–635, 661–669
transmission probability 642
SIRS model 637–639
and endemic disease 639
as a dynamical system 686
equations 638
oscillations in 638, 686
SIS model 636–637, 669–672
and eigenvector centrality 670
and endemic disease 637, 670,
672
basic reproduction number
637
degree-based approximation
671–672
early-time behavior 671–672
endemic state 637, 670, 672
epidemic threshold 637, 670,
672
fully mixed 636–637
initial conditions 637, 671
late-time behavior 648, 670,
672
logistic growth 637

short-time behavior 671–672
solution 637, 671
time-dependent properties
636–637, 669–672
site 109
site percolation 592ff
algorithm 616–621
and robustness 592, 601–602,
606, 608, 611–614,
623–624
Bethe lattice 598
breadth-ﬁrst search 616
by degree 594, 609, 611–615,
623–624
clusters 595ff
coauthorship network 621–624
conﬁguration model 596–615
exponential degree
distribution 602–604,
611–613
giant cluster 595, 596–608
graphical solution 598–599
immunization 592, 601–602,
609, 613, 673
Internet 600–601, 621–624
joint site/bond percolation 673
non-uniform 594, 609–615,
623–624
occupation probability
594–595
percolation threshold 595–596,
600–606, 614
phase transition 595, 604
Poisson random graph
600–601
power grid 621–624
power-law degree distribution
601–602, 607–608,
613–614, 623
random graphs 596–615
random removal of vertices
594–608, 621–623
real-world networks 615–624
relabeling algorithm 618–621
road networks 621–624
scale-free network 601–602,
607–608, 613–614, 623

social network 621–624
spanning cluster 595–596
targeted attacks 594, 609–615,
623–624
uniform removal of vertices
594–608, 621–623
vaccination 592, 601–602, 609,
613, 673
Six Degrees of Kevin Bacon 54
six degrees of separation 10, 56, 713
skew-symmetric matrix 703
small components 128, 235,
238–241, 408–419,
456–460, 465–470,
482–483
absence of loops in 410, 457,
482
average size 413–416, 465–467
conﬁguration model 456–460,
465–470
directed random graph
482–483
Poisson random graph 128,
408ff
random graph 128, 408ff,
456–460, 465–470
strongly connected 239–240,
482
tree-like 128, 410, 457
smallest eigenvalue
adjacency matrix 700
Laplacian 156, 693, 701
small-world effect 9–10, 54–58,
241–243
Internet 10
message passing experiments
54–58, 241–243, 713, 718,
719, 724–725
models of 554ff, 713–718,
719–725
Poisson random graph
419–420, 422–423, 555
random graph 419–420,
422–423, 555
small-world model 564–565
small-world experiment 54–58,
241–243

767

I NDEX

and network search 56–57,
713–724
biases 56, 57
email version 57
failure of 724–725
greedy algorithm 714–715, 716,
722
models of 713–718, 719–725
response rate 55, 57
reverse small-world
experiment 57–58, 719
small-world model 555–565
average path length 560–565
clustering coefﬁcient 558–560,
564–565
d-dimensional 718
degree distribution 557
geodesic distance 560–565
Kleinberg variant 713–718
mean-ﬁeld theory 563–564
message passing model
713–718
multiedges 555
numerical simulation 562
Poisson degree distribution
557
scaling theory 560–564
small-world effect 564–565
transitivity 558–560, 564–565
triangles in 558–559
two-dimensional 715, 718
variants 556–557, 586, 713–718
SMTP (Simple Mail Transfer
Protocol) 18
snowball sampling 58–60
and eigenvector centrality 59
biases 59
network reconstruction from
59–60
social network 5–6, 36ff
actors 36, 109–110
AddHealth study 43, 221
animals 47
animosity 113, 206
archival data 38, 47–53
assortative mixing 45, 220–222,
237, 267–268

768

average degree 45–46, 237, 422
biases in 43–44, 56, 59–62
bipartite 38, 53–54, 123
blogs 50
brokers 189
clustering coefﬁcient 45,
200–201, 237, 262–263
community structure 10, 357,
373–374, 390
degree 9, 41–42, 45–46, 135,
237, 446
degree distribution 42, 45–46
directed networks 41, 48–49,
50, 53
direct observation 46–47
disassortative mixing 267–268
disease spread 42, 60, 241, 592,
601–602, 614–615, 627,
639ff
edges 6, 37–38, 41, 42, 48–49,
50, 53
email network 48–49, 200, 237
empirical measurements of
36ff
Facebook 6, 36, 49, 63
ﬁlm actor network 54, 237
friendship network 6, 36, 37,
39–46
geodesic distances 10, 54–58,
183, 241–243
groups in 193–194, 221, 357,
373–374
in-degree 41–42
instant messaging 6, 49
intermarriage network 48
karate club network 6, 47,
373–374
LinkedIn 49
LiveJournal 50
mean degree 45–46, 237
medical doctors 42
MySpace 36
online 6, 36, 49–50
origin of the term 37
out-degree 41–42
percolation on 621–624
personal networks 44–46

questionnaires 38, 39–44
respondent-driven sampling
61–62
rumor spreading 10, 241,
694–695
schoolchildren 37, 40–42,
220–222, 226–227, 357
shortest distances 54–56, 183,
241–243
Southern Women Study 38, 53
sparse networks 135
third-party records 47–53
time-resolved 49–50
triads in 207–208, 263–264
Usenet 39, 50
weblogs 50
social network analysis 36–37,
38–39, 168ff
Social Science Citation Index 68
sociogram 37
sociometric network studies 44
sociometric superstars 47, 56, 243
sociometry 37
software call graph 28
software class network 237
software packages 276–278
Graphviz 277
GTL 277
igraph 277
InFlow 277
JUNG 277
LEDA/AGD 277
Mathematica 277, 354
Matlab 277, 354
Netminer 277
network of 237
Network Workbench 277
NetworkX 277
Pajek 277
UCINET 190, 277, 286
Visone 277
web crawlers 67
yEd 277
source food web 102
Southern Women Study 38, 53
afﬁliation network 38, 39, 53
bipartite network 38, 39, 53

I NDEX

picture of 39
spanning percolation cluster
595–596
spanning tree 128
sparse network 134–135
adjacency matrix of 134, 286
algorithms on 135, 280,
284–286, 306, 310, 321,
353–354
breadth-ﬁrst search on 280, 321
eigenvectors of 353–354
exponential random graphs
574, 575
friendship networks 135
Internet 134–135
running time of algorithms
135, 280, 284–286, 306,
310, 321, 353–354
social networks 135
World Wide Web 134–135
spectral gap 157
spectral partitioning 364–370
algebraic connectivity 368, 370
community detection 375–379
examples 363, 369–370
Laplacian 365–370
modularity matrix 376–379
running time 370
spectrum
adjacency matrix 121–122,
137–139, 170, 173,
345–350, 691–692,
698–701, 703–704
Laplacian 154–156, 370, 701
spontaneous symmetry breaking
579–582
stability analysis 680–686, 687–698
stability condition 691–693, 698
stability function 697–698, 699, 700,
701
star graph
betweenness centrality 189,
190
transportation network 543
static web pages 64, 66
Stirling’s approximation 494
stratiﬁed network 226

Strauss model 583–585
stretched exponential 525–526
strongly connected component
144–145, 239–241
acyclic networks 144, 172,
240–241
citation networks 172, 241
cycles in 144, 241
directed random graphs
477–479, 481–483, 485
giant 477–479
largest 239
small 239–240, 482
World Wide Web 143–145,
239–240
structural balance 208–211
structural equivalence 211–216
structural holes 202–203
subnet 24
class A and B 24
class C 4, 24
Internet representation 4, 24,
26
superhub 531–533
supernode 74, 711–712
superpeer 711–712
surveys 39ff
design of 40
ﬁxed choice 41–42
free choice 41, 45
General Social Survey 45
name generators 40–42, 220
respondent-driven sampling
61–62
telephone surveys 40, 59
susceptible–infected model, see SI
model
susceptible–infected–recovered
model, see SIR model
susceptible–infected–susceptible
model, see SIS model
susceptible state 628
symmetric ﬁxed point 689–690,
694–695
symmetry breaking 579–582
synchronization 701–702, 704
tandem afﬁnity puriﬁcation 88

TCP (Transmission Control
Protocol) 18
technological networks 17ff
airline network 32, 541–548
assortative mixing 237, 267
disassortative mixing 267
distribution networks 33–35
empirical measurements of
17ff
gas pipelines 31, 33–34
Internet 3, 18–28
oil pipelines 33
power grid 31–32, 621–624
rail network 32–33
road network 32, 113, 547–548,
621–624
statistics 237
telephone network 28–31
transportation networks
32–33, 541–548
telephone call graph 49, 237
telephone company 29
telephone exchange
local 30
long distance 30
telephone network 28–31
circuit switched 18, 29, 31
geography 31
long-distance ofﬁces 30
packet switched 31
schematic representation 30
toll-switching ofﬁces 30
telephone surveys 40, 59
Teoma 181
thesaurus network 237
third-order phase transition 607
threshold
appearance of giant
component 406–408, 456,
464–465
epidemic 636, 637, 643–644,
646–647, 664, 668–669,
670, 672
percolation 595–596, 600–607,
614, 621–623, 643–644,
646
tie 36, 109

769

I NDEX

time complexity 278–282
time-resolved social network 49–50
toll-switching ofﬁce 30
traceroute 21–23
train network, see rail network
transcription factor 86, 91
transfer RNA 91
transitivity 198–204
cliques 198
directed networks 201
exponential random graphs
583–585
food webs 264
Internet 200, 264
partial 198–199
perfect 198
Poisson random graph
402–403, 423, 552
random graphs 402–403, 423,
426–427, 474, 552
small-world model 558–560,
564–565
social networks 200–201
Strauss model 583–585
World Wide Web 264
transmission probability 642
transmission rate 640
transportation network 32–33,
541–548
airline network 32, 113,
541–544, 548, 673
maintenance costs 542
optimization 541
rail network 32–33, 237
road network 32, 113, 129–130,
329, 547–548, 621–624
star graph 543
tradeoffs 542
trapezium rule, see trapezoidal rule
trapezoidal rule 524–525, 626, 716
tree 127–129
absence of loops in 127–129,
410, 457, 482
adjacency tree 290–291,
297–298
and conﬁguration model 457
and random graph 128, 410

770

AVL tree 128, 297
Bethe lattice 128, 268–269, 598
betweenness centrality 182,
233
Cayley tree 128, 268–269, 598
clustering coefﬁcient 199
data structure 290–298
dendrogram 128, 383–384, 720
hierarchical network model
720–721
in-components 511
leaf nodes 127, 326–327, 328
minimum spanning tree 128
number of edges 128–129
percolation on 598
planarity 129
randomized 296
river networks 33, 128
rooted 127
root node 127–128, 291
small components 128, 410,
457
tree data structure 290–298
adding an element to 294–297
AVL tree 128, 297
balanced 293–294, 295–297
binary heap 301–305
child node 291
deleting an element in 297
depth 293
enumerating elements of 297
Euler tour 297
ﬁnding an element in 292–294
leaf node 291
parent node 291
pivot 297
rebalancing 295–297
root node 291
triad
closed 199–200, 263–264
signed networks 206–208
social networks 207–208,
263–264
stable 206–208
unstable 206–208
triadic closure 263–264
triangles 199–200, 262–265

and clustering coefﬁcient
199–200
random graphs 425, 426–427
small-world model 558–559
Strauss model 584–585
triangular lattice 553–554
triangular lattice 552–553
triangular matrix 120–121
tricomponent 196, 197
non-contiguous 197–198
tripartite network 80–81
trophic level 7, 101–102, 166–167
trophic species 100
trust network 53
two-hybrid screen 86–88
two-mode network 53, 123
two-star 577
two-star model 577–583, 584, 586
coexistence region 581,
582–583
continuous phase transition
582
edge probability 578–583
Hamiltonian 577–578
mean-ﬁeld theory 578–583
phase diagram 583, 584
phase transition 582
problems with 581–583
spontaneous symmetry
breaking 579–581
UCINET (software package) 190,
277, 286
UDP (User Datagram Protocol) 19
undirected network 110–112
adjacency list 286–287
adjacency matrix 110–112,
114–115, 137–138, 284
average degree 134
betweenness centrality
186–188
clustering coefﬁcient 198–201
components 142–143, 196–198,
235–239
connectivity 147–150
degree 9, 133
degree distribution 243–246
degree sequence 244–245

I NDEX

eigenvector centrality 171
excess degree distribution
445–449, 459, 597, 645
exponential random graph
571–575
friendship networks 41
from directed network 115–118
Katz centrality 174
k-components 196–198
loops in 137–138
metabolic networks 80–81
paths on 136–138, 139–142,
145–150, 196–197,
241–242, 322–324,
334–336
self-edges 112, 115
sexual contact networks 42
social networks 41, 42
transitivity 198–201
URL 65–66, 283
Usenet 39, 50
vaccination 592, 601–602, 614–615
acquaintance immunization
614–615
non-uniform 609, 613
percolation theory 592,
601–602, 609, 613,
614–615, 673
scale-free network 602,
613–614
targeted 609, 613, 614–615
valued network, see weighted
network
vertex connectivity 147, 148,
196–197, 333, 341–343
vertex copying 534–541
biological networks 539–541
citation networks 534–539
gene duplication 539–540
metabolic networks 539
model 534–541
protein–protein interaction
networks 539–540
vertex copying model 534–541
citation networks 534–539
connection to Price model
537–538

exponent 537–538
master equation 537
power-law degree distribution
537–538
vertex cut set 147–150, 196, 333
vertex-disjoint paths, see
vertex-independent paths
vertex-independent paths 146–150,
196–198, 333, 341–343
algorithm for 341–343
vertex percolation, see site
percolation
vertices 1, 109
age of 509–510
centrality 9, 168ff
copying 534–541
cut set 147–150, 196, 333
examples of 110, 123
food webs 6, 99–100
groups of 193–198, 354ff
high degree 9, 245–246, 424,
614–615
highest degree 245, 253,
259–260, 278–279,
306–307, 609, 611–614,
623–624, 626, 699–701
importance of 9, 168ff
Internet 19, 20, 23–25, 26–27
metabolic networks 79
percolation on 592ff
removal 514, 592ff
similarity 388
social networks 5, 36
values on 113–114, 282–283
World Wide Web 5, 63
virus, computer 48–49, 627
Visone (software package) 277
visualization 8–9
acyclic networks 120
software 8, 277
water supply network 33
Watts–Strogatz model 555–565
weakly connected component 143,
239
directed random graph 477,
479–480, 482
giant 479–480, 482

largest 239
web crawler 65–67, 705–706
biases 66–67, 238
breadth-ﬁrst search 65–66
for citations 68–69
operation of 65–66
robots.txt 66
software 67
web search 67, 705–706
web link, see hyperlink
weblog network 50
web pages 5, 63–67, 705–708
dynamic 65, 66, 706
indexes of 67, 76, 705–708
ranking of 176–177, 179–181,
705–708
static 64, 66
web search 5, 67, 176–177, 705–708
anchor text 707
Ask.com 181
breadth-ﬁrst search 65, 706
Google 176–177, 707–708
PageRank 176–177, 707, 708
Teoma 181
web crawlers 65–67, 705–706
website 50, 64
weighted edge 43, 112–113,
299–300, 329
negative weights 113, 206
weighted network 112–114
adjacency matrix 112–113, 283
betweenness centrality 333
bibliographic coupling
networks 117
bipartite 126
cocitation networks 116
connection to multigraphs 113
food webs 102–103, 112–113
geodesic paths 301, 329, 333
max-ﬂow/min-cut theorem
150–151
maximum ﬂow 150–151
minimum cut 150
one-mode projections 125–126
recommender networks 75
shortest paths on 301, 329–333
shortest path trees 333

771

I NDEX

Westlaw 72
W-function 405, 422, 647
wolves, social network 47
word network 237
World Wide Web 5, 63–67, 705–708
as distributed database 709
assortative mixing 222, 237
Barabási–Albert model
500–502
blogs 50
bow tie diagram 240
clustering coefﬁcient 237, 264
co-links 205
community structure 357
components 66–67, 143–145,
238, 239–240
cumulative degree
distribution 252–253
degree distribution 246,
252–253, 259
directed network 5, 63–64,
66–67, 143
disappearance of edges 514
disappearance of vertices 514
edges 5, 63–64, 143

772

exponent 237, 259
giant in-component 239–240
giant out-component 67,
239–240
hyperlinks 5, 63–64, 143,
259–260, 706–708
in-components 240
in-degree 9, 246, 252–253
in-degree distribution 246, 248,
252–253, 259
large components 237, 239–240
largest strongly connected
component 239–240
models of 514–521
nodes 5, 63
number of pages 64–65
out-components 240
out-degree 9, 246, 252–253
out-degree distribution 246,
248, 252–253
power-law degree distribution
248, 252–253, 259, 430,
487, 490, 503, 514, 516
Price model 490, 514
reciprocity 205

scale-free network 248, 514
search engine 5, 67, 176–177,
705–708
sparse network 134–135
statistics 237
strongly connected
components 143–145,
239–240
transitivity 264
vertices 5, 63
weblogs 50
web search 5, 67, 176–177,
705–708
yeast protein–protein interaction
network 88–89
yeast two-hybrid screen 86–88
yEd (software package) 277
Yule process 487
Yule, Udny 487
Zachary, Wayne 6, 47, 373
zeta function 256, 431, 471, 472
generalized 256
incomplete 256
z-transform 412

Plate I: The network structure of the Internet. The vertices in this representation of the Internet are “class C subnets”—
groups of computers with similar Internet addresses that are usually under the management of a single organization—
and the connections between them represent the routes taken by Internet data packets as they hop between subnets.
The geometric positions of the vertices in the picture have no special meaning; they are chosen simply to give a pleasing
layout and are not related, for instance, to geographic position of the vertices. The structure of the Internet is discussed
in detail in Section 2.1. Figure created by the Opte Project (www.opte.org). Reproduced with permission.

Plate II: The food web of Little Rock Lake, Wisconsin. This elegant picture summarizes the known predatory interactions between species in a freshwater lake in the
northern United States. The vertices represent the species and the edges run between
predator–prey species pairs. The vertical position of the vertices represents, roughly
speaking, the trophic level of the corresponding species. The figure was created by
Richard Williams and Neo Martinez [210].

Plate III: The structure of the Internet at the level of autonomous systems. The vertices in this network representation
of the Internet are autonomous systems and the edges show the routes taken by data traveling between them. This
figure is different from Plate I, which shows the network at the level of class C subnets. The picture was created by Hal
Burch and Bill Cheswick. Patent(s) pending and Copyright Lumeta Corporation 2009. Reproduced with permission.

2

O

O

O
C OO -

6.3.2.7-10
6.3.2.13 HO O

OP P U

C H 3C H

NHAC

C MP -N-A c etyl
neuraminate
O
C HOH
C HOH
C H 2 OH

C H 2 OH
O C OO
HO

C H 2 OH
O

5.1.3.12

5.1.3.6

OP P U
OH

UDP -G luc uronate

HO OH

OP

OH

OH

O
OH H
C

H

OH H

C

H

HO OH

OH OH
C

C

C

H

HOC H 2

OH H

OH

C

C

C

H

CO

HOC H 2

G ulonolac tone 1.1.3.8 2-Oxogulonolac tone
OH H
HOC H 2 C

OH

C
OH

H

H

OH H

OH

C

C

C

H

OH H

C HO

HOC H 2

HOC H 2

OH OH

C

C

C

H

C HO

H

CO

C

C H 2 OH

P OC H 2

2.7.1.53

C

OH OH

C

C

H

H

1.1 .1.9

C

C

H

OH

CO

C H 2 OH
HOC H 2

H

OH H

C

C

C

HOC H 2

C

H

OH

C

C

H

H

H

C

C

C

2. 7.

H

H

OH H

C

C

C

P OC H 2

R ibitol

H

H

H

OH

C

C

H

H

C

H

H

C

C

C

CO

H+

2H+

D-R ibos e
5.3.1.6

5.1.3.4

P OC H 2

2. 7.

C H 2 OH

OH
C

4.1.2.-

H

H

C

C

C HO
P OC H 2

OH OH OH

H

H

H OH

Cyt bc
2e-

P700

PC

C

C

C

NH 2

β

CO2

α

α

α

3

β

C OO

C OO

A rac hidonate 1.13.11.34

C OS C oA

C O-S -AC P

S tearoyl-C oA

C H 3 (C H 2 ) 14 C OC H 2 C OS -C oA

Dehydros tearoyl-C oA

OH-S tearoyl-C oA

Oxos tearoyl-C oA

C H 3 (C H 2 ) 14 C OS C oA

C hain elongation

P almitoyl-C oA
C H 3 (C H 2 ) n C H=C HC OS -C oA

1.3.1.9
2,
1.3.1.10

A C Y L -A C P

4.2 .1.6

Hexanoyl-A C P

C H 3 (C H 2 ) 2 C H=C HC O-S -AC P

1.3.1.9

2, 3-Hexenoyl-A C P

1.3.1.9

C rotonoyl-A C P

B utanoyl-A C P

C H 3 (C H 2 ) n+2 C OS -C oA

6.2.1.3

A C Y L -C oA

F A T T Y A C ID

3.1.2.20

2.3.1.15

2.3.1.7

C H 2 O-C O-R "

(Mitoc hondria)

C H 3 C O-S -AC P

P Y R UV A T E

C H 3 (C H 2 ) 2 C H 2 C H 2 C OS C oA

Hexanoyl-C oA
C H 3 C H 2 C H 2 C OS C oA

2, 3-E noyl-C oA
C H 3 (C H 2 ) 2 C H=C HC OS C oA

1.3.99.3

2, 3-Hexenoyl-C oA
C H 3 C H=C HC OS C oA

1.3.99.2

B utanoyl-C oA

4.2.1.17

1.1.1.35

C H 3 C H(OH)C H 2 C OS C oA

1.1.1.157

3-OH-Hexanoyl-C oA

4.2.1.55

C rotonoyl-C oA

3-OH-A c yl-C oA
C H 3 (C H 2 ) 2 C H(OH)C H 2 C OS C oA

3-OH-B utanoyl-C oA

2.3.1 .16

3-Oxohexanoyl-C oA
C H 3 C OC H 2 C OS C oA

1.2.4.1
2.3.1.12
1.8.1.4

C H 3 C H 2 C H 2 C H 2 C OS C oA

C H 3 C H 2 C H=C HC OS C oA

C H 3 C H 2 C H(OH)C H 2 C OS C oA

4.1.3.5

3-Oxopentanoyl-C oA

OH

R '-C O-OC H

O

-

R '-C O-OC H

C ardiolipin

P hos phatidyl
ethanolamine
C E P HA L IN

-

OP hos phatidylglyc erol

2.7.8.1

+
P OC H 2 C H 2 NH 3

2.7.7.14

C DP -E thanolamine

O
+
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3

R -C O-OC H

- L ys olec ithin

OC holine
plas malogen 1.3.1.35
S erine +NH

L E C IT HIN

3.1.4.4

3

2.7 .8.3

2.3.1.6

C HOL INE
2.7.1.32

C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 OH

C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 OH

2.7.8.3

C eramide

3.1.4.12

C H3

C H 3O

(C 20)

P hytol

P las toquinone

O

11-c is -R etinol

Dark

(V itamin K )

(C 15)

C H2
H
C

CH

H 3C

CH
N

CH

H2C

N
C
H

C OO -

HE ME

N
C H3

H
C
H2

C H2

C H2

C OO -

C OO -

4.99.1.1

N
H
N

C H3

C H2

1.3.3.3

C H2

H
C
H2

- OOC

C H2

N
H

H

H 3C
C H2

C H2

P rotoporphyrinogen

H2
C

H 2C

N

C H2

C H2

1.3.3.4

H3C

N
H

H

H 3C

C H2
C OO -

C H2

2

CH

H2O

H 2C

C H2

C OO -

-

N
H

C H2

H
N
C
H2

C H2
C H2
C H2

C OO -

C H2

C H2

C OO-

C OO -

4.1.1.37

C oproporphyrinogen

5-A mino-

Uroporphyrinogen

C OO levulinate

AαT

α

H+

N2

CH 2
CH 2

H 2C
H 2C

TE

P orphobilinogen

A DP

X

1.

1.

(C H 3 ) 2 C HC HC H(OH)C OO

H
C

HC
OOC C

1 0 c -s ucb- u

6.4.1.4

HOC H 2 C (C H 3 ) 2 C OC OO

Oxopantoate

1.1.1.169
HOC H 2 C (C H 3 ) 2 C H(OH)C OO

6.3.2.1
HOC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C OO

P A NTOT HE NA T E
2.7.1.33

C H3

+
C H C H(NH 3 )C OO

P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C OO

4-P -P antothenate
C ys teine
6.3.2.5

2.6.1.32

IS OL E UC INE
CH3

C OO
P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC HC H 2 S H

4-P -P antothenylc ys teine

1.2.1.25

C H 3 C H 2 C HC OS C oA

4.1.1.36
P OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

4-P -P antetheine

+
(C H 3 ) 2 C HC H 2 C H(NH 3 )C OO

C H3
C H 3 C = C HC OS C oA

2.6.1.6

H2
C

H 2C
OOC C

ADP - OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

L E UC INE

Dephos pho-C oenzyme A

1.4.1.9

2.7.1.24
1.2.1.25

1.3.99.10

3-Methylc rotonyl-C oA

C H2
C H-C OO

(C H 3 ) 2 C HC H 2 C OS C oA

P -ADP - OC H 2 C (C H 3 ) 2 C H(OH)C O NHC H 2 C H 2 C O NHC H 2 C H 2 S H

Is ovaleryl-C oA

C oenzyme A

+
NH 3

OOC C H 2 C H 2 C ONH
C H2
C H-C OO

N

1.14.11.1

OOC C H 2 C H 2 C ONH
OOC C OC H 2 C H 2 C H 2 C H-C OO

OOC C H-C H 2 C H 2 C H 2 C HC OO
+
NH 3

OOC C HC H 2 C H 2 C H 2 C H-C OO
+
NH 3

2.7. 2.11

B ios ynthes is
Degradation

S permidine

L ipids
2.5.1.16

B ios ynthes is
Degradation

H 2 NC H 2 C H 2 C H 2 C H 2 NH 2

P utres c ine

G lutamic
s emialdehyde

CH

C H 3 C OC OO

OHC C OO

C HC OO

P R OL INE
1.14.11.2

OOC C HC H 2 C OO
N
+
H 2 NC NHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

4.1.3.16

+ NH 2

P - HNC N(C H 3 )C H 2 C OO

P -C reatine
3.5.2.10

Degradation

4-Hydroxyglutamate

N
H

1.5.1.12

HY DR OXY
P R OL INE
NH

CO

N
C H3

CH2

HN C

C reatinine

Human Metabolis m is identified as far pos s ible by black arrows

B ios ynthes is

Degradation

C OMP A R T ME NT A T ION

2.6.1.23
+
OOC C H(OH)C H 2 C H(NH 3 )C OO

C HC OO

H 2C

A rgininos uc c inate

1.14.13.39

2.7.3.2

B ios ynthes is

P hotos ynthes is Dark R eac tions

4-Hydroxy2-oxoglutarate

C H2

HOC H

4.3.2.1
+ NH 2

C reatine

B ios ynthes is
Degradation

V itamins C o-enzymes & Hormones

OOC C H(OH)C H 2 C OC OO
C H2

NH

H 2 NC N(C H 3 )C H 2 C OO

B ios ynthes is
Degradation

P urines &
P yrimidines

P entos e P hos phate P athway

P yrroline-5c arboxylate
1.5.99.8
C H2
1.5.1.2
C H2

NO

A mino A c ids

P yruvate G lyoxylate

C HC OO
N

A R G ININE

2.1.1.2

L E G E ND
C arbohydrates

H 2 N(C H 2 ) 4 NH (C H 2 ) 3 NH 2

+
OHC C H 2 C H 2 C H (NH 3 ) C OO

6.3.4.5

+
H 2 NC NHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

2

H 2 NC NHC H 2 C OO

S ac c haropine

+

S -A denos ylmethyl
thiopropylamine

2.5.1.22

+
P OOC C H2C H 2 C H (NH 3 ) C OO

2.1.3.3

3.5.3.6

+
C H 2 C H 2 C H 2 C H 2 C H (NH 3 ) C OO

1.5.1.9

A denos yl

4.1.1.17

3.5.3.1

+
OHC C H 2 C H 2 C H 2 C H (NH 3 ) C OO

A
C
I
D
S

C OO
NH C HC H 2 C H 2 C OO

(Dec arboxylated S A M)

1.2.1.41

NH 2

LY S INE

A
M
I
N
O

C H 3 -S C H 2 C H 2 C HNH 2

S permine

+
H 2 NC ONHC H 2 C H 2 C H 2 C H (NH 3 ) C OO

UR E A

G lyc ine +

s
n it

N 6 -T rimethyllys ine

2-Oxoadipate 2.6.1.39 2-A minoadipate 1.2.1.31 2-A minoadipate
s emialdehyde
H 2 N(C H 2 ) 3 NH (C H 2 ) 4 NH (C H 2 ) 3 NH 2

C H2 C H2

H 2 NC ONH 2

5.1 .1.7
4.1. 1.20
1.5.1.7 - 10

+
H 2 N(C H 2 ) 4 C H(NH 3 )C OO

+
+
(C H 3 ) 3 N(C H 2 ) 3 C H 2 C H(NH 3 )C OO

1.14.11.8

+
OOC C H 2 C H 2 C H 2 C H (NH 3 ) C OO

OOC C H 2 C H 2 C H 2 C OC OO

G lutaryl-C oA

2.6.1.13

2.1.4.1

+ NH

Y

G lyc ine

P antoate
ß-A lanine
3.5.1.22

C H 3C H 2

C H3
C H 3 C H=C HC OS C oA

N

OOC C H 2 C H 2 C H 2 C OS C oA

2.1.3.3

G uanidoac etate
E R G O N IC R E A C T IO N

2.5.1.6

(S A M)

G lutathione

C H 3 C HC O-S C oA

C HC OC OO
C H 3C H 2

(C H 3 ) 2 C HC H 2 C OC OO

C H3
OOC C H 2 C = C HC OS C oA

3-Methylglutac onyl-C oA

6.3.5.5

Pi

ATP
E ND

1.2.1.32

S -A denos yl
methionine

C H 2S H
+
OOC C H(NH 3 )C H 2 C H 2 C ONHC HC ONHC H 2 C OO

1.2.1.25

C H3

C H3

15

OR NIT HINE

H+ H+
H+ H+

D P R OTONS

4.2.1.24

N
H

H2N

C H 2 = C C OS C oA

ME T HIONINE
+
C H 3 S C H C H C H(NH )C OO
2
2
3
+

2.1.1.10
2.1.1.20

4.1.2.12

3-Hydroxy- 4.2.1.17 Methyl 1.3.99.3 Is obutyryl-C oA
Is obutyryl-C oA
ac rylyl-C oA

N 6 -T rimethyl3-OH-lys ine

G lutamine

H 2 NC OO P

β

F0
H+

4.3.1.3

C H3
+
C HC H(NH 3 )C OO
C H3

2.6.1.32

HOC H 2 C HC OS -C oA-

+
+
(C H 3 ) 3 N(C H 2 ) 3 C H 2 C H(NH 3 )C OO

+
H 2 NOC C H 2 C H 2 C H (NH 3 ) C OO

ATP
C O2

H+
H+

C HC OO

2SO 4
2.7.7.4

Adenos yl

6.3 .2.3

HC HO

C arnitine

3.5.1.2
6.3.1.2

1.4.1.14

NH 4+

7.1
1.7. 6.4
1.6. .1
.6
18
6.3.4.16
1.

+
H 2 NC H 2 C H 2 C H 2 C H (NH 3 ) C OO

ε

N
C
H

4.2.1.19

+
C H 3 S C H C H C H(NH )C OO
2
2
3

γ-G lutamylc ys teine

C H3

C H 3 C H(OH)C HC OS C oA

(G A B A )

4.

G L UT A MA T E

T IO N

F1

+
H+

a

A

- OOC

4.3.1.8
4.2.1.75

3

α

γ

CH

2.1.1.13
2.1.1.14

B ile A c ids

C H3

C IT R UL L INE

γ

δ

CH2
H2NCH2C=O

C H2

N
H

H

H 2C

OOC

C H2

H2
C

NA

CH

C

C H 2 C OC H 2 OP

Uroc anate

Adenos yl

2-3-Dihydroxy 4.2.1.9 2-Oxo- 1.4.1.8 V A L INE
is ovalerate
is ovalerate

OOC C H 2 C H 2 C H 2 NH 2

ATP

P +1 P i

H+
H+
H+
β
H+
H+

COOCH2

C OO -

C H2

N

C H3
C H2
C H2

C OO -

C H2

H 2C

N

C H2

C OO -

C H2

Pi

NH

NH
CH

4.2.1.49

(A P S )

C HC OC OO

+
(C H 3 ) 3 NC H 2 C H(OH)C H 2 C OO

4.1.1.70

C

N

C H2
C H2

C H3 C H

H2
C

N
H

C OOC H3

ADP +

IV

1/ O
2 2

5.4.99.7
S qualene
1.14.99.7
(C 30)

C OO -

C H2

H 3C

N
Fe

HC
H3C

CH

L anos terol

TR A N S L O

C H3

H

β

2

β

1.9.3.1
HO

H

Zymos terol

C OO -

C

N

Imidazole
ac etol-P

C

CH
N

C H3

4-A minobutyrate

+
OOC C H 2 C H 2 C H (NH 3 ) C OO

C arbamoyl-P

AT P
AD

C H2
CH

2H +

2eHO

Des mos terol

C HL OR OP HY L L

HC
C
H

C H 2S H
+
OOC C H(NH 3 )C H 2 C H 2 C ONHC HC OO

T aurine

C (OH)C H(OH)C OO

2.6.1.19
1.3.99.7

NO2 -

F1
F6

H

H
HO

C HOL E S T E R OL

H
C

OH OH HN

Imidazole
glyc erol-P

2.6.1.9

S -A denos yl
homoc ys teine

C H3

G lutamyl-P

δ

2H+ C uB Heme a 3
H
HO

HE MOG L OB IN

H
P OC H 2 C

RP

+
S C H 2 C H 2 C H(NH 3 )C OO

HO 3 S C H 2 C H 2 NH 2

C H3

C (OH)C H(OH)C OO
C H 3C H 2

+
OHC C H 2 C H (NH 3 )C OO

2-OXO A C ID
2.6.1.-

MI

1.6.6.1
1.7.99.4

2H+

Heme a

S T E R OIDS
P roges terone
P regnenolone

1. 11

+
H 2 NOC C H 2 C H (NH 3 C OO

NO 3 -

nth

RPPP

N-S uc c inyl- 2.6.1.17N-S uc c inyl-2, 63.5.1.18 DiaminoA s partyl 4.2.1.52 2, 3-Dihydro-1.3.1.26 P iperideineS emialdehyde
dipic olinate 2, 6-dic arboxylate 2-amino-6-oxodiaminopimelate
pimelate
S uc c inic
pimelate
s emialdehyde
OH

1.4.1.2

2.5.1.21

(V itamin E )

1. 2.

UQ

4

CH

A denylyls ulphate

Homoc ys teine

C OOH

4.2.1 .18

R -C O-C OO

3

N

+
HS C H 2 C H 2 C H(NH 3 )C OO

4.4.1.8

2-Is opropyl3-Is opropyl- 1.1.1.85 Oxoleuc ine
4.2.1.33
malate
malate

2-A MINO A C ID

os cp

N

C DP

C H 2.7.4.6
CH

N

C Y T IDINE triphos phate

P
Y
R
I
M
I
D
I
N
E
S

(C T P )

C H 2 C H(NH 3 )C H 2 OP

C HC H 2 C H 2 C OO

2.7.1.25

6.3 .2.2

1. 29

1.8.1.3

CH3

(C H 3 ) 2 C HC (OH)C H 2 C OO

A s paragine

ting A
s por . 6 . 1 . 3 T P s y

C

N
OC

6.3.4.2

OOC C H 2 C H 2 C HO

C yt.c

F arnes yl-P P

C H3
O
C H3

α-T oc opherol

P hylloquinone

3.1.2.4

C OOH

+
R -C H(NH 3 ) C OO

n
tra

d-C DP

2.7.7.3

6.4.1.3

A s partyl-P

1.2.1.16

Glycine

_
UQ.

+-

C ONH 2
NH C
C
HC
N

2-Methylac eto-1.1.1.35 2-Methyl-3-4.2.1.17T iglyl-C oA
2 Methylbutyryl1.3.99.3
ac etyl-C oA
hydroxyC oA
butyryl-C oA

5-A minolevulinate

C uA C uA

HO
CH3

C H 2 OH

5.2.1.7

(V itamin A )

OPP
C H2

C H 2 OH

NH
CH

NH
CH

G lutamate

C H3

4.2.1.18

-OOCCH2CH2COO-

e

C H 2 OH

trans -R etinol

5.4.99.2

as

2.3.1.76
3.1.1.21

5.1.99.1

(C 20)

C H3

O

-OOCCH2CH2CO.SCoA

S UC C INY L -C oA

2H+

1.10.2.2

2.5.1.10

(C oenzyme Q)

1.1.1.105

C

N

Imidazolone
propionate

4.2.1.22

C ys tathionine

C H3

1.1.1.86

C OO

6.3.5.4

S UC C INA T E

1e-

C H2

HC

+
OOC C H 2C H 2 C OO C H 2 C H 2 C H(NH 3 )C OO

+
P OOC C H 2 C H (NH 3 )C OO

4.3.1.1

1eC yt.bH

C yt.c 1
2UQ

(C 10)

G eranyl-geranyl-P P
n

Ubiquinone

O

L ight

1.1. 1.31

1.1.1.3

1.2.4.2
2.3.1.61

A

G eranyl-P P

O
C H 3O

C HO

1.1.1.105

G L UT A R A T E

UQH 2
III

2eC yt.bL

N

3.5.2.7

P hos phoadenylyls ulphate

RP

2.7.4.14

NH 2

O
C
CH
CH
N
R PPP

His tidinol-P

3.1.3.15
OC

C HC H 2 C H 2 C OO
NH
CH

+
HOC H 2 C H 2 C H(NH 3 )C OO

1.1.1.3

3-Hydroxyis obutyrate

.3. 18

A S P A R T A T E 2.7.2.4

2.3.1.37

F e-S

CO

NH
CH

N

His tidinol

1.1.1.23

Hypotaurine

C H3
HOC H 2 C HC OO

Methylmalonyl-C oA

4.1.1.71

6.2.1.4

2UQH 2

2e- 2UQ _.

C H 3 C = C HC H 2 C H 2 C = C HC H 2 O P P
C H 2O P P

trans -R etinal 5.2.1.3 11-c is -R etinal C HO Menaquinone

2CH2COO

2H+

1.10.2.2

4H+

2.5.1.1
C H3

CH3

2.5.1.29

H
C

OH OH

C H 2 C H(NH 3 )C H 2 OH

CH
N

1.17.4.1

P ropanoyl-C oA

NS

R hodops in

Ops in

(C 5)

(C 5)

2.5.1.32

C

HC

O-P hos pho- 2.7.1.39Homos erine 2.3.1.46
homos erine

C H3

TR A

Metarhodops in
1.13.11.21
C OO-

R etinoate
1.2.1.36

R etinol es ters

C H 3 C -C H 2 C H 2 O P P

Is opentenyl-P P

C H3

Dimethylallyl-P P

(C 40)

hv

F AD

II

H
P OC H 2 C

RP

4. 1.

C H 3 C OC (OH)C H 3

OOC -C H-C OS C oA

UQH 2

NH 2
N
OC
C
NH
CH
C
HC
N
N

4.2.1.9
2-A c eto-22-Oxo-3-methyl
2: 3-Di-OHhydroxy- 1.1.1.86 3-methylvalerate
valerate
butyrate

C H3

C H2

C H 3 C = C HC H 2 O P P

P hytoene
T o B rain -V IS ION

F e-S
C yt.b

UQ

C erebros ide

3.2.1.46 2.4.1.47
1.3.99.7

(C 40)

(C 40)

C

C ys teate

C H 3 C OC HC OS C oA

2-OXO-

+

1.3.5.1

4.1.1.33

C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O- G alac tos e

H

+
C H 2 C H(NH 3 )C HO

+
C H 2 C H(NH 3 )C OO
+
S C H 2 C H 2 C H(NH 3 )C OO

4.2.99.9

C OO

C H 3 C H 2 C OS C oA

1.1.1.41

2H+ -OOCCH=CHCOOF UMA R A T E

d-C MP

C ytos ine

HN
OC

2.4.2.9

3.3.1.1

2-A c etolac tate

IS OC IT R A T E

-OOCCOCH

F ADH 2

CH

C
C

NH 2
C
CH
N
CH
OC
N
DP

NH 2
C
CH
CH
NH

N

P -R ibulos ylformimino
P -R ibos ylformimino
5-aminoimidazole- 5.3.1.16 5-aminoimidazolec arboxamide-R P+
c arboxamide-R P
+

1.8.99.2

C H 3 C H 2 C OC OO

2.1.3.1
4.1.1.41
5.1.99.1

or

C H 2 C OO

A c yl-C oA

H
C

OH OH
O

+
HO 3 S C H 2 C H(NH 3 )C OO

+
P OC H 2 C H 2 C H(NH 3 )C OO

4.2.99.2

8

2.3. 1.16

2.6.1.1

4.2.1.3

4.1.3.1

MA L A T E
4H+
2H+ 4.2.1.2

UQH 2

NHC OR

NHC OR

H

HO 2 S C H 2 C H 2 NH 2

4.1.3.7
CH2COOC(OH)COOCH2COO-

CH(OH)COOCHCOOC
CH2COO-

CH3CH(OH)CH2CO.SCoA

1.6. 5.3

Diphos phoC H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O- G alac tos e mevalonate
P s yc hos ine

S phinganin
4-S phingenin
2.4.1.23
UDP -S ugars A c yl-C oA
3.5.1.23
UDP -G alac tos e

-

L yc opene

2F e -S
(5 C lusters)

4H+

C H 3 C (OH)C H 2 C H 2 O P P

1.1.1.102

S P HING OMY E L IN

1.1.1.37

+
NH 3

2.4.1. 62

ß-C A R OT E NE

52

4.1

4.1.3.8

Glyoxylate
Cycle

F MNH2

d-UMP
4

3.5.4.1
O
C
HN

OC N C H
RP

NH

4.4.1.1

C Y S T E INE

C ys teine
s ulphinate

C IT R A T E

2.7.1.36
2.7.4.2

+
HOC H 2 C H 2 N(C H 3 ) 3

+
OC H 2 C H 2 N(C H 3 ) 3

C holine-P

3.1.4 .12
+
NH 3

C H 3 (C H 2 ) 14 C H(OH)C HC H 2 OH

C H 3 (C H 2 ) 14 C OC HC H 2 OH

Dehydros phinganin

2.7.7.15

C DP -c holine

2.7.8.2

NHAcyl O
+
C H 3 (C H 2 ) 12 C H=C HC H(OH)C HC H 2 O P O C H 2 C H 2 N(C H 3 ) 3
O

C H C OO

2
A c etylc holine C H C (OH)C
H 2 C H 2 OH
3
.4. 2
Mevalonate

3.1.4.3
+
C P P -O C H 2 C H 2 N(C H 3 ) 3

+
NH 3

G anglios ides

1.

C H3
OHC C HC OO

-OOCCHO

3.1

1.8.99.1

Oxobutyrate

4.1.3.2

2H

1.1.1.32

C H 3 C OC H 2 C H 2 N(C H 3 ) 3

+
C H 2 OP O C H 2 C H 2 N(C H 3 )

OG lyc erophos phoc holine

3.1.1.5

NAD+

N H

CH
C -C OO
RP

N

HN
H 2N C
N

CH
CH
N DP
3.5.4.12

HN
OC

2.1.1.45

OC

1.13.11.20

4.2.1.16

4.1.1.32

OX A L OA C E T A T E

+

E thanolamine

HOC H O

+
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3
O
C H 2 O-C O-R
3.1.1.32
O
R '-C O-OC H
+
C H 2 OP O C H 2 C H 2 N(C H 3 ) 3
O

Mevaldate

+
HOC H 2 C H 2 NH 3

C H 2 OH
C H 2 O-C O-R
HOC H O

2.1.1.17
2.1.1.71

C H 2 C OO
C H 3 C (OH)C H 2 C HO

HS O -

C H 3 C OC (OH)C H 2 C H 3

I

2.4 .2.

CH
CH

O
C

P
U
R
I
N
E
S

(G MP )

S uc c inylhomos erine

1.2.1.18

-OOCCOCH
2COO-

NA DH+H+

F MN

N

CH

4.1.1.29

4.1 .3.1

Methylmalonyl
s emialdehyde

I

1.4.3.8

2.7.1. 82

E thanolamine-P

N

+
.8 HS C H 2 C H(NH
3 )C OO

1.6.4.1

T HR E ONINE
Malonic
s emialdehyde

A C E T Y L -C oA

4.2.1 .18

1.1.1.34

Oxalate
G lyc ol
aldehyde

C -C H 3
CH
DP

CH
N RP

H

(P A P S )

99

+
C H 3 C H(OH)C H(NH 3 )C OO

OHC C H 2 C OO-

2.6.1.4 4

4.1.3.4

C H 3 C (OH)C H 2 C OS C oA

ß-OH-ß-Methylglutaryl-C oA

HOOC -C OOH

HOC H 2 C HO

C H 2 O-P O C H 2 C HOHC H 2 OH

+
C P P - OC H 2 C H 2 NH 3

O

1.2.3.5
HOC H 2 C OO

G lyc olate
1.2.1.21
2.7.8.5

O

O
C

F ormimino
glutamate

1.1.1.39

C H 2 C OO

1.1.1.79

O

C DP -diac yl
glyc erol

C H 2 O-C O-R

C H 2 O-C O-R ’

O
C

OC

C

HN

4.1.2.5

2.6.1.18

2.

GTP

NAD+

4.1.3.5

G lyoxylate

2.7.7.41

O

C H 2 O P OC MP

Inos itol

2.7.8.11

O HC O-C O-R

C H 2 O-P O C H 2 C H(OH)C H 2 O-P -OC H 2
O
O

+
C H 2 O P OC H 2 C H 2 NH 3

2.3.1.50

S erine

2.7.8.8

P HOS P HA T IDY L
S E R INE
C H 2 O-C O-R
R '-C O-OC H
O

O

C H 2 OC H=C HR

R '-C O-OC H

C OO
O
+
C H 2 O P O C H 2 C HNH 3

1.3.99.7
HO OH

4.1.1.65

OHC C OO

1.6.5.3

R '-C O-OC H

HOH
GDP
C O2

H

OH

C H 2 O-P O

-

C H 2 O-C O-R

N

Urac il

HN

His tidinal

4.1.1.12

LACTATE

NADH+H+

C H 3 C H 2 C OC H 2 C OS C oA

1.1.1.35

3-OH-P entanoyl-C oA

P entenoyl-C oA
C H 2 O-C O-R

C H 2 O-C O-R

8

.1. 27

4.

6.4.1.1

2.6.1.4

R '-C O-OC H O

A L A NINE
4.1 .3.1

C H 3 C H(OH)C OO

1.2.4.1
2.3.1.12
3.1.3.43

(XMP )
6.3.4.1
6.3.5.2

2.1

O
C

T HY MIDINE -P

1.3.1.2

H

C

HC

1.1.1.23

3-S ulphinyl
pyruvate

CH3COSCoA

P entanoyl-C oA

NH

HS

4. 2.

C Y S T INE

+
C H 3 C H(NH 3 )C OO

2.6.1.2

1.1

2.3.1.9

A c etoac etyl-C oA

Odd C F atty ac ids

C H 2 O-C O-R

1.4.1.1

CH3COCOO-

NA D
ATP
C O2

2.3. 1.16

3-Oxoac yl-C oA
C H 3 (C H 2 ) 2 C OC H 2 C OS C oA

C

.4. 9 HN

2.4.2.4

HN
OC

C

3.5.4.19

+
C H 2 C H(NH 3 )C OO

C

N

OOC

HS O 3-

4.1.1.9

2.3.1.38

2.7

N
C
C

N

G UA NOS INE -P

O

T DP

OC

2.7.4.8

G DP

RP

XA NT HOS INE -P

G uanine 2.4.

.1

1.17 .4.1

6

CH
C -C OO
NH

7.4

RP

CH
N

O
C
HN

3.5. 4.3

d-G DP

C
C

N

(IMP )

1.1.1.205

2.4.2.1

4.3.1.3

4.4.1.15

A c etyl-A C P

3.1.2.11

C H 3 (C H 2 ) n C OC H 2 C OS C oA

1.1.1.35

3.1.4.6

OC

C H2
C H2
NH

P OC H 2

P -R ibos yl-A MP

HC
CH

C H 2 C H 2 NH 2

+
S -C H 2 C H(NH 3 )C OO
+
S -C H 2 C H(NH 3 )C OO

4.4.1. 15

Malonyl-C o-A

1.1.1.30

C H 3 C OC H 2 C OO

A c etoac etate

P hos phatidate

C H 3 (C H n C H(OH)C H 2 C OS C oA

4.2.1.17

6.3.4.4

s uc c inate

CH
N

N

INOS INE -P

A s partate

4.3.2.2 A denylo-

N

C

O
C

HC

2.7.4.6

O
C

HN
OC

C H-C OO

HIS T A MINE

HO 2 S C H 2 C OC OO

HOOC C H 2 C O-S C oA

.7.

O
C

C H2

NH

O
C C
NH

3.5.4.10

4. 6

1.3.1.2 T hymine

OC

+
HO 2 S C H 2 C H(NH 3 )C OO

ATP

1. 2

H2N
HC O

C
A
T
E
C
H
O
L
A
M
I
N
E
S

F ormylamidoimidazolec arboxamide-R P

3.1. 3.5

2.4.2.1

1.1

d-C T P
GTP
T T P 2. 7.
2.7

C C H3
CH
NH

HN
OC

2.4.2.15

d-G T P

.7. 7

.7. 6
O
C

C H-C H 3
CH2
NH

HIS T IDINE

1. 1

P Y R UV A T E
C H 3 (C H 2 ) n C H=C HC OS C oA

1.3.99.3

OH

P
O
R
P
H
Y
R
I
N
S

C H 3 C H(OH)C H 2 C OO

4.1.1.4

C H 2O P

2.3.1.20 glyc erol 3.1.3.4 2.7.1.107

4. 1.

P

A C Y L -C oA

O

S
T
E
R
O
I
D
S

2.7.8.5

R ’-C O-OC H

C H 2 OH

Diac yl

FAT

3.1.1.28

3. 7.

Inos ine

3.2.2 .2

CH
NH

F umarate

2.7.7.7

2.7

NH 2
N
+ C
C
N
CH
C
HC
N
N
R P (P P )

3.6.1.31

A c etyls erine

2.7.1.40

C H 3 (C H 2 ) n C H 2 C H 2 C OS C oA

P hos phatidyl
inos itol

I
S
O
P
R
E
N
O
I
D
S

C H 2 O-C O-R

C H 2 O-C O-R
R ’-C O-OC H

R ’-C O-OC H

T riac ylglyc erol

O-A c yl-c arnitine

C H 3 C OC H 3

A c etone 3-OH-B utyrate

C H 2 O-C O-R

3.1.1.3

C arnitine
O-A c yl-c arnitine

L
I
P
I
D

C

+
C H 2 C O-OC H 2 C H(NH 3 )C OO

HS
A DP

K E TONE B ODIE S

2.3.1.51

H

C

4.1.1.22

C
H

.1. 30

C H 3 C HO

P -enolpyruvate

2.3.1.39

3-P -G lyc erol

RP

HN

2.7.7 .7
2.7.7.6

NH

N

2.3

2.1.3.2

A c etaldehyde

HOOC C H 2 C O-S -AC P

Malonyl-A C P

2.3.1.41

C H 2O P

2.7.1.30

G lyc erol

H

C

NHC OC H 2 C H 2 NH 2

C arnos ine

C

HC

1.2.1.4

C H 2 =C (O P ) C OO

C H 3 C OC H 2 C OS AC P

A c etoac etyl-A C P

1.1.1.8

HOC H

N

2.1.2.3
N
C
C

NH
N
C
C
N
CH
C
HC
NH R P
N

C H 3 C H 2 OH

1.1.1.1

3-Oxo-Hexanoyl-A C P

1.1.1.100

C H 2 OH

C H 2 OH

NH
H

ACE TATE

E T HA NOL

2.3.1.41

C H 3 C H(OH)C H 2 C OS -AC P

3-OH-B utanoyl-A C P
HOC H
C H 2 OH

(C ytos ol)

P
H
O
S
P
H
O
L
I
P
I
D
S

1.1.1.100

3-OH-Hexanoyl-A C P

4.2.1.58

R -C H 2 C OO

H

C

OH OH
O

HOC H2C H(O P ) C OO

C H 3 (C H 2 ) 2 C OC H 2 C OS AC P

CH

C

UR IDINE Dihydro
Orotate
Orotidine-P
Uridine-P
UDP
4.1.1.23 (UMP ) 2.7.4.4
2.4.2.10
2.7.4.6 triphos phate
orotate 1.3.1.14

C C H 2 C HC OO
C

2-P -G lyc erate

2.3.1.41

4.2.1.59

C H 3 C H=C HC O-S -AC P

H

P -R ibos yl-A T P
N

3-Oxoac yl-A C P

C H 3 C H=C HC O.S -AC P
C H 3 C H 2 C H 2 C OS AC P

P OC H 2

2.4.2.17

2.3.1.41

C H 3 (C H 2 ) 2 C H(OH)C H 2 C OS AC P

P lant P igments

N
C

H 2N

RP

A denine

O
C

O
C

HN
OC

3.5.2.3

2.6.1.22

2.6.1.52
P OC H 2 C OC OO

3-Oxo-Dec anoyl-A C P

0

O
C

OOC -C H-C H 2 C OO

C arbamoyl 3.5.2.2 Dihydroß-alanine
urac il

H

C arbamoyl
as partate

N

(A MP )

H 2 NC ONHC H 2 C H 2 C OO

3.5.1.6

-OOC
NH 2 C H 2
OC
C H-C OO
N

G lyc erate

4.2.1.11

2, 3-Dec enoyl-A C P
C H 3 (C H 2 ) 2 C H 2 C H 2 C OS AC P

HC

A DE NOS INE -P

HN

C H 3C OO

Mitoc hondrial

2.7.4.3
2.7.4.4

1. 13

ß-A lanine

C H 3 (C H 2 ) 6 C OC H 2 C OS AC P

1.1.1.100

3-OH-Dec anoyl-A C P

C H 3 (C H 2 ) 6 C H=C HC OS AC P

T annins

H 2N

(UT P )

C H 3 (C H 2 ) n C OC H 2 C OS AC P

1.1.1.100

3-OH-A c yl-A C P

4.2.1 .60 C H (C H ) C H(OH)C H C OS AC P
3
2 6
2

3, 4-Dec enoyl-A C P

1.3 .1.9

C H 3 (C H 2 ) n C H(OH)C H 2 C OS AC P

4.2.1.60
4.2.1.61

3-E noyl-A C P

C H 3 (C H 2 ) 5 C H=C HC H 2 C OS AC P

Dec anoyl-A C P

2. 1.

H 2 NC H 2 C H 2 C OO

HOC H2C H(OH) C OO

E ndoplas mic R etic ulum
C H 3 (C H 2 ) 14 C OS -AC P

P almitoyl-A C P

C H 3 (C H 2 ) 6 C H 2 C H 2 C OS AC P

4.1.1.11

3.1.3.3

HC

P OC H2 C H(O P ) C OO

2, 3-Diphos pho- 5.4.2.1
glyc erate

HN

CH
NH

NH 2 N
C
C
CH
C
HC
N R P (P )
N

ß-Ureido 3.5.2.2 Dihydro
is obutyrate
thymine

3.5.1.6

O
C

N
C
C

NH

N

A DP

HN
OC

C H3

4.2.1.22

P -Hydroxypyruvate

2.7.1.31

OH

T hromboxane B 2

C H 3 (C H 2 ) 14 C H(OH)C H 2 C OS -C oA

O
C

HN

2.7

H 2 NC ONHC H 2 C HC OO

3-A minois obutyrate

+

P hos phos erine

1.1.1.95

3-P -G lyc erate

C OO
O

HO

5.3.99.5

P ros taglandin P G E2

C H 3 (C H 2 ) 14 C H=C HC OS -C oA

L IG NIN

CH

N

RP

OC

DNA

7

4.2.1 .20

+
P OC H 2 C H(NH 3 )C OO

C H 3 (C H 2 ) 14 C OC H 2 C OS -C oA

B
I
O
S
Y
N
T
H
E
S
I
S

D
E
G
R
A
D
A
T
I
O
N

P OC H2C HOH C OO

OH

C OO

OH

HO

P almitoleoyl-A C P
C OS C oA

C

H 2N

1.1.1.29

ATP

C OO

L eukotriene B 4

O

5.
1. 14 3. 99
.9 9. .3
1

1.3.1.35

Oleoyl-C oA
1.14.99.5

OH

I
OH

T HY R OXINE
OOC -C H-C H 2 C OO
HNC O C N

1.17.4.1

2.7 .7.

S E R INE

2.6.1.51
1.4.1.7

CH
N

2.7.4.6

ATP

4.6.1.1

C H3
H 2 NC H 2 C HC OO

Hydroxypyruvate

C OO

γ-L inolenate

1.14.99.25

L inoleate

L
I
P
I
D

C oumarate

1.1.1.204
1.1.3.22
Hypoxanthine
1.1.3.22 Xanthine

A T P 2.7.7.6 R NA

4.1.2.5

HOC H 2 C OC OO

A DP
2.7.2.3

CO
NH

d-A T P

HOC H 2 C H(NH 3 )C OO

OH OH

A DP

C H=C HC OO

N

N

2.7.4.6

F OL IC
A C ID
C1
P OOL

2.1.2.1

C HOL INE

P -R ibos yl-P P

HC

C
C

N
H

UR A T E

OH OH

+
HOC H 2 C H 2 N (C H 3) 3

1: 3-bis -P -G lyc erate

OP OP

C innamate
Menaquinone
1.14.13.11

I

NH

ME L A NIN

N

A
C
I
D
S

P henylpyruvate

C H=C HC OO

OH

T yramine

O

d-A DP

+

P OC H 2C HOHC OO P

2.7.6.1

HO

NH 2

-O P ~O P ~O P O C H
2 O
O
O
O

OH

1.1.99.1

C H 2O P
O

Fixation

ATP
HO

C H 2 C H 2 NH 2

.1. 25

O

CH

NH

C

HN
OC

1.7.3.3

O

2.1.1.5

1.2.1.8

B etaine
aldehyde

1.2.1.12

3.6.1.34

I

N

H2N

O

NH
CO
NH

O

+

CHLOROPLAST OUTER MEMBRANE

2.6.1.5
4.3. 1.5

P HE NY L A L A NINE
4.1

I

RP

A
M
I
N
O

4.2.1.51

O
O

1.14.18.1

N

N

N
C H2 O

O

C
N H
H

O

CH

C yc lic A MP

OHC C H 2 N(C H 3 ) 3

NA DH

β2

ATP

P

OC

OC

N

HC

O

B etaine

Pi

N

A llantoin

1.4.4.2

1.2.1.13

ATP synthase
e

3.5.2.5

Dimethylglyc ine

2

c

H+

O

H2N

NH

OOC C H 2 N(C H 3 ) 3

Ribulose-1,5-bis-P

ATP

H+

STROMA

NH 2

N

1.5.99.2

2.4.2.14

1
5.3 .1.
2.7.1.28

1.14.16.1

1.3.1.13

C
C

C H 2 C OC OO

OH

P rephenate
C H 2 C OC OO

Ubiquinone
+

CH

5.4.99.5

+

C H 2 C H(NH 3 ) C OO

C H 2 C H (NH 3 ) C OO

OOC

N

HC
C

RP

NH 2
CO

C OO
C
N H
H

OC

O

1.
2.
OOC C H 2 NHC H 3

6.3.4.7
Pi
NA D+

Glyceraldehyde

εε

H+

γ

H+

THYLAKOID LUMEN

THYLAKOID MEMBRANE

H 2N

A llantoate

S arc os ine

G lyoxylate

4.1.2.13

β

H+

H+

NH

H 2N

OOC C H 2 N(C H 3 ) 2

1

OH

T Y R OS INE

O

C HO

RP

1. 4
2. 6. 10
1.
20
1. 4.
1.

3-P -G lyc eraldehyde
5.3 .1.

ADP
Pi

A DP
1

O2

Pi

α

a

H+

H+ H+
H+
H+ H+
H+ H+ H+ H+
H+
H+ H+
Protons from Water
H+
H+ H+
H+
H+ H+ H+ H+ H+
H+

Translocated protons
H+

H+
H+

H+
PC PC

4H +

H2O

NH

G LY C INE

C H 2O P
O

P -R ibos yl
amine
C O C H 2O P

C

2.2.1.1

(G lyc erone-P )

α
α
1

Fe-S 2e- Cyt.f

Mn

NADPH+H+

O

Dopaquinone
P las toquinone

NH

Urea

S edoheptulos e-P P

HOC H 2 C OC H 2 OP

Dihydroxyac etone-P

3
3

2e-

2e-

Chl.A0
2PQ

2
2

._

2PQ

8

2PQH2

8

Pheophytin
P680
Chl.a

H+
H+

(V itamin E )

OC H 3

H 2C
C

H 2 NC ONH 2

P OC H 2C HOHC HO

H+

A1

OOC

4.1.3.27

C horis mate

2-A mino
muc onate

A
R
O
M
A
T
I
C

1.3.1.13

1.14.16.2

H2
C
C H-C OO
+
NH 3

O

A nthranilate

C H2

+

NH 2

OOC
OOC

OC -C OO

OH

S hikimate-5 4.6.1.4
enolpyruvate 3-P

HN

OH

HN

+

2.2.1.1

NADP+

Fe-S

2e-

α-T oc opherol

4-OH-3-Methoxyphenylglyc ol

OH

OH OH OH H

D-R ibos e-5-P

H+

PQ

1e-

Cyt bf

OH
OH

1.2.1.32

1.14.12.1

NH 2

C OO

O-C -C OO

OH

2.5.1.19

C H 2 C H (NH 3 ) C OO

Dopa

1.14.18.1

C H 2 (NH 3 )C OOH

OH OH
H

2.4.2.18

N-(5-P -R ibos yl)
anthranilate

C H 2 C H (NH 3 ) C OO-

4.1.1.28

Dopamine

C HOHC H 2 OH

C HO

6.3.4.13

C O C H 2O P

F ruc tos e1: 6-bis -P

2.2.1.2

D-Xylulos e-5-P

P OC H 2 C

flo

ren
t)

H+

*
2e-

1e-

PQH2

QA

HO
C

OH OH H
C O C H 2 OH

OH H

1. 15

H
C

2.7.1.17

Ferredoxin

2e-

H
C

H
C

P O

2.6.1.5

Hydroxyphenyl
pyruvate

OH

1.14.17.1

1. 6

3.5.3.4

PQ
PQH2

QB

OH

OC H
NH 2
C OO

C OO

6.3.3.1
6.3.5.3
G lyc inamide- 2.1.2.2 F ormyl
F ormyl
5-A mino 4.1.1.21 5-A mino-4-imidazole 6.3.2.6 5-A mino-4-imidazole 4.3.2.2 5-A minoimidazole
c arboxylate-R P
(N-s uc c inylc arboxamide)-R P c arboxamide-R P
ribos yl-P
glyc inamide-R P glyc inamidine-R P imidazole-R P

A DP
P OC H 2

4.1.1.48

1.3.1.13

C H 2 C H 2 NH 2

NH
OC

OH OH

OH

1.13.11.27

OH

(Normetadrenaline)

3. 4

NHC OC H 2 NH 2

2.7.1.11

3.1.3.11

C HO

2. 1.

E rythros e-4-P

5.1.3.1

w

._

H
C

OH

OC H 3

H 2C

ATP
H
P OC H 2 C

1. 4.

C H 2O P
O

C O C H 2 OH

C O C H 2 OH

C HO

OH OH OH

OH H

HO
C

F ruc tos e-6-P

OH OH

D-R ibulos e-5-P
H
HOC H 2 C
C H 2 OH

H
C

C OO

NH 2

C H C H 2O P

O

C OO

OH

OH

S hikimate-3-P
PEP

(Noradrenaline)

4-OH-3-MethoxyD-mandelate

H
P OC H 2 C

OH OH H

NA DP H

5.1.3.1
C H 2 OH

OH

OC H 3
OH

OH

5.3.1.9

5.3.1.8

P O

2.7.1.71

S hikimate

OH

Norepinephrine

Normetepinephrine

OH

HO OH

NADP +

2.2.1.1

C

OH OH

C OO

OH
OH

1.1.1.25

C H 2 C OC OO

OH

2.1.1.28

C HOHC H 2 NH 2

C H(OH)C OO

G luc os e-6-P

P -G luc ono
lac tone

.1. 17

C OO

C

+

C H 2 OP
O

NADP +

1.1.1.44

H+

PQ

3.1

C C OO -

C H 2O P

HO

OH

Dehydros hikimate

C HOHC H 2 NH 2

OH
OH

A DP

1.1.1.49

OC H

NH

1-(o-C arboxy phenylamino)
1-deoxyribulos e-5-P

C H 2 C OO

C HOHC H 2 NHC H 3

(A drenaline)

C OO

N

Quinolinate

C OO

C OO
NH 2

H

C H2

E pinephrine

2.7.1.2
2.7.1.1

O
OH

2.4.2.19

OH

HOC -C H(OH)C H(OH)C H 2 OP
CH

C OO

OH

O

4.2.1.10

O
C H 2 C OO

F umaryl 5.2.1.2 Maleyl 1.13.11.5 Homogentis ate
ac etoac etate
ac etoac etate

ATP

3.1.3.9

HO OH

1. 4

OH OH H OH
6-P -G luc onate NA DP H
CO

OH OH OH

C HO

CO

D-Xylulos e

H+

OH

2.7.1.3

H

OH

G L UC OS E
5.4.2.2

2.6.1.16

+
C O C H 2 C H(NH 3 )C OO
NH 2

N

OH

C OO

Quinolinatenuc leotide

C H 2 C H 2 NHC OC H 3
NH

(ME L A TONIN)

OH

H

C OO

OH

Dehydroquinate

O

O
C H 2 C OO

+
C OO
N RP

N

2.4.2.19

C H 3O

(S E R OTONIN)

Indole-3-glyc erol-P

C OO

OH
O

4.6.1.3

O

HO OH

3.2.1.48

C H 2O P
O

C H 2 OH

CO

HOC H 2 C

OH

C

PHOTO- H+
c
otophosphoryla SYSTEM
n-cycli electr
2H+ yclic Ph
tion l
No (electric cur on
C

H+

CO

P OC H 2

OH OH
P OC H 2

C

HO

OH

H

C OO

C OO

1

Nic otinatenuc leotide

NH

NH

C -C H(OH)C H(OH)C H 2 O P
CH

N

4.2.1.20

T R Y P TOP HA N

HOC H HC OH
C

3-Deoxy-D-arabinoheptulos onate-7-P

OH

OH OH H

D-Xylos e

C O C H 2 OH

H+

2e-

G luc os amine-6-P
3.2.1.26

S UC R OS E

C

S orbitol

O

L -R ibulos e 2.7.1.16 L -R ibulos e-5-P

L -L yxos e

PHOTOSYSTEM
II

OH

C H 2 OH
O
-OOC

5.5.1.4
OH H

F ruc tos e-1-P

OH H

2.7.1.47

OH OH
HOC H 2

CO

2.7.1.47

OP P U

OH

4.1.1.28

2.4 .2.1

R ibos e- P

2.7.7.18

C H 2 C H 2 NHC OC H 3

5-Hydroxytryptamine 2.3.1.5 N-A c etyl-s erotonin 2.1.1.4 N-A c etyl-5-O-methyl-s erotonin

+
C O C H 2 C H(NH 3 )C OO

+
C H 2 C H(NH 3 )C OO

C OO
OC
P OC H 2 C H 2

HO

4.1.1.45
2-A minomuc onateF ormylkynurenine 3.5.1.9 K ynurenine 1.14.13.9 3-Hydroxy 3.7.1.3 3-Hydroxy 1.13.11.6 2-A mino-3-c arboxy
kynurenine
anthranilate
muc onate s emialdehyde
6-s emialdehyde
C OO
1.13.11.11
H
H
C atec hol
C OO
NH

T ryptamine

NH 2

5.3.1.8

C H 2 OH

H
C

OH OH H

C O C H 2 OH

L -Xylulos e-5-P
HOC H 2

C H 2 OH

OH

Xylitol
4

C HO

C

H

H
C

OH H
C

OH H

1.1.1.10

H
C

CO

H

Dehydroas c orbate

H
HOC H 2 C

OH OH

OH

C

HOC H 2

OH

C

C

1.10.2.1
1.10.3.3

OH H

C

H

C

H

OH H

C HO

L -Xylulos e

OH OH H
C

L -A rabinos e 5. 3. 1.
HOC H 2 C

HOC H 2

OH

OH

C

HOC H 2 C
H

C H 2 OH

L -A rabitol
HOC H 2

CO

C

H

H

C

OH H

C

C

HOC H 2 C

1.1.1.14

OH H

OH OH H

H

C

F ruc tos e

CO

C H 2 C H 2 NH 2
NH

UDP -G alac tos e

G luc os e-1-P

OH

O

Des amino-NA D

C H 2 C H 2 NH 2

NH 2

NH

4.1.99.1

2.4.1.22

OH

HO

HO OH

2.3. 1.4

OP

HO OH

C H 2O P
O

2.4.1.13

2.4.1.9

1.1.1 .21

C

A S C OR B A T E

C O C OO -

2, 3-Dioxogulonate

H

H

C

OH

O

D-A rabinos e 5.3.1.3 D-R ibulos e

4.1.1.34

L -Xylos e
OH H

HOC H 2 C

1.1.1.130

3-Dehydrogulonate
HOC H 2

OH OH
C

C

OH H

C C OO -

CO

H

Inos itol-P

OH H
C
H

O

OH

3.1.3.25

Inos itol

CO

H

O

1.1.1.45

HOC H 2

OP

OH

1.13.99.1

G luc uronate

CO

H

HO OH

HO OH

OH
OH

1.1.1.19

OH H
C
H

H

OH OH H

C OO -

C

G ulonate

OH
NHC OC H 3

OH

OH

OH OH

C

OH

HO
5.1.3.2
2.7.7.10

+
C O C H 2 C H(NH 3 )C OO
C HO

C H 2 C OC OO
NH

Indolepyruvate
OP

OH

2.7.7.12

C H 2 OH
O

2.7.7.24

Mannos e-6-P

OH

N-A c -G luc os amine-6-P

N-A c -G luc os amine-1-P
2.7.7.23

C OO

HOC H 2

HO

NHC OC H 3 5.4.2.3

UDP -N-A c -G luc os amine

HO

C H 2 OH
O

2.7.7.9

HO OH HO OH

C H 2O P
O

HO OH

OP P U

NHAC

3.1.1.18 HOC H 2

P
H
O
T
O
S
Y
N
T
H
E
S
I
S

5.4.2.8

C H 2 OH
O

4.1.3.20

2.7.1.60

5.1.3.14

2.7.7.34

T DP -G luc os e

C H 2O P
O

4.1.1.43

C H 2 OH
O

2.7.1.6

1.14.16.4

9

HO OH

2.7.7.27

Indole

.1

C H 2 OH
O

C H 2 OH
O
AC NH
HO OH
OH

N-A c -Mannos amine

1.1.1 .22

OP P U
HO

UDP -G luc os e
G alac tos e-P

4.2.1.46

2.7.1.7

Mannos e-1-P

5.1.3.7

OH

HO OH

G DP -G luc os e

MA NNOS E

2.7.7.13

NH

5-Hydroxy- 4.1.1.28
tryptophan

NH

Indoleac etaldehyde

3.2.1.23
2.7.1.38

G A L A C TOS E

C H 2OH
O
OH

A DP G luc os e

OH

HO OH HO OH

C H 2 OH
O

HO OH HO O P

O

HO

NIC OT INA T E

+
N

R ibos e - O - P - O - P - O -Adenos ine

6.3.5.1
6.3.1.5

+
C H 2 C H(NH 3)C OO

HO

C H 2 C HO
NH

OH

OP P T

OH

T DP -4-Oxo6-deoxygluc os e

C H 2 OH
O

G DP -Mannos e
OP P U
OH

O

2.4.1.33

HO OH HO OP P G

O
OH

UDP G alac turonate

C OO

UDP -N-A c G luc os amine
pyruvate
N-A c -Mannos amine-6-P

P
E
N
T
O
S
E
S

4.2.1.47
C OO HO

NHC OC H 3

O

5.1.3.13 O

C OO

O

O

N

O

O

NA D( + P )

1.2.3.7

OH

C H 2OH
O

2.4.1.11 HO
2.4.1.21

2.4.1.1
etc.

OH

C H 2 OH
O

UDP -N-A c G alac tos amine

OP P U
NHAC

C OO

C H3

2.4.1.21

+

O

O

R ibos e -O - P - O - P - O- Adenos ine(P )

NH

Indoxyl

(A uxin)
OH

OH
OH

L A C TOS E

.1

HO O
C H2 C

(S ialate)
C H 2O P
O

3.1.3.29
AC NH
4.1.3.20
HO OH
OH

H
E
X
O
S
E
S

G DP -F uc os e

OP P U

OH

1.1.1.158

3.1.3.29

N-A c -Neuraminate

OH OH

C OO

+

N

OH

NH

Indoleac etate

O
OH

2.4.1.29

T DP -R hamnos e

G DP Mannuronate

OH

2.4.1.16

C OO
OH 2.7.7.43

HO

C H 2 C OO
C H 2 OH
O

C H 2 OH
O
HO

OP P T

HO OP P G

HO

G LY C OG E N

O

HO C H 3

O
C H3

OH

UDP -N-A c -Muramate

1.1.1.132

2.4.1.68
2.4.1.69
OP P U

OH

UDP Iduronate

C OO-

HO

AcNH

HO

2.4.1.17

5

2.4.99.7
OP C

5.

C OO -

C H 2 OH

6.
3.

C HOH
C HOH

AcNH

C ONH 2

HY A L UR ONIC A C ID
DE R MA T A N B L OOD G R OUP A L G INA T E S O-A NT IG E NS
S TAR CH
S UB S T A NC E S
P E P T IDOC HONDR OIT IN
P E C T IN
INUL IN
C E L L UL OS E
G LY C A N C H OHC HIT IN

G LY C OP R OT E INS
G A NG L IOS IDE S
MUC INS

1 .4

P
O
L
Y
S
A
C
C
H
A
R
I
D
E
S

HOC H

C H2

HC

C HC OO
N

3-Hydroxypyrroline5-c arboxylate

T he "B ackbone" of metabolis m involves
G LY C OLY S IS in the C Y T OP LAS M,
the T C A C Y C LE (mainly) in the Mitochondrial matrix
and AT P F OR MAT ION s panning the
MIT OC HONDR IAL INNE R ME MB R ANE

An electron flow (an electric current) generated from
NADH and UQH2 drives the translocation of protons
from the matrix to the intermembrane space.
The retrolocation of these protons through the F0 subunits
of ATP synthase to the matrix then supplies the energy
needed to form ATP from ADP and phosphate

E lectron F low

P roton F low

1.5.1.2
S mall Numbers ( eg. 2.4.6.7) refer to the IUB MB E nzyme
C ommis s ion (E C ) R eference Numbers of E nzymes

Plate IV: A metabolic network. A wallchart showing the network formed by the major metabolic pathways. Created
by Donald Nicholson. Copyright of the International Union of Biochemistry and Molecular Biology. Reproduced with
permission.

